{"pageProps":{"config":{"footerNav":{"items":[{"_key":"f255606f8f25","_type":"navDropdownMenu","items":[{"_key":"76389ad94cbb","_type":"navItem","title":"Autonomous Transportation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"training-data-for-autonomous-driving"}}}},{"_key":"5f64a8d6a69d","_type":"navItem","title":"E-Commerce","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"training-data-for-ecommerce"}}}},{"_key":"f10e54ae04d0","_type":"navItem","title":"AR/VR","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"training-data-for-ar-vr"}}}},{"_key":"fd729b522a77","_type":"navItem","title":"Data Quality","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"data-quality"}}}}],"title":"Guides","url":null},{"_key":"681ef7d8763a","_type":"navDropdownMenu","items":[{"_key":"6238a422b667","_type":"navItem","title":"Our Story","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-story"}}}},{"_key":"258985d6d46b","_type":"navItem","title":"Our Team","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-team"}}}},{"_key":"e0a76077324a","_type":"navItem","title":"Our Mission","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"mission-vision-values"}}}},{"_key":"239e49661b0d","_type":"navItem","title":"Careers","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"careers"}}}},{"_key":"e005a740cd80","_type":"navItem","title":"Contact","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"company-contact"}}}}],"title":"Company","url":null}]},"logo":{"asset":{"_createdAt":"2021-12-09T21:42:35Z","_id":"image-4f4e2f86a8fad952c02dffffd7008aa35f83c850-2380x636-svg","_rev":"7Z7VDk3xHzg51hvomGzc99","_type":"sanity.imageAsset","_updatedAt":"2021-12-09T21:42:35Z","assetId":"4f4e2f86a8fad952c02dffffd7008aa35f83c850","extension":"svg","metadata":{"_type":"sanity.imageMetadata","blurHash":"D009jvfQfQfQfQfQfQfQfQfQ","dimensions":{"_type":"sanity.imageDimensions","aspectRatio":3.742138364779874,"height":636,"width":2380},"hasAlpha":true,"isOpaque":false,"lqip":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAYAAABFA8wzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAr0lEQVQYlU3QyUoDQBAE0HeIEjeixAVyESRI3BNFJSZxAU/+/wdJQSEehu6Zqa6uKnjBGz7xgTuc4gAj7LWe4LD9cc8Y+9jBUed84QGrEt/gEleYY9Ylr3jGU/tV77fFLirId0nWBYYgoACi+r3D6YPN0vwFm4VxmNlgfkK4qcLUZdVMcdHB+75FzWPfzzCpxXNcFxuOP2uxnhNLASaX5LjbnJJf6jYG2PpXh812/AvSEQ+GGZqgYgAAAABJRU5ErkJggg==","palette":{"_type":"sanity.imagePalette","darkMuted":{"_type":"sanity.imagePaletteSwatch","background":"#040404","foreground":"#fff","population":100.29,"title":"#fff"},"darkVibrant":{"_type":"sanity.imagePaletteSwatch","background":"#424242","foreground":"#fff","population":0,"title":"#fff"},"dominant":{"_type":"sanity.imagePaletteSwatch","background":"#040404","foreground":"#fff","population":100.29,"title":"#fff"},"lightMuted":{"_type":"sanity.imagePaletteSwatch","background":"#4c4c4c","foreground":"#fff","population":0,"title":"#fff"},"lightVibrant":{"_type":"sanity.imagePaletteSwatch","background":"#bcbcbc","foreground":"#000","population":0,"title":"#fff"},"muted":{"_type":"sanity.imagePaletteSwatch","background":"#4c4c4c","foreground":"#fff","population":0,"title":"#fff"},"vibrant":{"_type":"sanity.imagePaletteSwatch","background":"#7f7f7f","foreground":"#fff","population":0,"title":"#fff"}}},"mimeType":"image/svg+xml","originalFilename":"e20f8cc53e5f74df10ae9a822edb7ec2c4d00f02-2380x636.svg","path":"images/76e3r62u/production/4f4e2f86a8fad952c02dffffd7008aa35f83c850-2380x636.svg","sha1hash":"4f4e2f86a8fad952c02dffffd7008aa35f83c850","size":2009,"uploadId":"jTUF9DIFqAwpLJ0GcI9bRqb17D69QQlN","url":"https://cdn.sanity.io/images/76e3r62u/production/4f4e2f86a8fad952c02dffffd7008aa35f83c850-2380x636.svg"}},"mainNav":{"items":[{"_key":"58c18e9aa9ea","_type":"navDropdownMenu","items":[{"_key":"b5b5b8bee78b","_type":"navCat","items":[{"_key":"0e80156a2f1a","_type":"navItem","title":"How it Works","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"how-it-works"}}}},{"_key":"40bacee029b4","_type":"navItem","title":"Video Annotation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"video-annotation"}}}},{"_key":"32650ef07503","_type":"navItem","title":"Image Annotation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"image-annotation"}}}},{"_key":"fe9137cd0167","_type":"navItem","title":"3D & LiDAR Annotation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"3d-lidar"}}}},{"_key":"d9a1316d400a","_type":"navItem","title":"Natural Language Processing","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"natural-language-processing"}}}},{"_key":"ac12c7c5d70a","_type":"navItem","title":"Data Curation (Beta)","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"data-curation"}}}}],"title":"Platform","url":null},{"_key":"37ff4fa913bd","_type":"navCat","items":[{"_key":"6026b1a9314e","_type":"navItem","title":"Semantic Segmentation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"semantic-segmentation"}}}},{"_key":"f4611b19b406","_type":"navItem","title":"Polygons","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"polygons"}}}},{"_key":"5155d874d6c8","_type":"navItem","title":"Bounding Boxes","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"bounding-boxes"}}}},{"_key":"9ef3c1e21e74","_type":"navItem","title":"Key Points","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"key-points"}}}},{"_key":"314d4c00d351","_type":"navItem","title":"Cuboids","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"cuboids"}}}},{"_key":"8e17a6388d74","_type":"navItem","title":"Lines & Arrows","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"lines-and-arrows"}}}}],"title":"Shapes","url":null}],"title":"Platform","url":null},{"_key":"112867ca4d03","_type":"navDropdownMenu","items":[{"_key":"22699c7e06cb","_type":"navItem","items":null,"title":"Transportation & Navigation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"transportation-navigation"}}}},{"_key":"122ae5928d6d","_type":"navItem","items":null,"title":"Retail & E-Commerce","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"retail-ecommerce"}}}},{"_key":"7bb234b69fb0","_type":"navItem","items":null,"title":"Consumer & Media","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"consumer-media"}}}},{"_key":"33e6a886b39d","_type":"navItem","items":null,"title":"Biotech & Medtech","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"biotech-medtech"}}}},{"_key":"d095b2619c4e","_type":"navItem","items":null,"title":"Robotics & Manufacturing","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"robotics-and-manufacturing"}}}},{"_key":"2c4b82a94d79","_type":"navItem","items":null,"title":"Food & Agriculture","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"training-data-food-agriculture"}}}}],"title":"Industries","url":null},{"_key":"c47e8763a906","_type":"navDropdownMenu","items":[{"_key":"1d563df30b3f","_type":"navItem","items":null,"title":"Quality","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"quality-training-data"}}}},{"_key":"041725f35d96","_type":"navItem","items":null,"title":"Security","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"security-and-trust"}}}},{"_key":"fd64ede25798","_type":"navItem","items":null,"title":"Ethical AI","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-impact"}}}},{"_key":"398dcbb1c95d","_type":"navItem","items":null,"title":"Compare","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"compare"}}}},{"_key":"93bdfdd87879","_type":"navItem","items":null,"title":"Partners","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"partners"}}}}],"title":"Why Sama","url":null},{"_key":"1d38bf63df54","_type":"navDropdownMenu","items":[{"_key":"be81659b38a5","_type":"navItem","items":null,"title":"API Documentation","url":{"_type":"link","externalUrl":"https://docs.sama.com/reference/overview","internalLink":null}},{"_key":"2cec80e94962","_type":"navItem","items":null,"title":"Blog","url":{"_type":"link","internalLink":null,"internalLink_custom":"/blog"}},{"_key":"09e284fcb1d3","_type":"navItem","items":null,"title":"Events","url":{"_type":"link","internalLink":null,"internalLink_custom":"/events"}}],"title":"Resources","url":null},{"_key":"dbee93713c19","_type":"navDropdownMenu","items":[{"_key":"12d594a568bf","_type":"navItem","items":null,"title":"Our Story","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-story"}}}},{"_key":"ce36540a102d","_type":"navItem","items":null,"title":"Our Team","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-team"}}}},{"_key":"34fc328e8022","_type":"navItem","items":null,"title":"Careers","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"careers"}}}},{"_key":"c1fe2961020a","_type":"navItem","items":null,"title":"Contact","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"company-contact"}}}},{"_key":"ebd81873e538","_type":"navItem","items":null,"title":"Press","url":{"_type":"link","internalLink":null,"internalLink_custom":"/press"}}],"title":"Company","url":null}],"nav_cta":{"_type":"button","link":{"_type":"link","internalLink":{"_ref":"136788cb-06a6-4f27-b75b-07faf403bfa6","_type":"reference"}},"title":"Request a Demo","type":"secondary"}}},"data":{"post":{"_createdAt":"2021-06-24T16:00:00Z","author":{"_id":"e8a1f3c6-0b07-4638-93d5-61a0924f32e3","avatar":{"_type":"image","asset":{"_ref":"image-2f8efc599a377bd580d0ae12f022a15e7e1acacd-632x676-webp","_type":"reference"}},"bio":"Amanda is the Content Marketing Manager at Sama, where each day she gets to learn about AI and how it’s transforming industry. She’s passionate about technology but periodically tries to get away from her computer to explore more analog things like collage and quilting.","name":"Amanda Durepos","slug":{"_type":"slug","current":"amanda-durepos"}},"body":[{"_key":"d626e0c6f7b6","_type":"block","children":[{"_key":"494412bfd922","_type":"span","marks":[],"text":"Project Guideline is an early-stage research project by Google that explores how on-device machine learning can help people with reduced vision to walk and run for exercise independently. The team has partnered with Sama to help fuel their experimental technology; allowing people who are blind and low vision to use a mobile phone, headphones, and a yellow guideline painted on the ground run without a guide."}],"markDefs":[],"style":"normal"},{"_key":"a79124c80b0d","_type":"block","children":[{"_key":"0020adcbba170","_type":"span","marks":[],"text":""}],"markDefs":[],"style":"normal"},{"_key":"0014c68243f4","_type":"block","children":[{"_key":"aff8ea99cf9d0","_type":"span","marks":["strong"],"text":"Overview"},{"_key":"aff8ea99cf9d1","_type":"span","marks":[],"text":"\n"}],"markDefs":[],"style":"h2"},{"_key":"ca90777d3a5d","_type":"block","children":[{"_key":"de4fbb4731e80","_type":"span","marks":[],"text":"\nIt started with a pointed question during a Google hackathon in the fall of 2019. Thomas Panek, an avid runner and CEO of "},{"_key":"f60ba7839487","_type":"span","marks":["408f2a8e1773"],"text":"Guiding Eyes for the Blind"},{"_key":"ca4bbd6328cf","_type":"span","marks":[],"text":", posed the question to a group of designers and engineers:"}],"markDefs":[{"_key":"408f2a8e1773","_type":"button_link","externalUrl":"https://www.guidingeyes.org/"}],"style":"normal"},{"_key":"a3e80d53b7a2","_type":"block","children":[{"_key":"6e265f3e030f0","_type":"span","marks":[],"text":"“Would it be possible to help a blind runner navigate, independently?”"}],"markDefs":[],"style":"blockquote"},{"_key":"8768dfc3fb2d","_type":"block","children":[{"_key":"8de5ca26cdf00","_type":"span","marks":[],"text":"Panek, who is blind himself, has completed more than twenty marathons, including five Boston Marathons. While he’s had guide dogs and volunteer human guides to run with him throughout the years, he’s always had to follow—even though his legs and lungs had the capacity to go faster."}],"markDefs":[],"style":"normal"},{"_key":"124c0c3f01b2","_type":"block","children":[{"_key":"498a06633bce0","_type":"span","marks":[],"text":"It quickly took off from there. By end of day, the team had a working prototype. Less than a year later, Panek was able to run independently for the first time in more than two decades."}],"markDefs":[],"style":"normal"},{"_key":"0ba53b6ad22d","_type":"block","children":[{"_key":"435aacbc198d0","_type":"span","marks":["e94100d1ffce"],"text":"Read the full case study here"},{"_key":"9cb4c54261ab","_type":"span","marks":[],"text":". "}],"markDefs":[{"_key":"e94100d1ffce","_type":"button_link","externalUrl":"https://www.sama.com/google-project-guideline"}],"style":"h3"},{"_key":"834cd4e8b482","_type":"block","children":[{"_key":"38474a78f5840","_type":"span","marks":[],"text":""}],"markDefs":[],"style":"h5"},{"_key":"f658a1259b54","_type":"block","children":[{"_key":"b372495df1e70","_type":"span","marks":["strong"],"text":"The Challenge"}],"markDefs":[],"style":"h2"},{"_key":"33a28b56b8b9","_type":"block","children":[{"_key":"e192f31689000","_type":"span","marks":[],"text":""}],"markDefs":[],"style":"h5"},{"_key":"ee6cf58e150e","_type":"block","children":[{"_key":"99ea1884ad590","_type":"span","marks":[],"text":"The machine learning algorithm developed by Google requires only a line painted on a pedestrian path. Runners wear a regular Android phone in a harness around the waist and count on the camera to feed imagery to the algorithm, which identifies the painted line. The algorithm is tasked with detecting whether the line is to the runner’s left, right, or center, so audio signals can be sent to the runner to guide them to stay on track."}],"markDefs":[],"style":"normal"},{"_key":"1c7fcb93db1b","_type":"block","children":[{"_key":"a7daa00f4c960","_type":"span","marks":[],"text":"For humans, it’s fairly straightforward to recognize a line and follow it. For a machine learning model, it isn’t that easy. Imagine the running motion: as you start moving your feet you step from left to right, introducing a shake that can make the guideline blurry. Moving outdoors to Panek’s preferred running location, you introduce even more variables. The model must be able to handle a wide range of weather and lighting conditions, or objects like fallen leaves blocking the guideline."}],"markDefs":[],"style":"normal"},{"_key":"feea5a00137c","_type":"block","children":[{"_key":"f18bff1bc6f70","_type":"span","marks":[],"text":""}],"markDefs":[],"style":"h5"},{"_key":"0effb167e56f","_type":"block","children":[{"_key":"28b3f84773780","_type":"span","marks":["strong"],"text":"The Solution"}],"markDefs":[],"style":"h2"},{"_key":"cce440ba3b9b","_type":"block","children":[{"_key":"6a9acd8aa5f40","_type":"span","marks":[],"text":""}],"markDefs":[],"style":"h5"},{"_key":"5487573fac45","_type":"block","children":[{"_key":"c501789d790e0","_type":"span","marks":[],"text":"Sama’s expert annotators draw precise polygons around the single solid yellow lines and a single center line in the images. To do this, the Sama team underwent an intensive training process and continues to meet with Google’s engineers each week to check in on quality, discuss edge cases, and receive new instructions. Thus, with enough examples to learn from, the algorithm is trained to distinguish the pixels in the yellow line from everything else."}],"markDefs":[],"style":"normal"},{"_key":"8126bc6dba51","_type":"block","children":[{"_key":"729de4509aa70","_type":"span","marks":[],"text":"But quality AI starts with quality data. And quality data has to be diverse. The Project Guideline data needed to encompass every imaginable scenario that a runner might encounter. In Panek’s case, we quickly noticed that we had to include the runner’s hand blocking the guideline. This was solved by having our annotators infer the position of the line behind the hand—a great example of something that is easy for a human to do but rather difficult for a computer. By continuously adding these variations to the dataset, the model is getting smarter over time. "}],"markDefs":[],"style":"normal"},{"_key":"34f0737ae29a","_type":"block","children":[{"_key":"54d8d6c453340","_type":"span","marks":[],"text":"Fueling the cutting-edge technology that helps a blind man run without assistance truly is the stuff that dreams are made of. Sama’s annotators, the experts giving artificial intelligence its intelligence, love being a part of Project Guideline. Bridget Nattabi, who has worked on this project since its kickoff in July 2020, shares her thoughts:"}],"markDefs":[],"style":"normal"},{"_key":"b26dab90fb3f","_type":"block","children":[{"_key":"fd7aab1907110","_type":"span","marks":[],"text":"“Working on this project has allowed me to grow and master polygon annotation with high efficiency and accuracy. I also feel honored to be part of a team that is creating a life-changing navigation experience for the blind. It’s heartwarming to consider that what I do gives people a chance to navigate the world without a guide just like any sighted individual would.”"}],"markDefs":[],"style":"blockquote"},{"_key":"9ec2787f53c9","_type":"block","children":[{"_key":"354afc51eeca0","_type":"span","marks":["strong"],"text":"A word from Project Guideline"}],"markDefs":[],"style":"h2"},{"_key":"bad5489a4f2d","_type":"block","children":[{"_key":"4e4b6793654f0","_type":"span","marks":[],"text":"“Sama was a force multiplier for us and a key success factor for our project. They delivered high-quality annotated data on time, listened to our feedback, and were very flexible in accommodating our requests.”\n-Xuan Yang, Computer Vision Researcher at Google"}],"markDefs":[],"style":"blockquote"},{"_key":"40f34ad8bc28","_type":"block","children":[{"_key":"0e8325bf5e650","_type":"span","marks":["f44950c2a1ef"],"text":"Read the full case study here"},{"_key":"7a3fd65a8fa4","_type":"span","marks":[],"text":". \n"}],"markDefs":[{"_key":"f44950c2a1ef","_type":"button_link","externalUrl":"https://www.sama.com/google-project-guideline"}],"style":"h3"}],"config":{"description":"Project Guideline by Google partnered with Sama to help people who are blind run without a guide, using only a smartphone, headphones, and a yellow guideline.","openGraphImage":null,"title":"How Sama's Accurate AI is Helping Blind Runners Run Independently"},"estimatedReadingTime":5,"featured_image":{"_type":"image","asset":{"_ref":"image-080a7046afcb7bb25b5af2d55d55883944f1c5eb-3334x1668-png","_type":"reference"}},"plaintextBody":"Project Guideline is an early-stage research project by Google that explores how on-device machine learning can help people with reduced vision to walk and run for exercise independently. The team has partnered with Sama to help fuel their experimental technology; allowing people who are blind and low vision to use a mobile phone, headphones, and a yellow guideline painted on the ground run without a guide.\n\n\n\nOverview\n\n\n\nIt started with a pointed question during a Google hackathon in the fall of 2019. Thomas Panek, an avid runner and CEO of Guiding Eyes for the Blind, posed the question to a group of designers and engineers:\n\n“Would it be possible to help a blind runner navigate, independently?”\n\nPanek, who is blind himself, has completed more than twenty marathons, including five Boston Marathons. While he’s had guide dogs and volunteer human guides to run with him throughout the years, he’s always had to follow—even though his legs and lungs had the capacity to go faster.\n\nIt quickly took off from there. By end of day, the team had a working prototype. Less than a year later, Panek was able to run independently for the first time in more than two decades.\n\nRead the full case study here. \n\n\n\nThe Challenge\n\n\n\nThe machine learning algorithm developed by Google requires only a line painted on a pedestrian path. Runners wear a regular Android phone in a harness around the waist and count on the camera to feed imagery to the algorithm, which identifies the painted line. The algorithm is tasked with detecting whether the line is to the runner’s left, right, or center, so audio signals can be sent to the runner to guide them to stay on track.\n\nFor humans, it’s fairly straightforward to recognize a line and follow it. For a machine learning model, it isn’t that easy. Imagine the running motion: as you start moving your feet you step from left to right, introducing a shake that can make the guideline blurry. Moving outdoors to Panek’s preferred running location, you introduce even more variables. The model must be able to handle a wide range of weather and lighting conditions, or objects like fallen leaves blocking the guideline.\n\n\n\nThe Solution\n\n\n\nSama’s expert annotators draw precise polygons around the single solid yellow lines and a single center line in the images. To do this, the Sama team underwent an intensive training process and continues to meet with Google’s engineers each week to check in on quality, discuss edge cases, and receive new instructions. Thus, with enough examples to learn from, the algorithm is trained to distinguish the pixels in the yellow line from everything else.\n\nBut quality AI starts with quality data. And quality data has to be diverse. The Project Guideline data needed to encompass every imaginable scenario that a runner might encounter. In Panek’s case, we quickly noticed that we had to include the runner’s hand blocking the guideline. This was solved by having our annotators infer the position of the line behind the hand—a great example of something that is easy for a human to do but rather difficult for a computer. By continuously adding these variations to the dataset, the model is getting smarter over time. \n\nFueling the cutting-edge technology that helps a blind man run without assistance truly is the stuff that dreams are made of. Sama’s annotators, the experts giving artificial intelligence its intelligence, love being a part of Project Guideline. Bridget Nattabi, who has worked on this project since its kickoff in July 2020, shares her thoughts:\n\n“Working on this project has allowed me to grow and master polygon annotation with high efficiency and accuracy. I also feel honored to be part of a team that is creating a life-changing navigation experience for the blind. It’s heartwarming to consider that what I do gives people a chance to navigate the world without a guide just like any sighted individual would.”\n\nA word from Project Guideline\n\n“Sama was a force multiplier for us and a key success factor for our project. They delivered high-quality annotated data on time, listened to our feedback, and were very flexible in accommodating our requests.”\n-Xuan Yang, Computer Vision Researcher at Google\n\nRead the full case study here. \n","relatedPosts":[{"_id":"edd6abc4-87b4-42db-a32a-15900a353dbf","featured_image":{"_type":"image","asset":{"_ref":"image-30d0eaccd1e57322b31a4e16b84576ef1f8db57e-1920x960-png","_type":"reference"}},"slug":{"_type":"slug","current":"zerog-aircraft-turnaround"},"tags":[{"label":"Case Studies","value":"Case Studies"}],"title":"High-Quality Labeled Data Fuels zeroG’s Mission to Optimize Aircraft Turnaround Management"},{"_id":"4d9c5816-3584-4622-8ea6-77869ca8dbf0","featured_image":{"_type":"image","asset":{"_ref":"image-f80b5e83a9927bafc61285d9e7a16b07070f53c1-1200x630-png","_type":"reference"}},"slug":{"_type":"slug","current":"sama-mila-partnership"},"tags":[{"_key":"ZLub2KFj","label":"Company News","value":"Company News"}],"title":"Sama Partners with Mila to Solve Key Problems in AI Development"},{"_id":"728400d2-d453-42f7-b20c-47f753bc4583","featured_image":{"_type":"image","asset":{"_ref":"image-1502043edcf701cb4267cb2f6d7c6edf8e0e0cad-2500x1313-png","_type":"reference"}},"slug":{"_type":"slug","current":"podcast-episode-facebook-manohar-paluri"},"tags":[{"_key":"6BgUw5oN","label":"Podcast","value":"Podcast"}],"title":"New Podcast Episode: Facebook's Manohar Paluri Makes Machines See"}],"slug":{"_type":"slug","current":"google-project-guideline"},"tags":[{"_key":"3slAcWy7","label":"Case Studies","value":"Case Studies"}],"title":"How Sama's Accurate AI is Helping Blind Runners Run Independently"}}},"__N_SSG":true}