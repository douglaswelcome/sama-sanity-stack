{"pageProps":{"config":{"footerNav":{"items":[{"_key":"f255606f8f25","_type":"navDropdownMenu","items":[{"_key":"76389ad94cbb","_type":"navItem","title":"Autonomous Transportation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"training-data-for-autonomous-driving"}}}},{"_key":"5f64a8d6a69d","_type":"navItem","title":"E-Commerce","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"training-data-for-ecommerce"}}}},{"_key":"f10e54ae04d0","_type":"navItem","title":"AR/VR","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"training-data-for-ar-vr"}}}},{"_key":"fd729b522a77","_type":"navItem","title":"Data Quality","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"data-quality"}}}}],"title":"Guides","url":null},{"_key":"681ef7d8763a","_type":"navDropdownMenu","items":[{"_key":"6238a422b667","_type":"navItem","title":"Our Story","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-story"}}}},{"_key":"258985d6d46b","_type":"navItem","title":"Our Team","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-team"}}}},{"_key":"e0a76077324a","_type":"navItem","title":"Our Mission","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"mission-vision-values"}}}},{"_key":"239e49661b0d","_type":"navItem","title":"Careers","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"careers"}}}},{"_key":"e005a740cd80","_type":"navItem","title":"Contact","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"company-contact"}}}}],"title":"Company","url":null}]},"logo":{"asset":{"_createdAt":"2021-10-29T18:38:04Z","_id":"image-e20f8cc53e5f74df10ae9a822edb7ec2c4d00f02-2380x636-svg","_rev":"yuZxWYwFNB6KJB4TM9NtaY","_type":"sanity.imageAsset","_updatedAt":"2021-10-29T18:38:04Z","assetId":"e20f8cc53e5f74df10ae9a822edb7ec2c4d00f02","extension":"svg","metadata":{"_type":"sanity.imageMetadata","dimensions":{"_type":"sanity.imageDimensions","aspectRatio":3.742138364779874,"height":636,"width":2380},"hasAlpha":true,"isOpaque":false,"lqip":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAYAAABFA8wzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAr0lEQVQYlU3QyUoDQBAE0HeIEjeixAVyESRI3BNFJSZxAU/+/wdJQSEehu6Zqa6uKnjBGz7xgTuc4gAj7LWe4LD9cc8Y+9jBUed84QGrEt/gEleYY9Ylr3jGU/tV77fFLirId0nWBYYgoACi+r3D6YPN0vwFm4VxmNlgfkK4qcLUZdVMcdHB+75FzWPfzzCpxXNcFxuOP2uxnhNLASaX5LjbnJJf6jYG2PpXh812/AvSEQ+GGZqgYgAAAABJRU5ErkJggg==","palette":{"_type":"sanity.imagePalette","darkMuted":{"_type":"sanity.imagePaletteSwatch","background":"#040404","foreground":"#fff","population":100.29,"title":"#fff"},"darkVibrant":{"_type":"sanity.imagePaletteSwatch","background":"#424242","foreground":"#fff","population":0,"title":"#fff"},"dominant":{"_type":"sanity.imagePaletteSwatch","background":"#040404","foreground":"#fff","population":100.29,"title":"#fff"},"lightMuted":{"_type":"sanity.imagePaletteSwatch","background":"#4c4c4c","foreground":"#fff","population":0,"title":"#fff"},"lightVibrant":{"_type":"sanity.imagePaletteSwatch","background":"#bcbcbc","foreground":"#000","population":0,"title":"#fff"},"muted":{"_type":"sanity.imagePaletteSwatch","background":"#4c4c4c","foreground":"#fff","population":0,"title":"#fff"},"vibrant":{"_type":"sanity.imagePaletteSwatch","background":"#7f7f7f","foreground":"#fff","population":0,"title":"#fff"}}},"mimeType":"image/svg+xml","originalFilename":"image.svg","path":"images/76e3r62u/production/e20f8cc53e5f74df10ae9a822edb7ec2c4d00f02-2380x636.svg","sha1hash":"ae6a56857a230101a883a9b93974923879775bc9","size":2009,"uploadId":"mtOtmqAQnCEIG5cEqXZ1YAOCuqHJ4X3g","url":"https://cdn.sanity.io/images/76e3r62u/production/e20f8cc53e5f74df10ae9a822edb7ec2c4d00f02-2380x636.svg"}},"mainNav":{"items":[{"_key":"58c18e9aa9ea","_type":"navDropdownMenu","items":[{"_key":"b5b5b8bee78b","_type":"navCat","items":[{"_key":"0e80156a2f1a","_type":"navItem","title":"How it Works","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"how-it-works"}}}},{"_key":"40bacee029b4","_type":"navItem","title":"Video Annotation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"video-annotation"}}}},{"_key":"32650ef07503","_type":"navItem","title":"Image Annotation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"image-annotation"}}}},{"_key":"fe9137cd0167","_type":"navItem","title":"3D & LiDAR Annotation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"3d-lidar"}}}},{"_key":"d9a1316d400a","_type":"navItem","title":"Natural Language Processing","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"natural-language-processing"}}}},{"_key":"ac12c7c5d70a","_type":"navItem","title":"Data Curation (Beta)","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"data-curation"}}}}],"title":"Platform","url":null},{"_key":"37ff4fa913bd","_type":"navCat","items":[{"_key":"6026b1a9314e","_type":"navItem","title":"Semantic Segmentation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"semantic-segmentation"}}}},{"_key":"f4611b19b406","_type":"navItem","title":"Polygons","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"polygons"}}}},{"_key":"5155d874d6c8","_type":"navItem","title":"Bounding Boxes","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"bounding-boxes"}}}},{"_key":"9ef3c1e21e74","_type":"navItem","title":"Key Points","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"key-points"}}}},{"_key":"314d4c00d351","_type":"navItem","title":"Cuboids","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"cuboids"}}}},{"_key":"8e17a6388d74","_type":"navItem","title":"Lines & Arrows","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"lines-and-arrows"}}}}],"title":"Shapes","url":null}],"title":"Platform","url":null},{"_key":"112867ca4d03","_type":"navDropdownMenu","items":[{"_key":"22699c7e06cb","_type":"navItem","items":null,"title":"Transportation & Navigation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"transportation-navigation"}}}},{"_key":"122ae5928d6d","_type":"navItem","items":null,"title":"Retail & E-Commerce","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"retail-ecommerce"}}}},{"_key":"7bb234b69fb0","_type":"navItem","items":null,"title":"Consumer & Media","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"consumer-media"}}}},{"_key":"33e6a886b39d","_type":"navItem","items":null,"title":"Biotech & Medtech","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"biotech-medtech"}}}},{"_key":"d095b2619c4e","_type":"navItem","items":null,"title":"Robotics & Manufacturing","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"robotics-and-manufacturing"}}}},{"_key":"2c4b82a94d79","_type":"navItem","items":null,"title":"Food & Agriculture","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"training-data-food-agriculture"}}}}],"title":"Industries","url":null},{"_key":"c47e8763a906","_type":"navDropdownMenu","items":[{"_key":"1d563df30b3f","_type":"navItem","items":null,"title":"Quality","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"quality-training-data"}}}},{"_key":"041725f35d96","_type":"navItem","items":null,"title":"Security","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"security-and-trust"}}}},{"_key":"fd64ede25798","_type":"navItem","items":null,"title":"Ethical AI","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-impact"}}}},{"_key":"398dcbb1c95d","_type":"navItem","items":null,"title":"Compare","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"compare"}}}},{"_key":"93bdfdd87879","_type":"navItem","items":null,"title":"Partners","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"partners"}}}}],"title":"Why Sama","url":null},{"_key":"1d38bf63df54","_type":"navDropdownMenu","items":[{"_key":"be81659b38a5","_type":"navItem","items":null,"title":"API Documentation","url":{"_type":"link","externalUrl":"https://docs.sama.com/reference/overview","internalLink":null}},{"_key":"2cec80e94962","_type":"navItem","items":null,"title":"Blog","url":{"_type":"link","internalLink":null,"internalLink_custom":"/blog"}},{"_key":"09e284fcb1d3","_type":"navItem","items":null,"title":"Events","url":{"_type":"link","internalLink":null,"internalLink_custom":"/events"}}],"title":"Resources","url":null},{"_key":"dbee93713c19","_type":"navDropdownMenu","items":[{"_key":"12d594a568bf","_type":"navItem","items":null,"title":"Our Story","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-story"}}}},{"_key":"ce36540a102d","_type":"navItem","items":null,"title":"Our Team","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-team"}}}},{"_key":"34fc328e8022","_type":"navItem","items":null,"title":"Careers","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"careers"}}}},{"_key":"c1fe2961020a","_type":"navItem","items":null,"title":"Contact","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"company-contact"}}}},{"_key":"ebd81873e538","_type":"navItem","items":null,"title":"Press","url":{"_type":"link","internalLink":null,"internalLink_custom":"/press"}}],"title":"Company","url":null}],"nav_cta":{"_type":"button","link":{"_type":"link","internalLink":{"_ref":"136788cb-06a6-4f27-b75b-07faf403bfa6","_type":"reference"}},"title":"Request a Demo","type":"secondary"}}},"data":{"firstLoad":[{"_createdAt":"2020-11-23T16:48:22Z","author":{"_id":"10ead718-57e1-41a8-b846-da3c81cc323a","avatar":{"_type":"image","asset":{"_ref":"image-a4c79da81bb1e23ce10fba84ea2cba5efe67a2a5-200x200-webp","_type":"reference"}},"bio":"Currently a Director of Product Management at Sama, Saul is passionate about the intersection of technology and social impact. He manages Sama’s data labelling products to ensure high quality training data efficiently and reliably reaches our customers. Experienced in both product and professional services, Saul is a proven leader who takes a data driven approach to expanding Sama’s capabilities and features. When not at work, you can usually find Saul enjoying the outdoors and spending time with his family.","name":"Saul Miller","slug":{"_type":"slug","current":"saul-miller"}},"config":{"description":"Announcing our support for custom keypoint shapes in SamaHub, our training data platform trusted by the world's leading AI teams, for vector image and video annotation.","openGraphImage":null,"title":"Custom Keypoint Shapes for Vector Image & Video Annotation"},"estimatedReadingTime":3,"featured_image":{"_type":"image","asset":{"_ref":"image-0ea3313b4d00bb103e8441964eeb3968dfee2947-1144x644-png","_type":"reference"}},"plaintextBody":"As a leader in high-quality training data, Sama supports clients across various use cases and applications. The ability to identify specific keypoint landmarks and track their relationship to one another is unlocking some of the most interesting developments in computer vision technology. This includes motion tracking like human pose identification for virtual fitness trainers or sports analytics. It also includes facial landmarks for emotion analysis, facial verification security, or driver alertness detection. It could also include hand gesture control for AR/VR or sign language transcription.\n\nWe are thrilled to announce our support for custom keypoint shapes in our training data platform trusted by the world's leading AI teams, for vector image and video annotation. While Sama has long supported other vector shapes like bounding boxes, polygons, and cuboids, these keypoint use cases require custom shapes that have a predefined number and order of points. Sama can now be configured to support skeletons, hands, eyelids or any other complex custom shape. Each keypoint can have its own label, color, and connection to other points. Multiple keypoint shapes are supported on the same annotation project.\n\n\nOptimizing for Quality and Efficiency\n\nThis new capability optimizes quality and efficiency in producing ground truth training data for our clients. Our expert annotators have a facilitated drawing experience where the shape builds itself as they annotate each point. The correct label for each point is inferred from the order that it is placed so no extra time is spent assigning labels to each point. We see quality improvement from visualizing the annotations as a cohesive connected shape instead of as free standing individual points. The custom keypoint shape also always has the same number and order of points—this means that no points could ever be omitted or mislabeled. In addition to the quality benefits, our A/B testing showed an 27% decrease in annotation time on a skeleton image annotation workflow over individual points.\n\nCompleted annotation data is returned to our clients in a structured delivery format that contains information about each point, its relative order in the array and its connection to other points.\n\nIf you're currently working on a computer vision algorithm that requires high quality keypoint annotations on images or videos, make sure to read more on our platform page or get in touch with an expert to discuss your training data needs.","slug":{"_type":"slug","current":"custom-keypoint-shapes"},"tags":[{"_key":"T7HkzkJx","label":"Product","value":"Product"},{"_key":"j9XlG6o5","label":"Keypoints","value":"Keypoints"},{"_key":"o2UoWoaC","label":"Video Annotation","value":"Video Annotation"},{"_key":"3GbpMBcq","label":"Vector Annotation","value":"Vector Annotation"}],"title":"Custom Keypoint Shapes for Vector Image & Video Annotation"},{"_createdAt":"2020-04-02T20:30:00Z","author":{"_id":"6dd25391-26af-42ff-a2a2-f0778ce1b002","avatar":{"_type":"image","asset":{"_ref":"image-4e1c47984bb16cb0370855b6272663d6744216d3-450x450-jpg","_type":"reference"}},"bio":"Currently a Senior Product Manager at Sama, Audrey guides cross-functional teams to create thoughtful product solutions. She has guided teams of designers and engineers at HUGE Inc. and NBCUniversal, and monitored user analytics at the Wall Street Journal. With a BA in history from Harvard, an MA in anthropology from Columbia and an MBA from UNC Chapel Hill KFBS, Audrey is passionate a using technology and data analytics facilitate social impact and environmental solutions through technology.","name":"Audrey Boguchwal","slug":{"_type":"slug","current":"audrey-boguchwal"}},"config":{"description":"SamaHub's video and 3D object tracking with frame level labeling assists companies in quickly building models that better reflect real-world behavior.","openGraphImage":null,"title":"Object Tracking with Frame Level-Labeling"},"estimatedReadingTime":3,"featured_image":{"_type":"image","asset":{"_ref":"image-7eb4854393afff7be19269b7e8414936e411403f-5506x3671-jpg","_type":"reference"}},"plaintextBody":"We live in an ever-changing world, where AI-enabled technology has become a new normal for society. To assist top organizations in their efforts to build smarter computer vision algorithms, we’ve rolled out a new release for video and 3D object-tracking in our leading data annotation platform.\n\nThere are a number of applications that use computer vision to track how the world, and the objects in it, change overtime. For a self-driving car to navigate safely, it needs to track other moving objects on the road and make predictions about their future movement, so it can plan its driving path.\n\nAR and VR applications like video games need to track the motion of individual people to create a seamless digital experience. These vision applications have something in common: they all seek to understand the change in position, behavior and characteristics of unique objects over time.\n\nObject tracking annotation offers object tracking capabilities for complex scenarios, including path planning, traffic light status, sentiment analysis, etc.\n\nThis frame-level labeling technology allows unique objects to be dynamically tracked across a video or a sequence of 3D point cloud data from a Lidar sensor. Change in position and pose are captured with annotation shapes like cuboids, polygons and bounding boxes.\n\nSama supports custom label taxonomies for both the main object class (person, car, etc.) and dynamic labeling for other object characteristics that change over time, such as visibility percentage of an object or a specific set of characteristics like emotions. Sama’s built-in automated interpolation between video frames helps ensure efficient, high quality labeled training data for a variety of object tracking use cases.\n\nFor over 10 years, Sama has delivered turnkey, high-quality training data and validation to train the world's leading AI technologies. Video and 3D object tracking are no exception, and this update for video object tracking annotation in 2D RGB video and 3D Lidar data will continue to assist organizations in quickly building models that better reflect real-world behavior.\n\nSama has deep expertise working with training data for object tracking use cases across a variety of industries including autonomous vehicles, AR/VR, retail and e-commerce, communications, media and entertainment, to name just a few.\n\nDownload our solution brief to learn more about our secure training data annotation platform, or contact our team here.","slug":{"_type":"slug","current":"object-tracking-in-samahub-with-frame-level-labeling"},"tags":[{"_key":"OjIX5QKU","label":"Product","value":"Product"},{"_key":"2ZGxEWq0","label":"Video Annotation","value":"Video Annotation"},{"_key":"iBmdS1VE","label":"Training Data","value":"Training Data"},{"_key":"uZYhm6jx","label":"Data Annotation","value":"Data Annotation"}],"title":"Object Tracking with Frame Level-Labeling"},{"_createdAt":"2018-07-17T00:00:00Z","author":{"_id":"71091c91-664a-44a6-9474-acc40eb12457","avatar":{"_type":"image","asset":{"_ref":"image-bc776336801adf71e2599337e8d6f02186b109d0-500x500-jpg","_type":"reference"}},"bio":"Matthew leads the product team at Sama, responsible for the platform that enables Sama's AI/ML data enrichment teams, internal enterprise operations tools to ensure quality and scalability, and all new product initiatives for the evolution of algorithm development and human-powered automation.","name":"Matthew Landry","slug":{"_type":"slug","current":"matthew-landry"}},"config":{"description":"Announcing object tracking with video annotation","openGraphImage":null,"title":"Introducing Object Tracking with Video Annotation"},"estimatedReadingTime":null,"featured_image":{"_type":"image","asset":{"_ref":"image-af58edf394d9676203b9bc44284f08ccf52125a6-1000x1500-jpg","_type":"reference"}},"plaintextBody":null,"slug":null,"tags":[{"_key":"lFK49VoI","label":"Machine Learning","value":"Machine Learning"},{"_key":"uWZdY0Qc","label":"Product","value":"Product"},{"_key":"vbSgnXan","label":"Video Annotation","value":"Video Annotation"},{"_key":"NfB0x55k","label":"Data Annotation","value":"Data Annotation"}],"title":"Introducing Object Tracking with Video Annotation"}],"morePosts":[],"slug":"video-annotation","tagName":"Video Annotation","pageConfig":{"title":"Sama Blog | Training Data, AI and Impact Sourcing Insights","description":"From machine learning to training data strategy, the Sama blog covers research, news and other AI trends from thought leaders across the globe."}}},"__N_SSG":true}