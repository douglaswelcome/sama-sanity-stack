{"pageProps":{"config":{"footerNav":{"items":[{"_key":"f255606f8f25","_type":"navDropdownMenu","items":[{"_key":"76389ad94cbb","_type":"navItem","title":"Autonomous Transportation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"training-data-for-autonomous-driving"}}}},{"_key":"5f64a8d6a69d","_type":"navItem","title":"E-Commerce","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"training-data-for-ecommerce"}}}},{"_key":"f10e54ae04d0","_type":"navItem","title":"AR/VR","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"training-data-for-ar-vr"}}}},{"_key":"fd729b522a77","_type":"navItem","title":"Data Quality","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"data-quality"}}}}],"title":"Guides","url":null},{"_key":"681ef7d8763a","_type":"navDropdownMenu","items":[{"_key":"6238a422b667","_type":"navItem","title":"Our Story","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-story"}}}},{"_key":"258985d6d46b","_type":"navItem","title":"Our Team","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-team"}}}},{"_key":"e0a76077324a","_type":"navItem","title":"Our Mission","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"mission-vision-values"}}}},{"_key":"239e49661b0d","_type":"navItem","title":"Careers","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"careers"}}}},{"_key":"e005a740cd80","_type":"navItem","title":"Contact","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"company-contact"}}}}],"title":"Company","url":null}]},"logo":{"asset":{"_createdAt":"2021-12-09T21:42:35Z","_id":"image-4f4e2f86a8fad952c02dffffd7008aa35f83c850-2380x636-svg","_rev":"7Z7VDk3xHzg51hvomGzc99","_type":"sanity.imageAsset","_updatedAt":"2021-12-09T21:42:35Z","assetId":"4f4e2f86a8fad952c02dffffd7008aa35f83c850","extension":"svg","metadata":{"_type":"sanity.imageMetadata","blurHash":"D009jvfQfQfQfQfQfQfQfQfQ","dimensions":{"_type":"sanity.imageDimensions","aspectRatio":3.742138364779874,"height":636,"width":2380},"hasAlpha":true,"isOpaque":false,"lqip":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAYAAABFA8wzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAr0lEQVQYlU3QyUoDQBAE0HeIEjeixAVyESRI3BNFJSZxAU/+/wdJQSEehu6Zqa6uKnjBGz7xgTuc4gAj7LWe4LD9cc8Y+9jBUed84QGrEt/gEleYY9Ylr3jGU/tV77fFLirId0nWBYYgoACi+r3D6YPN0vwFm4VxmNlgfkK4qcLUZdVMcdHB+75FzWPfzzCpxXNcFxuOP2uxnhNLASaX5LjbnJJf6jYG2PpXh812/AvSEQ+GGZqgYgAAAABJRU5ErkJggg==","palette":{"_type":"sanity.imagePalette","darkMuted":{"_type":"sanity.imagePaletteSwatch","background":"#040404","foreground":"#fff","population":100.29,"title":"#fff"},"darkVibrant":{"_type":"sanity.imagePaletteSwatch","background":"#424242","foreground":"#fff","population":0,"title":"#fff"},"dominant":{"_type":"sanity.imagePaletteSwatch","background":"#040404","foreground":"#fff","population":100.29,"title":"#fff"},"lightMuted":{"_type":"sanity.imagePaletteSwatch","background":"#4c4c4c","foreground":"#fff","population":0,"title":"#fff"},"lightVibrant":{"_type":"sanity.imagePaletteSwatch","background":"#bcbcbc","foreground":"#000","population":0,"title":"#fff"},"muted":{"_type":"sanity.imagePaletteSwatch","background":"#4c4c4c","foreground":"#fff","population":0,"title":"#fff"},"vibrant":{"_type":"sanity.imagePaletteSwatch","background":"#7f7f7f","foreground":"#fff","population":0,"title":"#fff"}}},"mimeType":"image/svg+xml","originalFilename":"e20f8cc53e5f74df10ae9a822edb7ec2c4d00f02-2380x636.svg","path":"images/76e3r62u/production/4f4e2f86a8fad952c02dffffd7008aa35f83c850-2380x636.svg","sha1hash":"4f4e2f86a8fad952c02dffffd7008aa35f83c850","size":2009,"uploadId":"jTUF9DIFqAwpLJ0GcI9bRqb17D69QQlN","url":"https://cdn.sanity.io/images/76e3r62u/production/4f4e2f86a8fad952c02dffffd7008aa35f83c850-2380x636.svg"}},"mainNav":{"items":[{"_key":"58c18e9aa9ea","_type":"navDropdownMenu","items":[{"_key":"b5b5b8bee78b","_type":"navCat","items":[{"_key":"0e80156a2f1a","_type":"navItem","title":"How it Works","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"how-it-works"}}}},{"_key":"40bacee029b4","_type":"navItem","title":"Video Annotation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"video-annotation"}}}},{"_key":"32650ef07503","_type":"navItem","title":"Image Annotation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"image-annotation"}}}},{"_key":"fe9137cd0167","_type":"navItem","title":"3D & LiDAR Annotation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"3d-lidar"}}}},{"_key":"d9a1316d400a","_type":"navItem","title":"Natural Language Processing","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"natural-language-processing"}}}},{"_key":"ac12c7c5d70a","_type":"navItem","title":"Data Curation (Beta)","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"data-curation"}}}}],"title":"Platform","url":null},{"_key":"37ff4fa913bd","_type":"navCat","items":[{"_key":"6026b1a9314e","_type":"navItem","title":"Semantic Segmentation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"semantic-segmentation"}}}},{"_key":"f4611b19b406","_type":"navItem","title":"Polygons","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"polygons"}}}},{"_key":"5155d874d6c8","_type":"navItem","title":"Bounding Boxes","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"bounding-boxes"}}}},{"_key":"9ef3c1e21e74","_type":"navItem","title":"Key Points","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"key-points"}}}},{"_key":"314d4c00d351","_type":"navItem","title":"Cuboids","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"cuboids"}}}},{"_key":"8e17a6388d74","_type":"navItem","title":"Lines & Arrows","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"lines-and-arrows"}}}}],"title":"Shapes","url":null}],"title":"Platform","url":null},{"_key":"112867ca4d03","_type":"navDropdownMenu","items":[{"_key":"22699c7e06cb","_type":"navItem","items":null,"title":"Transportation & Navigation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"transportation-navigation"}}}},{"_key":"122ae5928d6d","_type":"navItem","items":null,"title":"Retail & E-Commerce","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"retail-ecommerce"}}}},{"_key":"7bb234b69fb0","_type":"navItem","items":null,"title":"Consumer & Media","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"consumer-media"}}}},{"_key":"33e6a886b39d","_type":"navItem","items":null,"title":"Biotech & Medtech","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"biotech-medtech"}}}},{"_key":"d095b2619c4e","_type":"navItem","items":null,"title":"Robotics & Manufacturing","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"robotics-and-manufacturing"}}}},{"_key":"2c4b82a94d79","_type":"navItem","items":null,"title":"Food & Agriculture","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"training-data-food-agriculture"}}}}],"title":"Industries","url":null},{"_key":"c47e8763a906","_type":"navDropdownMenu","items":[{"_key":"1d563df30b3f","_type":"navItem","items":null,"title":"Quality","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"quality-training-data"}}}},{"_key":"041725f35d96","_type":"navItem","items":null,"title":"Security","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"security-and-trust"}}}},{"_key":"fd64ede25798","_type":"navItem","items":null,"title":"Ethical AI","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-impact"}}}},{"_key":"398dcbb1c95d","_type":"navItem","items":null,"title":"Compare","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"compare"}}}},{"_key":"93bdfdd87879","_type":"navItem","items":null,"title":"Partners","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"partners"}}}}],"title":"Why Sama","url":null},{"_key":"1d38bf63df54","_type":"navDropdownMenu","items":[{"_key":"be81659b38a5","_type":"navItem","items":null,"title":"API Documentation","url":{"_type":"link","externalUrl":"https://docs.sama.com/reference/overview","internalLink":null}},{"_key":"2cec80e94962","_type":"navItem","items":null,"title":"Blog","url":{"_type":"link","internalLink":null,"internalLink_custom":"/blog"}},{"_key":"09e284fcb1d3","_type":"navItem","items":null,"title":"Events","url":{"_type":"link","internalLink":null,"internalLink_custom":"/events"}}],"title":"Resources","url":null},{"_key":"dbee93713c19","_type":"navDropdownMenu","items":[{"_key":"12d594a568bf","_type":"navItem","items":null,"title":"Our Story","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-story"}}}},{"_key":"ce36540a102d","_type":"navItem","items":null,"title":"Our Team","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-team"}}}},{"_key":"34fc328e8022","_type":"navItem","items":null,"title":"Careers","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"careers"}}}},{"_key":"c1fe2961020a","_type":"navItem","items":null,"title":"Contact","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"company-contact"}}}},{"_key":"ebd81873e538","_type":"navItem","items":null,"title":"Press","url":{"_type":"link","internalLink":null,"internalLink_custom":"/press"}}],"title":"Company","url":null}],"nav_cta":{"_type":"button","link":{"_type":"link","internalLink":{"_ref":"136788cb-06a6-4f27-b75b-07faf403bfa6","_type":"reference"}},"title":"Request a Demo","type":"secondary"}}},"data":{"firstLoad":[{"_createdAt":"2021-11-23T20:36:31Z","author":{"_id":"70f24746-bdb3-4801-adfd-17508d02ae50","avatar":{"_type":"image","asset":{"_ref":"image-9a5184335ade812b332047f70963b6e72a885c67-1194x1284-webp","_type":"reference"}},"bio":"Rob hosts & produces Sama's podcast, How AI Happens. How AI Happens is a podcast featuring experts and practitioners explaining their work at the cutting edge of Artificial Intelligence. Tune in to hear AI Researchers, Data Scientists, ML Engineers, and the leaders of today’s most exciting AI companies explain the newest and most challenging facets of their field.","name":"Rob Stevenson","slug":{"_type":"slug","current":"rob-stevenson"}},"config":{"description":"Facebook Director in AI Manohar Paluri joins the Sama Podcast, How AI Happens, to discuss the state of computer vision and egocentric perception.","openGraphImage":{"_type":"image","asset":{"_ref":"image-1502043edcf701cb4267cb2f6d7c6edf8e0e0cad-2500x1313-png","_type":"reference"}},"title":"New Podcast Episode: Facebook's Manohar Paluri Makes Machines See"},"estimatedReadingTime":2,"featured_image":{"_type":"image","asset":{"_ref":"image-1502043edcf701cb4267cb2f6d7c6edf8e0e0cad-2500x1313-png","_type":"reference"}},"plaintextBody":"Manohar Paluri has spent the bulk of his career developing methods to make machines see. Now, in his role as Director, Artificial Intelligence at Facebook (now Meta), computer vision is one building block in the massive undertaking of developing egocentric perception: making sense of data collected from a first-person perspective via wearable devices.\n\nMano joined our podcast, How AI Happens, to discuss the current state of computer vision, the challenges inherent in developing egocentric perception, and how Facebook is weighing the issues of transparency and privacy as personal data becomes, well, more personal.\n\nChief among considerations for Mano’s team is the shift from third-person sensor perception — that is, holding out a smartphone at arm’s length — to the first-person perspective granted to sensors in wearable tech. While it may not seem obvious, the difference in the data collected is tremendous. First-person perspective allows for better intention prediction with gaze recognition and hand-object interaction. However, it also has its own set of challenges, such as the user not bothering to hold their head as steady as they might hold a smartphone.\n\nMano explains how his team is tackling these issues, the ethical considerations at play, and the importance of not making sacrifices to transparency in the interest of accuracy. To hear Mano explain this and much more, you can stream the full episode below, or anywhere you get your podcasts.","slug":{"_type":"slug","current":"podcast-episode-facebook-manohar-paluri"},"tags":[{"_key":"6BgUw5oN","label":"Podcast","value":"Podcast"}],"title":"New Podcast Episode: Facebook's Manohar Paluri Makes Machines See"},{"_createdAt":"2021-10-25T18:45:56Z","author":{"_id":"70f24746-bdb3-4801-adfd-17508d02ae50","avatar":{"_type":"image","asset":{"_ref":"image-9a5184335ade812b332047f70963b6e72a885c67-1194x1284-webp","_type":"reference"}},"bio":"Rob hosts & produces Sama's podcast, How AI Happens. How AI Happens is a podcast featuring experts and practitioners explaining their work at the cutting edge of Artificial Intelligence. Tune in to hear AI Researchers, Data Scientists, ML Engineers, and the leaders of today’s most exciting AI companies explain the newest and most challenging facets of their field.","name":"Rob Stevenson","slug":{"_type":"slug","current":"rob-stevenson"}},"config":{"description":"Embodied Chief Technology Officer Stefan Scherer explains how conversational AI, few-shot learning, and lean robotic design brings Moxie the Robot to life.","openGraphImage":null,"title":"New Podcast Episode: Moxie the Conversational AI Robot Teaches Children Kindness"},"estimatedReadingTime":2,"featured_image":{"_type":"image","asset":{"_ref":"image-1502043edcf701cb4267cb2f6d7c6edf8e0e0cad-2500x1313-png","_type":"reference"}},"plaintextBody":"When you were a child, do you remember learning what it means to be kind?\n\nWhat about reading sadness in someone’s face, understanding the anger you felt, or respecting personal space?\n\nIf you don’t remember learning about any of these human moments, then Moxie, a conversational AI robot built by Embodied, is the android friend you never knew your childhood self needed.\n\nMoxie is designed to teach children social and emotional maturity, both through human-to-robot conversation as well as various missions that send the child out into the world to learn about kindness and friendship.\n\nTo learn more about what makes Moxie tick, we hosted Stefan Scherer, Chief Technology Officer at Embodied, on the latest episode of our How AI Happens podcast. Stefan explains the language processing happening within Moxie, and how the team was able to generate reliable conversational ability through lean few-shot learning.\n\nMoxie’s ability to shift between dynamic responsive conversation and scripted programmatic content raises fascinating questions about conversational AI: exactly how much responsiveness is required to create the feeling of a 1:1 conversation? And how can technologists draw a circle around a concept such as “kindness” in such a way that enables it to be shared between a child and an AI?\n\nStefan explains all this and more in the full episode. And, of course, we hear from Moxie, too.\n\n\n\n","slug":{"_type":"slug","current":"moxie-the-robot-teaches-children-kindness-conversational-ai-child-development"},"tags":[{"_key":"0CNsp60Q","label":"Podcast","value":"Podcast"}],"title":"New Podcast Episode: Moxie the Conversational AI Robot Teaches Children Kindness"},{"_createdAt":"2021-08-10T18:08:48Z","author":{"_id":"e8a1f3c6-0b07-4638-93d5-61a0924f32e3","avatar":{"_type":"image","asset":{"_ref":"image-2f8efc599a377bd580d0ae12f022a15e7e1acacd-632x676-webp","_type":"reference"}},"bio":"Amanda is the Content Marketing Manager at Sama, where each day she gets to learn about AI and how it’s transforming industry. She’s passionate about technology but periodically tries to get away from her computer to explore more analog things like collage and quilting.","name":"Amanda Durepos","slug":{"_type":"slug","current":"amanda-durepos"}},"config":{"description":"Laurence Moroney, Lead AI Advocate at Google, joined our podcast to talk about how his team is democratizing access to AI's development.","openGraphImage":null,"title":"New Podcast Episode: Making AI Development Global with Google's Laurence Moroney"},"estimatedReadingTime":45,"featured_image":{"_type":"image","asset":{"_ref":"image-1502043edcf701cb4267cb2f6d7c6edf8e0e0cad-2500x1313-png","_type":"reference"}},"plaintextBody":"Many of the exciting advances in AI have resulted from well-funded companies and research departments, stocked with high-performance computers and every shiny toy the AI practitioner could want. But according to Laurence Moroney, Lead AI Advocate at Google, that’s not the only way to develop artificial intelligence.\n\n\n\nSo these students got together and they realized... if they take a picture of the sky, they have data. If they measure the air quality on the sensor, they have a label.\n\nLaurence joined our podcast, How AI Happens, to share examples of exciting advances in AI that are happening all over the world, many with no more than basic mobile devices. Laurence and his team have made it their mission to evangelize the opportunity of AI and work towards democratizing access to the technology’s development, a mission they accomplish via MooCs, YouTube, and a series of books on AI development. \n\nIn this episode, Laurence shares the nature of AI hype cycles, how AI practitioners can navigate them within their own organizations, and some of the amazing opportunities coming into play when access to AI & ML is made global. You can stream the full episode below, tune in via your favorite podcasting app, or read the whole transcript below.\n\n(audio embed)\n\nTranscript:\n\n0:00:00.0 Laurence Moroney: And then when they fed this back through an intention mechanism, they realized they didn't build a camouflage detector, they built a cloudy sky detector.\n\n0:00:12.2 Rob Stevenson: Welcome to 'How AI Happens', a podcast where experts explain their work at the cutting edge of artificial intelligence. You'll hear from AI researchers, data scientists and machine learning engineers, as they get technical about the most exciting developments in their field and the challenges they're facing along the way. I'm your host, Rob Stevenson, and we are about to learn how AI happens.\n\n0:00:42.0 RS: You don't have to be an AI expert to be skeptical about all the hype surrounding artificial intelligence and machine learning. Every company claims they have it, every sales deck mentions it, and worse, the media act as if the rise of the machines is happening sometime in late 2022. But amidst this hype cycle, those in the know understand the opportunity has never been greater. Enter Laurence Moroney. He's an industry veteran who has authored several books on AI development and even advises British Parliament on their AI approach. His mission in his role at Google is to evangelize the opportunity of AI and work towards democratizing access to the development of this technology.\n\n0:01:25.3 LM: I'm an AI lead at Google, so I lead the developer advocacy team, and our job is really to help inform and inspire the world around machine learning, artificial intelligence, deep learning and all that good stuff. So working with developers, working with communities, universities, all of those kind of folks to really help scale out the message and the opportunity that's there with AI.\n\n0:01:47.4 RS: Laurence joined the podcast to discuss the nature of AI hype cycles, how AI practitioners can navigate those cycles within their own organizations, and some of the amazing opportunities coming into play when access to AI and ML is made global.\n\n0:02:01.8 LM: As for my background, I was doing developer advocacy for a few years prior to Google, at places like Microsoft, a wonderful start-up in Israel, called Main Soft, and at Reuters, the news agency, kind of doing an internal advocacy role there, and then prior to that, the typical software engineer, all of those kind of things. Although my background at school was actually physics, my degree was in physics, but I came to the realization that nobody hires physicists, or very few people hire them, and I guess I wasn't good enough a physicist to be hired, so I ended up in this wonderful field instead.\n\n0:02:37.9 RS: It's interesting, you're the second individual I've spoken to, who got their start in physics and now have a career in AI. Is that a natural progression? What do you think is the link there?\n\n0:02:48.2 LM: I honestly... I don't think there is a natural progression, it's probably just a happy coincidence and maybe you're over-fitting in your audience. Sorry, AI joke there. For me, my path to AI actually came... It was really interesting that... 'cause when I first graduated college as a physicist, and it was in the UK, and it was in the middle of the worst recession that they had had since World War II. The current one, obviously, 'cause of COVID, is even worse. But back then, this was a pretty bad one, there was no kind of jobs or anything. And the government launched an initiative in 1992, the UK government, that they were gonna put together a cohort of 20 people to become AI specialists who could maybe be form the backbone of trying to help industry through AI and all of that kind of thing. And they needed people who were smart, but unemployed, and I at least fit one of those criteria, and I was unemployed, but we kinda did this battery of tests, it was like these kind of strange movies kind of thing, and I was accepted into the cohorts, which was really, really cool. And then I guess I got bitten by the AI bug then.\n\n0:03:53.7 LM: But in 1992, trying to do any kind of AI program was intensely difficult, it really didn't have any practical use. We were learning the languages like Prolog and LISP, and there was no industrial use for them, but there was some really fun academic stuff that you could do. But in the end, the program failed completely, but the potential was there, and I gotta give credit to the UK government, of figuring this out back in 1992. They were a little bit early, but it was really cool that they did it. It's funny that recently, in the last couple of years, I've been doing briefs to the UK governments, around AI, and I was like, \"Hey, do you know about that program?\" And of course, the MPs there, they're all long gone, the ones that did it. And the current ones were like, \"Did we really do that? That's awesome.\" I guess that's what got me bit by the bug and that led me down a career of programming and software engineering, to get me where I am today.\n\n0:04:45.9 RS: I'm interested to hear that you are spreading this message of the opportunity of AI, but then you also see all of these companies who are sort of saying they have AI or using AI in their messaging. Is there a gap of actual technology there? What is the difference between the reality of the technology and maybe the hype surrounding it?\n\n0:05:04.7 LM: Yeah, it's a great question. And by the fact that there's so many people doing this and waving around the AI magic pixie dust, hoping for customers or VC funding, that... If nothing else, that is a signal that this technology does have legs. The question is, does it get lost in the hype cycle or do we bust out of the hype cycle and start doing something really interesting? I always like to talk about, there's the... Gartner has this hype cycle curve, where you start with the peak of inflated expectations, and then you drop into something called the trough of disillusionment, and then once you're in the through of disillusionment, that's when you can really understand what the technology is and then you start climbing up through the plateau of productivity. And the kind of behavior that you're talking about just means that we're kind of on the wrong side at the moment, of this peak of inflated expectations. Part of what I'd like to describe my job as, is to do some quantum tunneling through that peak and end up in the trough of disillusionment. So I'm a professional disillusioner.\n\n0:06:02.9 LM: And then once you get into that and you understand what the technology actually is and what it does, then you can start being really useful with it. Obviously, you can look to the past to be able to predict the future. And in my career, there have been two massive tectonic shifts in computing. The first was really the widespread advent of the web and internet technology. The second was the smartphone. And if you think about, exactly the same thing happened in both those cases. I'll talk about the smartphone, which is the more recent one. So the hype cycle at the time was like, \"Throw away your desktop PC, throw away your laptop. You'll be able to do everything on your phone.\" And it's like, \"Forget about Office Suites, forget about programming environments, all of these kind of things. You're gonna get your phone, you're gonna plug it into a station on your desk and a big monitor will magically appear and it'll change how work is done.\" Well, that didn't happen. That to me, was a great example of the hype around the smartphone. But the smart phone still was a massive revolutionary technology that created a tectonic shift in the industry. I saw a stat, the largest creator of jobs in Western Europe during COVID, was the smartphone ecosystem. So not just people building smartphone applications, but people using them, and all of the stuff around that, like delivery services and all that type of stuff.\n\n0:07:23.8 LM: So we could see, that revolution started in 2007, and even now, 14 years later, the economy is benefiting greatly from it. The web revolution, the same thing, there was a whole ton of hype around the web, every shop in existence will go out of business, libraries will close. There was disruption and there were changes as a result of the web, but of course there was, I believe, an overall net gain. So when you start seeing these kind of things like when the hype first came in, but the people who were able to see through the hype and to be able to do something reasonable and productive when they fell into the trough of disillusionment, created whole new industries. Google came out as a result of the web, Amazon, Facebook, the Apple are the highest market cap company in the world right now, and that came as a result of the smartphone revolution. So there's so much that can happen when you can understand the actual limitations, start building to them and then rise up through that plateau of productivity as it's called in the Gartner Hype Cycle.\n\n0:08:28.1 LM: And that's really what I'm here to do, that's my role at Google, is to help people who are technically savvy to understand, \"Here's the possibility of things that you can do. Here's what you need to communicate within your business,\" and so when your product managers or when your CEO is wanting to wave that AI magic pixie dust, that kind of stuff, then it's the case, well, you can be the person who's got the expertise, who's able to say, \"I know this domain, and here's where AI can be used in this domain for real.\" And it might be nice to attract attention through marketing or through VC, but when you build a real product and you start building a real market around that, that's when the business can take off.\n\n0:09:09.7 RS: So if I'm an AI practitioner and I am contending with the hype around AI, or the example you gave of the CEO who's white boarding, \"Can we do this with AI?\" How can I level set expectations? There seems to be this little bit of education necessary, to make sure that people are steeped in reality when it comes to, \"What can this technology do? And what can you reasonably expect within your organization?\"\n\n0:09:34.5 LM: Yeah, I think effective communication is the number one tool, managing upwards like that is the number one tool. I've had a number of those conversations with folks who just thought that they can wave their arms and say, \"AI,\" and then find a programmer who could build the AI for them as they envisage it. But then to kinda just talk them through, \"Well, this is how it actually works, this is what it actually is. And if you wanna reach these goals, here's the kind of work that you would need to do, to be able to reach them.\" And often, it's setting lower goals and having a plan to be able to reach those lower goals and then use that as a plateau to go further and further and further. And I find in general, like CEO speak or CXO speak, they like that, instead of a yes person going, \"Yes, we can do whatever your vision is,\" that kind of thing, to actually be able to say, \"Well, here's a plan for how we can get to a very profitable future. It may not be the vision that you have, but it's concrete,\" and often, the folks in that level see themselves as the inspirational folks who get the plan moving in that direction by setting the goal and setting the long-term vision.\n\n0:10:45.8 LM: And when somebody can communicate up like that to say it's like, \"Well, we can't reach the exact nirvana that you're specifying, but we can build great products to do A, B, C and D, not all the way A through Z, and we can do it in this time frame,\" that, having that level of expertise to be able to speak to that comfortably and realistically, ends up being, I think, a great gift for everybody. If we go back to the conversation of what AI is and what AI isn't, is that I always like to draw this diagram that I say, \"Okay, here's traditional programming,\" and traditional programming, I draw it as a box, and that box is saying, \"You're putting rules in, you're putting data in and you're getting answers out.\" This is what programmers and the software department in your company have been doing since the dawn of software time, and the case is, what a programmer does is, they have to figure out how to express those rules in the programming language, so computers can do the work.\n\n0:11:36.2 LM: So for example, a very simple thing, like in financial services, there's a ratio called the price over earnings ratio, that's often a good one to determine the value of a company or one of the signals to determine the value of a company. And that's a very simple rule. Get the data of the price, get the data of the earnings, divide one by the other, and then you get an answer. There's obviously far more complex ones than that, but I like to use that one as a simple example. And you hire programmers because they know how to express those rules in a programming language and run them in an infrastructure. In the machine learning and AI world, I flip the axis around on that box. So instead of you trying to figure out the rules, you give the machine the answers and the data, and you have it figure out the rules. So for something like price over earnings, it's overkill, you don't need to do it. But what if there are patterns in your data that you don't see?\n\n0:12:26.5 LM: There are things about this company, and you can get a wealth of data around a company that you're doing an analysis on, and you can see that this company has done extremely well in the stock market, but you have no idea why, and this company has done extremely well, and you have no idea why, and then these bunch have done badly and you've no idea why. So then you have the answers, they've done well, they've done badly. You have the data, and the idea behind machine learning and AI is then, you can build a system that can do that pattern matching of the answers to the data and figure out what the rules are, to be able to do that.\n\n0:13:01.1 LM: So for you to do that effectively, you need good data scientists. It's not just, you get a shovel and you throw the data into the machine and something magic happens. You have your data scientists to try and make this as efficient as possible by picking the columns in the database or maybe doing feature crosses on those columns, where multiply this one by this one, that kind of thing. And the same way as your coders today, they're not just typing on a keyboard and stuff magically appears, they are figuring out the rules, they're figuring how to scale them. And that's really where the magic of good data science department applies, and so you've got skilled people who know the domain data, who know how to build models, so that the data is being used efficiently, so you can train a model in a couple of hours instead of a couple of decades, and that kind of thing. So it's like, that's where those folks, beyond trendy, really, really can show massive value for the company. And I'd say the same analogy, if you can get a programmer to build an effective program that runs your business in a day or a week, as opposed to an ineffective programmer who takes years to do the same task.\n\n0:14:07.6 LM: The same kind of thing can be applied with data scientists, that they can figure out which parts of the data to shovel, which parts not to shovel, they can figure out how to label those answers and all of those kind of things, so that the machine learning engineer can do their job effectively.\n\n0:14:21.7 LM: The way I generally like to define AI itself is, when you make a machine that responds the same way that an intelligent being would respond. So computer vision is a good example of that, is that if I show you a picture of a cat... If I show you a picture of my pet, you would say, \"That is a dog.\" Showing a computer a picture of my pets, prior to AI machine learning, deep learning, it would see a whole bunch of pixels and it has no parsing of the content, other than white pixels, blue pixels, those kind of things. When you start using machine learning and deep learning to then kind of train a computer to understand the difference between a cat and a dog, and then I show it this picture of my pets, and the computer will say, \"That's a dog.\" Now, the computer is responding in the same way as an intelligent being would respond, and that to me, is what artificial intelligence is all about. So you play it a sound, and instead of it saying, \"Here's a number of audio levels,\" it's actually able to determine your speech and to determine what you're saying, the same way as an intelligent being would. That to me, is artificial intelligence.\n\n0:15:31.6 LM: There are lots of ways that you can get there. Machine learning, deep learning are probably the most efficient way for things like computer vision, for audio processing, for tax processing and those types of things. So if we think about it and what it is... In terms of what it is and what it's not, it's not this magic thing that you can just say, \"We're gonna... Like in a Dilbert cartoon, we're gonna say, \"Let's put machine learning and artificial intelligence into our product and we get an upgrade.\" It doesn't really work like that.\n\n0:15:58.7 RS: The training is in the interest of an inference. When your technology can make an inference, an accurate inference, it has mimicked human cognition, right?\n\n0:16:06.5 LM: Yeah, exactly. And the nice thing is then, it can even go beyond human cognition, and let me give an example of this, that blows my mind. And so we worked on a project for diabetic retinopathy, at Google, where diabetic retinopathy is the world's leading cause of blindness. And the thing about it is that, it's easy to diagnose and it's easy to cure with early diagnosis. India has the world's second largest population, but it has a shortage of over 100 thousand qualified ophthalmologists. So we worked with doctors and hospitals in India to gather lots and lots of retina scans, to see... We'd label these retina scans... Data plus answers. We'd label these, based on those five different buckets, no diabetic retinopathy, all the way up to severe, and trained a machine learning model on this, to be able to be an artificial intelligence to respond the way an ophthalmologist would, and it ended up, like the publications that we did in various journals, showed that it was at least equivalent to a qualified ophthalmologist and often better. And so, that's the first mind-blowing part.\n\n0:17:13.5 LM: But then the second mind-blowing part, and the one that really hooked my interest in this was then a scientist within Google was looking at the data and realized, we don't just have labels of the diagnosis, we also have labels of the person's birth gender, or the person's age, or the person's blood pressure.\n\n0:17:33.6 LM: Now, an ophthalmologist can look at the scan of an eye and see blood clots and determine do they have diabetic retinopathy or not, but an ophthalmologist can't look at that scan and pick their age, or pick their gender. And so what if you have all of this data, you have your answers, you have your data, what if we could feed this into a model and do it? And it ended up, they trained a model that was 98% accurate in picking the assigned gender at birth, which is as good as, if not better than the average human, but obviously much better than a human looking at a retina, that kind of thing. It would be 50-50, it would be a coin flip. But it was 90% accurate, and it was also able to predict their age, with a mean average error of about three years.\n\n0:18:19.1 LM: And a few times in the past, I've told this story to an audience and I'd asked the audience to guess my age, and on average, the audience was... The mean average error from the audience was way more than that, and they're looking at me, they're looking at my gray hair, they're looking at my mannerisms, they're not looking at my retina, and they're still getting it even more wrong than this was... Again, looking at the retina. So we talk about human cognition and that kind of stuff, but in some ways, doing this kind of pattern recognition, we can go beyond human cognition, with examples like that one. If you have the data and if you have the labels that it's possible now for a machine to be able to do the matching of that data to that label and spot patterns that you as a human, wouldn't previously spot, and then there's massive, untold opportunities in that. So again, if we get down into that trust of disillusionment, and part of that is, I'm saying Machine Learning is fancy pattern matching.\n\n[chuckle]\n\n0:19:13.8 LM: And that kind of thing. There's nothing magical about it. And then when you understand that and you say, \"Well, I have this wealth of data in my business, can I find new business opportunities with this?\" And the answer to that, then is potentially, yes. In the same way as that scientist at Google was able to build a system to be able to predict somebody's age from a retina scan, which nobody knows how you can look at a retina and determine an age. From the model that they built, so you can now do an audit of that, and there's something called attention mechanisms, so you can see where the computer is paying attention to, to be able to derive what it is in a retina that let's you pick somebody's age. But it's like those are the kind of things that now, that the brute-force aspect of sheer compute power, doing that kind of pattern matching allows you to come up with these new scenarios that will rise you up through that plateau of productivity.\n\n\n\n0:20:07.3 RS: Yes, so you said it was an attention mechanism? And this allows you to clue in on, this is the variables that it was taking into account to result in this insight?\n\n\n\n0:20:18.1 LM: Yeah. Exactly, exactly. I teach it in one of my Coursera courses. I do advanced computer vision. And there's one really fun example that we go through in that one, it's not the retina one, that one is a little bit too complex, but there's a very famous machine learning exercise, which is pictures of cats and dogs that I was talking about earlier on, and how you train a computer to be able to recognize the difference between a cat and a dog. And you build a machine learning model in the course that can quite accurately tell the difference between a cat and a dog. But then you also do the attention mechanism stuff on that. And it turns out the primary difference that in this case, the computer was looking at, to pick the difference between a cat and a dog was the eyes. Sometimes you think, \"Oh the cat has pointy ears, the dog has floppy ears, for the most part\" or \"Their noses look differently\", but for the most part, when this model was actually working to pick the difference, it was like those were the features that it had zeroed in on and so then I was able to learn from that and go, \"Aha, so now when I build a model, maybe I should focus on the eyes to be more efficient\", that type of thing.\n\n0:21:16.7 RS: Yes, it strikes me as a crucial mechanism in removing harmful biases, for example, from a black box AI, from being able to look under the hood and say, \"Okay, this is what it was looking at to get this insight\". That can help remove a lot of this fear and a lot of these potentially, harmful biases or incorrect assumptions that technology would make.\n\n0:21:41.9 LM: Yeah, yeah, exactly. And there's a technique, it's also called... There's a thing that you can build, called a class activation map, and the idea with the class activation map is, you're seeing what the computer was paying attention to. A funny story about them, the US Army, realized that maybe computer vision could be used to see things and images that humans couldn't see. And say take for example, on the battlefield, what about being able to see a camouflaged tank? That like a human could look at it, camouflage is designed to fool the human eye, but what if you could have a machine be able to detect like a camouflage camouflaged tank? So they did an experiment where they got a bunch of data scientists and a bunch of machine learning engineers and they gave them a tank, and they said, \"Hey, you go out into the woods and one day take a whole bunch of pictures of this tank un-camouflaged\", and then the following day, they got the camouflage nets, and they put the camouflage nets on the tank and take a whole bunch of pictures of this tank camouflaged. And so build a model off of this one to see if you can pick a camouflage tank or a non-camouflage one, and they did what all good data scientists do, they had a training set of data, they had a test set of data, they had a validation set.\n\n0:22:54.3 LM: They built their model, they ran it and it was like 99% plus accurate. And they were like, \"Oh my gosh, we have built something that can really, really change the course of the battlefield\". They presented that to the Army, the Army loved it, and then they took it out and tested it and it failed completely.\n\n0:23:10.8 RS: Oh no. [chuckle]\n\n0:23:12.5 LM: And the reason why it failed completely was that, they took the pictures of the un-camouflaged tank one day, and they took the pictures of the camouflaged tank on another day. And on the day that they took the camouflaged tank, the sky was cloudy, and on the other day they had a blue sky, and then when they fed this back through an intention mechanism, they realized they didn't build a camouflage detector. They built a cloudy sky detector. [chuckle] So with the black box element of this kind of thing, it's easy to think that these are hard to debug and that kind of stuff, but they're not necessarily that difficult to debug if you understand how they're architected, and if I gave the elevator pitch for how you to do this, when you train an AI system or a machine learning system, you're flowing data one way and doing back prop the other way, but when you wanna do these attention mechanisms, those kind of things, it's just the way of flowing data in the other direction and effectively de-compiling it. If you're going through convolutions, you're de-convoluting it and that kind of stuff, and you can get a pretty good estimate for how the computer is looking at your data.\n\n\n\n0:24:12.1 RS: What is the difference between a classification map and an attention mechanism?\n\n\n\n0:24:15.6 LM: A class activation map is a...\n\n\n\n0:24:17.1 RS: Yeah. Thank you.\n\n\n\n0:24:18.3 LM: So it's a case of when you build a Convolutional Neural Network in particular, you're learning filters that can isolate features in a map, and a class activation map is where you just figure out where those features are on, you light it up on a diagram with a heat map or something like that. And that is a type of attention mechanism. There are also other ways of you being able to pick out attention within a machine learning model or something like that. Class activation maps are a very common one that are used in Computer Vision. Anything that you do, Convolutional Neural Networks, to be able to identify features, there are... Sometimes also use used Convolutions for sequence maps, so if you wanna predict weather in the future or something like that, you may use a one-dimensional convolution on that, and you can potentially have a class activation map there where it spots like, \"Hey, when you got a spike followed by a dip\", in this kind of thing, then that's usually followed by something else. But typically, it would be in an image-based one, it's where it's most commonly used.\n\n0:25:17.6 RS: I like how you mentioned the examples of the smartphone and understanding Hype Cycles, I'm curious if there are any lessons you think we can learn from the way that, that sort of technology was deployed and iterated upon that we can correct or do better with... As AI is sort of spread to the world.\n\n0:25:35.7 LM: The first part is letting people realize that they are in a hype cycle, we've been in hype cycles before. The people who were successful, were the ones... Or initially successful, at least, were the ones who saw through that, and this is what they did to see through it. Exposure to the platform, exposure to the technology, trying out new and exciting and different things, there's a whole graveyard of failed apps on Android and iOS, which laid the framework and the pathway for those apps that were successful. So really being those kind of early adopters, having that, try what you can, learn, iterate, continue. That's what's led to success, and I think that's the same kind of thing that can lead to success in the AI space.\n\n0:26:19.2 LM: One of the advantages of the AI space, is that the amount of investment that you have to make to be successful is a lot less than the amount of investment you might have previously had to make to become the big mobile app developer or to become the big website, and as a result, you don't necessarily have to be housed in the traditional areas on centers of excellence and success. So if we can try to democratize AI as much as possible by making it as available to as many people as possible so that they can seize opportunities that the rest of us may not actually think about, that could pave the way to success for them and for everybody else also. For every success, there's probably going to be a 100 failures, and it's really understanding that, realizing that, but I would rather have a 101,000 people do something so that there's a thousand successes and 100,000 failures, than have 1001 people do it where there's only one success, if my math add up. I told you I'm not very good at math.\n\n[chuckle]\n\n0:27:23.4 RS: Yeah, the one... Yeah, I think that adds up. Of course, the YouTube channel and the MOOCS, and a lot of the content that you produce is any in the interest... It's accessible anywhere. Someone who has internet access can learn from an expert, such as yourself. I do worry though, at what point is there a breakdown in terms of the hardware and the ability to actually design this technology? Does one need access to cloud computing and a work horse of a laptop to be able to play in this field?\n\n0:27:53.3 LM: To be able to get started and play in this field, absolutely no. To be able to go huge in this field, you do need access to high-end hardware like GPUs and TPUs and that kind of thing. So to split those two audiences for the Getting Started one, that's where we've been very carefully focused on easy high-level APIs that will run in Python, which is easy to install and use, that you can do on any laptop with the a CPU so that you can get up and running and kick the tires with these kind of things and to make that as quick and easy as possible for anybody to do. When you go beyond that though, and you start trying to train bigger models, not everybody has access to GPUs, not everybody has access to TPUs. So part of our strategy there was, we have this thing called Google Colab, and Google Colab is an in the browser notebook that runs with a Google Cloud back-end that can provide you free access to a GPU or a TPU. Obviously it's limited, but it's pretty generous. It's many hours of training that you can get for that, and all you need is a browser and a web connection to be able to do that, if you don't already have the hardware.\n\n0:29:00.3 LM: So that's the one first part of the offering. The another part of the offering though, is that when we start thinking about where do your models execute? Okay, so that many models are gonna be built to execute in data centers, the likes of Google or Amazon or Microsoft or on... But that's not the only area of opportunity, we can see that the area of opportunity on mobile handheld devices, embedded systems and all those kind of things is possibly even larger. And with the price of them dropping sharply, the hardware to build a phone is getting cheaper, the hardware to build embedded systems is getting cheaper. Then as long as we have an ecosystem of tools that will allow you to build for them with as low a dollar cost of entry as possible, as low an intellectual cost of entry as possible, those kind of things, that's when those markets can be seeded and those markets can grow. And like I said, I think we can all benefit. Let me share one example, 'cause there's a great project that... It was a couple of years ago, that was built by a bunch of high school and college students in India. And it's called Air Cognizer, I think that's the right phrase.\n\n0:30:09.6 LM: And it's on the YouTube web... The TensorFlow YouTube website. And what they did was that they realized that in their city in India, there was extensive air pollution. And you know what it's like, we all probably are encountering and nowadays with fires nearby, I live in Washington, so every year we have to start looking at air quality because of forest fires. But what they realized was that, when you look at air quality and you see it on the news, or you see it on a website, that's the air quality at a sensor, which is being operated by somebody. Now that might be 20-30 miles from where you live, and the air quality where you live might be severely worse. Elderly parents that they had and grandparents were afraid to go out because they don't know the air quality and they could get sick. So these students got together and they realized if they get a sensor to measure the air quality, and they get a phone, a cheap Android phone with a camera on it, if they take a picture of the sky, they have data. If they measure the air quality on the sensor, they have a label, and if they go all over their city and they take lots of these pictures and lots of these sensors, you do that basic pattern matching to kind of build a model where you're saying, \"Well, when the sky looks like this, the pollution is like this\".\n\n0:31:27.8 LM: And they turned that into an app, and now lots of folks in India can use that app where they can just take a photo of the sky and see a good prediction of the air quality near them, instead of looking at the news and seeing an air quality indicator that could be 20, 30, 40 miles away. And it's like little things like that, little innovations like that, because these were high school and college students, they don't have a lot of money, they're not forming a startup where they're hiring developers to do this kind of thing, the equipment for them to do that, was basic laptops that they had, the data? They generated the data themselves because they had the sensor and they had a cell phone where they could take a picture of the sky, they were able to build a model for this using the open source ecosystem, and they were able to deploy it for free to Android phones.\n\n0:32:12.5 LM: These kind of things, when I talk about really lowering that bar so we could raise the floor, but now it's like, \"Well, the rest of the world can benefit from what they learned\", because we now have the same problem in the West because of forest fires. And I could potentially go out and do the same thing to build an Air Cognizer for Washington State without needing to invest millions of dollars in a start-up to do so. So when you bust through that hype cycle and you understand how this works, then you can think like that, and that's what they did, they thought like that, and boom, they came up with this really cool solution.\n\n0:32:42.8 RS: This is the focus of your, about to be published, new book. Is that correct?\n\n0:32:47.1 LM: Yep, so it's an AI and Machine Learning for On-Device Development is my upcoming book. I originally was gonna create this mega-book for O'Reilly called AI and Machine Learning for Coders. We realized this weighed too much for one book.\n\n[chuckle]\n\n0:33:02.4 LM: So last year, I released the AI and Machine Learning for Coders, and now this year, it's kind of like the complimentary book/sequel, which is a AI and Machine Learning for On-Device Development. So it's really showing you how, as a mobile developer, you can start using models on Android, on iOS and a little sprinkling of doing it in a server with remote access or doing it on things like Raspberry Pi. It's packed with lots of examples of things like, you take a picture, here's how you can detect a face in the picture. Or here's how you can count the number of objects in the picture, like maybe you're building an app that's counting traffic, driving past your house. How do you count the number of cars? Those kind of examples... So I try to get very hands-on with them, of like, here's basically how this stuff works on your device. As of today, you don't train models on the device, you use models on the device. So the concept of my first book, AI and Machine Learning for Coders, or my first book in the series was really, \"Here's how you build the models\", and then the second book is, \"Okay, when you have models or there are off the shelf models available, here's how you use them, or here's how you can customize them to actually use them on your device\".\n\n0:34:16.9 RS: Okay, so the model is not constructed locally? The model is accessed?\n\n0:34:20.9 LM: Yeah. As of today, trying to train a model on a mobile device, it's just going to be very hostile towards your battery because model training is very intensive. We are doing a lot of work on making that better, but as of today... Yeah, as a developer, you're better off training a model in the cloud with something like Colab, or on your developer workstation and then deploying it to your device.\n\n0:34:46.4 RS: Yes.\n\n0:34:47.3 LM: But that's changing. That is changing.\n\n0:34:48.1 RS: Yeah. Well, fans of this podcast will remember our episode with Sama CEO, Wendy Gonzalez, who was speaking about this similar kind of problem of, \"How do we democratize access to AI?\" and I can envision an approach to that, which is just drop a 100 copies of your book and a 100 Android devices, just anywhere in the world and let a rip, right?\n\n0:35:10.2 LM: Yeah, yeah, please do. I'd love to see the results.\n\n0:35:16.8 RS: Laurence has published all manner of content about the realities an opportunities of AI, both philosophical and technical. In the episode description, you'll find links to his MOOCs, books, and the TensorFlow YouTube channel where he frequently contributes. You can also find Laurence's resources on the new, How AI Happens, LinkedIn group. Here, we'll post all the research and resources mentioned by our guests and give you the opportunity to rub shoulders and ask follow-up questions with the experts you hear featured on the show. Just search How AI Happens on LinkedIn and say, hello. How AI Happens is brought to you by Sama. Sama provides accurate data for ambitious AI. Specializing in image, video and sensor data annotation and validation for Machine Learning algorithms in industries such as transportation, retail, e-commerce, media, MedTech, robotics and agriculture. For more information, head to sama.com.","slug":{"_type":"slug","current":"/podcast-google-global-ai-development"},"tags":[{"_key":"saTGs8ZP","label":"Ethical AI","value":"Ethical AI"},{"_key":"jr0XK73o","label":"Podcast","value":"Podcast"}],"title":"New Podcast Episode: Making AI Development Global with Google's Laurence Moroney"},{"_createdAt":"2021-06-17T19:32:29Z","author":{"_id":"e8a1f3c6-0b07-4638-93d5-61a0924f32e3","avatar":{"_type":"image","asset":{"_ref":"image-2f8efc599a377bd580d0ae12f022a15e7e1acacd-632x676-webp","_type":"reference"}},"bio":"Amanda is the Content Marketing Manager at Sama, where each day she gets to learn about AI and how it’s transforming industry. She’s passionate about technology but periodically tries to get away from her computer to explore more analog things like collage and quilting.","name":"Amanda Durepos","slug":{"_type":"slug","current":"amanda-durepos"}},"config":{"description":"Sama CEO Wendy Gonzalez joins our podcast, How AI Happens, to discuss why providing work is a more impactful approach to ending poverty than providing aid.","openGraphImage":{"_type":"image","asset":{"_ref":"image-1502043edcf701cb4267cb2f6d7c6edf8e0e0cad-2500x1313-png","_type":"reference"}},"title":"New Podcast Episode: Sama CEO Wendy Gonzalez on Upskilling Talent from Developing Nations"},"estimatedReadingTime":21,"featured_image":{"_type":"image","asset":{"_ref":"image-1502043edcf701cb4267cb2f6d7c6edf8e0e0cad-2500x1313-png","_type":"reference"}},"plaintextBody":"AI starts with data. Clean, curated, labeled, ready-to-plug-into-your-models data. But it’s not always so easy to get your hands on a dataset that you can use to quickly and efficiently push your models into production. That’s why the individuals who focus on data labeling are so important, and why Sama is making huge efforts to cultivate the next generation of AI specialists.\n\n\nRather than sourcing from the world’s top universities or boot camps, Sama has spent several years delivering a course entitled Artificial Intelligence 101 to individuals in Kibera, the largest slum in Africa. This course teaches students the basics of AI work, simultaneously training AI talent and taking aim at systemic poverty.\n\nTo discuss the results of these efforts, Sama’s CEO Wendy Gonzalez joined our podcast, How AI Happens. Wendy explains:\n\n🖥️ Why providing work is a more impactful approach to ending poverty than providing aid;\n\n🎓 How Sama’s program has measurably improved women’s income and employment rate by 60%;\n\n✏️ How data labeling skills provide talent with access to employment in AI and beyond.\n\n\n\nStream the full episode below, and if you’d like to see the nuts and bolts of how Sama’s mission has affected the community, be sure to check out MIT’s recent RCT study measuring the impact of AI education on student employability and income.\n\n\n(audio embed)\n\n\n\nAnd don’t forget to subscribe to How AI Happens on your favorite podcast streaming platform!\n\n\n\nTranscript:\n\n\n0:00:00.0 Wendy Gonzalez: Talent is distributed equally, but opportunity is not. And the best way to solve poverty, which is basically the root cause for every major social ill in the world, is by giving work, not giving aid.\n\n0:00:16.8 Rob Stevenson: Welcome to How AI Happens, a podcast where experts explain their work at the cutting edge of artificial intelligence. You'll hear from AI researchers, data scientists, and machine learning engineers as they get technical about the most exciting developments in their field and the challenges they're facing along the way. I'm your host, Rob Stevenson, and we are about to learn how AI happens.\n\n0:00:48.1 Rob: Today on How AI Happens, we're going to talk about the next generation of AI specialists. While this might bring to mind the image of a starry-eyed Stanford PhD or a youthful self-taught prodigy, I'm thinking of a different source of talent, because over the last several years, Sama has been delivering a training program entitled Artificial Intelligence 101 to eager individuals in Kibera, the largest slum in Africa, just outside Nairobi, Kenya. To learn more about how an AI company can train technical talent while simultaneously taking aim at systemic poverty, I sat down with Wendy Gonzalez, CEO of Sama.\n\n0:01:29.5 Wendy: I have, I'm a little embarrassed to say, over 25 years of experience [chuckle] in enterprise technology and SaaS and AI. I started my career in management consulting, really helping large companies figure out how to leverage technology. I switched over to the enterprise side, working to really implement disruptive technologies. And then I co-founded an Internet of Things startup about a decade back to build a SaaS platform, because again, IoT was a way to really disrupt the industry, and then I switched over to AI. So I joined Sama in 2015, and Sama is the leading trainee data as a service platform. We work with the Global 2000 to really help enable their mission-critical AI applications.\n\n0:02:13.1 Wendy: I was really compelled to join Sama because I believe deeply in Sama's mission, and really, our philosophy that Sama was founded on is that talent is distributed equally, but opportunity is not. And the best way to solve poverty, which is basically the root cause for every major social ill in the world is by giving work, not giving aid. Over a trillion dollars' worth of aid has been donated to sub-Saharan Africa since the 1960s, yet, GDP hasn't changed. While it seems like the right thing to do, the best thing that we can do to really solve the problem of poverty is by providing financial independence, and that's through giving work. And so, Sama's mission of purposely hiring people in underserved communities to give work was something that really spoke to me, because as a child of immigrants and marrying my husband who was the first person in his entire family through all generations to go to school, the power of work is transformative in terms of lifting up your community and lifting up the people in your family.\n\n0:03:11.4 Wendy: So that mission spoke very, very deeply to me. Sama had a really unique and audacious view on this, which is, it's not just about kind of paying living wages and providing employment and benefits; it's about purposely hiring people who've got the greatest barriers to employment. And so, Sama's model is to hire, in underserved communities, 50% women, 50% youth who have household incomes of less than $2 a day, which is the World Bank standard for poverty. And so I was fascinated with this idea of taking purposeful action and change to hire people and not just sort of provide wages, but really provide a transformative career path to hopefully break the poverty cycle permanently.\n\n0:03:52.1 Rob: This notion of giving work rather than aid has taken the form of Sama's Digital Basics Program, that's the AI 101 course I mentioned earlier. As Wendy explains, this training is the first step in removing the barriers to access between eager, underserved workers and well, work.\n\n0:04:12.8 Wendy: One of the challenges is not just about, \"Hey, I'm in this situation, I didn't graduate from a fancy school or college,\" it's also by just having access to the network to get jobs. So I say barriers to employment, it's not just kind of education and where I live, but it's like, \"Do I know the right people, how do we even get connected to a job?\" So the Sama Digital Basics Program really started by working with community partners in underserved communities, I'll give you an example in Nairobi, to where we work with partners like the Human Needs project that has a facility that is embedded in the Kibera slum, which is the largest slum sub-Saharan Africa. So, it was an idea to bring digital skills training into communities, so that, again, to provide and reduce that barrier to access.\n\n0:04:57.7 Wendy: And so what the Digital Basics Program does is it provides everything from basic skills like mounting and keyboards, but also the basics of AI. So what is artificial intelligence, what role does training data play in empowering artificial intelligence applications, and it's really the initial training that is necessary for somebody to come and join the Sama program.\n\n0:05:20.2 Rob: It should be pointed out here that the goal of the Digital Basics Program isn't merely to create a farm team of future Sami employees, though many of them do wind up working there; rather, the skills that go along with data labeling end up providing individuals with a much wider breadth of opportunity.\n\n0:05:38.4 Wendy: It's not just about building training for the purpose of, \"Okay, now you can do data labeling,\" what we found, if they're doing this program 'cause we were actually launched in 2008, is that the skills necessary to do labeling and tagging are critical thinking skills that actually apply to many different jobs on a go-forward basis. Our intention was always not just hiring people into Sama and you'll be with Sama for the rest of your lives; it was really about building the skills that allow our workers to go on to higher-paying jobs, return to university. That's the entire idea of when I say permanently breaking the poverty cycle, is to build the foundation so that people can move on to higher-paying jobs.\n\n0:06:16.1 Wendy: So while we have a pathway, of course, to move up within Sama, the other objective of this is to build a core set of technical skills. So the training typically occurs within community or at our offices, and then of the people who are trained, some go on and move on to other jobs, many come and apply at Sama. After doing this level of training, we would hire people in as employees, so we're different, we are not freelancing, we are not crowdsourcing. A part of our mission is to provide living wages, benefits, and professional development that'll allow people to further their careers. And so they get hired into Sama, and typically, they will do data labeling as an entry point. And so data labeling, just to take us back a little bit in terms of artificial intelligence, is that...\n\n0:07:03.7 Wendy: You think about it this way, AI is as intelligent as the trainee data it's built on, because machine learning is all about recognizing patterns, then using deep learning techniques for the application to make decisions. Put another way, before a car can drive itself, like a self-driving car, it needs to be able to detect roads, pedestrians, vehicles, and traffic signs, and training data is basically structuring the data so that a computer vision application can identify, what is a car, what's a drivable space, what's a road sign, et cetera. And while that sounds like it's relatively simple, it's actually incredibly, incredibly complex. Some of these data labeling activities include data labeling in 3D. I don't know if you've ever seen radar or light or images, it's very, very complex. And then beyond that, it's not just about detecting and after being that information correctly; it's about the precision of it. And so, tagging a car is not just tagging a car, sometimes you need to include the side-view mirrors, maybe you need to include the shadow under the car, maybe you do need to include what's behind the car, maybe you don't.\n\n0:08:05.3 Wendy: So there's actually quite a bit of complexity, and so, in terms of the types of work and the skills that are being built, you have to tie it back to a taxonomy, there could be business rules. So, a part of what's being developed as critical thinking skills as well.\n\n0:08:22.9 Rob: As I mentioned before, this program has been underway for years, so, this podcast episode isn't meant to be an audio press release. The reason I wanted to bring Wendy on to discuss the program is because of a recent study measuring the effects of these efforts, a six-year randomized control trial conducted by MIT and Innovations for Poverty Action, a research and policy nonprofit promoting effective solutions to global poverty. Wendy explained some findings from the report, and whether those findings were in line with initial goals.\n\n0:08:55.4 Wendy: The thing that we are really trying to understand or MIT was trying to understand is this purposeful hiring model that this part of Sama's mission, that's core to the way that we operate, is that intervention of purposely hiring somebody from an underserved community, does that actually improve their employability and their income rates in the long term? Does it actually break the poverty cycle that I was talking about before, or would these people just would have succeeded anyways?\n\n0:09:18.5 Wendy: So when we talk about really, how do you measure that, it's called a counterfactual study, which, when friends ask, \"Well, what do you mean? What is an RCT? Why did you do this study\", it's kind of like, the FDA does it for drug approvals, right? Somebody takes a placebo, somebody takes the medicine, and then you find out at the end, well, did the medicine really work? And so that's really what we're trying to do here. Did this purposeful intervention of hiring, did it make a difference in somebody's employability and growth and income?\n\n0:09:46.0 Wendy: The study wasn't just a matter of, \"Hey, let's take some surveys.\" It's actually even something in the works for six years. So we plan for a year, a year and a half, to identify folks and create a very detailed study, three years of actually surveying people on a regular basis. So, fun fact, over 2000-plus hours of surveying time [chuckle] and interviews and calls. But at the end of the day, the idea was to say, \"Did the intervention work? Is there a meaningful and material difference, and do we have all over the data over time to prove it?\" I believe all of our internal tracking that yes, we were, so it was amazing to get that ratified, that, yes, indeed, over the long term, this purposeful hiring model made a huge difference in terms of income and employment levels. But in particular for women, that was the thing that was really exciting to learn, and that was a little bit surprising, is that Sama's model has been to create a purposeful higher model of 50% women and 50% youth.\n\n0:10:48.0 Wendy: And we focused there from a mission perspective, because what I think has been well-researched and understood is that when women are lifted up in the economy and when women are lifted up in income, they contribute back to their communities, more kids go to school, there's a real network effect of investing in women. And so that was part of our purposeful hiring model, to where we have a criteria in hiring at least 50% women, which is a little bit unique, and again, purposeful. And what we found is that after this three-year time frame, there was a 60% improvement in employability and income rates for women who went through the Sama intervention versus who did not. And that was really exciting. Really, really exciting to see that that basically means that our hypothesis that women have barriers to entry and employment is indeed true, but that the purposeful hiring model at the beginning of their careers actually makes a difference in them not only having greater income but continuing to stay employed.\n\n0:11:46.5 Rob: When you look at the impact these studies showed with women specifically, was that surprising or just delighting?\n\n0:11:54.7 Wendy: It was delighting. We did a lot of community surveys before launching this program, because let's not just assume we know what people need, that's the entire point of financial independence, let's hear from them what is needed, and what we found is that, in particular, it was just really challenging for women to get into the right networks, to get jobs. And so, this was the model between that and knowing that the impact that women can have when they are lifted up, but I think what was surprising is not just the income levels, but I think what surprised me was the employment levels. I mean, 60% is significant. So, yeah, I was delighted, [chuckle] to answer your question.\n\n0:12:34.3 Rob: Of course, the ability to do a job and the ability to get a job are vastly different skills. This was reflected in the report, as researchers found subjects who did not receive employment placement assistance had a much harder time finding work, even if they had the same technical training as others. So, does that mean mere up-skilling is not enough?\n\n0:12:57.2 Wendy: I think what that speaks to is that while training is incredibly important, that action, the purposeful hiring, is really kind of what moves the needle. I'm all for providing the training, and I think what we found is that what we're trying to do is, in addition to the core skills training, is gonna be, how do we help people match themselves to jobs, and there's some pretty incredible organizations out there who are specializing in this area, so we don't assume we've gotta figure it all out. [chuckle] We are working with partners to help us on things like the skills matching. But the key thing, you have to make those purposeful choices, so, oftentimes, I talk to our customers about the ethical AI supply chain, or really how you use impact criteria as part of how you make your buying decisions. And I think that's something that's incredibly important, because I know we're going to be a proof point and move tens of thousands and over time, hundreds of thousands, of people out of poverty, but imagine the world's biggest corporations are spending trillions of dollars in procurement. Imagine what they can do if they make those same purposeful hiring decisions. We can leave millions and tens of millions of people out of poverty.\n\n0:14:08.6 Wendy: We're doing this at Sama, but I would love for every company in the world to take the same approach, and if you're not in a position to make these purposeful hiring decisions, well, work with suppliers, use social impact criteria as part of how you make your buying decisions. So the more we can get this out there, that, \"Hey, the model works,\" makes a meaningful difference, it also has tremendous business benefits as well. What happens for us, we have incredible retention, and that has created more value in our AI platform. So there are many, many different reasons to take this approach, and from a social mission standpoint, we can build incredible technology, create incredible value from our products, and we can change lives at the same time.\n\n0:14:51.5 Rob: What do you foresee in terms of additional education beyond data labeling? When you look at further development for their up-skilling, do you foresee that being an offering over time?\n\n0:15:00.8 Wendy: Oh, yeah, absolutely. I love that you mentioned that. I hate to sound buzz wordy, if you will, but I mean, data is the new code. The skills that are being built here aren't just for, \"Okay, I can label\"; it's really about building not just those critical thinking skills, but the way that we move our workforce up the value chain is that they are building analytical skills. So gone are the days where our workforce would come in and be like, \"Oh, is there a dog in this picture?\" or something like that. They're doing way more sophisticated work, doing everything from training machine learning models and driving very sophisticated training data sets, to evaluating and quality sharing training data sets that have been produced by automation, all the way to identifying what's missing, do we have a representative and complete data set? So it's really about moving from labeling and taxonomies and workflows to analytics and beyond. So, yeah, there's a lot of exciting work ahead, and beyond the analytics and management, yes, data science, that is the next frontier.\n\n0:16:08.7 Rob: If data science is the next frontier, then any company seriously deploying it has an awesome responsibility, not just to make a great product, but to utilize this technological position to up-skill the next generation of talent, and do so in such a way that ensures representative, more diverse, more creative future for our industry.\n\n0:16:31.6 Wendy: Next time on How AI Happens:\n\n0:16:38.5 Speaker 3: There's a pretty substantial rules-based expert system that sits on top of this to help manage some of the downsides of the inherent biases we have in the data.\n\n0:16:53.0 Wendy: How AI happens is brought to you by Sama. Sama provides accurate data for ambitious AI, specializing in image, video, and sensor data annotation and validation for machine learning algorithms in industries such as transportation, retail, e-commerce, media, med tech, robotics, and agriculture. For more information, head to sama.com.","slug":{"_type":"slug","current":"podcast-episode-wendy-gonzales"},"tags":[{"_key":"lSFpOak0","label":"Impact","value":"Impact"},{"_key":"hJS7rXT4","label":"Podcast","value":"Podcast"}],"title":"New Podcast Episode: Sama CEO Wendy Gonzalez on Upskilling Talent from Developing Nations"},{"_createdAt":"2021-05-27T16:50:20Z","author":{"_id":"e8a1f3c6-0b07-4638-93d5-61a0924f32e3","avatar":{"_type":"image","asset":{"_ref":"image-2f8efc599a377bd580d0ae12f022a15e7e1acacd-632x676-webp","_type":"reference"}},"bio":"Amanda is the Content Marketing Manager at Sama, where each day she gets to learn about AI and how it’s transforming industry. She’s passionate about technology but periodically tries to get away from her computer to explore more analog things like collage and quilting.","name":"Amanda Durepos","slug":{"_type":"slug","current":"amanda-durepos"}},"config":{"description":"How AI Happens is a podcast by Sama featuring experts and practitioners explaining their work at the cutting edge of AI/ML.","openGraphImage":null,"title":"How AI Happens: A Podcast by AI Practitioners for AI Practitioners"},"estimatedReadingTime":2,"featured_image":{"_type":"image","asset":{"_ref":"image-1502043edcf701cb4267cb2f6d7c6edf8e0e0cad-2500x1313-png","_type":"reference"}},"plaintextBody":"How AI Happens is a podcast featuring experts and practitioners explaining their work at the cutting edge of AI/ML. Tune in to hear AI Researchers, Data Scientists, ML Engineers, and the leaders of today’s most exciting AI companies explain the newest and most challenging facets of their field.\n\n\n\nEvery day, most of us will touch AI in some way — whether at work, at home, or strapped to our wrists and in the palm of our hands. Applications of ML have seamlessly found their way into our lives and our businesses, thanks to a select few who have set out to reimagine how we work in virtually every industry.\n\nMany may understand how AI impacts their daily lives, but few know how to effectively build it.\n\nIn Sama’s new podcast, How AI Happens, we sit down with AI Researchers, Data Scientists, ML Engineers and the leaders of today’s most exciting AI companies to discuss the newest and most challenging facets of their field. \n\nFor our inaugural episode, we sat down with Adnan Khaleel, an HPC and AI expert from Dell. Adnan explains how Dell’s HPC customers are scaling out their AI implementations, how they balance speed vs. accuracy, and explores the parallelization of a radiology algorithm built to detect anomalous cells.\n\nListen and subscribe to How AI Happens on Apple Podcasts, Spotify, Amazon, Google Podcasts, or Overcast.\n\nHappy listening!","slug":{"_type":"slug","current":"how-ai-happens-podcast"},"tags":[{"_key":"TpMM6FVr","label":"Machine Learning","value":"Machine Learning"},{"_key":"sR9wjqUS","label":"AI Practitioners","value":"AI Practitioners"},{"_key":"5AlBk2XP","label":"Podcast","value":"Podcast"}],"title":"How AI Happens: A Podcast by AI Practitioners for AI Practitioners"}],"morePosts":[],"slug":"podcast","tagName":"Podcast","pageConfig":{"title":"Sama Blog | Training Data, AI and Impact Sourcing Insights","description":"From machine learning to training data strategy, the Sama blog covers research, news and other AI trends from thought leaders across the globe."}}},"__N_SSG":true}