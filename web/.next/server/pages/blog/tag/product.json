{"pageProps":{"config":{"footerNav":{"items":[{"_key":"f255606f8f25","_type":"navDropdownMenu","items":[{"_key":"76389ad94cbb","_type":"navItem","title":"Autonomous Transportation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"training-data-for-autonomous-driving"}}}},{"_key":"5f64a8d6a69d","_type":"navItem","title":"E-Commerce","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"training-data-for-ecommerce"}}}},{"_key":"f10e54ae04d0","_type":"navItem","title":"AR/VR","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"training-data-for-ar-vr"}}}},{"_key":"fd729b522a77","_type":"navItem","title":"Data Quality","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"data-quality"}}}}],"title":"Guides","url":null},{"_key":"681ef7d8763a","_type":"navDropdownMenu","items":[{"_key":"6238a422b667","_type":"navItem","title":"Our Story","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-story"}}}},{"_key":"258985d6d46b","_type":"navItem","title":"Our Team","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-team"}}}},{"_key":"e0a76077324a","_type":"navItem","title":"Our Mission","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"mission-vision-values"}}}},{"_key":"239e49661b0d","_type":"navItem","title":"Careers","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"careers"}}}},{"_key":"e005a740cd80","_type":"navItem","title":"Contact","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"company-contact"}}}}],"title":"Company","url":null}]},"logo":{"asset":{"_createdAt":"2021-10-29T18:38:04Z","_id":"image-e20f8cc53e5f74df10ae9a822edb7ec2c4d00f02-2380x636-svg","_rev":"yuZxWYwFNB6KJB4TM9NtaY","_type":"sanity.imageAsset","_updatedAt":"2021-10-29T18:38:04Z","assetId":"e20f8cc53e5f74df10ae9a822edb7ec2c4d00f02","extension":"svg","metadata":{"_type":"sanity.imageMetadata","dimensions":{"_type":"sanity.imageDimensions","aspectRatio":3.742138364779874,"height":636,"width":2380},"hasAlpha":true,"isOpaque":false,"lqip":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAYAAABFA8wzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAr0lEQVQYlU3QyUoDQBAE0HeIEjeixAVyESRI3BNFJSZxAU/+/wdJQSEehu6Zqa6uKnjBGz7xgTuc4gAj7LWe4LD9cc8Y+9jBUed84QGrEt/gEleYY9Ylr3jGU/tV77fFLirId0nWBYYgoACi+r3D6YPN0vwFm4VxmNlgfkK4qcLUZdVMcdHB+75FzWPfzzCpxXNcFxuOP2uxnhNLASaX5LjbnJJf6jYG2PpXh812/AvSEQ+GGZqgYgAAAABJRU5ErkJggg==","palette":{"_type":"sanity.imagePalette","darkMuted":{"_type":"sanity.imagePaletteSwatch","background":"#040404","foreground":"#fff","population":100.29,"title":"#fff"},"darkVibrant":{"_type":"sanity.imagePaletteSwatch","background":"#424242","foreground":"#fff","population":0,"title":"#fff"},"dominant":{"_type":"sanity.imagePaletteSwatch","background":"#040404","foreground":"#fff","population":100.29,"title":"#fff"},"lightMuted":{"_type":"sanity.imagePaletteSwatch","background":"#4c4c4c","foreground":"#fff","population":0,"title":"#fff"},"lightVibrant":{"_type":"sanity.imagePaletteSwatch","background":"#bcbcbc","foreground":"#000","population":0,"title":"#fff"},"muted":{"_type":"sanity.imagePaletteSwatch","background":"#4c4c4c","foreground":"#fff","population":0,"title":"#fff"},"vibrant":{"_type":"sanity.imagePaletteSwatch","background":"#7f7f7f","foreground":"#fff","population":0,"title":"#fff"}}},"mimeType":"image/svg+xml","originalFilename":"image.svg","path":"images/76e3r62u/production/e20f8cc53e5f74df10ae9a822edb7ec2c4d00f02-2380x636.svg","sha1hash":"ae6a56857a230101a883a9b93974923879775bc9","size":2009,"uploadId":"mtOtmqAQnCEIG5cEqXZ1YAOCuqHJ4X3g","url":"https://cdn.sanity.io/images/76e3r62u/production/e20f8cc53e5f74df10ae9a822edb7ec2c4d00f02-2380x636.svg"}},"mainNav":{"items":[{"_key":"58c18e9aa9ea","_type":"navDropdownMenu","items":[{"_key":"b5b5b8bee78b","_type":"navCat","items":[{"_key":"0e80156a2f1a","_type":"navItem","title":"How it Works","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"how-it-works"}}}},{"_key":"40bacee029b4","_type":"navItem","title":"Video Annotation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"video-annotation"}}}},{"_key":"32650ef07503","_type":"navItem","title":"Image Annotation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"image-annotation"}}}},{"_key":"fe9137cd0167","_type":"navItem","title":"3D & LiDAR Annotation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"3d-lidar"}}}},{"_key":"d9a1316d400a","_type":"navItem","title":"Natural Language Processing","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"natural-language-processing"}}}},{"_key":"ac12c7c5d70a","_type":"navItem","title":"Data Curation (Beta)","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"data-curation"}}}}],"title":"Platform","url":null},{"_key":"37ff4fa913bd","_type":"navCat","items":[{"_key":"6026b1a9314e","_type":"navItem","title":"Semantic Segmentation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"semantic-segmentation"}}}},{"_key":"f4611b19b406","_type":"navItem","title":"Polygons","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"polygons"}}}},{"_key":"5155d874d6c8","_type":"navItem","title":"Bounding Boxes","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"bounding-boxes"}}}},{"_key":"9ef3c1e21e74","_type":"navItem","title":"Key Points","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"key-points"}}}},{"_key":"314d4c00d351","_type":"navItem","title":"Cuboids","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"cuboids"}}}},{"_key":"8e17a6388d74","_type":"navItem","title":"Lines & Arrows","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"lines-and-arrows"}}}}],"title":"Shapes","url":null}],"title":"Platform","url":null},{"_key":"112867ca4d03","_type":"navDropdownMenu","items":[{"_key":"22699c7e06cb","_type":"navItem","items":null,"title":"Transportation & Navigation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"transportation-navigation"}}}},{"_key":"122ae5928d6d","_type":"navItem","items":null,"title":"Retail & E-Commerce","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"retail-ecommerce"}}}},{"_key":"7bb234b69fb0","_type":"navItem","items":null,"title":"Consumer & Media","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"consumer-media"}}}},{"_key":"33e6a886b39d","_type":"navItem","items":null,"title":"Biotech & Medtech","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"biotech-medtech"}}}},{"_key":"d095b2619c4e","_type":"navItem","items":null,"title":"Robotics & Manufacturing","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"robotics-and-manufacturing"}}}},{"_key":"2c4b82a94d79","_type":"navItem","items":null,"title":"Food & Agriculture","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"training-data-food-agriculture"}}}}],"title":"Industries","url":null},{"_key":"c47e8763a906","_type":"navDropdownMenu","items":[{"_key":"1d563df30b3f","_type":"navItem","items":null,"title":"Quality","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"quality-training-data"}}}},{"_key":"041725f35d96","_type":"navItem","items":null,"title":"Security","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"security-and-trust"}}}},{"_key":"fd64ede25798","_type":"navItem","items":null,"title":"Ethical AI","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-impact"}}}},{"_key":"398dcbb1c95d","_type":"navItem","items":null,"title":"Compare","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"compare"}}}},{"_key":"93bdfdd87879","_type":"navItem","items":null,"title":"Partners","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"partners"}}}}],"title":"Why Sama","url":null},{"_key":"1d38bf63df54","_type":"navDropdownMenu","items":[{"_key":"be81659b38a5","_type":"navItem","items":null,"title":"API Documentation","url":{"_type":"link","externalUrl":"https://docs.sama.com/reference/overview","internalLink":null}},{"_key":"2cec80e94962","_type":"navItem","items":null,"title":"Blog","url":{"_type":"link","internalLink":null,"internalLink_custom":"/blog"}},{"_key":"09e284fcb1d3","_type":"navItem","items":null,"title":"Events","url":{"_type":"link","internalLink":null,"internalLink_custom":"/events"}}],"title":"Resources","url":null},{"_key":"dbee93713c19","_type":"navDropdownMenu","items":[{"_key":"12d594a568bf","_type":"navItem","items":null,"title":"Our Story","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-story"}}}},{"_key":"ce36540a102d","_type":"navItem","items":null,"title":"Our Team","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-team"}}}},{"_key":"34fc328e8022","_type":"navItem","items":null,"title":"Careers","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"careers"}}}},{"_key":"c1fe2961020a","_type":"navItem","items":null,"title":"Contact","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"company-contact"}}}},{"_key":"ebd81873e538","_type":"navItem","items":null,"title":"Press","url":{"_type":"link","internalLink":null,"internalLink_custom":"/press"}}],"title":"Company","url":null}],"nav_cta":{"_type":"button","link":{"_type":"link","internalLink":{"_ref":"136788cb-06a6-4f27-b75b-07faf403bfa6","_type":"reference"}},"title":"Request a Demo","type":"secondary"}}},"data":{"firstLoad":[{"_createdAt":"2021-06-22T15:12:25Z","author":{"_id":"f972de8a-10c1-45e3-97c9-ac490eaceabe","avatar":{"_type":"image","asset":{"_ref":"image-4aa17073cfd70d2e8f7d8ed85325c14cb1519577-692x691-jpg","_type":"reference"}},"bio":"Loic has over 20 years of industry experience in the Cloud services and AI industry. At Sama he works as the VP of Research & Development. His experience includes Fortune 500 Companies such as Salesforce.com, Unity Technologies, and AT&T where he led the development of large scale AI, data analytics, and cloud solutions. Loic received his MS in computer science from UTBM, France.","name":"Loic Juillard","slug":{"_type":"slug","current":"loic-juillard"}},"config":{"description":"Sama's third annual Innovation Week is coming to a close, and once more, our teams have given us plenty to be excited about.","openGraphImage":{"_type":"image","asset":{"_ref":"image-c1343597ce10d9d908608f0be0204d0a0d9a09b2-1200x600-png","_type":"reference"}},"title":"Innovation Week: How Sama Builds a Culture of Experimentation"},"estimatedReadingTime":3,"featured_image":{"_type":"image","asset":{"_ref":"image-c1343597ce10d9d908608f0be0204d0a0d9a09b2-1200x600-png","_type":"reference"}},"plaintextBody":"At Sama, we are committed to building a platform that helps organizations bring their models to production more quickly. But succeeding in a field as nascent as AI requires more than just bright minds and an ambitious roadmap.\n\n\n\nA key ingredient to success – and one that is often overlooked – is a mindset of experimentation; a culture that encourages teams to solve issues in new and more efficient ways. Early on, we found that our teams thrive in this kind of environment, which is why this week, we’re wrapping up our third Innovation Week. \n\nThe concept is simple: for one week, anyone can work on a project they feel passionate about. During the week, you have free rein to work on whatever you please in whichever way you choose. There are no meetings and no interruptions. You are free to try new things, invent and learn. You can be part of a team or single-handedly run with your ideas.\n\nThis year, some exciting highlights include:\n\nA more efficient approach to video tracking and segmentation\n\nNew Smart Polygon tool that is able to greatly increase annotation efficiency\n\nEnhancing our platform through the introduction of a Sama CLI and data pre-processing capabilities\n\nThe atmosphere is incredible. The week starts with a kickoff, where everyone can present the problem they are trying to solve and how they are planning to solve it. The closing ceremony is called the “Grand Reveal,” where each individual or group demos what they worked on. It sometimes yields incredible presentations... other times, it doesn't.\n\nFreedom breeds creativity. These events have brought some of the most core and innovative components of our platform. Last year, over 50% of all Innovation Week projects were incorporated into our roadmap and implemented within the following two quarters. A perfect example of this is our MicroModel technology, which was initially borne from one of these projects. We now use this technology for Machine Assisted Annotation for deployments in the automotive and e-commerce industries.\n\nNot only does the event enhance our product, it also attracts talent. This year, we doubled our R&D team and are continuing to grow.\n\nInnovation Week gives our R&D team the space to do what they do best: observe, experiment and discover.\n\nInnovation Week is coming to a close, and once more, our teams have given us plenty to be excited about. As always, many of the projects are slated to appear on our platform. In particular, we saw lots of work around our new 3D LiDAR annotation automation and data processing… stay tuned for that.\n\nAt Sama, Innovation Week is designed to encourage experimentation by allowing teams to shift the focus from our immediate customer’s needs to a broader, more bold approach to Machine Learning. If that sounds fun to you, consider checking out the open roles on our R&D team here.","slug":{"_type":"slug","current":"innovation-week-2021"},"tags":[{"_key":"DWf2I8xz","label":"Machine Learning","value":"Machine Learning"},{"_key":"TUfn4bAi","label":"Product","value":"Product"},{"_key":"imL766wL","label":"AI Practitioners","value":"AI Practitioners"}],"title":"Innovation Week: How Sama Builds a Culture of Experimentation"},{"_createdAt":"2021-03-23T19:00:21Z","author":{"_id":"4e2e7cef-d6eb-4bb7-bd39-375c6299677e","avatar":{"_type":"image","asset":{"_ref":"image-f1a274bcfdb5e70d814f1bab2b6bbd644728e9be-1480x1462-jpg","_type":"reference"}},"bio":"With a background in Computer Science, Abha leads the Customer Success Engineering team at Sama. The team is responsible for managing technical relationships with customers and prospects to understand their business needs, ideate upon them, and manage the implementation and communication of the solutions developed. ","name":"Abha Laddha","slug":{"_type":"slug","current":"abha-laddha"}},"config":{"description":"Sama is an expert in efficiently designing annotation guidelines that enhance data quality. Gold Tasks refer to tasks that have been annotated perfectly.","openGraphImage":null,"title":"Sama's Gold Tasks: ML Training Data with Gold-Standard Quality"},"estimatedReadingTime":4,"featured_image":{"_type":"image","asset":{"_ref":"image-2be5ee7e7ae0847f3bedec01bb88266c371e3eb9-4000x2250-jpg","_type":"reference"}},"plaintextBody":"Several methods exist to help companies define and measure data quality. To define the correct annotation of given data, you want to start by creating annotation guidelines. On top of proposing a multi-level quality checks system, Sama’s experts have built unique know-how in efficiently designing annotation guidelines that enhance data quality.\n\nCue Gold Tasks; referring to tasks that have been annotated “perfectly” or meet the “gold standard”. Such tasks are often used by the client to communicate their expectations around precision and quality used as examples during training. At Sama, we use Gold Tasks in two more ways: During training, to assess annotators and identify those who are ready to move into production and during production to generate an automated metric on quality.\n\nGold Assessments\n\nEvery project launch at Sama is accompanied with a period of training, where annotators focus on requirements for the specific workflow, familiarizing themselves with the taxonomy, accuracy levels needed, and edge cases. Gold tasks come in as they move from classroom training to practice tasks.\n\nA gold set is created that is representative of the overall complexity of the dataset, ensuring a healthy mix of the edge cases. annotators practice on this set of which we already have “gold” answers. As each task is submitted we are able to compare the annotator answers with the gold task, generating custom metrics and error tags. The metrics are determined by the type of workflow and tool used, for e.g. in a semantic segmentation workflow, we focus on IoU calculations per label and depending on the client rubric each label may be weighed differently.\n\nThese metrics are then used to create trends and analyze each annotator’s performance individually, and provide relevant feedback. We are able to analyze trends at an asset label (which type of images are more difficult than others?), annotator level (which annotator is struggling exactly where?), and the impact of time (was today better than yesterday?).\n\nGold assessments, therefore, help us accelerate training by providing customized feedback to each annotator early on and allowing us to track their improvement over time. This enables Sama to quickly identify doubts, find edge cases, and have high confidence that annotators are ready to move on to production. Lastly, this allows us to calibrate and train the manual QAs on the specifics of this particular workflow, ensuring that nothing is missed.\n\n\nGold Metrics\n\nSimilar to gold assessments, gold metrics compare an annotator’s tasks against a known, completed task. These tasks, however, are interspersed within the production queue with the annotators unaware that these are gold tasks. These tasks then act as tests for the annotators, generating similar metrics as mentioned above. This allows the team to report upon the annotator’s performance against the gold tasks that increase insight into quality and help to further tailor training and coaching.\n\nGold metrics are most useful for clients looking to automate the quality loop on their side. Given that their Sama project team consistently samples and approves only high quality tasks, it is a neat way for them to save time and capacity.\n\nBecause no two AI projects are alike, you need to make sure that your quality assurance (QA) process is designed to meet the unique needs of your particular project. Learn more on how to supercharge your data quality with Sama's Automated Quality Accelerators. ","slug":{"_type":"slug","current":"sama-gold-tasks"},"tags":[{"_key":"YSoeJ1Gj","label":"Product","value":"Product"},{"_key":"AHeszSpi","label":"Training Data","value":"Training Data"},{"_key":"9nTBOCjn","label":"Data Annotation","value":"Data Annotation"},{"_key":"ku9OMDnM","label":"Data Quality","value":"Data Quality"}],"title":"Sama's Gold Tasks: ML Training Data with Gold-Standard Quality"},{"_createdAt":"2021-03-14T21:00:14Z","author":{"_id":"4e2e7cef-d6eb-4bb7-bd39-375c6299677e","avatar":{"_type":"image","asset":{"_ref":"image-f1a274bcfdb5e70d814f1bab2b6bbd644728e9be-1480x1462-jpg","_type":"reference"}},"bio":"With a background in Computer Science, Abha leads the Customer Success Engineering team at Sama. The team is responsible for managing technical relationships with customers and prospects to understand their business needs, ideate upon them, and manage the implementation and communication of the solutions developed. ","name":"Abha Laddha","slug":{"_type":"slug","current":"abha-laddha"}},"config":{"description":"Automated quality accelerators are technology innovations that are focused on reducing the amount of manual quality assurance time spent in QA processes.","openGraphImage":null,"title":"Supercharge Your Data Quality with Automated Quality Accelerators"},"estimatedReadingTime":4,"featured_image":{"_type":"image","asset":{"_ref":"image-0353ebdd4cd94e4e29f102019edc39fb91d77499-4485x2522-png","_type":"reference"}},"plaintextBody":"Let’s start at the beginning. What are automated quality accelerators and why should we care? Automated quality accelerators are technology innovations that are focused on reducing the amount of manual quality assurance time spent in QA processes. They may be used to expedite annotator education, generate automated measures of annotation quality, and prevent logical fallacies. Our accelerators are integrated into our Sama training data platform and can be customized for unique use cases and needs by our dedicated Customer Success Engineering team.\n\nWhile it’s key to have a human in the loop when creating and verifying training data, automating processes within the workflow improves efficiency while guaranteeing high quality, saving everyone time and money. Quality accelerators also focus the effort of Sama’s annotators towards the most challenging aspect of the task, minimizing the volume of manual rework they need to do, and catching mistakes early in the process —equipping them to do their job well. Ultimately, automated quality accelerators enable us to deliver super high-quality data for complex use cases in the most efficient manner.\n\n\n\nAutomated Quality Accelerators at Sama\n\nAutomated Logic Checks:\n\n\n\nAutomated Logic checks are triggered before a task is submitted on Sama by our annotators. Each task is assessed using a fixed set of rules to check for invalid combinations of labels within a shape, across all shapes, and dependencies with the metadata. These rules are flexible and customized to each workflow, focusing on all errors types that don’t need human judgement. If an error is found, the annotator needs to fix the task before it can be submitted. To help the annotator to fix the task and learn from their mistake, a message is displayed which contains shape specific error tags.\n\nAuto logic checks are optimized for different kinds of errors, including but not limited to:\n\nInvalid answer combinations: Combinations that the ontology prevents, for example more than two wheels being tagged on an item labeled “bicycle.”\n\nUniqueness or preventing repetitions: More than one object in an image being assigned the same unique identifier or the same label when the ontology prohibits that. For example, two noses in a single person keypoints workflow.\n\nSize requirements: Ensuring that size specifications are met. For example, guaranteeing consistent size in a 3D workflow where constant cuboid size is required or enforcing a minimum pixel rule\n\nRelational checks: Given attributes and sub-attributes, ensure that values selected aren’t contradictory. For example, a bicyclist polygon isn’t grouped/attached to a car bounding box\n\nThese checks are incredibly efficient for the following reasons:\n\nCreate an instant feedback loop to prevent logical fallacies, which helps annotators improve and get it right the first time\n\nPrevents errors that may be impossible to detect by a manual QA review processes\n\nReduces time spent by manual QAs and allow them to focus on the more critical errors or sample more tasks\n\nHelps annotators to adapt quickly to changing project instructions, ensuring that new instructions are being followed and are understood correctly\n\nLastly, it improves overall TPT and reduces the time from task creation to delivery\n\nUnder a strictly manual process, highly skilled quality assurance annotators would need to review and provide feedback manually. While the latter process is still a vital part of our human-in-the-loop data annotation, auto logic checks free up their expertise to focus on more subjective errors and edge cases.\n\nOur enterprise-level clients are successfully using Sama Quality Accelerators to realize extremely high data quality for their most complex use cases, improving overall model performance. Now is the time to supercharge your data quality.","slug":{"_type":"slug","current":"data-quality-with-auto-q-a"},"tags":[{"_key":"5AiNXS1h","label":"Product","value":"Product"},{"_key":"Izvu8Acj","label":"Training Data","value":"Training Data"},{"_key":"6O3wnuJC","label":"Data Quality","value":"Data Quality"}],"title":"Supercharge Your Data Quality with Automated Quality Accelerators"},{"_createdAt":"2020-11-23T16:48:22Z","author":{"_id":"10ead718-57e1-41a8-b846-da3c81cc323a","avatar":{"_type":"image","asset":{"_ref":"image-a4c79da81bb1e23ce10fba84ea2cba5efe67a2a5-200x200-webp","_type":"reference"}},"bio":"Currently a Director of Product Management at Sama, Saul is passionate about the intersection of technology and social impact. He manages Sama’s data labelling products to ensure high quality training data efficiently and reliably reaches our customers. Experienced in both product and professional services, Saul is a proven leader who takes a data driven approach to expanding Sama’s capabilities and features. When not at work, you can usually find Saul enjoying the outdoors and spending time with his family.","name":"Saul Miller","slug":{"_type":"slug","current":"saul-miller"}},"config":{"description":"Announcing our support for custom keypoint shapes in SamaHub, our training data platform trusted by the world's leading AI teams, for vector image and video annotation.","openGraphImage":null,"title":"Custom Keypoint Shapes for Vector Image & Video Annotation"},"estimatedReadingTime":3,"featured_image":{"_type":"image","asset":{"_ref":"image-0ea3313b4d00bb103e8441964eeb3968dfee2947-1144x644-png","_type":"reference"}},"plaintextBody":"As a leader in high-quality training data, Sama supports clients across various use cases and applications. The ability to identify specific keypoint landmarks and track their relationship to one another is unlocking some of the most interesting developments in computer vision technology. This includes motion tracking like human pose identification for virtual fitness trainers or sports analytics. It also includes facial landmarks for emotion analysis, facial verification security, or driver alertness detection. It could also include hand gesture control for AR/VR or sign language transcription.\n\nWe are thrilled to announce our support for custom keypoint shapes in our training data platform trusted by the world's leading AI teams, for vector image and video annotation. While Sama has long supported other vector shapes like bounding boxes, polygons, and cuboids, these keypoint use cases require custom shapes that have a predefined number and order of points. Sama can now be configured to support skeletons, hands, eyelids or any other complex custom shape. Each keypoint can have its own label, color, and connection to other points. Multiple keypoint shapes are supported on the same annotation project.\n\n\nOptimizing for Quality and Efficiency\n\nThis new capability optimizes quality and efficiency in producing ground truth training data for our clients. Our expert annotators have a facilitated drawing experience where the shape builds itself as they annotate each point. The correct label for each point is inferred from the order that it is placed so no extra time is spent assigning labels to each point. We see quality improvement from visualizing the annotations as a cohesive connected shape instead of as free standing individual points. The custom keypoint shape also always has the same number and order of points—this means that no points could ever be omitted or mislabeled. In addition to the quality benefits, our A/B testing showed an 27% decrease in annotation time on a skeleton image annotation workflow over individual points.\n\nCompleted annotation data is returned to our clients in a structured delivery format that contains information about each point, its relative order in the array and its connection to other points.\n\nIf you're currently working on a computer vision algorithm that requires high quality keypoint annotations on images or videos, make sure to read more on our platform page or get in touch with an expert to discuss your training data needs.","slug":{"_type":"slug","current":"custom-keypoint-shapes"},"tags":[{"_key":"T7HkzkJx","label":"Product","value":"Product"},{"_key":"j9XlG6o5","label":"Keypoints","value":"Keypoints"},{"_key":"o2UoWoaC","label":"Video Annotation","value":"Video Annotation"},{"_key":"3GbpMBcq","label":"Vector Annotation","value":"Vector Annotation"}],"title":"Custom Keypoint Shapes for Vector Image & Video Annotation"},{"_createdAt":"2020-04-02T20:30:00Z","author":{"_id":"6dd25391-26af-42ff-a2a2-f0778ce1b002","avatar":{"_type":"image","asset":{"_ref":"image-4e1c47984bb16cb0370855b6272663d6744216d3-450x450-jpg","_type":"reference"}},"bio":"Currently a Senior Product Manager at Sama, Audrey guides cross-functional teams to create thoughtful product solutions. She has guided teams of designers and engineers at HUGE Inc. and NBCUniversal, and monitored user analytics at the Wall Street Journal. With a BA in history from Harvard, an MA in anthropology from Columbia and an MBA from UNC Chapel Hill KFBS, Audrey is passionate a using technology and data analytics facilitate social impact and environmental solutions through technology.","name":"Audrey Boguchwal","slug":{"_type":"slug","current":"audrey-boguchwal"}},"config":{"description":"SamaHub's video and 3D object tracking with frame level labeling assists companies in quickly building models that better reflect real-world behavior.","openGraphImage":null,"title":"Object Tracking with Frame Level-Labeling"},"estimatedReadingTime":3,"featured_image":{"_type":"image","asset":{"_ref":"image-7eb4854393afff7be19269b7e8414936e411403f-5506x3671-jpg","_type":"reference"}},"plaintextBody":"We live in an ever-changing world, where AI-enabled technology has become a new normal for society. To assist top organizations in their efforts to build smarter computer vision algorithms, we’ve rolled out a new release for video and 3D object-tracking in our leading data annotation platform.\n\nThere are a number of applications that use computer vision to track how the world, and the objects in it, change overtime. For a self-driving car to navigate safely, it needs to track other moving objects on the road and make predictions about their future movement, so it can plan its driving path.\n\nAR and VR applications like video games need to track the motion of individual people to create a seamless digital experience. These vision applications have something in common: they all seek to understand the change in position, behavior and characteristics of unique objects over time.\n\nObject tracking annotation offers object tracking capabilities for complex scenarios, including path planning, traffic light status, sentiment analysis, etc.\n\nThis frame-level labeling technology allows unique objects to be dynamically tracked across a video or a sequence of 3D point cloud data from a Lidar sensor. Change in position and pose are captured with annotation shapes like cuboids, polygons and bounding boxes.\n\nSama supports custom label taxonomies for both the main object class (person, car, etc.) and dynamic labeling for other object characteristics that change over time, such as visibility percentage of an object or a specific set of characteristics like emotions. Sama’s built-in automated interpolation between video frames helps ensure efficient, high quality labeled training data for a variety of object tracking use cases.\n\nFor over 10 years, Sama has delivered turnkey, high-quality training data and validation to train the world's leading AI technologies. Video and 3D object tracking are no exception, and this update for video object tracking annotation in 2D RGB video and 3D Lidar data will continue to assist organizations in quickly building models that better reflect real-world behavior.\n\nSama has deep expertise working with training data for object tracking use cases across a variety of industries including autonomous vehicles, AR/VR, retail and e-commerce, communications, media and entertainment, to name just a few.\n\nDownload our solution brief to learn more about our secure training data annotation platform, or contact our team here.","slug":{"_type":"slug","current":"object-tracking-in-samahub-with-frame-level-labeling"},"tags":[{"_key":"OjIX5QKU","label":"Product","value":"Product"},{"_key":"2ZGxEWq0","label":"Video Annotation","value":"Video Annotation"},{"_key":"iBmdS1VE","label":"Training Data","value":"Training Data"},{"_key":"uZYhm6jx","label":"Data Annotation","value":"Data Annotation"}],"title":"Object Tracking with Frame Level-Labeling"},{"_createdAt":"2020-03-26T16:49:42Z","author":{"_id":"6dd25391-26af-42ff-a2a2-f0778ce1b002","avatar":{"_type":"image","asset":{"_ref":"image-4e1c47984bb16cb0370855b6272663d6744216d3-450x450-jpg","_type":"reference"}},"bio":"Currently a Senior Product Manager at Sama, Audrey guides cross-functional teams to create thoughtful product solutions. She has guided teams of designers and engineers at HUGE Inc. and NBCUniversal, and monitored user analytics at the Wall Street Journal. With a BA in history from Harvard, an MA in anthropology from Columbia and an MBA from UNC Chapel Hill KFBS, Audrey is passionate a using technology and data analytics facilitate social impact and environmental solutions through technology.","name":"Audrey Boguchwal","slug":{"_type":"slug","current":"audrey-boguchwal"}},"config":{"description":"Samasource is excited to launch the PII Data Anonymizer for video training data. This technology enables obscuring of sensitive information in training data.","openGraphImage":null,"title":"Keep it Secret, Keep it Safe: Announcing the PII Data Anonymizer"},"estimatedReadingTime":3,"featured_image":{"_type":"image","asset":{"_ref":"image-70afee37d4e99e8fac42e758c436c2f61d991a7d-1904x797-jpg","_type":"reference"}},"plaintextBody":"Sama is excited to launch the PII Data Anonymizer as part of our platform for video training data. This technology enables obscuring of sensitive, personally identifying information (PII) in training data.\n\nIn light of new laws like GDPR and CCPA, it’s important for companies building AI and ML technologies to carefully manage data with PII information. Obscuring PII helps Sama and our customers work to protect privacy.\n\nSama’s PII Data Anonymizer helps make more data available to train AI by keeping personally identifying information safe across a variety of data sources: People in camera images from retail spaces and public places, street-level images of people and license plates captured by vehicles, smart city applications on public transit and more.\n\nApplications for anonymization range from autonomous transportation, detailed customer demographics, customer data like clothing and emotion, people counters, and security.\n\nThis deep learning pre-annotation technology allows Sama to obscure faces and vehicle license plates that appear in data without the need for any human intervention. That means that private information remains private and is never seen by another person.\n\n\n\nWhen Sama receives customer data, it can be run through our anonymizer technology service before any labeling occurs. The service would automatically detect faces and license plates and obscure them, as well as blur faces and license plates so they are not recognizable.\n\nAlternatively, it can replace faces and license plates with realistic computer-generated avatars. This AI-generated content creates training data that looks like real-time data when people and vehicles are the primary objects of interest for the algorithm.\n\nUnlike manual blurring, Sama’s PII Data Anonymizer is run without a human examining the data, which contributes to the privacy of PII data. It is built on deep learning and is run within our technology platform, ensuring that customer data never leaves Sama’s secure cloud environment.\n\nFrom pilots to multi-year projects, Sama securely trains and validates computer vision and NLP models. We work on a range of use cases ranging from e-commerce to autonomous transportation, manufacturing, navigation, retail, AR/VR, and biotech. If your goal is to quickly build smarter AI, contact our team to discuss your training data needs.","slug":{"_type":"slug","current":"keep-it-secret-keep-it-safe-announcing-the-pii-data-anonymizer"},"tags":[{"_key":"4C8kDRnD","label":"Product","value":"Product"},{"_key":"sCm7cDGc","label":"Security & Trust","value":"Security & Trust"},{"_key":"w6zwqXk4","label":"Anonymization","value":"Anonymization"}],"title":"Keep it Secret, Keep it Safe: Announcing the PII Data Anonymizer"},{"_createdAt":"2019-07-11T22:00:00Z","author":{"_id":"6dd25391-26af-42ff-a2a2-f0778ce1b002","avatar":{"_type":"image","asset":{"_ref":"image-4e1c47984bb16cb0370855b6272663d6744216d3-450x450-jpg","_type":"reference"}},"bio":"Currently a Senior Product Manager at Sama, Audrey guides cross-functional teams to create thoughtful product solutions. She has guided teams of designers and engineers at HUGE Inc. and NBCUniversal, and monitored user analytics at the Wall Street Journal. With a BA in history from Harvard, an MA in anthropology from Columbia and an MBA from UNC Chapel Hill KFBS, Audrey is passionate a using technology and data analytics facilitate social impact and environmental solutions through technology.","name":"Audrey Boguchwal","slug":{"_type":"slug","current":"audrey-boguchwal"}},"config":{"description":"Samasource's revamped toolset for 2D image vector segmentation is ideal for computer vision projects using vector shapes to structure training data.","openGraphImage":null,"title":"Revamped 2D Vector Segmentation"},"estimatedReadingTime":null,"featured_image":{"_type":"image","asset":{"_ref":"image-31269a4f01b8e495d1ec30a473f063a4957254c6-5760x3840-jpg","_type":"reference"}},"plaintextBody":null,"slug":null,"tags":[{"_key":"oc26gThR","label":"Product","value":"Product"},{"_key":"8Uhzi08N","label":"Vector Annotation","value":"Vector Annotation"},{"_key":"W46d0x8z","label":"Training Data","value":"Training Data"},{"_key":"NwhOkizM","label":"Data Annotation","value":"Data Annotation"},{"_key":"46Go0q8m","label":"Data Quality","value":"Data Quality"}],"title":"Revamped 2D Vector Segmentation"},{"_createdAt":"2018-12-14T19:54:00Z","author":{"_id":"71091c91-664a-44a6-9474-acc40eb12457","avatar":{"_type":"image","asset":{"_ref":"image-bc776336801adf71e2599337e8d6f02186b109d0-500x500-jpg","_type":"reference"}},"bio":"Matthew leads the product team at Sama, responsible for the platform that enables Sama's AI/ML data enrichment teams, internal enterprise operations tools to ensure quality and scalability, and all new product initiatives for the evolution of algorithm development and human-powered automation.","name":"Matthew Landry","slug":{"_type":"slug","current":"matthew-landry"}},"config":{"description":"Training your AI in 3D","openGraphImage":null,"title":"Training Your AI in 3D"},"estimatedReadingTime":null,"featured_image":{"_type":"image","asset":{"_ref":"image-9a175242c5b6d9d34ab8d001420280c4279ffe11-1125x1500-jpg","_type":"reference"}},"plaintextBody":null,"slug":null,"tags":[{"_key":"C3ND2OEf","label":"Product","value":"Product"},{"_key":"dJfUvcIY","label":"Training Data","value":"Training Data"},{"_key":"Se91A2Xp","label":"Data Annotation","value":"Data Annotation"}],"title":"Training Your AI in 3D"},{"_createdAt":"2018-07-17T00:00:00Z","author":{"_id":"71091c91-664a-44a6-9474-acc40eb12457","avatar":{"_type":"image","asset":{"_ref":"image-bc776336801adf71e2599337e8d6f02186b109d0-500x500-jpg","_type":"reference"}},"bio":"Matthew leads the product team at Sama, responsible for the platform that enables Sama's AI/ML data enrichment teams, internal enterprise operations tools to ensure quality and scalability, and all new product initiatives for the evolution of algorithm development and human-powered automation.","name":"Matthew Landry","slug":{"_type":"slug","current":"matthew-landry"}},"config":{"description":"Announcing object tracking with video annotation","openGraphImage":null,"title":"Introducing Object Tracking with Video Annotation"},"estimatedReadingTime":null,"featured_image":{"_type":"image","asset":{"_ref":"image-af58edf394d9676203b9bc44284f08ccf52125a6-1000x1500-jpg","_type":"reference"}},"plaintextBody":null,"slug":null,"tags":[{"_key":"lFK49VoI","label":"Machine Learning","value":"Machine Learning"},{"_key":"uWZdY0Qc","label":"Product","value":"Product"},{"_key":"vbSgnXan","label":"Video Annotation","value":"Video Annotation"},{"_key":"NfB0x55k","label":"Data Annotation","value":"Data Annotation"}],"title":"Introducing Object Tracking with Video Annotation"}],"morePosts":[],"slug":"product","tagName":"Product","pageConfig":{"title":"Sama Blog | Training Data, AI and Impact Sourcing Insights","description":"From machine learning to training data strategy, the Sama blog covers research, news and other AI trends from thought leaders across the globe."}}},"__N_SSG":true}