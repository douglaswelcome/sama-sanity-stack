{"pageProps":{"config":{"footerNav":{"items":[{"_key":"f255606f8f25","_type":"navDropdownMenu","items":[{"_key":"76389ad94cbb","_type":"navItem","title":"Autonomous Transportation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"training-data-for-autonomous-driving"}}}},{"_key":"5f64a8d6a69d","_type":"navItem","title":"E-Commerce","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"training-data-for-ecommerce"}}}},{"_key":"f10e54ae04d0","_type":"navItem","title":"AR/VR","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"training-data-for-ar-vr"}}}},{"_key":"fd729b522a77","_type":"navItem","title":"Data Quality","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"data-quality"}}}}],"title":"Guides","url":null},{"_key":"681ef7d8763a","_type":"navDropdownMenu","items":[{"_key":"6238a422b667","_type":"navItem","title":"Our Story","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-story"}}}},{"_key":"258985d6d46b","_type":"navItem","title":"Our Team","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-team"}}}},{"_key":"e0a76077324a","_type":"navItem","title":"Our Mission","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"mission-vision-values"}}}},{"_key":"239e49661b0d","_type":"navItem","title":"Careers","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"careers"}}}},{"_key":"e005a740cd80","_type":"navItem","title":"Contact","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"company-contact"}}}}],"title":"Company","url":null}]},"logo":{"asset":{"_createdAt":"2021-12-09T21:42:35Z","_id":"image-4f4e2f86a8fad952c02dffffd7008aa35f83c850-2380x636-svg","_rev":"7Z7VDk3xHzg51hvomGzc99","_type":"sanity.imageAsset","_updatedAt":"2021-12-09T21:42:35Z","assetId":"4f4e2f86a8fad952c02dffffd7008aa35f83c850","extension":"svg","metadata":{"_type":"sanity.imageMetadata","blurHash":"D009jvfQfQfQfQfQfQfQfQfQ","dimensions":{"_type":"sanity.imageDimensions","aspectRatio":3.742138364779874,"height":636,"width":2380},"hasAlpha":true,"isOpaque":false,"lqip":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAYAAABFA8wzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAr0lEQVQYlU3QyUoDQBAE0HeIEjeixAVyESRI3BNFJSZxAU/+/wdJQSEehu6Zqa6uKnjBGz7xgTuc4gAj7LWe4LD9cc8Y+9jBUed84QGrEt/gEleYY9Ylr3jGU/tV77fFLirId0nWBYYgoACi+r3D6YPN0vwFm4VxmNlgfkK4qcLUZdVMcdHB+75FzWPfzzCpxXNcFxuOP2uxnhNLASaX5LjbnJJf6jYG2PpXh812/AvSEQ+GGZqgYgAAAABJRU5ErkJggg==","palette":{"_type":"sanity.imagePalette","darkMuted":{"_type":"sanity.imagePaletteSwatch","background":"#040404","foreground":"#fff","population":100.29,"title":"#fff"},"darkVibrant":{"_type":"sanity.imagePaletteSwatch","background":"#424242","foreground":"#fff","population":0,"title":"#fff"},"dominant":{"_type":"sanity.imagePaletteSwatch","background":"#040404","foreground":"#fff","population":100.29,"title":"#fff"},"lightMuted":{"_type":"sanity.imagePaletteSwatch","background":"#4c4c4c","foreground":"#fff","population":0,"title":"#fff"},"lightVibrant":{"_type":"sanity.imagePaletteSwatch","background":"#bcbcbc","foreground":"#000","population":0,"title":"#fff"},"muted":{"_type":"sanity.imagePaletteSwatch","background":"#4c4c4c","foreground":"#fff","population":0,"title":"#fff"},"vibrant":{"_type":"sanity.imagePaletteSwatch","background":"#7f7f7f","foreground":"#fff","population":0,"title":"#fff"}}},"mimeType":"image/svg+xml","originalFilename":"e20f8cc53e5f74df10ae9a822edb7ec2c4d00f02-2380x636.svg","path":"images/76e3r62u/production/4f4e2f86a8fad952c02dffffd7008aa35f83c850-2380x636.svg","sha1hash":"4f4e2f86a8fad952c02dffffd7008aa35f83c850","size":2009,"uploadId":"jTUF9DIFqAwpLJ0GcI9bRqb17D69QQlN","url":"https://cdn.sanity.io/images/76e3r62u/production/4f4e2f86a8fad952c02dffffd7008aa35f83c850-2380x636.svg"}},"mainNav":{"items":[{"_key":"58c18e9aa9ea","_type":"navDropdownMenu","items":[{"_key":"b5b5b8bee78b","_type":"navCat","items":[{"_key":"0e80156a2f1a","_type":"navItem","title":"How it Works","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"how-it-works"}}}},{"_key":"40bacee029b4","_type":"navItem","title":"Video Annotation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"video-annotation"}}}},{"_key":"32650ef07503","_type":"navItem","title":"Image Annotation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"image-annotation"}}}},{"_key":"fe9137cd0167","_type":"navItem","title":"3D & LiDAR Annotation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"3d-lidar"}}}},{"_key":"d9a1316d400a","_type":"navItem","title":"Natural Language Processing","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"natural-language-processing"}}}},{"_key":"ac12c7c5d70a","_type":"navItem","title":"Data Curation (Beta)","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"data-curation"}}}}],"title":"Platform","url":null},{"_key":"37ff4fa913bd","_type":"navCat","items":[{"_key":"6026b1a9314e","_type":"navItem","title":"Semantic Segmentation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"semantic-segmentation"}}}},{"_key":"f4611b19b406","_type":"navItem","title":"Polygons","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"polygons"}}}},{"_key":"5155d874d6c8","_type":"navItem","title":"Bounding Boxes","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"bounding-boxes"}}}},{"_key":"9ef3c1e21e74","_type":"navItem","title":"Key Points","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"key-points"}}}},{"_key":"314d4c00d351","_type":"navItem","title":"Cuboids","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"cuboids"}}}},{"_key":"8e17a6388d74","_type":"navItem","title":"Lines & Arrows","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"lines-and-arrows"}}}}],"title":"Shapes","url":null}],"title":"Platform","url":null},{"_key":"112867ca4d03","_type":"navDropdownMenu","items":[{"_key":"22699c7e06cb","_type":"navItem","items":null,"title":"Transportation & Navigation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"transportation-navigation"}}}},{"_key":"122ae5928d6d","_type":"navItem","items":null,"title":"Retail & E-Commerce","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"retail-ecommerce"}}}},{"_key":"7bb234b69fb0","_type":"navItem","items":null,"title":"Consumer & Media","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"consumer-media"}}}},{"_key":"33e6a886b39d","_type":"navItem","items":null,"title":"Biotech & Medtech","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"biotech-medtech"}}}},{"_key":"d095b2619c4e","_type":"navItem","items":null,"title":"Robotics & Manufacturing","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"robotics-and-manufacturing"}}}},{"_key":"2c4b82a94d79","_type":"navItem","items":null,"title":"Food & Agriculture","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"training-data-food-agriculture"}}}}],"title":"Industries","url":null},{"_key":"c47e8763a906","_type":"navDropdownMenu","items":[{"_key":"1d563df30b3f","_type":"navItem","items":null,"title":"Quality","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"quality-training-data"}}}},{"_key":"041725f35d96","_type":"navItem","items":null,"title":"Security","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"security-and-trust"}}}},{"_key":"fd64ede25798","_type":"navItem","items":null,"title":"Ethical AI","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-impact"}}}},{"_key":"398dcbb1c95d","_type":"navItem","items":null,"title":"Compare","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"compare"}}}},{"_key":"93bdfdd87879","_type":"navItem","items":null,"title":"Partners","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"partners"}}}}],"title":"Why Sama","url":null},{"_key":"1d38bf63df54","_type":"navDropdownMenu","items":[{"_key":"be81659b38a5","_type":"navItem","items":null,"title":"API Documentation","url":{"_type":"link","externalUrl":"https://docs.sama.com/reference/overview","internalLink":null}},{"_key":"2cec80e94962","_type":"navItem","items":null,"title":"Blog","url":{"_type":"link","internalLink":null,"internalLink_custom":"/blog"}},{"_key":"09e284fcb1d3","_type":"navItem","items":null,"title":"Events","url":{"_type":"link","internalLink":null,"internalLink_custom":"/events"}}],"title":"Resources","url":null},{"_key":"dbee93713c19","_type":"navDropdownMenu","items":[{"_key":"12d594a568bf","_type":"navItem","items":null,"title":"Our Story","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-story"}}}},{"_key":"ce36540a102d","_type":"navItem","items":null,"title":"Our Team","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-team"}}}},{"_key":"34fc328e8022","_type":"navItem","items":null,"title":"Careers","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"careers"}}}},{"_key":"c1fe2961020a","_type":"navItem","items":null,"title":"Contact","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"company-contact"}}}},{"_key":"ebd81873e538","_type":"navItem","items":null,"title":"Press","url":{"_type":"link","internalLink":null,"internalLink_custom":"/press"}}],"title":"Company","url":null}],"nav_cta":{"_type":"button","link":{"_type":"link","internalLink":{"_ref":"136788cb-06a6-4f27-b75b-07faf403bfa6","_type":"reference"}},"title":"Request a Demo","type":"secondary"}}},"data":{"firstLoad":[{"_createdAt":"2021-07-29T17:14:55Z","author":{"_id":"10ead718-57e1-41a8-b846-da3c81cc323a","avatar":{"_type":"image","asset":{"_ref":"image-a4c79da81bb1e23ce10fba84ea2cba5efe67a2a5-200x200-webp","_type":"reference"}},"bio":"Currently a Director of Product Management at Sama, Saul is passionate about the intersection of technology and social impact. He manages Sama’s data labelling products to ensure high quality training data efficiently and reliably reaches our customers. Experienced in both product and professional services, Saul is a proven leader who takes a data driven approach to expanding Sama’s capabilities and features. When not at work, you can usually find Saul enjoying the outdoors and spending time with his family.","name":"Saul Miller","slug":{"_type":"slug","current":"saul-miller"}},"config":{"description":"ML Assisted Annotation can help you generate high-quality pre-labeled and human-assisted annotations, for predictably higher quality data in half the time.","openGraphImage":null,"title":"ML Assisted Annotation Powered by MicroModels"},"estimatedReadingTime":7,"featured_image":{"_type":"image","asset":{"_ref":"image-65b7fac1b60586a0a7b9ff75006684e2c2467f1e-1800x900-png","_type":"reference"}},"plaintextBody":"Your machine learning model is only as good as the data it’s trained on. And with 80% of AI project time being spent training the large volume of data necessary to train a model, efficiency improvements early on in the process are sure to have compounding effects.\n\nAt Sama, we have a dedicated Machine Learning team working at the forefront of AI research to identify optimization opportunities just like this, so we can develop advanced annotation tools to smooth the path to production for our clients. One of the papers the team presented at last year’s CVPR—Human-Centric Efficiency Improvements in Image Annotation for Autonomous Driving—shared an approach to speeding up polygonal instance segmentation using ML.\n\nToday, this technology has been incorporated into our platform to make our clients’ labeling process more efficient.\n\nWe call it ML Assisted Annotation powered by our MICROMODEL technology, and it’s already helping clients predictably get higher quality training data in half the time.\n\nRead on for an overview of ML Assisted Annotation powered by MICROMODEL technology how it can help you develop models that are more scalable, robust and accurate – and can be brought into production more quickly.\n\nWhat is ML Assisted Annotation powered by MICROMODEL technology?\n\n\nML Assisted Annotation (MAA) powered by MICROMODEL technology is an architecture that allows Sama to expedite the labeling process by drawing from a library of models trained on specific use cases. MAA can be used to generate high-quality pre-labeled annotations, which annotators validate to help them continuously improve over time.\n\nThis powerful combination of skilled annotators and an AI-powered platform allows us to deliver a high standard of label quality to our customers every time, along with efficiency improvements and quicker time to market.\n\nHow it works\n\nIn order to understand how MAA works, we first need to discuss the DEXTR model. DEXTR, or “Deep Extreme Cut,” is a publicly available object segmentation model for images and videos. \n\n\n\nWe’ve outlined the DEXTR model and our approach in detail in this post.\n\n\n\nMany ML methods like DEXTR have been suggested to speed up the process of instance segmentation, but these are not typically tested in a high-scale production environment, nor are ML outputs easily edited by human annotators. This makes it difficult to confidently reach the label quality standards required to run a model in production.\n\nMAA combines the well-known DEXTR approach with a raster-to-polygon algorithm to make results easily editable by a human in the loop. We’ve found that this approach—which pairs skilled annotators with ML-powered automation—significantly increases labeling efficiency and quality.\n\nLet’s see what that looks like in practice, using an example from the Autonomous Vehicle industry.\n\nMachine-Assisted Polygon Annotation\n\n\n\nWhen an annotator logs into the Sama annotation platform, they are presented with this workspace. In this example, the workspace is customized to allow the annotator to draw instance segmentation polygons around each of these vehicles:\n\n\n\nYou’ll notice that there are several vehicles in this image. In a manual context, it could take a human several hours to deliver high-quality annotations of every single vehicle:\n\nWhat the manual annotation process would look like (sped up significantly): several clicks are required to draw a polygon around each of the vehicles.\n\n\n\nThis process is significantly accelerated with Machine-Assisted Polygon Annotation.\n\nThe model allows the annotator to use a crosshair tool to identify only four extreme points: left, right, top and bottom boundaries. These four clicks are the only inputs needed to create a heat map that is then sent to the inference server, returning an accurate prediction of a raster mask.\n\n\n\nWith Machine-Assisted Polygon Annotation, annotators only need to perform four clicks to produce an accurate raster mask prediction.\n\n\n\nMachine-Assisted Polygon Editing\n\n\n\nA polygon prediction can then be further refined by an annotator by switching into editing mode. This enables annotators to label precisely and ensure that high-quality requirements are met without compromise.\n\n\n\nIn this example, the raster mask prediction is edited by the annotator to ensure precise and high-quality labels.\n\n\n\nThis mode also enables annotators to use more than four extreme points in order to produce even more accurate predictions. A fifth user input point can easily be added, with the model immediately incorporating the new input to update its prediction.\n\nIf an ML model struggles to identify specific shapes, annotators can add a few more inference points to help result in a more accurate prediction, and then refine that prediction manually to ensure high-quality labels.\n\nResults from ML Assisted Annotation powered by MICROMODEL technology\n\n\nOur clients are already seeing impressive results from MAA powered by MICROMODEL technology:\n\nPredictably producing 94-98% IOU (Intersection over Union) accuracy\nBecause our models are pre-trained on specific use cases for better performance out of the gate, our clients are seeing a quicker time to accuracy.\n\n2-4x more efficient annotation process\nYou can clearly see above that using MAA over a more manual polygon labeling approach results in significant time savings. But it’s also an iterative process with a human annotator in the loop; modifications to the predictions get fed back into the training data pipeline to retrain the model, enabling it to perform better predictions over time.\n\n\nQuicker time to market\nThe end result for our clients is faster iterations and a quicker time to market. A more efficient annotation process results in more data returned quickly, and ultimately a significantly shorter path to production.\n\nWhat’s more: increasing the efficiency of this labor-intensive manual data annotation process reduces the barrier to entry for more ML teams... and not just those with large R&D budgets. Technology like this can also help democratize data labeling by driving down cost, so we can see even more deserving companies leverage AI to drive value for their business.\n\nSmall teams who are getting started with labeling may not have yet defined what type of annotations they need, or how much data they need to be successful. MAA can help them iterate more quickly, developing models in short increments rather than in large, cumbersome workstreams. The end result is a quicker time to value, and ultimately, to market — for organizations of all shapes and sizes.\n\nLearn more about ML Assisted Annotation powered by MICROMODEL technology by watching our recent webinar here, or reading more about it here.","slug":{"_type":"slug","current":"ml-assisted-annotation-micromodels"},"tags":[{"_key":"giPx682h","label":"Machine Learning","value":"Machine Learning"},{"_key":"JOgmW0AV","label":"Data Annotation","value":"Data Annotation"},{"_key":"45fExC0n","label":"Autonomous Transportation","value":"Autonomous Transportation"}],"title":"ML Assisted Annotation Powered by MicroModels"},{"_createdAt":"2021-06-22T15:12:25Z","author":{"_id":"f972de8a-10c1-45e3-97c9-ac490eaceabe","avatar":{"_type":"image","asset":{"_ref":"image-4aa17073cfd70d2e8f7d8ed85325c14cb1519577-692x691-jpg","_type":"reference"}},"bio":"Loic has over 20 years of industry experience in the Cloud services and AI industry. At Sama he works as the VP of Research & Development. His experience includes Fortune 500 Companies such as Salesforce.com, Unity Technologies, and AT&T where he led the development of large scale AI, data analytics, and cloud solutions. Loic received his MS in computer science from UTBM, France.","name":"Loic Juillard","slug":{"_type":"slug","current":"loic-juillard"}},"config":{"description":"Sama's third annual Innovation Week is coming to a close, and once more, our teams have given us plenty to be excited about.","openGraphImage":{"_type":"image","asset":{"_ref":"image-c1343597ce10d9d908608f0be0204d0a0d9a09b2-1200x600-png","_type":"reference"}},"title":"Innovation Week: How Sama Builds a Culture of Experimentation"},"estimatedReadingTime":3,"featured_image":{"_type":"image","asset":{"_ref":"image-c1343597ce10d9d908608f0be0204d0a0d9a09b2-1200x600-png","_type":"reference"}},"plaintextBody":"At Sama, we are committed to building a platform that helps organizations bring their models to production more quickly. But succeeding in a field as nascent as AI requires more than just bright minds and an ambitious roadmap.\n\n\n\nA key ingredient to success – and one that is often overlooked – is a mindset of experimentation; a culture that encourages teams to solve issues in new and more efficient ways. Early on, we found that our teams thrive in this kind of environment, which is why this week, we’re wrapping up our third Innovation Week. \n\nThe concept is simple: for one week, anyone can work on a project they feel passionate about. During the week, you have free rein to work on whatever you please in whichever way you choose. There are no meetings and no interruptions. You are free to try new things, invent and learn. You can be part of a team or single-handedly run with your ideas.\n\nThis year, some exciting highlights include:\n\nA more efficient approach to video tracking and segmentation\n\nNew Smart Polygon tool that is able to greatly increase annotation efficiency\n\nEnhancing our platform through the introduction of a Sama CLI and data pre-processing capabilities\n\nThe atmosphere is incredible. The week starts with a kickoff, where everyone can present the problem they are trying to solve and how they are planning to solve it. The closing ceremony is called the “Grand Reveal,” where each individual or group demos what they worked on. It sometimes yields incredible presentations... other times, it doesn't.\n\nFreedom breeds creativity. These events have brought some of the most core and innovative components of our platform. Last year, over 50% of all Innovation Week projects were incorporated into our roadmap and implemented within the following two quarters. A perfect example of this is our MicroModel technology, which was initially borne from one of these projects. We now use this technology for Machine Assisted Annotation for deployments in the automotive and e-commerce industries.\n\nNot only does the event enhance our product, it also attracts talent. This year, we doubled our R&D team and are continuing to grow.\n\nInnovation Week gives our R&D team the space to do what they do best: observe, experiment and discover.\n\nInnovation Week is coming to a close, and once more, our teams have given us plenty to be excited about. As always, many of the projects are slated to appear on our platform. In particular, we saw lots of work around our new 3D LiDAR annotation automation and data processing… stay tuned for that.\n\nAt Sama, Innovation Week is designed to encourage experimentation by allowing teams to shift the focus from our immediate customer’s needs to a broader, more bold approach to Machine Learning. If that sounds fun to you, consider checking out the open roles on our R&D team here.","slug":{"_type":"slug","current":"innovation-week-2021"},"tags":[{"_key":"DWf2I8xz","label":"Machine Learning","value":"Machine Learning"},{"_key":"TUfn4bAi","label":"Product","value":"Product"},{"_key":"imL766wL","label":"AI Practitioners","value":"AI Practitioners"}],"title":"Innovation Week: How Sama Builds a Culture of Experimentation"},{"_createdAt":"2021-05-27T16:50:20Z","author":{"_id":"e8a1f3c6-0b07-4638-93d5-61a0924f32e3","avatar":{"_type":"image","asset":{"_ref":"image-2f8efc599a377bd580d0ae12f022a15e7e1acacd-632x676-webp","_type":"reference"}},"bio":"Amanda is the Content Marketing Manager at Sama, where each day she gets to learn about AI and how it’s transforming industry. She’s passionate about technology but periodically tries to get away from her computer to explore more analog things like collage and quilting.","name":"Amanda Durepos","slug":{"_type":"slug","current":"amanda-durepos"}},"config":{"description":"How AI Happens is a podcast by Sama featuring experts and practitioners explaining their work at the cutting edge of AI/ML.","openGraphImage":null,"title":"How AI Happens: A Podcast by AI Practitioners for AI Practitioners"},"estimatedReadingTime":2,"featured_image":{"_type":"image","asset":{"_ref":"image-1502043edcf701cb4267cb2f6d7c6edf8e0e0cad-2500x1313-png","_type":"reference"}},"plaintextBody":"How AI Happens is a podcast featuring experts and practitioners explaining their work at the cutting edge of AI/ML. Tune in to hear AI Researchers, Data Scientists, ML Engineers, and the leaders of today’s most exciting AI companies explain the newest and most challenging facets of their field.\n\n\n\nEvery day, most of us will touch AI in some way — whether at work, at home, or strapped to our wrists and in the palm of our hands. Applications of ML have seamlessly found their way into our lives and our businesses, thanks to a select few who have set out to reimagine how we work in virtually every industry.\n\nMany may understand how AI impacts their daily lives, but few know how to effectively build it.\n\nIn Sama’s new podcast, How AI Happens, we sit down with AI Researchers, Data Scientists, ML Engineers and the leaders of today’s most exciting AI companies to discuss the newest and most challenging facets of their field. \n\nFor our inaugural episode, we sat down with Adnan Khaleel, an HPC and AI expert from Dell. Adnan explains how Dell’s HPC customers are scaling out their AI implementations, how they balance speed vs. accuracy, and explores the parallelization of a radiology algorithm built to detect anomalous cells.\n\nListen and subscribe to How AI Happens on Apple Podcasts, Spotify, Amazon, Google Podcasts, or Overcast.\n\nHappy listening!","slug":{"_type":"slug","current":"how-ai-happens-podcast"},"tags":[{"_key":"TpMM6FVr","label":"Machine Learning","value":"Machine Learning"},{"_key":"sR9wjqUS","label":"AI Practitioners","value":"AI Practitioners"},{"_key":"5AlBk2XP","label":"Podcast","value":"Podcast"}],"title":"How AI Happens: A Podcast by AI Practitioners for AI Practitioners"},{"_createdAt":"2021-04-16T00:13:26Z","author":{"_id":"88e43c38-2712-41d4-9df3-8656c163c4db","avatar":{"_type":"image","asset":{"_ref":"image-af1346669e45d7264a36f051c18aea76061725bb-1895x1894-webp","_type":"reference"}},"bio":"Kyra is passionate about world-changing tech and sustainability, and happiest when these come together (looking at you, Sama). Stereotypical Dutch, she enjoys urban cycling and eating stroopwafels.","name":"Kyra Harrington","slug":{"_type":"slug","current":"kyra-harrington"}},"config":{"description":"We asked experts working in the field about their thoughts on the role of humans in Machine Learning, and humans and the future of ML.","openGraphImage":null,"title":"Experts Explain: How to Think About Human-Centered Machine Learning"},"estimatedReadingTime":6,"featured_image":{"_type":"image","asset":{"_ref":"image-a780ec1434b6c9c7513e0346be3e51fea3b5961b-1800x1013-png","_type":"reference"}},"plaintextBody":"If, as many assume, AI is to take over many organizational roles from humans, it would have to develop considerably from its current standing. MIT has defined ‘human-centered AI’ as “the design, development, and deployment of systems that learn from and collaborate with humans in a deep, meaningful way”. Therefore, to become less ‘human-centered’, you would need an AI landscape in which smart algorithms do all the heavy lifting. We asked experts working in the field about their thoughts on the role of humans in Machine Learning, and humans and the future of ML.\n\nRemo, Senior Software Engineer at Apple, states: “ML as a part of software engineering is by definition human-centric. It is human-centric because it substitutes the work of humans. For example in the recommendation of music, the identification of spam, or in object recognition. ML is human-centric because it is often (or almost always) trained on human generated or at least labeled data. And it is human-centric because ML models are built and designed on top of people's inductive biases about the world. At the same time it is not human (or human centric) because it does not reason or think. It spots patterns but does not \"connect the dots.\" \n\nIndu Khatri, the Machine Learning Lead at financial giant HSBC echoed the point above: “I would break down ML problems into three parts. The first one being identifying the problem to which ML needs to be applied and defining a broad architecture about how ML models will solve the problem. The second stage is developing the ML models and the third stage is taking actions based on ML models, getting the feedback from your environment and improving the models further. Out of these three stages, I believe Stage one will always need some kind of human intervention. With the advent of AutoML the amount of human intervention is decreasing everyday. Finally, for decreasing the amount of human intervention in Stage three we would need to improve the sample efficiency of Reinforcement Learning so that our Models can map predictions to actions in a feasible way.”\n\nConversely, Staff ML / NLP Research Scientist at Stanford and former Senior Research Scientist at Uber AI, Piero Molino, suggested that moving away from a human-centric model would be a mistake. “I believe there are several friction points that can be automated, like the data/model interface, the model search, evaluation and monitoring, Ops in general. But what I would rather wish is for ML to become more human-centric in the sense that it should put more humans at the center of its strategy rather than increased efficiency, and that is achieved with more humans in the loop evaluation and data generation processes, more robustness and more fairness evaluations.”\n\nData Scientist at Gartner, Lavi Nigam, thinks we’re already fairly close to an AutoML model, which as the name suggests, would mean far less human-interaction needed. So much so, that we could only be a few years away from this coming to fruition. “When more and more intrinsic pieces of data science workflows are automated mathematically and programmatically. We already see AutoML models that can figure out the best model for your data with any constraint defined. As the AutoML advances, we will eventually see that human interference in model building will greatly reduce and result in more optimized models. Deployment automation and Model Tracking (both part of MLOps) are other areas of focus where human involvement will drastically reduce in the coming years.”\n\nShuo Zhang, Senior Machine Learning Engineer, Bose Corporation, agreed that we’re fairly close to an ML model which requires little human interaction. “There are many current techniques that make ML algorithms less dependent on human supervision by leveraging the intrinsic structures of large amounts of data, such as self supervision and unsupervised techniques.”\n\nTwo other experts we asked agreed that ML as a concept requires human intervention. Removing this wouldn’t be beneficial and could actually be the opposite. Jason Gauci, a Software Engineering Manager at Facebook stated that “ML should work hand-in-hand with people, not replace them or automate the things that they do without oversight.” This was somewhat echoed by Sean Xie, Director of AI at Pfizer: “Current technologies are still focused on solving narrowly defined and specific problems. There’s a long way to go to be less human-centric.”\n\nIf we were to move toward an AutoML/less human-centric model, how could it be done? Yaman Kumar, PhD Computer Science at the University of Buffalo suggested that you would need to “join forces with the philosophy, metaphysics and ethics department and see the field adopting human-centric vision right, left and centre. As long as both AI and philosophy departments are cutoff and work in their own silos, things will go on as-is. Recent times have shown green shoots where more and more people from philosophy backgrounds are entering the field and guiding key areas such as fairness in ML.”","slug":{"_type":"slug","current":"how-to-think-about-human-centered-machine-learning"},"tags":[{"_key":"pOB3rwcB","label":"Machine Learning","value":"Machine Learning"},{"_key":"v412ROa8","label":"Expert Advice","value":"Expert Advice"}],"title":"Experts Explain: How to Think About Human-Centered Machine Learning"},{"_createdAt":"2021-03-29T21:29:09Z","author":{"_id":"785c9b8f-1869-4ce3-9eaa-c53945aa9736","avatar":{"_type":"image","asset":{"_ref":"image-c187f0a84bc4d1a6870d3a7a8528f242920a33aa-309x343-webp","_type":"reference"}},"bio":"Aurelie Drouet leads Product Marketing at Sama. Hailing from France and with expertise in driving revenue growth for companies in the US and Latin America, Aurelie's expertise spans several countries. She previously led Strategic Partnerships at Dreem.","name":"Aurélie Drouet","slug":{"_type":"slug","current":"aurelie-drouet"}},"config":{"description":"87% of AI projects will never make it into production. Why? We asked ML experts.","openGraphImage":null,"title":"10 Experts on the Biggest Roadblocks to Bringing ML Models to Production"},"estimatedReadingTime":7,"featured_image":{"_type":"image","asset":{"_ref":"image-b5b41f578774ef4d9391188b97c960a4f9e43e2c-900x506-png","_type":"reference"}},"plaintextBody":"In its infancy, Machine Learning was hailed as a silver bullet, something that could solve your problems and automate tasks with high-quality output with less effort required than ever. It's been predicted that 87% of AI projects will never make it into production. Why? We asked ML experts what they believe to be the main reasons that ML projects fail.\n\n\n\nTL;DR:\n\nA disconnect between the science and real-world application of the ML solutions and business expectations.\n\nUnreasonable expectations from business hierarchies on both the outcome and cost of many ML projects .\n\nAiming to develop MLOps without due diligence and research into some of the challenges that could be faced along the way .\n\nTo make an ML project successful, we need to find the right problem, use the right data, and develop the right method. Many ML projects do not meet these three requirements.\n\nIt’s not easy for companies to find enough data to run useful and high quality ML models.\n\n\n\nLavi Nigam\nData Scientist, Gartner\n\n“The biggest reason for project failure is ML processes maturity. There are too many moving and distinct pieces in ML/DL workflows and they are not mostly tied intrinsically by a single tool/framework. Enterprises and open source projects are trying to bridge this gap and I feel in the next 3 years we will see good progress in this area. Open source end-to-end MLOps are very important since they will help with wider adoption just like Tensorflow did for deep learning. Another big issue which increases project failure is that currently data science is evolving and has not reached ‘enterprise ready consensus’ with regards to set practices for different domains.”\n\n\n\nSparkle R. \nAssociate Director Data Science, Johnson & Johnson\n\n“ML projects still fail because of the disconnect between the science and real-world application of the ML solutions and business expectations. We are now in a society that prefers to use the word ML to demonstrate prestige despite having no clear impact. While there are many other reasons that can contribute to a ML project’s failure, the major factors include: a lack of high-quality data, poorly designed research questions, overly optimistic business expectations and a disconnect between the developers, product owners, data scientist and the ML-based system end users.”\n\n\n\nRemo Storni\nSenior Software Engineer, Apple\n\n“The biggest reason for ML project failures are unreasonable expectations about what is possible and unreasonable optimism about the project. People have trouble expecting the unexpected. There are a number of ML projects that fail and often these are problems that ML can't easily solve properly right now like conversational AI. There is a much bigger number of problems where ML falls short of expectations or where the project hits unexpected data or engineering problems.”\n\n\n\nRavi Dalal \nSenior Computer Vision Engineer, Walmart\n\n“I think this happens because people don’t do enough prep work before starting the project. It doesn’t make sense to apply a deep learning model where a logistic regression can do the trick. So, HOMEWORK before starting the project is very critical for the success of any ML project”.\n\n\n\nPiero Molino\nStaff ML / NLP Research Scientist, Stanford University\n\n\"Because of the uncertainty baked in many parts of the machine learning development process. It is very difficult to assess beforehand if a machine learning project will succeed without analyzing the data, training initial models, evaluating them and then iterating. Product teams still don't know if there's enough signal in the data to begin with, how much data would they need, how expensive annotating it would be, and in many cases they don't have great ways to monitor and evaluate models. All these uncertainty sources, together with wrong expectations, may lead to failure of ML projects.\"\n\n\n\nManmeet Singh\nMachine Learning Lead, Apple\n\n“There are a variety of reasons ML projects fail. Sometimes ML projects are initiated without synergy on expectations, objectives, and success criteria of the project between the business and ML teams. There could be other reasons ranging from lack of expected data, expertise, limitations in the technology itself for certain domains. This is a long-term investment & hence clear strategy and leadership support are necessary for success.”\n\n\n\nJason Gauci\nSoftware Engineering Manager, Facebook\n\n“Many projects fail because people don't trade off the benefit of success with the consequence of failure. Imagine a smart garage door opener that could open your garage door in anticipation of your arrival. If it opens when you want, it saves a button press. But if it opens when you aren't around, someone can rob your house. Because of this extreme tradeoff, the model needs to be impossibly accurate because it's competing with a button press that is almost 100% accurate”\n\n\n\nZhiyong (Sean) Xie\nDirector, AI, Pfizer\n\n“Most people just tried to find nails with an existing hammer. To make an ML project successful, we need to find the right problem, use the right data, and develop the right method. Many ML projects do not meet these three requirements. There is also miscommunication between the ML scientists and domain experts. It is not easy to find enough data to train the model. New methods need to be developed based only on the problem and available data.”\n\n\n\nIndu Khatri \nMachine Learning Lead, HSBC\n\n“Most ML projects fail because of a lack of understanding among the Business Executives about how ML models apply to their business. This usually leads to ML teams not solving the right problem for the business and underwhelming results. I have heard about projects that are stuck in research because of unclear problem statements.”\n\n\n\nYaman Kumar\nPhD Computer Science, University of Buffalo\n\n“Projects failing in ML, in my opinion, is chiefly due to three reasons: under-specification, over-expectation and clean toy datasets. While most of our datasets are so clean that the models trained on them hardly work in the real conditions, the ones that do are marred by the hype surrounding AI and ML. Underspecification normally comes from a lack of maturity in the field.”","slug":{"_type":"slug","current":"10-experts-biggest-roadblocks-ml-production"},"tags":[{"_key":"fLUi1ttd","label":"Machine Learning","value":"Machine Learning"},{"_key":"1iCuMNwM","label":"Expert Advice","value":"Expert Advice"}],"title":"10 Experts on the Biggest Roadblocks to Bringing ML Models to Production"},{"_createdAt":"2021-01-22T23:06:59Z","author":{"_id":"88e43c38-2712-41d4-9df3-8656c163c4db","avatar":{"_type":"image","asset":{"_ref":"image-af1346669e45d7264a36f051c18aea76061725bb-1895x1894-webp","_type":"reference"}},"bio":"Kyra is passionate about world-changing tech and sustainability, and happiest when these come together (looking at you, Sama). Stereotypical Dutch, she enjoys urban cycling and eating stroopwafels.","name":"Kyra Harrington","slug":{"_type":"slug","current":"kyra-harrington"}},"config":{"description":"2021 Predictions: We asked a range of ML experts about what they believe will be the next big thing in AI and Machine Learning.","openGraphImage":null,"title":"What's next? 17 Machine Learning Predictions for 2021"},"estimatedReadingTime":10,"featured_image":{"_type":"image","asset":{"_ref":"image-21b9dcfd77e3eb1e777b3d499c73c89ddf24d454-1200x675-png","_type":"reference"}},"plaintextBody":"Large developments in AI and Machine Learning are normally announced as part of a campaign or during important keynote presentations, but we thought we would try and get a sneak peak into 2021 developments in the field. We partnered with our friends from RE•WORK by asking a range of experts in Machine Learning what they believe will be the next big thing. \n\n\n\nTushar Chugh\n\nMachine Learning Software Engineer, Google\nTushar’s predictions for 2021 are very much based on the outcome of work already underway. The former General Motors trailblazer suggested that he was on the lookout for the following in 2021: 1. The “rapid” training, evaluation and productionization for the large sequence models (such as GPT-3, T5). 2. The research towards developing giant ML models that can cater to multi-model inputs from various tasks and that can generalize well to the new tasks.\n\n\n\nZhiyong (Sean) Xie\n\nDirector, AI, Pfizer\nWith over 17 years at Pfizer working in AI, Sean has overseen tasks ranging from quantification of MRIs to multivariate analysis of disease progress and most recently, a global effort in drug safety assessments. When asked what he thought might be on the horizon for this year, Sean suggested “We may train the machine to predict the Machine Learning in 2021.” This rather funny response, if true, could see a move toward the automation in ML we have discussed for some years.\n\n\n\nAlireza Rostamzadeh\n\nData Science & Machine Learning, Apple\nAlireza’s predictions for the year ahead were quite something, and we love the sound of this! “2021 will be the year when we start to see more tangible ML-driven products; from significant improvements in self-driving cars to a wave of new products based on augmented reality”.\n\n\n\nShuo Zhang \n\nSenior Machine Learning Engineer, Bose Corporation\nWorking across NLP, Deep Learning and now ML, Shuo has a range of experience. When asked, Shuo suggested that while the question in itself is extremely broad, “I'd say that less dependence on human supervision by leveraging the intrinsic structures of large data is a path ML research is heading toward.” A step closer to the infamous automation buzzword.\n\n\n\nJason Gauci\n\nSoftware Engineering Manager, Facebook\nJason’s experience has spanned creative positions at Apple, Google and now Facebook, where he is working on a scalable reinforcement learning platform. When we asked Jason what he thought we could see in ML this year, he suggested “I predict that decision making AI will surge in popularity. Imagine an AI system that can tune constants in your code, or one that monitors your diet and suggests food. We have done a lot in the realm of signal processing but decision making continues to be an area with a lot of engineering trial-and-error.”\n\n\n\nSadid Hasan\n\nSenior Director of AI, CVS\n“In 2021, researchers would continue to take a leap in developing complex AI applications related to natural language understanding and generation by leveraging the ongoing advancements in multi-modal (text, speech, image) data fusion-based algorithms and more efficient transformer architectures. In addition, powerful synthetic data generation and augmentation techniques would enhance effective training of machine learning models by alleviating the challenges related to accessing sufficient ground-truth data. We would also see further emphasis on AI model’s ethicality, generalizability, explainability, and reproducibility along with efficient model Ops for a beneficial and robust on-device deployment. Furthermore, with the ongoing proliferation of healthcare data, the AI community would continue to build novel machine learning-based healthcare applications leading to increased AI adoption for providing meaningful decision-making support to end-users.”\n\n\n\nLavi Nigam \n\nData Scientist, Gartner\n“As more and more companies are heading towards AI/ML Maturity and working with more production scale ML/DL deployments, their focus in 2021 will be more on MLOps where they need to work on key aspects of processes like - Model/Data Drift Analysis, Model Interpretability, Data Governance, Model Scaling & AutoML. This year we will finally see many maturity models and practices for ML/DL operations coming up from different vendors and companies which will be very crucial in the long run.”\n\n\n\nBeat Raphael Schaad\n\nSenior Data Scientist, Sky\nThe Senior Data Scientist at Sky when asked his predictions for 2021 stayed very much on the hot topic of COVID. “The goal for 2021 is that Data can support governments beyond counting Covid19 cases and death rates. Given the recent events ML will have to improve massively in inference and causality issues. Forecasting methods using AI do not deliver anything on our historic events scenarios mainly because of the lack of explainability of the generated features.”\n\n\n\n\nIndu Khatri\n\nMachine Learning Lead, HSBC\n2021 will be the Year of MLOps. Many cloud services such as GCP's AI Platform, AWS's Sagemaker have matured over the past years and are readily adaptable by ML teams. In 2021 and beyond Data Scientists would have to work collaboratively with DEs/MLEs to take their beautiful models from lab to production and realize business value.\n\n\n\nPiero Molino\n\nNLP Research Scientist, Staff ML Team, Stanford\nThe former Senior ML practitioner at UBER, currently makes up part of Professor Chris Ré's Hazy Research group on ML systems in California. Piero suggested that in industry he believes “models will start to come closer instead of being in separate silos like it happens today in most cases. In academia, I believe there will be more research focused on robustness and generalization.”\n\n\n\nKiana Alikhademi \n\nResearch Assistant, University of Florida\n“The year 2020 has significantly changed our lives in many ways. The way we work, communicate and learn has been impacted in many significant ways. Artificial Intelligence continues to be a key technology trend when it comes to the things that will change how we live, work, and play in the near future. I predict that artificial intelligence will be the main technology in the following areas: If any threat such as COVID were to occur, then that should be detected ahead of time. To help businesses prepare for situations like this pandemic, we must understand how users behave during such an emergency.”\n\n\n\nDivya Sivasankaran\n\nSenior Machine Learning Engineer, Autodesk\n\"Over the last year, we've seen a lot of local AI startups being sold/acquired. Many are struggling to bring AI products to market. I believe the pandemic merely sped up the inevitable. The silver lining to me here is that we've managed to cut down on the hype (noise) giving us time and resources to focus on impact with tangible applications (signal). That's why I think 2021 will be the year we will start to see AI/ML features in production for real - i.e., AI will successfully make the transition from being a spice to a core ingredient.\"\n\n\n\nRavi Dalal\n\nSenior Computer Vision Engineer, Walmart\n“I think 2020 has changed the world around us in many ways, and the retail sector is no exception. The pandemic has taught everyone new ways of shopping whether it's online, curbside pickup or concierge services for senior members. And AI/ML has played a major role in shaping all these solutions everywhere. Going in 2021, I feel rather than quantity of data, the market will shift towards the quality of data being captured. As more and more data points are getting captured to make better ML models; need of the hour is to make light weight models that can run on edge devices to filter and capture just the meaningful data. I call it -- \"AI/ML for Intelligent Data collection.”\n\n\n\nShaina Raza\n\nResearch Assistant, Ryerson University\nShaina, a former lecturer and now Research Assistant in ML gave one of the more exciting predictions on the list, which would mean large scale change and positive development in the field in the months to come. “Machine Learning is going to be easier, cheaper and beyond the limitations. The exponential power of the computing resources will be in the hands of laymen, and we see the revolution of the world much more earlier than expected.”\n\n\n\nYaman Kumar\n\nPhD Computer Science, University of Buffalo\nYaman’s research in ML revolves around Adversarial Networks, Interpretability, QA and Speech and is supported by Google doctoral Fellowship. Yaman simply suggested three compartments of ML which he believes will develop rapidly in 2021. “Unsupervised Learning, Explainability, and Fairness in ML.” Surprisingly, it was the only mention of unsupervised learning, which has seen to become somewhat of a buzzword at the backend of 2020.\n\n\n\nJack Brzezinski\n\nChief AI Scientist at AI Systems & Strategy Lab\nI feel that the role of knowledge will be increasing. Structures, various knowledge representation types will be essential for the next wave of AI innovation. The lawmakers might soon require AI, ML models to be compliant with multiple statutes or regulations.\n\n\n2021 is set to be uncertain in many ways. However, as with last year, hard work behind the scenes in AI and ML continues. The range of optimistic yet realistic predictions above, if accurate, could see 2021 as a year in which some of the largest steps in AI and Machine Learning advancement for some years take place.\n\nWhat do you think could be developed this year?","slug":{"_type":"slug","current":"17-machine-learning-predictions-for-2021"},"tags":[{"_key":"94W8kEob","label":"Machine Learning","value":"Machine Learning"},{"_key":"CKYpD6ea","label":"AI","value":"AI"},{"_key":"CzXbg3oJ","label":"Expert Advice","value":"Expert Advice"}],"title":"What's next? 17 Machine Learning Predictions for 2021"},{"_createdAt":"2020-12-21T18:21:43Z","author":{"_id":"785c9b8f-1869-4ce3-9eaa-c53945aa9736","avatar":{"_type":"image","asset":{"_ref":"image-c187f0a84bc4d1a6870d3a7a8528f242920a33aa-309x343-webp","_type":"reference"}},"bio":"Aurelie Drouet leads Product Marketing at Sama. Hailing from France and with expertise in driving revenue growth for companies in the US and Latin America, Aurelie's expertise spans several countries. She previously led Strategic Partnerships at Dreem.","name":"Aurélie Drouet","slug":{"_type":"slug","current":"aurelie-drouet"}},"config":{"description":"If you have a passing interest or are just looking for a refresher in all things Machine Learning, we have put together a list of 10 books.","openGraphImage":null,"title":"10 Must-Read Machine Learning Books"},"estimatedReadingTime":9,"featured_image":{"_type":"image","asset":{"_ref":"image-bc8699367ba2089c548213191c632bbbe6c784a9-1280x640-png","_type":"reference"}},"plaintextBody":"With the year coming to a close and not many other things to do than to stay put at home, this holiday season could be the perfect time to dive deeper into some books. If you have a passing interest or are just looking for a refresher in all things Machine Learning, we have put together a list of 10 books. Although published at varying points in the development of Deep Learning and Machine Learning, each book offers unique insights. It was near impossible to narrow the list to just ten, but we couldn’t look past those below.\n\n\n1. Grokking Deep Learning\nAndrew W Trask (2009)\n\nGrokking Deep Learning is suggested to be a perfect place to delve into the subset of Machine Learning, not only describing and explaining APIs and frameworks, but also talking the reader through how they can actually build algorithms from scratch. This hands-on style of writing will help you build an AI capable of beating you in a classic game of Atari and Neural Networks capable of understanding basic images. While this is not a beginners guide, experience with calculus is not required, merely a high school level of mathematical understanding.\n\n2. The Hundred-Page Machine Learning Book\nAndriy Burkov (2019)\n\nAn all you need to know guide to Machine Learning in just 100 pages, what more could you need? The Director of Data Science at Gartner, Andriy, suggests that you are a mere read of this book away from being ready to build complex AI systems, pass an interview or start your own business. Also available on Kindle, the 2019 release covers gradient descent, cluster analysis, dimensionality reduction and more. Is it for you? Andriy suggests that it is suitable for those both working in the field and those dipping their toe to find out more about the increasingly complex field of Machine Learning.\n\n\n3. Introduction to Machine Learning with Python: A Guide for Data Scientists\nSarah Guido & Andreas C. Mueller (2016)\n\nAlthough released in 2016, this 400 word bible for Machine Learning gives a great grounding in the basics of ML, providing a thorough and hands-on approach to Python use in ML. Learn not only what the most important concepts and algorithms are, but also when and how to use them. Imperative topics including machine learning workflow: data preprocessing and working with data are covered, as well as training algorithms, evaluating results, and implementing those algorithms into a production-level system\n\n\n4. Machine Learning For Absolute Beginners: A Plain English Introduction\nOliver Theobold (2017)\n\nA curveball, maybe, as we realize that those reading this list may have experience in the field, however, Machine Learning for Absolute Beginners walks through ML history and works in plain english with no coding experience necessary. What exactly will you be learning? The very basics including, decision trees, regression analysis, data reduction, k-means and more, giving you a great underlying understanding of the building blocks used in Machine Learning and how they can be used. Finally, some career advice with Oliver talking you through career options and how best to utilize the ML knowledge just picked up post-read.\n\n\n5. Mathematics for Machine Learning\nMarc Peter Deisenroth (2020)\n\nThis textbook puts the normally disparate course style of teaching in Mathematics to shame, combining together all of the fundamental mathematical tools needed to understand machine learning, including linear algebra, analytic geometry, matrix decompositions, vector calculus, optimization, probability and statistics. These concepts are then used to derive four central machine learning methods: linear regression, principal component analysis, Gaussian mixture models and support vector machines, giving a brilliant starting point for those entering the field and those looking for a refresher. Alongside the textual information, this book also includes examples and tests to ensure the reader's understanding.\n\n\n6. Pattern Recognition and Machine Learning\nChristopher M. Bishop (2007)\n\nChristopher Bishop’s Pattern Recognition and Machine Learning presents approximate inference algorithms that permit fast approximate answers in situations where exact answers are not feasible. The first of its kind on pattern recognition to present the Bayesian viewpoint, uses graphical models to describe probability distributions, which at the time, was not evident in any other ML text. Unlike some of the other inclusions on this list, familiarity with multivariate calculus and basic linear algebra is required, and some experience in the use of probabilities would be helpful though not essential.\n\n\n7. Probabilistic Graphical Models: Principles and Techniques\nDaphne Koller & Nir Friedman (2009)\n\nA general framework for constructing and using probabilistic models of complex systems that would enable a computer to use available information for making decisions. This book isn’t for beginners, nor for the faint of heart as it dives right into probabilistic graphical models in detail, including Bayesian and Markov Networks, inference, and learning from complete / incomplete data. If you want to get the most out of this book, there’s an option to attend Daphne Koller’s lectures on Probabilistic Graphical Models at Stanford University, on Coursera. Fun fact, Koller is actually one of the founders of Coursera, an online education platform.\n\n\n8. Machine Learning: A Bayesian and Optimization Perspective (Net Developers)\nSergios Theodoridis (2015)\n\nThe book builds carefully from the basic classical methods to the most recent trends of the time, including chapters on pattern recognition, statistical/adaptive signal processing, statistical/Bayesian learning, as well as short courses on sparse modeling, deep learning, and probabilistic graphical models. All of the major techniques you’ll need to know prior to working in the field are covered, including Mean/Least-Squares regression and filtering, Kalman filtering, stochastic approximation and online learning, Bayesian classification, decision trees, logistic regression and boosting methods. Alongside all of the theoretical text, this book includes case studies, code to be experimented with and more.\n\n\n9. Machine Learning: A Probabilistic Perspective\nKevin P. Murphy & Francis Bach (2012)\n\nKevin describes this text as a comprehensive introduction to machine learning methods that use probabilistic models and inference as a unifying approach. This overview text combines breadth and depth, offering necessary background material on such topics as probability, optimization, and linear algebra as well as discussion of recent developments in the field, including conditional random fields, L1 regularization, and deep learning. Rather than providing a cookbook of different heuristic methods, the book stresses a principled model-based approach, often using the language of graphical models to specify models in a concise and intuitive way. Alongside this, the software platforms used in examples are freely available online. Unlike some of the other texts in this list, Machine Learning: A Probabilistic Perspective is suitable for upper-level undergraduates, giving an ideal introduction to ML and Mathematical formulas.\n\n\n10. Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems\nAurelien Geron (2019)\n\nIn the last few years, breakthroughs in Deep Learning have boosted the entire field of machine learning. Now, even programmers who know close to nothing about this technology can use simple, efficient tools to implement programs capable of learning from data. Through minimal use of theory and maximum practical examples, this text helps you gain an intuitive understanding of the concepts and tools for building intelligent systems. You'll learn a range of techniques, starting with simple linear regression and progressing to deep neural networks. With regular examples throughout, it’s a great book to not only grasp how and why it all works, but to also test it yourself.","slug":{"_type":"slug","current":"10-must-read-machine-learning-books"},"tags":[{"_key":"R9BEAeeH","label":"Machine Learning","value":"Machine Learning"},{"_key":"OUl8Z7DG","label":"Best of","value":"Best of"}],"title":"10 Must-Read Machine Learning Books"},{"_createdAt":"2020-11-18T19:05:07Z","author":{"_id":"88e43c38-2712-41d4-9df3-8656c163c4db","avatar":{"_type":"image","asset":{"_ref":"image-af1346669e45d7264a36f051c18aea76061725bb-1895x1894-webp","_type":"reference"}},"bio":"Kyra is passionate about world-changing tech and sustainability, and happiest when these come together (looking at you, Sama). Stereotypical Dutch, she enjoys urban cycling and eating stroopwafels.","name":"Kyra Harrington","slug":{"_type":"slug","current":"kyra-harrington"}},"config":{"description":"12 Influential Women Working in Machine Learning, 2020.","openGraphImage":null,"title":"12 Women in Machine Learning to Watch"},"estimatedReadingTime":9,"featured_image":{"_type":"image","asset":{"_ref":"image-3651ed4b3fa5305116eb19a08c7ca1ac4b1ce130-900x506-png","_type":"reference"}},"plaintextBody":"Global spend on AI is predicted to be $98 Billion by 2023, up from 37.5 Billion in 2019. Maybe not unexpected for those witnessing it up close, but a whopping growth trajectory nonetheless. While machine learning models strive to mirror and predict real life as closely as possible, the people behind these models don't represent the real world. Despite this rapid forecasted growth, women still only make up a 12% of the ML workforce.\n\nAt Sama we believe in inclusive AI that benefits everyone, and believe highlighting role models is a key part in this work. With that in mind, we put together a celebratory list of some of the women we look up to and have spearheaded development in AI and Machine Learning in 2020. While it was near impossible to narrow down our list, we highly encourage you to connect with them and follow their incredible work going into 2021.\n\n\n\nFeryal Behbahani, Research Scientist, DeepMind\n\nFeryal obtained her BEng from Heron-Watt University in 2006, later going on to receive her MSc in Artificial Intelligence and Doctor of Philosophy in Machine Learning from Imperial College London. Post graduation, Feryal worked as a mentor at OpenAI and as a Research Scientist for Latent Logic (now Waymo). In 2019, Feryal started working as a Research Scientist at DeepMind, alongside volunteering at the Women in Machine Learning initiative as a director. Freyal’s work is currently focussed on Reinforcement Learning.\n\n\n\nMartine Bertrand, Lead AI, Sama\n\nThe desire to understand the universe led Martine to study physics at the University of Ottawa where she ultimately completed a Ph.D. in 2012. She then held Post-Doctoral Fellowships at the University of Carleton and her alma mater before undertaking a career as an industrial Research Scientist. She tackled challenges in computational chemistry at the Chemical Computing Group, natural language processing at Stradigi AI, and medical imaging at Imagia before joining Sama as Lead AI where she now steers ML R&D efforts and guides the development of the MLOps infrastructure.\n\n\n\nJenny Sy, Data Scientist, USA for UNHCR\n\nCurrently working as a Data Scientist at the UNHCR, an organization which protects refugees and empowers them with hope and opportunity, Jenny is focussed on building the organizations analytics database, developing key department metrics, conducting research and more. Jenny obtained her B.Sc from Ateneo de Manila University and her MBA in Business Administration from China Europe International Business School. Alongside working at UNHCR, Jenny also volunteers as a Treasurer for the Women in Machine Learning organization, supporting Women in STEM fields.\n\n\n\nJulia Kroll, Data & ML Engineer, Amazon\n\nJulia Kroll is a Data and ML Engineer at Amazon, currently advising engineers at enterprise companies on migrating to and innovating with the AWS cloud. Julia also works on implement performant, scalable, and secure solutions on AWS, specializing in big data, analytics, and machine learning applications. Julia has also worked as a Data Engineer at Alexa artificial intelligence, following her role as a software engineer at HubSpot.\n\n\n\nKallirroi Dogani, Machine Learning Engineer, Facebook\n\nEarlier this year, Facebook gained a brilliant Machine Learning engineer in Kallirroi Dogani. Having previously worked as a ML Scientist at ASOS and Data Scientist at Tractable and Workable. Kallirroi obtained her second MSC in Artificial Intelligence from the University of Leuven, having received her first a year earlier from the University of Athens in Advanced Information Systems.\n\n\n\nLucy Wang, Machine Learning Engineer, Twitter\n\nCurrently working as a Machine Learning Engineer at Twitter, Lucy is focussed on the use of Machine Learning in Healthcare. Lucy previously held positions of Staff and Senior Data Scientist as Buzzfeed having earlier graduated from Columbia Engineering with an M.S in Computer Science. Aside from ML, Lucy holds interests in Natural Language Processing and Deep Learning.\n\n\n\nTobi Bosede, Founder & CEO, Ilekun Health\n\nTobi obtained a BA in Mathematics from the University of Pennsylvania and MSE from John Hopkins University in Applied Mathematics and Statistics before beginning her career as a Software Engineer at JPMorgan Chase. In the years since, Tobi has held positions as a Data Scientist at Sprint, Researcher at John Hopkins University and Lead in ML at Capital One, all prior to becoming the founder of Ilekun Health, a smart technology company in the healthcare space. Ilekun Health is a technology company that gleans insight around provider quality, services offered, and price from a complex deluge of unstructured health data using artificial intelligence (AI)—currently raising initial pre-seed.\n\n\n\nTian Su, Director of Machine Learning, Walmart\n\nAs an experienced Data Scientist, Tian is currently working as Director of ML at Walmart. Having previously held positions of Senior Data Scientist & Head of AI/ML at 7-Eleven, Tian has been heavily focussed on personalization and delivery for customers in the CPG market. Dr Tian holds considerable experience and skill in Advanced Analytics, Data Mining, Statistical Modeling, Machine Learning, Databases and Artificial Intelligence. She also boasts a strong research background with a Ph.D. from Yale University and Master’s Degree focused on Computer Science from Georgia Institute of Technology.\n\n\n\nNicole Barberis, Machine Learning & Quantum ML, IBM\n\nNicole currently works as a Deep Learning and Quantum ML Developer for IBM in the US, aiding in the development of IBMs python solution. Nicole is a big believer in doing quantum machine learning (QML) research as she states this evolving field will eventually complement your modern suite of analytics solutions (machine learning, deep learning, etc.) Nicole worked at IBM for nine years as a Data Scientist and Information Security Analyst, before landing at her current position after two years at Bloomberg as a Data Scientist. Nicole received her MS in Applied Statistics from the University of Wyoming.\n\n\n\nSaeedeh Salimianrizi, Applied ML Scientist, Amazon\n\nHaving held several data science positions at companies including Verisk Analytics, Simarian and Farmers insurance, Saeedeh currently works as an Applied ML Scientist at Amazon in San Francisco. For the past two years, Saeedeh has been improving Amazon’s augmented reality pipeline acceptance rate using CNNs as well as building a CNN-based solution with 95% accuracy, eliminating the need for manual data annotation for shoe vendors. Saeedeh received her MSc in Systems Engineering from Boston University having also studied Industrial Engineering at the University of Tehran.\n\n\n\nQian (Wendy) Xiong, Machine Learning Engineer, Google\n\nAfter achieving a 3.95 GPA in her Statistics PhD, Qian stayed at the University of Colorado State for five years, first as a statistical consultant and latest a graduate teaching assistant. In 2018, Qian moved out of the educational setting altogether, starting as a Data Scientist/ML Engineer at the Expedia Group, working on conversational AI to provide intelligent and personalized automatic customer service. Having spent 18 months at Expedia, Qian moved to Google in April of this year. Qian is Proficient in Python (tensorflow/keras/pandas/scikit-learn/numpy), AWS, Linux, R and SQL. Hands-on Big Data experience with Spark.\n\n\n\nGalina Malovichko, PhD, Applied Machine Learning Scientist, Lyft\n\nGalina obtained her PhD from UC Davis in Condensed Matter and Material Physics, having previously received an MS in Physics from the Moscow Institute of Physics and Technology. Whilst studying, Galina worked as a PhD Student Researcher and Teaching Assistant, later moving to Lyft in 2018. Initially working as a Data Scientist analyzing new features for machine learning models, predicting Lyft rides ETA, Galina later moved on to be an Applied ML Scientist, a position she has held for the last two and a half years. In her current role, Galina has built an ML stack to predict travel times, built traffic detection models and more.","slug":{"_type":"slug","current":"12-women-in-machine-learning-to-watch"},"tags":[{"_key":"Fysfdyt0","label":"Machine Learning","value":"Machine Learning"},{"_key":"nnpdrksh","label":"Best of","value":"Best of"},{"_key":"2MmoF9VK","label":"Women in AI","value":"Women in AI"}],"title":"12 Women in Machine Learning to Watch"},{"_createdAt":"2020-06-29T19:47:48Z","author":{"_id":"1a59f036-e3fe-4f02-9a34-688ce45de143","avatar":{"_type":"image","asset":{"_ref":"image-7d8f236ba010dd4927d0c5a93368bdce1f712843-390x390-webp","_type":"reference"}},"bio":"Currently a Project Manager at Sama, Taylor Rouleau has a passion for ensuring ethical and sustainable practices in tech. After 5 years leading production teams for our customers, Taylor's expertise is applied internally in our Project Management Office. She heads up efforts to maintain our industry-leading data training processes with a special focus on Security & Compliance.","name":"Taylor Rouleau","slug":{"_type":"slug","current":"taylor-rouleau"}},"config":{"description":"We explain the various types of machine learning algorithms including supervised, unsupervised and reinforcement learning, as well as business use cases.","openGraphImage":null,"title":"What Are the Types of Machine Learning?"},"estimatedReadingTime":6,"featured_image":{"_type":"image","asset":{"_ref":"image-3faf334fa409d858100d8be69e4f3a1c87e85922-4096x2732-png","_type":"reference"}},"plaintextBody":"Many will recognize the term AI or Artificial Intelligence, understanding that this broad term applies to almost any technique which allows for computers to mimic human behavior. Machine Learning is a subset of AI which includes abstruse statistical techniques, supporting gradual task improvement through experience gained. These broad sets of algorithms are used to extract useful models from raw data which are in turn used for a variety of mining tasks & synthetic tasks. In this blog we aim to explain both the various types of machine learning algorithms including supervised, unsupervised and reinforcement learning, as well as highlighting its business use examples. Many of the terms used in the blog can be further understood through Google’s extensive ML glossary, found here.\n\n\n\n“Machine learning research is part of research on artificial intelligence, seeking to provide knowledge to computers through data, observations and interacting with the world. That acquired knowledge allows computers to correctly generalize to new settings”\n\n- Yoshua Bengio\n\n\n\nSupervised Learning - Definition, benefits & limitations\n\nRecognized as the most common type of Machine Learning, supervised learning algorithms are designed to learn through example, hence the term ‘supervised’. To achieve this, the algorithm uses provided input and output data. This provided data is labeled to provide a base for future data processing. Using this data, the goal is to produce an accurate mapping function which in-turn allows for prediction of the desired output. Supervised learning is then further compartmentalized into a range of algorithms, including, but not limited to decision trees, logistic regression & support vector machines. Of course, as with many facets of AI, supervised learning has both advantages and disadvantages. Firstly, supervised learning is a simple process to understand and is extremely useful in classification problems. That said, supervised learning is not ‘real-time’ data, meaning that there will be delays in results required. Alongside this, supervised learning requires substantial computation time for training and is considerably more complex in comparison to unsupervised learning due to the need for labeling all inputs.\n\nUnsupervised Learning - Definition, benefits & limitations\n\nUnsupervised learning refers to the process of giving an algorithm no labeled data and leaving it to structure its own output. Through this lack of labeling, models using unsupervised learning can suggest subtle trends that would otherwise be unfound, especially when using semi-supervised learning. Unsupervised Learning can be seen as extremely beneficial, as it then becomes possible to uncover previously unknown patterns in data. The downside? Unsupervised learning results make it hard to find meaning in the data due to the lack of answer labels and this also makes it harder to compare to supervised learning tasks. Applications of unsupervised learning include clustering, anomaly detection and association mining.\n\nBefore moving on to reinforcement learning, it is important to also address semi-supervised learning. Semi-supervised learning sits between the two aforementioned methods, using a mixture of both tagged and untagged data to fit models. This technique is best suited for a large amount of data with both tagged and untagged sections. An example of this? Amazon’s Alexa! Jeff Bezos has previously spoken very highly of semi-supervised learning, suggesting that the reduced amount of labeled data needed to achieve the same accuracy improvement by 40 times.\n\n\n\nReinforcement Learning - Definition, benefits & limitations\n\nA recent buzzword, reinforcement learning is a technique used to aid the development of 'learning' in an environment, through the process of trial and error. This in turn, uses 'feedback' to correct itself. Unlike the above, whereby feedback provided to the agent is a correct set of actions for performing a task, Reinforcement Learning uses reward and punishment as signals for positive and negative behavior, with the goal to find a suitable action model that would maximize the total cumulative reward of the agent. This feedback design acts as a motivational factor for the RL-agent, whereby an understanding of outcome pushes the agent to learn the method of maximizing accumulated rewards over time. Applications of reinforcement learning are often seen in robotics for industrial automation, for data processing and in the creation of training systems. This technique has many positives, including being seen to solve various complicated problems which cannot be solved with conventional techniques including robotic movement and video game completion, similar to human problem solving in regard to process and repeat and the lessening in the potential for repeat mistakes.\n\nA challenge that should be recognized when looking at RL is the time it takes to generate data. This seems to be commonplace in the majority of keynote discussions surrounding different algorithms and subsets of AI. Alongside this, it is suggested that RL assumes the world is Markovian, which it is not. The Markovian model describes a sequence of possible events in which the probability of each event depends only on the state attained in the previous event.\n\nMachine Learning, in its many forms, is seen as a staple in AI, with the potential to scale, a key factor in the growth of intelligent machines. A number of industries utilizing large swathes of data already recognize the potential of ML, as it’s regularly used in financial services, healthcare, government processes, transportation, and more. Using ML not only increases the potential effectiveness of the product, but can aid in a competitive advantage over those proceeding without.","slug":{"_type":"slug","current":"types-of-machine-learning"},"tags":[{"_key":"xTN3uVzu","label":"Machine Learning","value":"Machine Learning"}],"title":"What Are the Types of Machine Learning?"},{"_createdAt":"2019-12-20T02:00:00Z","author":{"_id":"97dc2368-fffb-4c41-82aa-5a9cbe2ec670","avatar":{"_type":"image","asset":{"_ref":"image-af58425525bb33d8cffdc1f1b10f02bf1e4faf57-1916x2028-jpg","_type":"reference"}},"bio":"Sharon is the Content Marketing Manager at Sama where she's responsible for telling the story behind the company's impact sourcing mission and human-powered training data solutions. Sharon holds a MS in Integrated Marketing Communications and is passionate about helping social enterprises transform abstract concepts into results-driven marketing.","name":"Sharon L. Hadden","slug":{"_type":"slug","current":"sharon-l-hadden"}},"config":{"description":"In this interview, we chat with Head of AI at Samasource about AI trends to expect in 2020, as well as frequently asked questions about AI and machine learning.","openGraphImage":null,"title":"8 Answers to Your Questions About AI and Machine Learning"},"estimatedReadingTime":18,"featured_image":{"_type":"image","asset":{"_ref":"image-ade4117797bfbff2e90f48d6ad558ab992aca273-3423x2283-jpg","_type":"reference"}},"plaintextBody":"McKinsey Global Institute shared that among the top 5 limitations to adopt AI, two common challenges are labeling training data and obtaining datasets.\n\nIn this interview, Frédéric Ratle, Head of Artificial Intelligence at Sama answers frequently asked questions about AI and machine learning.\n\nRatle also shares AI trends you can expect to see in 2020, how Sama helps enterprise organizations overcome training data challenges, and his thoughts on how AI is shaping the world around us.\n\naudio embed\n\nTranscript: \"Ask Me Anything\" Part 2: 8 Answers to Your Questions About AI and Machine Learning\n\n(00:04) Hello, and welcome to the Ask Me Anything series by Sama, where we interview subject matter experts working in artificial intelligence. I'm your host, Sharon L. Hadden, an AI enthusiast and content marketing manager at Sama.\n\nFrédéric Ratle is the Head of Artificial Intelligence at Sama. He brings 15+ years of R&D experience in machine learning, AI, NLP and computer vision to his role at the company. Frédéric holds a PhD in machine learning, has published numerous research papers and has experience bringing products to market across multiple industries, including healthcare, automotive, consumer electronics and retail.\n\n(00:56) Hi Frédéric. Thanks for joining me today. A little bit about my background, I worked at NVIDIA for a number of years, and it was my first intro into machine learning, deep learning, artificial intelligence. The number one question we were always asked is what's the difference between machine learning and artificial intelligence?\n\n(01:21) It's a really good question. Well, machine learning specifically is concerned with algorithms that can efficiently learn from data. For example, building a classifier that can learn to distinguish, let's say lion images from tiger images based on a set of labeled images is a typical machine learning problem, but it's a subset of AI because AI also includes approaches that aren't data-driven, which I refer to as symbolic approaches. For example, rule-based systems or knowledge or ontology based systems.\n\nThose are AI, but they're not specifically machine learning. Knowing this, the distinction has been a little bit blurred. So we tend to call everything AI. Another difference is that AI implies some kind of goal of mimicking human intelligence, while machine learning clearly is in engineering territory and really aimed at building data-driven decision making systems.\n\n(02:18) That's a great way to put it, Frédéric, and where does deep learning fit into the picture of all of this?\n\n(02:26) Right, so deep learning is a part of machine learning. It's a class of models in machine learning so it's also concerned with algorithms that can learn from data. But the difference with other kinds of models is that it's specifically concerned with so-called deep architectures. These are a model that stack multiple layers of representation and that is believed to lead to the model being able to learn more meaningful features as opposed to traditional shallow models like support vector machines, for example.\n\nIt's a field that has existed for a while actually. People have been trying to use deep neural networks since the 80s, I think, but it only started gaining some traction about 10 years ago, mostly because researchers have found mathematical tricks to optimize those models in an end-to-end way. And also thanks to the increasing availability of computational power, so really cloud computing.\n\n(03:26) Anytime I'm doing research around the history of AI, it's remarkable to see how long we've been using it, but have only just arrived at being able to maximize the technology. Let's talk a little bit about AI versus general artificial intelligence.\n\n(03:46) What we describe as a general artificial intelligence, sometimes is also called strong AI. It's the idea that a machine would be able to be trained and then, it would be able to learn any task that a human can learn.\n\nIt's more of an academic notion really, and I believe we're very far from that because we lack a lot of scientific knowledge about many mechanisms that underlie human intelligence and reasoning. The other kind of AI that you mentioned is the one that's been most successful, in my view. And people in academia typically refer to it as narrow AI.\n\nIt's the ability to really, for machines to mimic your very specific cognitive ability that's normally associated with humans, like speech for example, and in a way that is useful to us. This is mostly on the engineering side and most AI work in industry fall into that category. But that being said, a strong versus narrow AI or AI versus general AI, is really more of an academic debate in my view.\n\nThere's an article that was written last year by professor Michael Jordan from Berkeley, which I really liked, where he presented a framework to categorize different kinds of AI work in a way that is meaningful. I really encourage our listeners to take a look at it. It's called, Artificial Intelligence—The Revolution Hasn't Happened Yet. The three categories that he outlines, there are first what he calls the human imitative AI, which is mostly an academic field of work where people try to build an intelligence that somewhat resembles that of humans.\n\nThe second category is what he calls intelligence augmentation. And this is really an engineering domain that aims at augmenting human intelligence with things like web search, machine translation, and these are things that that really changed the way we interact with information.\n\nAnd the third category is called intelligent infrastructure. So everything around internet of things, sensors—these are basically systems that capture information about the world and try to make intelligent decisions based on that.\n\n(06:08) That really sounds like a crash course on AI, the way you've described it. I would love to know if you have any just examples of technology that isn't artificial intelligence. I know when you were describing kind of the difference between machine learning and AI, you talked a little bit about rule-based systems and I think often in movies media, AI is depicted as you know, anything smart is AI. Could you just share a few examples of technology that isn't AI? Maybe some things that are even commonly mistaken as AI?\n\n(06:49) Actually, I don't really want to single out a particular field because I think in every field there is room for research and development around something that is AI. I do want to point out that many fields of research and many fields of engineering are now called AI because as you say, the media talks a lot about it.\n\nEven practitioners in those domains are starting to talk about AI, but those domains often have a history of their own and most importantly, they have challenges and goals of their own. If you think, for example, the fields like data mining, like operations research, like control theory, even some parts of statistics for example.\n\nI don't think it's necessarily useful to call them out as AI in that sense because we can easily lose sight of what the goal of those disciplines is. For example, if you look at operations research, its goal really is to solve some very specific optimization problems in business. But if you call it an AI, it kind of blurs the notion of what the goal of that field is.\n\n(07:50)Well, thanks. Thanks for laying that out Frédéric. I'd love to talk more about your work at Sama, specific to our training data annotation platform.\n\n(08:02) Humans are much better than machines at recognizing and judging complex situations and use cases. Sama is a human-in-the-loop labeling platform where our customers can upload their data and receive annotations. We really want to make this platform more intuitive and more helpful to AI practitioners, in terms of tools that are available to slice and dice data sets, for example, to sample data sets for labeling. Because sometimes you have huge videos, but it's not exactly clear if you need to label the whole of it or whether you need to apply some smart way of just picking the frames that are important.\n\nWe support many types of annotation formats within that platform, but there are many features that are in the making, in my team, that will soon make their way into production.\n\n(08:57)Thanks for really pointing out that human-to-machine interaction. I think it often gets lost that humans help train AI. So thanks so much for pointing that out. Of the features that you're working on within the platform, how do you see that technology benefiting our customers at Sama?\n\n(09:21) So things like object detection and image segmentation in computer vision should really be an integral part of a data labeling solution. I think that what's really at the top of our team's list, in terms of priority is better quality in terms of annotation, and better efficiency. So that's really what we're looking to achieve. I believe customers can benefit from even better quality of our in-house labeling and also our ability to take on larger sets of data in a matter that is efficient and scalable. It's about being able to scale and also preserving the quality\n\n(10:06) In terms of limitations around AI—I read so much from McKinsey Global Institute, and I think it was last year, they shared a report of the top five limitations to adopt AI. Two of those common challenges are labeling training data and then obtaining datasets. How can Sama help with this? \n\n(10:28) Of course, Sama as a training data provider can of course help with this aspect, more profoundly, as machine learning and AI gain importance in technology, but also generally in our lives, so will the importance of those data sets and more specifically how those data sets are gathered, if you will.\n\nSo I think that beyond the core labeling services, providing expertise on data acquisition and data labeling not only in technical terms, but also from a social and ethical perspective is really essential and will be increasingly important as society evolves, and also as regulation evolves.\n\n(11:13) Well, in your opinion, Frédéric, how is AI shaping the world around us?\n\n(11:20) Oh wow. That's a really good and open question. I have a few ideas about it. Uh, of course, this is only a subset of all of the ways that I think the world will be shaped. But I think it's shaping the world in many ways and whether those ways are positive or negative are really dependent on how we make use of those advances.\n\nSo first from engineering perspective, I think it's really pushing the boundary of many fields that we thought really were more the realm of humans. For example, if we think of speech recognition, machine translation, and also computer vision, advances in AI have rendered those systems very close to human capability.\n\nWhile maybe 10 or 15 years ago that technology really wasn't there yet, and using these systems really felt still cumbersome. So in that sense, I think it's changing the way we interact with technology and the way we interact with information in general. From a social perspective, I think it's pushing a lot of automation and decision making, in ways that can be both good and bad.\n\nI think it can be very good because machines are much better than humans at making very large scale inferences and taking a lot of factors into account when making that decision leading to, you know, high quality decision systems. It can also be very bad, because if we give too much control to these systems without any human oversight, it can be dangerous. And, the nature of the data used to train these models will ultimately determine its performance.\n\nAlso, if you look at a system that's working in a given context and that's been trained in a given context, it may have unpredictable behavior if we slightly changed the context. So that can be also very dangerous.\n\nAnd finally, I think it's of course changing the dynamics of the job market. And the impact that will have on society is I guess in the realm of politics more than technology, but you know, how do we make the greater number of people benefit from the advances that are provided by AI.\n\n(13:40) Frédéric, 2020 is just around the corner and lots of reports are coming out on the state of AI. Are there any trends that you want to call out that we could expect to see in 2020 regarding AI?\n\n(13:58) There are many exciting fields right now that are progressing very, very quickly in AI, but I'd like to call out three things.\n\nI think in the last one or two years there's been a lot of progress in natural language processing. I think what happened in vision, you know, around 2015, 2016 is happening now in NLP because the accuracy of models is increasing quickly. So I think we can expect some more progress in that area in general.\n\nOf course human communication is not only based on words. I think to reach a really human level of understanding of semantics, we'll have to integrate other modalities like nonverbal communication, visual cues, etc. But there's still room for progress, just based on text.\n\nThe second thing I really find very interesting is causality, so the study of cause and effect between different co-variants and explainability, the ability to explain the why it model is making the prediction it's making will keep growing as a topic of interest. It's actually growing very fast right now, and on another level I think that another area that is a really, really interesting is lower resource machine learning.\n\nSo models that can function with energy constraints or size constraints. Because as we grow more conscious about the energetic and environmental impact with machine learning, there's been a couple of articles recently in various newspapers, so models that require less computing will become more popular.\n\nThis is overall a pretty positive trend I think. Not only because it's more environmentally friendly, but also because I think it puts less of an advantage on very large players in the industry that have an unlimited access to computing power.\n\n(16:01) For sure. So, are we talking at all about AI at the edge?\n\n(16:08) Yeah, we're seeing that a lot. On a lot of devices you can see that you have models that you run on the platform, and I think that's something that will only grow because there will also be more regulations pertaining to data exchange.\n\n(16:24) For sure. For sure. Well, is there anything else that stands out to you regarding the state of AI or any challenges with AI adoption?\n\n(16:34) I think there's a couple of things, but just to call out, two of them, you mentioned earlier the data labeling aspect that is difficult for organizations, but I think it goes deeper than that.\n\nI think even the raw data really is an issue because very often in various organizations, depending on their level of technical savviness, the raw data, if available even is often distributed across different departments and various formats, you know—Excel sheets, SQL databases, etc. So it's very difficult to actually take that data and even just do anything with it. I think that's a very big challenge that organizations really need to tackle.\n\nThe second aspect I wanted to call out is also the increasing debate on the use of data in many applications where massive data is collected from users. I think it's a very welcome debate because we're all aware of that regulation has somewhat been lagging behind in that respect, and it has led to a number of problematic situations. But, I think it will be very interesting to see how will the technologies be impacted by all of the new regulations with respect to data ownership and privacy.\n\n(17:50) It's been incredibly eye opening talking with you today, and I think my last question for you is just, what do you love most about working in AI?\n\n(18:02) Most definitely I think it's the ability to constantly work on new problems, and also the ability to really work with really smart and talented people all the time. I also enjoy really shaping a whole new engineering discipline. I think that's very exciting.\n\n\n\nThis interview is the second installment of a new audio blogging series titled, \"Ask Me Anything,\" where Sama interviews subject matter experts working in artificial intelligence.","slug":{"_type":"slug","current":"8-answers-to-your-questions-about-ai-and-machine-learning"},"tags":[{"_key":"Y7bAcGrE","label":"Machine Learning","value":"Machine Learning"},{"_key":"qhgHNaG5","label":"AI","value":"AI"},{"_key":"0PqR2xB7","label":"Best of","value":"Best of"},{"_key":"NoohHt2W","label":"Sama Engineering","value":"Sama Engineering"}],"title":"8 Answers to Your Questions About AI and Machine Learning"},{"_createdAt":"2019-10-24T22:00:00Z","author":{"_id":"97dc2368-fffb-4c41-82aa-5a9cbe2ec670","avatar":{"_type":"image","asset":{"_ref":"image-af58425525bb33d8cffdc1f1b10f02bf1e4faf57-1916x2028-jpg","_type":"reference"}},"bio":"Sharon is the Content Marketing Manager at Sama where she's responsible for telling the story behind the company's impact sourcing mission and human-powered training data solutions. Sharon holds a MS in Integrated Marketing Communications and is passionate about helping social enterprises transform abstract concepts into results-driven marketing.","name":"Sharon L. Hadden","slug":{"_type":"slug","current":"sharon-l-hadden"}},"config":{"description":"This list of computer vision insights shares how artificial intelligence is learning to understand and relate to the intensely visual world around us.","openGraphImage":null,"title":"Computer Vision Insights From Around the Web"},"estimatedReadingTime":3,"featured_image":{"_type":"image","asset":{"_ref":"image-31c1da1bdf3c6cd218e26d4f06a30f002ec18a8e-2000x1333-jpg","_type":"reference"}},"plaintextBody":"Computer vision is one of the most basic and crucial elements of artificial intelligence, but that doesn’t make it any less interesting.\n\nOur daily experience of the world is human nature and computer vision provides an avenue for artificial intelligence to understand and relate to the intensely visual world we live in.\n\nHere are a few interesting insights about computer vision that we’ve sourced from around the web.\n\n\n\nMost Popular Computer Vision Research Areas\n\nOf all the research papers submitted to this year’s Computer Vision and Pattern Recognition (CVPR) conference, the most popular computer vision research areas were detection, segmentation, 3D and adversarial training, showing an increased interest in unsupervised learning.\n\nIndustries Adopting Computer Vision\n\nWhile automotive continues to hold the largest share of the computer vision market, increasing quality standards across industries has prompted more companies to adopt factory automation fueled by computer vision systems. There’s also a rising demand for vision-guided robotic systems and application-specific computer vision systems, alongside a growing adoption of 3D computer vision.\n\n\n\nA Fundamental Problem with Computer Vision\n\nBhargav Desai, Technical Writer and Instructor at Eduonix shares that deep learning itself is arguably the most fundamental problem with computer vision. The emphasis on its strengths while lacking acknowledgement for apparent weaknesses such as mistaking an overturned school bus for a snowplow is not just a mistake but a revealing mistake.\n\n“It not only shows that deep learning systems can get confused, but that they are challenged in making a fundamental distinction known to all us humans, the distinction between “understanding” the object and “seeing” an object,” Desai explains.\n\nComputer Vision as Part of the Shopping Experience\n\nThere’s a growing demand among consumers for more robust search options including visual and voice search. A recent survey found that over 60% of respondents would be comfortable with new technologies like the ability to search by image as a part of their digital shopping experience.\n\nProjected Market Growth in Computer Vision Solutions\n\nThe market for computer vision solutions is expected to reach over 17 billion U.S. dollars by 2023, which is indicative of the growing pace of research and advancements in computer vision.\n\nThe Growing Application of Computer Vision Systems\n\nEnterprises like DHL are using extended reality experiences like AR to boost accuracy in their business operations. The company is using AR glasses to display picking and placement directions to its operators, and this application of computer vision systems has led to a 15 percent average increase in productivity.\n\n\n\nIf you’re interested in learning more about how Sama quickly trains and validates machine learning, download our solution brief for details on our project set-up and workflows, platform security and annotation tools for computer vision.","slug":{"_type":"slug","current":"computer-vision-insights-from-around-the-web"},"tags":[{"_key":"gRBnMPo9","label":"Machine Learning","value":"Machine Learning"},{"_key":"rxlxYiKX","label":"AI","value":"AI"},{"_key":"kT5jCNe2","label":"Best of","value":"Best of"},{"_key":"3o90fgFc","label":"Computer Vision","value":"Computer Vision"}],"title":"Computer Vision Insights From Around the Web"},{"_createdAt":"2019-08-20T21:30:00Z","author":{"_id":"97dc2368-fffb-4c41-82aa-5a9cbe2ec670","avatar":{"_type":"image","asset":{"_ref":"image-af58425525bb33d8cffdc1f1b10f02bf1e4faf57-1916x2028-jpg","_type":"reference"}},"bio":"Sharon is the Content Marketing Manager at Sama where she's responsible for telling the story behind the company's impact sourcing mission and human-powered training data solutions. Sharon holds a MS in Integrated Marketing Communications and is passionate about helping social enterprises transform abstract concepts into results-driven marketing.","name":"Sharon L. Hadden","slug":{"_type":"slug","current":"sharon-l-hadden"}},"config":{"description":"Data isn’t the only thing holding back artificial intelligence. Read more about some of the challenges and trends in AI.","openGraphImage":null,"title":"What's Holding Back Artificial Intelligence?"},"estimatedReadingTime":3,"featured_image":{"_type":"image","asset":{"_ref":"image-f0d61bc7762955f6affe83c5358b216c9fdc77e3-4836x3372-jpg","_type":"reference"}},"plaintextBody":"Data isn’t the only thing holding back artificial intelligence. Factors like deciding where and how to deploy AI in business and public perception also play a role in the future of AI.\n\n\nChallenges in Artificial Intelligence\n\nThere’s still work to be done before achieving true intelligence. The gap between artificial intelligence and artificial general intelligence is wide. AI must first “learn to learn” in order to understand and perform intellectual tasks that can be done by humans. (MIT Technology Review)\n\nAI doesn’t always live up to its expectations. With over 50% of people getting their information on AI from movies and TV or social media, the high expectations of AI don’t live up to the hype surrounding it. (McKinsey Global Institute)\n\nPublic opinion of AI is tentative. Public opinion regarding the trustworthiness of AI is tentative. A recent survey found that 50% of consumers feel “optimistic and informed” about AI, while the other half feel “fearful and uninformed”. (Blumberg Capital)\n\nFalse positives and bias in data cause uncertainty. Datasets are curated based on human logic and values, making it difficult to completely rule out bias in the resulting ML model. (Sama)\n\nShortage of data and lack of infrastructure impede the AI pipeline. More companies are considering AI projects, but few have a process to bring projects to production. Enterprises lack the data and infrastructure to support smooth data flow from ingestion to algorithm, making it difficult to operationalize ML models and intelligence. (IDC)\n\nLabeling datasets is arguably the hardest part of building AI. Among other AI challenges like having a clear strategy to source the data that AI requires, organizations argue that the hardest part of building AI products is data preparation and labeling. (Inside Big Data)\n\nDifficulty explaining why a complex decision was reached. AI is programmed to learn by itself, and sometimes, it reaches decisions that no human can explain. We’ve seen this with Google DeepMind’s AlphaZero algorithm, and initiatives like Explainable AI (https://bdtechtalks.com/2019/01/10/darpa-xai-explainable-artificial-intelligence/)have developed to find answers to this problem. (Intercepting Horizons)\n\nFear that AI will negate the necessity of humans in the workforce. There’s a prevailing fear that AI will take over jobs previously performed by humans. However, AI has its limitations. The Future of Jobs report predicts how the division tasks between human and machine will shift between now and 2022. (World Economic Forum)\n\nGood talent is hard to find. Finding professionals that have the right skillset and experience for AI work is among the top challenges for enterprises who have piloted or embedded AI in their organization. (McKinsey Global Institute)\n\nAs new developments in AI occur, the societal and data challenges surrounding the technology will continue to shift and evolve. These challenges should not be overlooked, but rather carefully observed as we pursue human-level intelligence for AI.\n\n","slug":{"_type":"slug","current":"whats-holding-back-artificial-intelligence"},"tags":[{"_key":"opg67GGB","label":"Machine Learning","value":"Machine Learning"},{"_key":"zbe0rrVL","label":"AI","value":"AI"},{"_key":"dV7VmzZT","label":"Best of","value":"Best of"}],"title":"What's Holding Back Artificial Intelligence?"}],"morePosts":[{"_createdAt":"2019-06-07T20:00:00Z","author":{"_id":"97dc2368-fffb-4c41-82aa-5a9cbe2ec670","avatar":{"_type":"image","asset":{"_ref":"image-af58425525bb33d8cffdc1f1b10f02bf1e4faf57-1916x2028-jpg","_type":"reference"}},"bio":"Sharon is the Content Marketing Manager at Sama where she's responsible for telling the story behind the company's impact sourcing mission and human-powered training data solutions. Sharon holds a MS in Integrated Marketing Communications and is passionate about helping social enterprises transform abstract concepts into results-driven marketing.","name":"Sharon L. Hadden","slug":{"_type":"slug","current":"sharon-l-hadden"}},"config":{"description":"13 open source datasets for machine learning, including one dataset featured in the Fine-Grained Visual Categorization (FGVC) workshop at CVPR 2019.","openGraphImage":null,"title":"13 Open Source Datasets for Machine Learning"},"estimatedReadingTime":3,"featured_image":{"_type":"image","asset":{"_ref":"image-bbc3a22b57173b2dd2c6020fe7af40171efed6a9-2250x1500-jpg","_type":"reference"}},"plaintextBody":"tion (FGVC) workshop at CVPR 2019 on June 17.\n\nMachine Learning Datasets\n\nCOVID-19 Open Research Dataset Allen Institute for AI partnered with leading research groups to prepare this research dataset of over 45,000 scholarly articles about COVID-19 and the coronavirus family of viruses.\n\nGoogle Open Images Google AI introduced over 9 million images spanning 6,000 categories--”enough to train a deep neural network from scratch.”\n\nWaymo Open Dataset Waymo released one of the largest, most diverse autonomous driving datasets to date. All you need is a Gmail account, and you can access the dataset.\n\nImageNet If you’re looking for an image database organized according to the WordNet hierarchy, give ImageNet a try.\n\niMaterialist-Fashion Sama and Cornell Tech announced the iMaterialist-Fashion dataset in May 2019, with over 50K clothing images labeled for fine-grained segmentation. The dataset was used in the FGVC workshop at CVPR, co-sponsored by Google AI.\n\nFishnet.AI Working together with Sama, The Nature Conservancy released Fishnet.AI, an AI training dataset for fisheries. This dataset of approximately 35,000 images with an average of 5 bounding boxes per image was collected from on-board monitoring cameras for long line tuna fishing activity in the Western and Central Pacific.\n\nVisual Genome Visual Genome is the product of 9 technology professionals with a goal of connecting structured image concepts to language. \n\nUCI Machine Learning Repository The University of California - Irvine (UCI) maintains 474 datasets as a service to the machine learning community. \n\nPew Research Center Gain access to raw data from survey research via Pew Research Center. An account is required to access their datasets, but registration is easy.\n\nLabelme Use the Labelme Matlab toolbox to access a large dataset of annotated images. \n\nLabelled Faces in the Wild (LFW) Develop your facial recognition application using LFW, a collection of over 13,000 face photographs collected from around the web.\n\nDataset Finders\n\nKaggle Data scientists and machine learners can find and publish datasets on Kaggle, an online community that was acquired by Google in 2017. Kaggle’s master list of datasets boasts a wide range of niche data sources.\n\nAmazon Web Services (AWS) With over 110 datasets and counting, you’ll find a web crawl of billions of web pages, NASA satellite imagery and more on the Registry of Open Data for AWS. If you want to add to the registry, of course there’s an AWS Labs GitHub repository (https://github.com/awslabs/open-data-registry/) for that.\n\nGoogle Dataset Search Google Dataset Search indexes datasets from digital libraries, personal websites and publisher pages, so you can find them when you need them. It’s currently in beta, but the predictive interface makes it easy to see what datasets are available on your selected topic at a glance.\n\nThis is just a small sample of the free, open source datasets that are available for machine learning use cases. If you have a dataset or dataset finder you’d like to add, hit us up and let us know.","slug":{"_type":"slug","current":"11-open-source-datasets-for-machine-learning"},"tags":[{"_key":"h28cARez","label":"Machine Learning","value":"Machine Learning"},{"_key":"dDZvCu9M","label":"Best of","value":"Best of"},{"_key":"WAc2iHgu","label":"Events","value":"Events"},{"_key":"hPEDVzwV","label":"Open Datasets","value":"Open Datasets"}],"title":"13 Open Source Datasets for Machine Learning"},{"_createdAt":"2019-06-06T23:01:00Z","author":{"_id":"26fb3cc4-608d-40e1-bb4d-955bceda232a","avatar":{"_type":"image","asset":{"_ref":"image-f1fd7fbcc4633299cdbedddba22cb44e24f17317-518x518-svg","_type":"reference"}},"bio":"From self-driving cars to smart hardware, Sama fuels AI. Founded over a decade ago, we’re experts in image, video and sensor data annotation and validation for machine learning algorithms in industries including automotive, navigation, AR/VR, biotech, agriculture, manufacturing, and e-commerce. Our staff are driven by a mission to expand opportunity for low-income people through the digital economy, and our social business model has helped over 50,000 people lift themselves out of poverty.","name":"Sama Team","slug":{"_type":"slug","current":"sama-team"}},"config":{"description":"Kirk Boydston, Training Data Specialist at Sama shares five considerations to move your machine learning model toward level 4 autonomous driving.","openGraphImage":null,"title":"Moving Toward Level 4 Autonomous Driving"},"estimatedReadingTime":4,"featured_image":{"_type":"image","asset":{"_ref":"image-ea7c2cbe6b2ae714f214ce5750d2f485e58d429e-2441x1500-jpg","_type":"reference"}},"plaintextBody":"Last week at Autonomous Vehicle Technology Expo, Kirk Boydston, Training Data Specialist, Sama asked attendees if more data was required to get their machine learning model even close to 100% accuracy.\n\nThe answer was an unanimous yes, and the best practices Kirk shared emphasized the importance of a solid training data strategy to move toward level 4 autonomous driving.\n\nHere are five considerations to move your machine learning model down the training data continuum.\n\n1. Train a Proof-of-Concept ASAP to Determine Data Needs\n\nThe feedback gained from a proof-of-concept (POC) model provides the necessary insight to estimate how much data is needed to achieve level 4 maturity. Don’t wait until you have the “right” amount of data, or an all-encompassing data content scope.\n\nAllow the results of your POC to drive the need for more data and refine, expand and improve as unknown use cases and edge cases surface.\n\n2. Set Clear Training Data Rules to Cover Edge Cases\n\nEdge cases should not be an afterthought, but rather a key component of your training data strategy. Objects may have many different names e.g., Is it a scooter? Or a small moped? Or, perhaps a mini motorbike?\n\nDefine clear classification rules for subjective and specific objects, and set objective rules to determine their class. These training data rules will help you cover edge cases effectively.\n\n3. Choose Your Training Data Partner Wisely\n\nImpact and sustainability have become increasingly more important corporate values. Consider partnering with a training data supplier that utilizes an ethical supply chain like Sama.\n\nOur directly managed workforce has annotated over one million images on Sama, and we’ve helped partners like General Motors and Volkswagen achieve high-quality data at scale with our training data expertise.\n\nBottom line is your actions have impact. Not only will an ethically minded training data strategy lead to higher quality results, you’ll be making a difference in communities near and far.\n\n4. Test Your Model for Bias\n\nIn addition to lower precision, models trained on biased data can have ethical, legal and safety problems. For example, data biased toward pedestrians with lighter skin may cause the model to identify pedestrians with darker skin less accurately. \n\nYou will almost always have overrepresentation of some elements and underrepresentation of others, and thoughtfully testing your model for bias before, after and throughout production will help move your model to maturity.\n\n\n\n5. Continuously Evolve Your Model\n\nModel training is never done. Every day, the world is changing around you. New cars, new fashions, etc., require newly sourced and labeled training data. According to McKinsey Global Institute 1 out of 3 AI systems require model refresh at least monthly and sometimes daily. In cases where your model is weak, treat the occurrence like a bug that needs to be fixed and continuously evolve your model.\n\nAchieving 100% accuracy can feel a lot like approaching the speed of light, and while 100% accuracy isn’t necessary for all algorithms (like chatbots), level 4 maturity is the goal automotive OEMs are striving for.\n\nKirk’s presentation, “Warp “Driving” Approaching AI’s Speed of Light,” urged attendees to be relentless in seeking out weak scenarios to train with new data.\n\nHis key takeaway was training and validation for machine learning may require different precision thresholds and volumes depending on the stage of maturity. If you want to get your AV machine learning model toward 100% accuracy, success will come from being quality-focused and iterative.\n\n","slug":{"_type":"slug","current":"https://www.sama.com/blog/moving-toward-level-4-autonomous-driving"},"tags":[{"_key":"3KIYoFV1","label":"Machine Learning","value":"Machine Learning"},{"_key":"bPng3xAl","label":"Training Data","value":"Training Data"},{"_key":"TRiIb7nw","label":"Data Quality","value":"Data Quality"},{"_key":"KO7eeuZJ","label":"Autonomous Transportation","value":"Autonomous Transportation"}],"title":"Moving Toward Level 4 Autonomous Driving"},{"_createdAt":"2018-07-17T00:00:00Z","author":{"_id":"71091c91-664a-44a6-9474-acc40eb12457","avatar":{"_type":"image","asset":{"_ref":"image-bc776336801adf71e2599337e8d6f02186b109d0-500x500-jpg","_type":"reference"}},"bio":"Matthew leads the product team at Sama, responsible for the platform that enables Sama's AI/ML data enrichment teams, internal enterprise operations tools to ensure quality and scalability, and all new product initiatives for the evolution of algorithm development and human-powered automation.","name":"Matthew Landry","slug":{"_type":"slug","current":"matthew-landry"}},"config":{"description":"Announcing object tracking with video annotation","openGraphImage":null,"title":"Introducing Object Tracking with Video Annotation"},"estimatedReadingTime":5,"featured_image":{"_type":"image","asset":{"_ref":"image-af58edf394d9676203b9bc44284f08ccf52125a6-1000x1500-jpg","_type":"reference"}},"plaintextBody":"Today, Sama announces the availability of our latest image annotation toolset for advanced video object tracking. These new tools, in the hands of our expert annotation workforce, level up Sama’s object tracking performance while maintaining the same extreme quality results of our ground truth training data services.\n\nWhat this means for our customers is an even more scalable approach to annotating the growing stream of video object tracking data. Faster training data production speeds your algorithm development and gets you to market faster.\n\nWhy focus on video object tracking?\n\nTesla, as an example, has over 250,000 cars on the road, each packed with high quality cameras to capture the world around them. Video footage collected from a fleet of this size can feed an extremely sophisticated autonomous driving deep learning system. And it's not just Tesla. In the Bay Area, we've become accustomed to seeing data capture vehicles from just about every autonomous driving company out there -- and all of them are collecting video.\n\nAs the computer vision industry progresses from simple object identification (can the algorithm tell what an object is?) to object tracking (can the algorithm follow a specific object over time?), we need tools that can effortlessly annotate this video stream. Sama delivers.\n\nWhat difference does a tool make?\n\nThe traditional approach to an object tracking project is to split the video into individual images and then annotate each image separately, paying careful attention to ensure consistent identifiers for each unique object in sequential images. It's very challenging work, as any Sama agent or quality analyst will tell you. It takes careful attention to detail and often exceeds the capabilities of most annotation services. (We had to build some supporting tools in our platform to make it tractable.)\n\nSama’s introduction of video annotation for object tracking completely changes the game. Now, an entire video sequence can be assessed as a whole, whether the clip contains 2 frames or 2,000 frames. This feature makes it much easier and faster to follow a single object -- even if it's moving -- from beginning to end of a video. If the object disappears from the camera view and reenters later (think: overtaking a cyclist in traffic, only to have them blow past you at the next intersection), we can easily, accurately accommodate it. The whole process is more efficient while maintaining the highest annotation quality, especially as the density of objects increases. And believe me, image complexity at the cutting edge of computer vision is getting up there.\n\nNo, really, why are you so excited?\n\nOne of the coolest aspects of the new tool is how it semi-automatically annotates frames, which makes for a more efficient workflow. If a user starts by drawing a bounding box around an object, the tool automatically estimates the object's location in subsequent or previous frames. Our expert annotation workforce carefully scrutinizes those estimates, and manually tweaks them as needed to get the tracking fully dialed in.\n\nWhen we think about where to focus our platform development, we're always looking for ways to augment the capabilities of our human workforce. We think about how we can make our data services better by using technology to make our team more efficient and more accurate -- with ever more complicated annotation projects. Video annotation is a very visceral demonstration of this approach.\n\n\n\n(By the way, the process couldn't be easier for customers. Hand over camera footage -- color, b&w, high frame rate, low frame, SD, UHD, whatever -- to our project team, and we manage the entire project from start to finish, delivering annotation results that you can immediately route into your training pipeline.)\n\n\nThat’s a wrap!\n\nIt's the leveling up in the speed -- with the highest accuracy -- of our ground truth training data annotation service that really matters. We work with a many clients developing sophisticated vision algorithms, with very aggressive targets for annotation completeness and correctness. Ground truth training data is precious and object tracking video sequences particularly so. Data scientists need confidence in the quality of that training data so that they squeeze the maximum performance out of their deep learning models, focusing on the architecture and hyper-parameter tuning instead of grooming erroneous data.\n\nPartnering with Sama, you can get the most from your object tracking projects. We’re proud of this production-ready video annotation tool, and have big plans for evolving it. If you have object tracking on your mind and would like to see a demo of our annotation platform in action: Drop us a line!","slug":{"_type":"slug","current":"announcing-object-tracking-with-video-annotation"},"tags":[{"_key":"lFK49VoI","label":"Machine Learning","value":"Machine Learning"},{"_key":"uWZdY0Qc","label":"Product","value":"Product"},{"_key":"vbSgnXan","label":"Video Annotation","value":"Video Annotation"},{"_key":"NfB0x55k","label":"Data Annotation","value":"Data Annotation"}],"title":"Introducing Object Tracking with Video Annotation"},{"_createdAt":"2018-06-21T18:31:10Z","author":{"_id":"26fb3cc4-608d-40e1-bb4d-955bceda232a","avatar":{"_type":"image","asset":{"_ref":"image-f1fd7fbcc4633299cdbedddba22cb44e24f17317-518x518-svg","_type":"reference"}},"bio":"From self-driving cars to smart hardware, Sama fuels AI. Founded over a decade ago, we’re experts in image, video and sensor data annotation and validation for machine learning algorithms in industries including automotive, navigation, AR/VR, biotech, agriculture, manufacturing, and e-commerce. Our staff are driven by a mission to expand opportunity for low-income people through the digital economy, and our social business model has helped over 50,000 people lift themselves out of poverty.","name":"Sama Team","slug":{"_type":"slug","current":"sama-team"}},"config":{"description":"Machine Learning 101: in this post, we'll present a simple overview of machine learning and how it helps computers solve complex problems.","openGraphImage":null,"title":"Machine Learning 101"},"estimatedReadingTime":7,"featured_image":{"_type":"image","asset":{"_ref":"image-c664f546c6c09a66a670e1248bbb5b2b9055ae81-1500x1072-jpg","_type":"reference"}},"plaintextBody":"If you’ve kept up with today’s tech news, then you’ve probably read some pieces about machine learning. Unfortunately, many of those articles target expert audiences who already know how to code and design algorithms. What is machine learning, anyway, and where can you turn to get up to speed on the basics?\n\nIn this post, we’ll present a simple overview of machine learning and how it helps computers solve complex problems. Even if you're a complete novice, you'll learn something new from the information below.\n\n\nWhat is Machine Learning?\n\nInsider blog TechEmergence compiled a definition of machine learning that aggregates definitions from several leading experts in industry and academia:\n\n“Machine Learning is the science of getting computers to learn and act like humans do, and improve their learning over time in autonomous fashion, by feeding them data and information in the form of observations and real-world interactions.” - TechEmergence\n\nThe key difference between machine learning and traditional programming is that a machine learning algorithm does not have to be told formally how to get from the input data to the output data. The machine learning algorithm is given examples of input and the expected output and it learns the rules itself. As the algorithm is presented with more input examples and their associated expected output, it can improve decision making performance over time.\n\n\n\nFor example, if you played chess against software that was built using machine learning, the software powering your computer opponent would study the results of your moves, its moves and its strategies to become a better player. Eventually, it would learn so much that it would defeat you in every game - even when presented with unfamiliar scenarios it had not seen and analyzed. Even if you're a chess master, the computer will almost certainly learn to play better than you.\n\nYou can apply the chess example to any type of information. For instance, machine learning could help software identify people trespassing on property, predict stock market trends, navigate autonomous vehicles, identify farming pests and more. As long as the software has access to useful data and a reliable algorithm, it can learn.\n\n\n\nThe Three Types of Machine Learning\n\nNot surprisingly, a cutting-edge computer science topic like machine learning can get very complicated. Most machine learning work can be grouped into three categories: supervised learning, unsupervised learning, and reinforcement learning.\n\n\nSUPERVISED LEARNING\n\nSupervised learning means that software is trained on data that has been labeled. For instance, you might input a 500 images labeled \"cow\" and another 500 images labeled \"human” into the algorithm. After analyzing the images, the program could differentiate between a picture of a human or a cow based on an analysis of the pixels arrangement color and shape. Reasonably accurate computer vision programs require large quantities training images and can make amusing mistakes if inadvertently trained to notice something else -- like grass. \n\n\n\nLabeling data makes it considerably easier for computers to learn. This principle isn't surprising when you think about how you learn. Imagine if someone handed you a page full of numbers with no explanation. You probably wouldn't know what the numbers mean and thus you wouldn’t know how to process that data right away. However, if you were then handed the same page of data with the label “phone numbers,” the numbers suddenly make more sense.\n\nUNSUPERVISED LEARNING\n\nIn unsupervised machine learning, the data used do not have any labels. Without labels, successful machine learning usually requires more data before it can generate useful outputs. The algorithm can try to detect similarities and differences in the input data and start to group them based on those characteristics. With enough examples, the groupings can become very meaningful.\n\nReferring to the scenario above, the phone numbers (assuming they have area codes) would have three digits that vary far less than the following seven. The unsupervised learning algorithm could start to group the phone numbers based on their similar area codes, and correctly assign a newly discovered phone number into the appropriate area code group.\n\nOf course, the algorithm doesn’t even know what an area code is, but it has learned something important about patterns that it can apply to sorting future samples. (And now you perhaps have an inkling of how Netflix can recommend movies based on your previous viewing choices.)\n\nREINFORCEMENT LEARNING\n\nReinforced learning conceptually splits the difference between supervised and unsupervised approaches with a trial-and-error approach. In the chess-playing example, you might have an algorithm that can make any move, and a grader that tells the algorithm whether the player’s move is legal (that is, if it tries to move a pawn six spaces forward, the grader says, “nope!”). Through trial-and-error, the algorithm would eventually learn how each chess piece should move. Similarly, as it plays through more games, it would learn what it means to win or lose, and how to better achieve the wins.\n\nIn fact, just these kinds of techniques allowed the AlphaGo and AlphaGo Zero programs to very rapidly become world-class Go players.\n\n\nClean Data is Necessary (But Hard to Get)\n\n\nMachine learning relies on clean data. Without reliable data, software can't learn the right lessons or become better at usefully automating tasks. It might learn from the noise instead of the signal.\n\nUnfortunately, it's difficult for data scientists to provide the most advanced learning algorithms with good, clean data. Some of the reasons include:\n\nInsufficient people to label a mountain of raw data;\n\nIrrelevant data that gets mixed in with desired data;\n\nIncomplete or partially labeled data; and\n\nHuman error in labeling data\n\nThese challenges could mean that your machine learning algorithm uses corrupted training data, which could lead to poor learning results that get repeated and amplified. The software, in other words, doesn't learn the right lessons to do its job well.\n\nWorking with a partner that understands the most effective ways to source and identify clean data will give you an advantage over competitors. You can learn more about data enrichment by reaching out to Sama. Our training data work is trusted by the world’s leading technology teams working on AI and Machine Learning across industries, from self driving cars to robotics for advanced surgery.\n\n\n\n\n\n\n\n\n","slug":{"_type":"slug","current":"machine-learning-101"},"tags":[{"_key":"sD519oq6","label":"Machine Learning","value":"Machine Learning"},{"_key":"y63rBA8Q","label":"Best of","value":"Best of"},{"_key":"NDx7I7j8","label":"Training Data","value":"Training Data"}],"title":"Machine Learning 101"}],"slug":"machine-learning","tagName":"Machine Learning","pageConfig":{"title":"Sama Blog | Training Data, AI and Impact Sourcing Insights","description":"From machine learning to training data strategy, the Sama blog covers research, news and other AI trends from thought leaders across the globe."}}},"__N_SSG":true}