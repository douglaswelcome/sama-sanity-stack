<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"/><meta name="viewport" content="initial-scale=1.0, width=device-width, viewport-fit=cover"/><title>Sama Blog | Training Data, AI and Impact Sourcing Insights</title><link rel="canonical" href="https://sama.com/blog/tag/sama-engineering"/><meta name="description" content="From machine learning to training data strategy, the Sama blog covers research, news and other AI trends from thought leaders across the globe."/><meta property="og:type" content="website"/><meta property="og:description" content="From machine learning to training data strategy, the Sama blog covers research, news and other AI trends from thought leaders across the globe."/><meta property="og:title" content="Sama Blog | Training Data, AI and Impact Sourcing Insights"/><meta property="og:url" content="https://sama.com/blog/tag/sama-engineering"/><meta name="twitter:card" content="summary"/><meta property="twitter:description" content="From machine learning to training data strategy, the Sama blog covers research, news and other AI trends from thought leaders across the globe."/><meta property="twitter:title" content="Sama Blog | Training Data, AI and Impact Sourcing Insights"/><meta name="msapplication-TileColor" content="#28282a"/><meta name="theme-color" content="#ffffff"/><link rel="apple-touch-icon" sizes="180x180" href="/static/apple-touch-icon.png"/><link rel="shortcut icon" href="/static/favicon.ico"/><meta name="next-head-count" content="17"/><link rel="preload" href="/_next/static/css/bd60e2be2420db639f1f.css" as="style"/><link rel="stylesheet" href="/_next/static/css/bd60e2be2420db639f1f.css" data-n-g=""/><link rel="preload" href="/_next/static/css/bfc9e7bd13d5ad59bf17.css" as="style"/><link rel="stylesheet" href="/_next/static/css/bfc9e7bd13d5ad59bf17.css" data-n-p=""/><link rel="preload" href="/_next/static/css/0d4bd6b9e4f2c8d7d433.css" as="style"/><link rel="stylesheet" href="/_next/static/css/0d4bd6b9e4f2c8d7d433.css"/><link rel="preload" href="/_next/static/css/3b03d00d40d80e105549.css" as="style"/><link rel="stylesheet" href="/_next/static/css/3b03d00d40d80e105549.css"/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-a40ef1678bae11e696dba45124eadd70.js"></script><script defer="" src="/_next/static/chunks/1776.8a2533c590b21f9a9b53.js"></script><script defer="" src="/_next/static/chunks/4934.37651fffe4e244d39030.js"></script><script defer="" src="/_next/static/chunks/1952.c48d8556ec1dc7f6b94b.js"></script><script defer="" src="/_next/static/chunks/3551.e6d3a24e74ae2a11cefe.js"></script><script src="/_next/static/chunks/webpack-83b31492c6777a885ffc.js" defer=""></script><script src="/_next/static/chunks/framework-bdc1b4e5e48979e16d36.js" defer=""></script><script src="/_next/static/chunks/main-6409a04df91a58e5134b.js" defer=""></script><script src="/_next/static/chunks/pages/_app-8b37b83a9f5e9f7f90ae.js" defer=""></script><script src="/_next/static/chunks/commons-38d39b8714d89582ab40.js" defer=""></script><script src="/_next/static/chunks/pages/blog/tag/%5Bslug%5D-03b8b977e5f158c8d5d1.js" defer=""></script><script src="/_next/static/6obM5ETMXaNFf2HCFynGI/_buildManifest.js" defer=""></script><script src="/_next/static/6obM5ETMXaNFf2HCFynGI/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="container"><header class="header_outer__yu9q7 "><nav class="umoja-l-grid--12 header_wrapper__3Ghzm"><a class="header_logo__eiLSq" href="/"></a><button class="header_hamburger__1ZcbZ" type="button"><span class="header_hamburger_box__RZ7CY"><span class="header_hamburger_box_inner__1PmWZ"></span></span></button><ul class="header_navBar__37eSJ"><li class="header_navItem__1HiGN"><p class="header_navItem_label__fN3Cy">Platform</p><div class="header_dropDown__6NxUb"><div class="header_dropDown_group__2BZXC"><p class="header_dropdown_group_label__tmND8">Platform</p><a class="header_navLink__1ARu5" href="/how-it-works">How it Works</a><a class="header_navLink__1ARu5" href="/video-annotation">Video Annotation</a><a class="header_navLink__1ARu5" href="/image-annotation">Image Annotation</a><a class="header_navLink__1ARu5" href="/3d-lidar">3D &amp; LiDAR Annotation</a><a class="header_navLink__1ARu5" href="/natural-language-processing">Natural Language Processing</a><a class="header_navLink__1ARu5" href="/data-curation">Data Curation (Beta)</a></div><div class="header_dropDown_group__2BZXC"><p class="header_dropdown_group_label__tmND8">Shapes</p><a class="header_navLink__1ARu5" href="/semantic-segmentation">Semantic Segmentation</a><a class="header_navLink__1ARu5" href="/polygons">Polygons</a><a class="header_navLink__1ARu5" href="/bounding-boxes">Bounding Boxes</a><a class="header_navLink__1ARu5" href="/key-points">Key Points</a><a class="header_navLink__1ARu5" href="/cuboids">Cuboids</a><a class="header_navLink__1ARu5" href="/lines-and-arrows">Lines &amp; Arrows</a></div></div></li><li class="header_navItem__1HiGN"><p class="header_navItem_label__fN3Cy">Industries</p><div class="header_dropDown__6NxUb"><a class="header_navLink__1ARu5" href="/transportation-navigation">Transportation &amp; Navigation</a><a class="header_navLink__1ARu5" href="/retail-ecommerce">Retail &amp; E-Commerce</a><a class="header_navLink__1ARu5" href="/consumer-media">Consumer &amp; Media</a><a class="header_navLink__1ARu5" href="/biotech-medtech">Biotech &amp; Medtech</a><a class="header_navLink__1ARu5" href="/robotics-and-manufacturing">Robotics &amp; Manufacturing</a><a class="header_navLink__1ARu5" href="/training-data-food-agriculture">Food &amp; Agriculture</a></div></li><li class="header_navItem__1HiGN"><p class="header_navItem_label__fN3Cy">Why Sama</p><div class="header_dropDown__6NxUb"><a class="header_navLink__1ARu5" href="/quality-training-data">Quality</a><a class="header_navLink__1ARu5" href="/security-and-trust">Security</a><a class="header_navLink__1ARu5" href="/our-impact">Ethical AI</a><a class="header_navLink__1ARu5" href="/compare">Compare</a><a class="header_navLink__1ARu5" href="/partners">Partners</a></div></li><li class="header_navItem__1HiGN"><p class="header_navItem_label__fN3Cy">Resources</p><div class="header_dropDown__6NxUb"><a href="https://docs.sama.com/reference/overview" class="header_navLink__1ARu5" target="_blank">API Documentation</a><a class="header_navLink__1ARu5" href="/blog">Blog</a><a class="header_navLink__1ARu5" href="/events">Events</a></div></li><li class="header_navItem__1HiGN"><p class="header_navItem_label__fN3Cy">Company</p><div class="header_dropDown__6NxUb"><a class="header_navLink__1ARu5" href="/our-story">Our Story</a><a class="header_navLink__1ARu5" href="/our-team">Our Team</a><a class="header_navLink__1ARu5" href="/careers">Careers</a><a class="header_navLink__1ARu5" href="/company-contact">Contact</a><a class="header_navLink__1ARu5" href="/press">Press</a></div></li></ul><div class="header_cta__3J8I7"><a class="button_wrapper__3lRbv button__secondary__1pZ5q button__small__2kIwW" href="/[object%20Object]"><button class="button_btn__1qxP1"><h3 class="button_text__3_sCS">Request a Demo</h3></button></a></div></nav></header><main class="content"><section class="umoja-l-grid-section umoja-u-bg--white"><div class="umoja-l-grid--12"><div class="blog-tag_name__-rmiA"><h1>Sama Engineering</h1></div></div></section><section class="umoja-l-grid-section umoja-u-bg--white"><div class="umoja-l-grid--12 umoja-l-grid-gap--row-1"><div class="blog-post_postCard__i0O-O"><a class="blog-post_postCard_image__3k8eA" href="/[object%20Object]"><div style="display:block;overflow:hidden;position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;margin:0"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img sizes="100vw" srcSet="https://cdn.sanity.io/images/76e3r62u/production/bbf0e002b88fd9c3b2fcbd032f60f114bc93eed0-1980x990.png?w=640&amp;q=75&amp;fit=clip&amp;auto=format 640w, https://cdn.sanity.io/images/76e3r62u/production/bbf0e002b88fd9c3b2fcbd032f60f114bc93eed0-1980x990.png?w=750&amp;q=75&amp;fit=clip&amp;auto=format 750w, https://cdn.sanity.io/images/76e3r62u/production/bbf0e002b88fd9c3b2fcbd032f60f114bc93eed0-1980x990.png?w=828&amp;q=75&amp;fit=clip&amp;auto=format 828w, https://cdn.sanity.io/images/76e3r62u/production/bbf0e002b88fd9c3b2fcbd032f60f114bc93eed0-1980x990.png?w=1080&amp;q=75&amp;fit=clip&amp;auto=format 1080w, https://cdn.sanity.io/images/76e3r62u/production/bbf0e002b88fd9c3b2fcbd032f60f114bc93eed0-1980x990.png?w=1200&amp;q=75&amp;fit=clip&amp;auto=format 1200w, https://cdn.sanity.io/images/76e3r62u/production/bbf0e002b88fd9c3b2fcbd032f60f114bc93eed0-1980x990.png?w=1920&amp;q=75&amp;fit=clip&amp;auto=format 1920w, https://cdn.sanity.io/images/76e3r62u/production/bbf0e002b88fd9c3b2fcbd032f60f114bc93eed0-1980x990.png?w=2048&amp;q=75&amp;fit=clip&amp;auto=format 2048w, https://cdn.sanity.io/images/76e3r62u/production/bbf0e002b88fd9c3b2fcbd032f60f114bc93eed0-1980x990.png?w=3840&amp;q=75&amp;fit=clip&amp;auto=format 3840w" src="https://cdn.sanity.io/images/76e3r62u/production/bbf0e002b88fd9c3b2fcbd032f60f114bc93eed0-1980x990.png?w=3840&amp;q=75&amp;fit=clip&amp;auto=format" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" loading="lazy"/></noscript></div></a><div class="blog-post_postCard_data__2vfn3"><a href="/[object%20Object]"><h3>Part 3: A/B Testing with Python</h3></a><a class="blog-post_postCard_author__Y7RjO" href="/[object%20Object]">Rafael Alfaro &amp; Juan Esquivel</a><p class="blog-post_postCard_date__hrDMA ">March 16, 2021<!-- --> | 6 Min Read</p></div></div><div class="blog-post_postCard__i0O-O"><a class="blog-post_postCard_image__3k8eA" href="/[object%20Object]"><div style="display:block;overflow:hidden;position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;margin:0"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img sizes="100vw" srcSet="https://cdn.sanity.io/images/76e3r62u/production/bbf0e002b88fd9c3b2fcbd032f60f114bc93eed0-1980x990.png?w=640&amp;q=75&amp;fit=clip&amp;auto=format 640w, https://cdn.sanity.io/images/76e3r62u/production/bbf0e002b88fd9c3b2fcbd032f60f114bc93eed0-1980x990.png?w=750&amp;q=75&amp;fit=clip&amp;auto=format 750w, https://cdn.sanity.io/images/76e3r62u/production/bbf0e002b88fd9c3b2fcbd032f60f114bc93eed0-1980x990.png?w=828&amp;q=75&amp;fit=clip&amp;auto=format 828w, https://cdn.sanity.io/images/76e3r62u/production/bbf0e002b88fd9c3b2fcbd032f60f114bc93eed0-1980x990.png?w=1080&amp;q=75&amp;fit=clip&amp;auto=format 1080w, https://cdn.sanity.io/images/76e3r62u/production/bbf0e002b88fd9c3b2fcbd032f60f114bc93eed0-1980x990.png?w=1200&amp;q=75&amp;fit=clip&amp;auto=format 1200w, https://cdn.sanity.io/images/76e3r62u/production/bbf0e002b88fd9c3b2fcbd032f60f114bc93eed0-1980x990.png?w=1920&amp;q=75&amp;fit=clip&amp;auto=format 1920w, https://cdn.sanity.io/images/76e3r62u/production/bbf0e002b88fd9c3b2fcbd032f60f114bc93eed0-1980x990.png?w=2048&amp;q=75&amp;fit=clip&amp;auto=format 2048w, https://cdn.sanity.io/images/76e3r62u/production/bbf0e002b88fd9c3b2fcbd032f60f114bc93eed0-1980x990.png?w=3840&amp;q=75&amp;fit=clip&amp;auto=format 3840w" src="https://cdn.sanity.io/images/76e3r62u/production/bbf0e002b88fd9c3b2fcbd032f60f114bc93eed0-1980x990.png?w=3840&amp;q=75&amp;fit=clip&amp;auto=format" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" loading="lazy"/></noscript></div></a><div class="blog-post_postCard_data__2vfn3"><a href="/[object%20Object]"><h3>Part 2: A/B Testing</h3></a><a class="blog-post_postCard_author__Y7RjO" href="/[object%20Object]">Rafael Alfaro &amp; Juan Esquivel</a><p class="blog-post_postCard_date__hrDMA ">March 8, 2021<!-- --> | 4 Min Read</p></div></div><div class="blog-post_postCard__i0O-O"><a class="blog-post_postCard_image__3k8eA" href="/[object%20Object]"><div style="display:block;overflow:hidden;position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;margin:0"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img sizes="100vw" srcSet="https://cdn.sanity.io/images/76e3r62u/production/bbf0e002b88fd9c3b2fcbd032f60f114bc93eed0-1980x990.png?w=640&amp;q=75&amp;fit=clip&amp;auto=format 640w, https://cdn.sanity.io/images/76e3r62u/production/bbf0e002b88fd9c3b2fcbd032f60f114bc93eed0-1980x990.png?w=750&amp;q=75&amp;fit=clip&amp;auto=format 750w, https://cdn.sanity.io/images/76e3r62u/production/bbf0e002b88fd9c3b2fcbd032f60f114bc93eed0-1980x990.png?w=828&amp;q=75&amp;fit=clip&amp;auto=format 828w, https://cdn.sanity.io/images/76e3r62u/production/bbf0e002b88fd9c3b2fcbd032f60f114bc93eed0-1980x990.png?w=1080&amp;q=75&amp;fit=clip&amp;auto=format 1080w, https://cdn.sanity.io/images/76e3r62u/production/bbf0e002b88fd9c3b2fcbd032f60f114bc93eed0-1980x990.png?w=1200&amp;q=75&amp;fit=clip&amp;auto=format 1200w, https://cdn.sanity.io/images/76e3r62u/production/bbf0e002b88fd9c3b2fcbd032f60f114bc93eed0-1980x990.png?w=1920&amp;q=75&amp;fit=clip&amp;auto=format 1920w, https://cdn.sanity.io/images/76e3r62u/production/bbf0e002b88fd9c3b2fcbd032f60f114bc93eed0-1980x990.png?w=2048&amp;q=75&amp;fit=clip&amp;auto=format 2048w, https://cdn.sanity.io/images/76e3r62u/production/bbf0e002b88fd9c3b2fcbd032f60f114bc93eed0-1980x990.png?w=3840&amp;q=75&amp;fit=clip&amp;auto=format 3840w" src="https://cdn.sanity.io/images/76e3r62u/production/bbf0e002b88fd9c3b2fcbd032f60f114bc93eed0-1980x990.png?w=3840&amp;q=75&amp;fit=clip&amp;auto=format" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" loading="lazy"/></noscript></div></a><div class="blog-post_postCard_data__2vfn3"><a href="/[object%20Object]"><h3>Part 1: Experiment Driven Development</h3></a><a class="blog-post_postCard_author__Y7RjO" href="/[object%20Object]">Rafael Alfaro &amp; Juan Esquivel</a><p class="blog-post_postCard_date__hrDMA ">March 1, 2021<!-- --> | 3 Min Read</p></div></div><div class="blog-post_postCard__i0O-O"><a class="blog-post_postCard_image__3k8eA" href="/[object%20Object]"><div style="display:block;overflow:hidden;position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;margin:0"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img sizes="100vw" srcSet="https://cdn.sanity.io/images/76e3r62u/production/19ef3f125b8ee47727e9f94dc3aff7ed08a4d78c-720x360.png?w=640&amp;q=75&amp;fit=clip&amp;auto=format 640w, https://cdn.sanity.io/images/76e3r62u/production/19ef3f125b8ee47727e9f94dc3aff7ed08a4d78c-720x360.png?w=750&amp;q=75&amp;fit=clip&amp;auto=format 750w, https://cdn.sanity.io/images/76e3r62u/production/19ef3f125b8ee47727e9f94dc3aff7ed08a4d78c-720x360.png?w=828&amp;q=75&amp;fit=clip&amp;auto=format 828w, https://cdn.sanity.io/images/76e3r62u/production/19ef3f125b8ee47727e9f94dc3aff7ed08a4d78c-720x360.png?w=1080&amp;q=75&amp;fit=clip&amp;auto=format 1080w, https://cdn.sanity.io/images/76e3r62u/production/19ef3f125b8ee47727e9f94dc3aff7ed08a4d78c-720x360.png?w=1200&amp;q=75&amp;fit=clip&amp;auto=format 1200w, https://cdn.sanity.io/images/76e3r62u/production/19ef3f125b8ee47727e9f94dc3aff7ed08a4d78c-720x360.png?w=1920&amp;q=75&amp;fit=clip&amp;auto=format 1920w, https://cdn.sanity.io/images/76e3r62u/production/19ef3f125b8ee47727e9f94dc3aff7ed08a4d78c-720x360.png?w=2048&amp;q=75&amp;fit=clip&amp;auto=format 2048w, https://cdn.sanity.io/images/76e3r62u/production/19ef3f125b8ee47727e9f94dc3aff7ed08a4d78c-720x360.png?w=3840&amp;q=75&amp;fit=clip&amp;auto=format 3840w" src="https://cdn.sanity.io/images/76e3r62u/production/19ef3f125b8ee47727e9f94dc3aff7ed08a4d78c-720x360.png?w=3840&amp;q=75&amp;fit=clip&amp;auto=format" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" loading="lazy"/></noscript></div></a><div class="blog-post_postCard_data__2vfn3"><a href="/[object%20Object]"><h3>Factotum: Containerizing DevOps Tools for Cloud Native Engineering and CI/CD</h3></a><a class="blog-post_postCard_author__Y7RjO" href="/[object%20Object]">Mathieu Frenette</a><p class="blog-post_postCard_date__hrDMA ">February 1, 2021<!-- --> | 4 Min Read</p></div></div><div class="blog-post_postCard__i0O-O"><a class="blog-post_postCard_image__3k8eA" href="/[object%20Object]"><div style="display:block;overflow:hidden;position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;margin:0"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img sizes="100vw" srcSet="https://cdn.sanity.io/images/76e3r62u/production/04641081798c41caebebefa44685828d80b7434f-1200x675.png?w=640&amp;q=75&amp;fit=clip&amp;auto=format 640w, https://cdn.sanity.io/images/76e3r62u/production/04641081798c41caebebefa44685828d80b7434f-1200x675.png?w=750&amp;q=75&amp;fit=clip&amp;auto=format 750w, https://cdn.sanity.io/images/76e3r62u/production/04641081798c41caebebefa44685828d80b7434f-1200x675.png?w=828&amp;q=75&amp;fit=clip&amp;auto=format 828w, https://cdn.sanity.io/images/76e3r62u/production/04641081798c41caebebefa44685828d80b7434f-1200x675.png?w=1080&amp;q=75&amp;fit=clip&amp;auto=format 1080w, https://cdn.sanity.io/images/76e3r62u/production/04641081798c41caebebefa44685828d80b7434f-1200x675.png?w=1200&amp;q=75&amp;fit=clip&amp;auto=format 1200w, https://cdn.sanity.io/images/76e3r62u/production/04641081798c41caebebefa44685828d80b7434f-1200x675.png?w=1920&amp;q=75&amp;fit=clip&amp;auto=format 1920w, https://cdn.sanity.io/images/76e3r62u/production/04641081798c41caebebefa44685828d80b7434f-1200x675.png?w=2048&amp;q=75&amp;fit=clip&amp;auto=format 2048w, https://cdn.sanity.io/images/76e3r62u/production/04641081798c41caebebefa44685828d80b7434f-1200x675.png?w=3840&amp;q=75&amp;fit=clip&amp;auto=format 3840w" src="https://cdn.sanity.io/images/76e3r62u/production/04641081798c41caebebefa44685828d80b7434f-1200x675.png?w=3840&amp;q=75&amp;fit=clip&amp;auto=format" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" loading="lazy"/></noscript></div></a><div class="blog-post_postCard_data__2vfn3"><a href="/[object%20Object]"><h3>The Sama MLOps Pipeline: Automating Model Training on the Cloud</h3></a><a class="blog-post_postCard_author__Y7RjO" href="/[object%20Object]">Dimitri Gallos</a><p class="blog-post_postCard_date__hrDMA ">January 19, 2021<!-- --> | 3 Min Read</p></div></div><div class="blog-post_postCard__i0O-O"><a class="blog-post_postCard_image__3k8eA" href="/[object%20Object]"><div style="display:block;overflow:hidden;position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;margin:0"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img sizes="100vw" srcSet="https://cdn.sanity.io/images/76e3r62u/production/6abd2f846119ba50a8325787f99ec3aeec68ffff-1076x605.png?w=640&amp;q=75&amp;fit=clip&amp;auto=format 640w, https://cdn.sanity.io/images/76e3r62u/production/6abd2f846119ba50a8325787f99ec3aeec68ffff-1076x605.png?w=750&amp;q=75&amp;fit=clip&amp;auto=format 750w, https://cdn.sanity.io/images/76e3r62u/production/6abd2f846119ba50a8325787f99ec3aeec68ffff-1076x605.png?w=828&amp;q=75&amp;fit=clip&amp;auto=format 828w, https://cdn.sanity.io/images/76e3r62u/production/6abd2f846119ba50a8325787f99ec3aeec68ffff-1076x605.png?w=1080&amp;q=75&amp;fit=clip&amp;auto=format 1080w, https://cdn.sanity.io/images/76e3r62u/production/6abd2f846119ba50a8325787f99ec3aeec68ffff-1076x605.png?w=1200&amp;q=75&amp;fit=clip&amp;auto=format 1200w, https://cdn.sanity.io/images/76e3r62u/production/6abd2f846119ba50a8325787f99ec3aeec68ffff-1076x605.png?w=1920&amp;q=75&amp;fit=clip&amp;auto=format 1920w, https://cdn.sanity.io/images/76e3r62u/production/6abd2f846119ba50a8325787f99ec3aeec68ffff-1076x605.png?w=2048&amp;q=75&amp;fit=clip&amp;auto=format 2048w, https://cdn.sanity.io/images/76e3r62u/production/6abd2f846119ba50a8325787f99ec3aeec68ffff-1076x605.png?w=3840&amp;q=75&amp;fit=clip&amp;auto=format 3840w" src="https://cdn.sanity.io/images/76e3r62u/production/6abd2f846119ba50a8325787f99ec3aeec68ffff-1076x605.png?w=3840&amp;q=75&amp;fit=clip&amp;auto=format" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" loading="lazy"/></noscript></div></a><div class="blog-post_postCard_data__2vfn3"><a href="/[object%20Object]"><h3>Fast Vector Annotation with Machine Learning Assisted Annotation</h3></a><a class="blog-post_postCard_author__Y7RjO" href="/[object%20Object]">Frederic Ratle</a><p class="blog-post_postCard_date__hrDMA ">December 15, 2020<!-- --> | 8 Min Read</p></div></div><div class="blog-post_postCard__i0O-O"><a class="blog-post_postCard_image__3k8eA" href="/[object%20Object]"><div style="display:block;overflow:hidden;position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;margin:0"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img sizes="100vw" srcSet="https://cdn.sanity.io/images/76e3r62u/production/8b71517603a306e0f80ea070e3d0d532f0039105-1024x512.png?w=640&amp;q=75&amp;fit=clip&amp;auto=format 640w, https://cdn.sanity.io/images/76e3r62u/production/8b71517603a306e0f80ea070e3d0d532f0039105-1024x512.png?w=750&amp;q=75&amp;fit=clip&amp;auto=format 750w, https://cdn.sanity.io/images/76e3r62u/production/8b71517603a306e0f80ea070e3d0d532f0039105-1024x512.png?w=828&amp;q=75&amp;fit=clip&amp;auto=format 828w, https://cdn.sanity.io/images/76e3r62u/production/8b71517603a306e0f80ea070e3d0d532f0039105-1024x512.png?w=1080&amp;q=75&amp;fit=clip&amp;auto=format 1080w, https://cdn.sanity.io/images/76e3r62u/production/8b71517603a306e0f80ea070e3d0d532f0039105-1024x512.png?w=1200&amp;q=75&amp;fit=clip&amp;auto=format 1200w, https://cdn.sanity.io/images/76e3r62u/production/8b71517603a306e0f80ea070e3d0d532f0039105-1024x512.png?w=1920&amp;q=75&amp;fit=clip&amp;auto=format 1920w, https://cdn.sanity.io/images/76e3r62u/production/8b71517603a306e0f80ea070e3d0d532f0039105-1024x512.png?w=2048&amp;q=75&amp;fit=clip&amp;auto=format 2048w, https://cdn.sanity.io/images/76e3r62u/production/8b71517603a306e0f80ea070e3d0d532f0039105-1024x512.png?w=3840&amp;q=75&amp;fit=clip&amp;auto=format 3840w" src="https://cdn.sanity.io/images/76e3r62u/production/8b71517603a306e0f80ea070e3d0d532f0039105-1024x512.png?w=3840&amp;q=75&amp;fit=clip&amp;auto=format" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" loading="lazy"/></noscript></div></a><div class="blog-post_postCard_data__2vfn3"><a href="/[object%20Object]"><h3>Code.Jam(2020)-McGill Hackathon: and the winner is A Virtual Fitting Room</h3></a><a class="blog-post_postCard_author__Y7RjO" href="/[object%20Object]">Loic Juillard</a><p class="blog-post_postCard_date__hrDMA ">November 16, 2020<!-- --> | 3 Min Read</p></div></div><div class="blog-post_postCard__i0O-O"><a class="blog-post_postCard_image__3k8eA" href="/[object%20Object]"><div style="display:block;overflow:hidden;position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;margin:0"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img sizes="100vw" srcSet="https://cdn.sanity.io/images/76e3r62u/production/ade4117797bfbff2e90f48d6ad558ab992aca273-3423x2283.jpg?w=640&amp;q=75&amp;fit=clip&amp;auto=format 640w, https://cdn.sanity.io/images/76e3r62u/production/ade4117797bfbff2e90f48d6ad558ab992aca273-3423x2283.jpg?w=750&amp;q=75&amp;fit=clip&amp;auto=format 750w, https://cdn.sanity.io/images/76e3r62u/production/ade4117797bfbff2e90f48d6ad558ab992aca273-3423x2283.jpg?w=828&amp;q=75&amp;fit=clip&amp;auto=format 828w, https://cdn.sanity.io/images/76e3r62u/production/ade4117797bfbff2e90f48d6ad558ab992aca273-3423x2283.jpg?w=1080&amp;q=75&amp;fit=clip&amp;auto=format 1080w, https://cdn.sanity.io/images/76e3r62u/production/ade4117797bfbff2e90f48d6ad558ab992aca273-3423x2283.jpg?w=1200&amp;q=75&amp;fit=clip&amp;auto=format 1200w, https://cdn.sanity.io/images/76e3r62u/production/ade4117797bfbff2e90f48d6ad558ab992aca273-3423x2283.jpg?w=1920&amp;q=75&amp;fit=clip&amp;auto=format 1920w, https://cdn.sanity.io/images/76e3r62u/production/ade4117797bfbff2e90f48d6ad558ab992aca273-3423x2283.jpg?w=2048&amp;q=75&amp;fit=clip&amp;auto=format 2048w, https://cdn.sanity.io/images/76e3r62u/production/ade4117797bfbff2e90f48d6ad558ab992aca273-3423x2283.jpg?w=3840&amp;q=75&amp;fit=clip&amp;auto=format 3840w" src="https://cdn.sanity.io/images/76e3r62u/production/ade4117797bfbff2e90f48d6ad558ab992aca273-3423x2283.jpg?w=3840&amp;q=75&amp;fit=clip&amp;auto=format" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" loading="lazy"/></noscript></div></a><div class="blog-post_postCard_data__2vfn3"><a href="/[object%20Object]"><h3>8 Answers to Your Questions About AI and Machine Learning</h3></a><a class="blog-post_postCard_author__Y7RjO" href="/[object%20Object]">Sharon L. Hadden</a><p class="blog-post_postCard_date__hrDMA ">December 19, 2019</p></div></div><div class="blog-post_postCard__i0O-O"><a class="blog-post_postCard_image__3k8eA" href="/[object%20Object]"><div style="display:block;overflow:hidden;position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;margin:0"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img sizes="100vw" srcSet="https://cdn.sanity.io/images/76e3r62u/production/980fdc38382a1cc5d9c462b19141b595b5d9ea31-974x460.png?w=640&amp;q=75&amp;fit=clip&amp;auto=format 640w, https://cdn.sanity.io/images/76e3r62u/production/980fdc38382a1cc5d9c462b19141b595b5d9ea31-974x460.png?w=750&amp;q=75&amp;fit=clip&amp;auto=format 750w, https://cdn.sanity.io/images/76e3r62u/production/980fdc38382a1cc5d9c462b19141b595b5d9ea31-974x460.png?w=828&amp;q=75&amp;fit=clip&amp;auto=format 828w, https://cdn.sanity.io/images/76e3r62u/production/980fdc38382a1cc5d9c462b19141b595b5d9ea31-974x460.png?w=1080&amp;q=75&amp;fit=clip&amp;auto=format 1080w, https://cdn.sanity.io/images/76e3r62u/production/980fdc38382a1cc5d9c462b19141b595b5d9ea31-974x460.png?w=1200&amp;q=75&amp;fit=clip&amp;auto=format 1200w, https://cdn.sanity.io/images/76e3r62u/production/980fdc38382a1cc5d9c462b19141b595b5d9ea31-974x460.png?w=1920&amp;q=75&amp;fit=clip&amp;auto=format 1920w, https://cdn.sanity.io/images/76e3r62u/production/980fdc38382a1cc5d9c462b19141b595b5d9ea31-974x460.png?w=2048&amp;q=75&amp;fit=clip&amp;auto=format 2048w, https://cdn.sanity.io/images/76e3r62u/production/980fdc38382a1cc5d9c462b19141b595b5d9ea31-974x460.png?w=3840&amp;q=75&amp;fit=clip&amp;auto=format 3840w" src="https://cdn.sanity.io/images/76e3r62u/production/980fdc38382a1cc5d9c462b19141b595b5d9ea31-974x460.png?w=3840&amp;q=75&amp;fit=clip&amp;auto=format" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" loading="lazy"/></noscript></div></a><div class="blog-post_postCard_data__2vfn3"><a href="/[object%20Object]"><h3>Highlights from McGill CodeJam 2019</h3></a><a class="blog-post_postCard_author__Y7RjO" href="/[object%20Object]">Taylor Rouleau</a><p class="blog-post_postCard_date__hrDMA ">December 2, 2019</p></div></div></div></section></main><footer class="footer_wrapper__2VAfJ"><div class="umoja-l-grid--12"><div class="footer_upper__2a6XG"><div><h4>Newsletter</h4><p>Subscribe today and be the first to receive the latest from Sama.</p></div><div class="footer_upper_right__cpliC"><div><p class="footer_nav_head__1keQK">Guides</p><a class="footer_nav_link__X1RNI" href="/training-data-for-autonomous-driving">Autonomous Transportation</a><a class="footer_nav_link__X1RNI" href="/training-data-for-ecommerce">E-Commerce</a><a class="footer_nav_link__X1RNI" href="/training-data-for-ar-vr">AR/VR</a><a class="footer_nav_link__X1RNI" href="/data-quality">Data Quality</a></div><div><p class="footer_nav_head__1keQK">Company</p><a class="footer_nav_link__X1RNI" href="/our-story">Our Story</a><a class="footer_nav_link__X1RNI" href="/our-team">Our Team</a><a class="footer_nav_link__X1RNI" href="/mission-vision-values">Our Mission</a><a class="footer_nav_link__X1RNI" href="/careers">Careers</a><a class="footer_nav_link__X1RNI" href="/company-contact">Contact</a></div></div></div><div class="footer_middle__iiTSJ"><div class="footer_middle_left__3ff78"><a href="/"></a></div><div class="footer_middle_right__2b-lC"><div class="footer_social__1NFfV"><a href="https://www.facebook.com/samaartificialintelligence" class="footer_social_icon__wI2OK" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 35.1 64.89"><title>facebook</title><g id="fb3209c8-23d4-4288-984d-a2b8f32b7f0c" data-name="Layer 2"><g id="ba1a815d-13f1-45f9-9321-18e9a3cfa5db" data-name="Layer 1"><path d="M35.1,11.26V1.36A1.35,1.35,0,0,0,33.76,0H25.35A15.34,15.34,0,0,0,14,4.35C11.24,7.2,9.78,11.22,9.78,16v7.34H1.34A1.34,1.34,0,0,0,0,24.66V35.32a1.35,1.35,0,0,0,1.34,1.35H9.78V63.55a1.34,1.34,0,0,0,1.34,1.34h11a1.34,1.34,0,0,0,1.34-1.34V36.67h9.87a1.35,1.35,0,0,0,1.34-1.35V24.66a1.37,1.37,0,0,0-.7-1.18,1.47,1.47,0,0,0-.67-.16H23.49V17.1c0-1.72.25-2.69.84-3.37s1.88-1.13,3.77-1.13h5.66A1.34,1.34,0,0,0,35.1,11.26Z"></path></g></g></svg></a><a href="https://www.instagram.com/sama_ai_" class="footer_social_icon__wI2OK" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 57 57"><title>insta</title><g id="ef02a3ef-c0d3-4be7-9d4e-2c42263777a3" data-name="Layer 2"><g id="a0a92778-6c5c-4e06-a08f-641546580dd0" data-name="Layer 1"><circle cx="28.5" cy="28.5" r="9.24"></circle><path d="M41.57,0H15.43A15.45,15.45,0,0,0,0,15.43V41.57A15.45,15.45,0,0,0,15.43,57H41.57A15.45,15.45,0,0,0,57,41.57V15.43A15.45,15.45,0,0,0,41.57,0ZM28.5,42.74A14.24,14.24,0,1,1,42.74,28.5,14.26,14.26,0,0,1,28.5,42.74ZM44.46,17a5,5,0,1,1,5-5A5,5,0,0,1,44.46,17Z"></path></g></g></svg></a><a href="https://twitter.com/SamaAI" class="footer_social_icon__wI2OK" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 62 51.19"><title>twitter</title><g id="e7743e55-1863-47ad-a995-4b7f1f924f07" data-name="Layer 2"><g id="ec8c6fd9-2f52-4507-9a24-804bc60dbc33" data-name="Layer 1"><path d="M23.59,51.19c-10.35,0-18.53-1.81-22.44-5l-.07-.06L1,46.1a3.19,3.19,0,0,1-.84-3.35l0-.1a3.24,3.24,0,0,1,3-2,26.57,26.57,0,0,0,7.06-1,13.45,13.45,0,0,1-7.07-8.16,2.92,2.92,0,0,1,1-3.38,3.06,3.06,0,0,1,.88-.45,19.52,19.52,0,0,1-4-7.18l0-.08,0-.09a3,3,0,0,1,1.4-3.23,3,3,0,0,1,1.43-.4,15.15,15.15,0,0,1-1.14-3.49A14.59,14.59,0,0,1,4.24,3.47l.38-.77a2.15,2.15,0,0,1,3.44-.56l.7.7c5.53,5.81,10.49,8.56,19.06,10.44a15.17,15.17,0,0,1,4.1-8.75A14.39,14.39,0,0,1,42.19,0h0c2.84,0,6.36,1.62,8.49,2.77,1.83-.6,4-1.53,6.32-2.51a2.88,2.88,0,0,1,3.22.57,2.85,2.85,0,0,1,.62,3.11c-.17.47-.36.92-.57,1.36a3.07,3.07,0,0,1,.84.58,3.13,3.13,0,0,1,.78,2.92l0,.1a11.92,11.92,0,0,1-4.78,6.56C56.73,35.23,41.84,51.19,23.59,51.19Z"></path></g></g></svg></a><a href="https://www.linkedin.com/company/sama-ai/" class="footer_social_icon__wI2OK" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 59.71 60.79"><title>linkedin</title><g id="bd073dff-b6ea-4cf0-bfeb-c3ce392ee6a5" data-name="Layer 2"><g id="f6b6eb77-7c10-4e27-a3d0-6f8b14e97f2e" data-name="Layer 1"><path d="M59.65,60.79l-12.35,0,0-19.36c0-4.62-.07-10.56-6.41-10.58s-7.44,5-7.45,10.21l0,19.7-12.36,0,.09-40.95,11.87,0v6.57h.16c1.66-3.13,5.7-6.42,11.73-6.41,12.51,0,14.81,8.28,14.79,19l-.05,21.85Z"></path><path d="M7.17,14.35a7.18,7.18,0,1,1,7.18-7.18A7.17,7.17,0,0,1,7.17,14.35Z"></path><rect x="0.98" y="19.8" width="12.39" height="40.95"></rect></g></g></svg></a><a href="https://www.youtube.com/c/SamaAI" class="footer_social_icon__wI2OK" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 65 44.63"><title>youtube</title><g id="b03ac260-8029-40d4-832d-1f2d757db2d5" data-name="Layer 2"><g id="eca1bfe4-f0ec-4c24-9169-be6d2f8b24b5" data-name="Layer 1"><path d="M55,0H10A10,10,0,0,0,0,10V34.63a10,10,0,0,0,10,10H55a10,10,0,0,0,10-10V10A10,10,0,0,0,55,0ZM40.89,24.41,28.3,31.18a2.31,2.31,0,0,1-3.41-2V15.48a2.3,2.3,0,0,1,3.42-2l12.6,6.89a2.31,2.31,0,0,1,0,4.06Z"></path></g></g></svg></a></div></div></div><div class="footer_lower__1z3Av"><div class="footer_lower_left__141hE"><a class="footer_nav_link__X1RNI" href="/terms-of-service">Terms</a><a class="footer_nav_link__X1RNI" href="/privacy-policy">Privacy</a><a class="footer_nav_link__X1RNI" href="/quality-and-information-policy">Quality &amp; Information</a></div><div class="footer_lower_right__22vMw"><h6>Copyright © <!-- -->0<!-- --> Sama Inc.</h6><h6>All rights reserved.</h6></div></div></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"config":{"footerNav":{"items":[{"_key":"f255606f8f25","_type":"navDropdownMenu","items":[{"_key":"76389ad94cbb","_type":"navItem","title":"Autonomous Transportation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"training-data-for-autonomous-driving"}}}},{"_key":"5f64a8d6a69d","_type":"navItem","title":"E-Commerce","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"training-data-for-ecommerce"}}}},{"_key":"f10e54ae04d0","_type":"navItem","title":"AR/VR","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"training-data-for-ar-vr"}}}},{"_key":"fd729b522a77","_type":"navItem","title":"Data Quality","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"data-quality"}}}}],"title":"Guides","url":null},{"_key":"681ef7d8763a","_type":"navDropdownMenu","items":[{"_key":"6238a422b667","_type":"navItem","title":"Our Story","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-story"}}}},{"_key":"258985d6d46b","_type":"navItem","title":"Our Team","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-team"}}}},{"_key":"e0a76077324a","_type":"navItem","title":"Our Mission","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"mission-vision-values"}}}},{"_key":"239e49661b0d","_type":"navItem","title":"Careers","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"careers"}}}},{"_key":"e005a740cd80","_type":"navItem","title":"Contact","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"company-contact"}}}}],"title":"Company","url":null}]},"logo":{"asset":{"_createdAt":"2021-10-29T18:38:04Z","_id":"image-e20f8cc53e5f74df10ae9a822edb7ec2c4d00f02-2380x636-svg","_rev":"yuZxWYwFNB6KJB4TM9NtaY","_type":"sanity.imageAsset","_updatedAt":"2021-10-29T18:38:04Z","assetId":"e20f8cc53e5f74df10ae9a822edb7ec2c4d00f02","extension":"svg","metadata":{"_type":"sanity.imageMetadata","dimensions":{"_type":"sanity.imageDimensions","aspectRatio":3.742138364779874,"height":636,"width":2380},"hasAlpha":true,"isOpaque":false,"lqip":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAYAAABFA8wzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAr0lEQVQYlU3QyUoDQBAE0HeIEjeixAVyESRI3BNFJSZxAU/+/wdJQSEehu6Zqa6uKnjBGz7xgTuc4gAj7LWe4LD9cc8Y+9jBUed84QGrEt/gEleYY9Ylr3jGU/tV77fFLirId0nWBYYgoACi+r3D6YPN0vwFm4VxmNlgfkK4qcLUZdVMcdHB+75FzWPfzzCpxXNcFxuOP2uxnhNLASaX5LjbnJJf6jYG2PpXh812/AvSEQ+GGZqgYgAAAABJRU5ErkJggg==","palette":{"_type":"sanity.imagePalette","darkMuted":{"_type":"sanity.imagePaletteSwatch","background":"#040404","foreground":"#fff","population":100.29,"title":"#fff"},"darkVibrant":{"_type":"sanity.imagePaletteSwatch","background":"#424242","foreground":"#fff","population":0,"title":"#fff"},"dominant":{"_type":"sanity.imagePaletteSwatch","background":"#040404","foreground":"#fff","population":100.29,"title":"#fff"},"lightMuted":{"_type":"sanity.imagePaletteSwatch","background":"#4c4c4c","foreground":"#fff","population":0,"title":"#fff"},"lightVibrant":{"_type":"sanity.imagePaletteSwatch","background":"#bcbcbc","foreground":"#000","population":0,"title":"#fff"},"muted":{"_type":"sanity.imagePaletteSwatch","background":"#4c4c4c","foreground":"#fff","population":0,"title":"#fff"},"vibrant":{"_type":"sanity.imagePaletteSwatch","background":"#7f7f7f","foreground":"#fff","population":0,"title":"#fff"}}},"mimeType":"image/svg+xml","originalFilename":"image.svg","path":"images/76e3r62u/production/e20f8cc53e5f74df10ae9a822edb7ec2c4d00f02-2380x636.svg","sha1hash":"ae6a56857a230101a883a9b93974923879775bc9","size":2009,"uploadId":"mtOtmqAQnCEIG5cEqXZ1YAOCuqHJ4X3g","url":"https://cdn.sanity.io/images/76e3r62u/production/e20f8cc53e5f74df10ae9a822edb7ec2c4d00f02-2380x636.svg"}},"mainNav":{"items":[{"_key":"58c18e9aa9ea","_type":"navDropdownMenu","items":[{"_key":"b5b5b8bee78b","_type":"navCat","items":[{"_key":"0e80156a2f1a","_type":"navItem","title":"How it Works","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"how-it-works"}}}},{"_key":"40bacee029b4","_type":"navItem","title":"Video Annotation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"video-annotation"}}}},{"_key":"32650ef07503","_type":"navItem","title":"Image Annotation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"image-annotation"}}}},{"_key":"fe9137cd0167","_type":"navItem","title":"3D \u0026 LiDAR Annotation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"3d-lidar"}}}},{"_key":"d9a1316d400a","_type":"navItem","title":"Natural Language Processing","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"natural-language-processing"}}}},{"_key":"ac12c7c5d70a","_type":"navItem","title":"Data Curation (Beta)","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"data-curation"}}}}],"title":"Platform","url":null},{"_key":"37ff4fa913bd","_type":"navCat","items":[{"_key":"6026b1a9314e","_type":"navItem","title":"Semantic Segmentation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"semantic-segmentation"}}}},{"_key":"f4611b19b406","_type":"navItem","title":"Polygons","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"polygons"}}}},{"_key":"5155d874d6c8","_type":"navItem","title":"Bounding Boxes","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"bounding-boxes"}}}},{"_key":"9ef3c1e21e74","_type":"navItem","title":"Key Points","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"key-points"}}}},{"_key":"314d4c00d351","_type":"navItem","title":"Cuboids","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"cuboids"}}}},{"_key":"8e17a6388d74","_type":"navItem","title":"Lines \u0026 Arrows","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"lines-and-arrows"}}}}],"title":"Shapes","url":null}],"title":"Platform","url":null},{"_key":"112867ca4d03","_type":"navDropdownMenu","items":[{"_key":"22699c7e06cb","_type":"navItem","items":null,"title":"Transportation \u0026 Navigation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"transportation-navigation"}}}},{"_key":"122ae5928d6d","_type":"navItem","items":null,"title":"Retail \u0026 E-Commerce","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"retail-ecommerce"}}}},{"_key":"7bb234b69fb0","_type":"navItem","items":null,"title":"Consumer \u0026 Media","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"consumer-media"}}}},{"_key":"33e6a886b39d","_type":"navItem","items":null,"title":"Biotech \u0026 Medtech","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"biotech-medtech"}}}},{"_key":"d095b2619c4e","_type":"navItem","items":null,"title":"Robotics \u0026 Manufacturing","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"robotics-and-manufacturing"}}}},{"_key":"2c4b82a94d79","_type":"navItem","items":null,"title":"Food \u0026 Agriculture","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"training-data-food-agriculture"}}}}],"title":"Industries","url":null},{"_key":"c47e8763a906","_type":"navDropdownMenu","items":[{"_key":"1d563df30b3f","_type":"navItem","items":null,"title":"Quality","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"quality-training-data"}}}},{"_key":"041725f35d96","_type":"navItem","items":null,"title":"Security","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"security-and-trust"}}}},{"_key":"fd64ede25798","_type":"navItem","items":null,"title":"Ethical AI","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-impact"}}}},{"_key":"398dcbb1c95d","_type":"navItem","items":null,"title":"Compare","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"compare"}}}},{"_key":"93bdfdd87879","_type":"navItem","items":null,"title":"Partners","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"partners"}}}}],"title":"Why Sama","url":null},{"_key":"1d38bf63df54","_type":"navDropdownMenu","items":[{"_key":"be81659b38a5","_type":"navItem","items":null,"title":"API Documentation","url":{"_type":"link","externalUrl":"https://docs.sama.com/reference/overview","internalLink":null}},{"_key":"2cec80e94962","_type":"navItem","items":null,"title":"Blog","url":{"_type":"link","internalLink":null,"internalLink_custom":"/blog"}},{"_key":"09e284fcb1d3","_type":"navItem","items":null,"title":"Events","url":{"_type":"link","internalLink":null,"internalLink_custom":"/events"}}],"title":"Resources","url":null},{"_key":"dbee93713c19","_type":"navDropdownMenu","items":[{"_key":"12d594a568bf","_type":"navItem","items":null,"title":"Our Story","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-story"}}}},{"_key":"ce36540a102d","_type":"navItem","items":null,"title":"Our Team","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-team"}}}},{"_key":"34fc328e8022","_type":"navItem","items":null,"title":"Careers","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"careers"}}}},{"_key":"c1fe2961020a","_type":"navItem","items":null,"title":"Contact","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"company-contact"}}}},{"_key":"ebd81873e538","_type":"navItem","items":null,"title":"Press","url":{"_type":"link","internalLink":null,"internalLink_custom":"/press"}}],"title":"Company","url":null}],"nav_cta":{"_type":"button","link":{"_type":"link","internalLink":{"_ref":"136788cb-06a6-4f27-b75b-07faf403bfa6","_type":"reference"}},"title":"Request a Demo","type":"secondary"}}},"data":{"firstLoad":[{"_createdAt":"2021-03-17T03:58:33Z","author":{"_id":"40a70383-c941-405c-ae5b-f0aba421ee53","avatar":{"_type":"image","asset":{"_ref":"image-e0fe681e594567792ac79048513fe955cc770f54-518x518-svg","_type":"reference"}},"bio":"Rafael and Juan are both senior members of Sama R\u0026D where they focus on Data Engineering and Data Science initiatives that help boost operational efficiency and achieve the highest quality.","name":"Rafael Alfaro \u0026 Juan Esquivel","slug":{"_type":"slug","current":"rafael-alfaro-and-juan-esquivel"}},"config":{"description":"In this series of three we’ll go into Experiment Driven Development and A/B Testing. EDD is fact-based development: based on evidence, not intuition.","openGraphImage":null,"title":"Part 3: A/B Testing with Python"},"estimatedReadingTime":6,"featured_image":{"_type":"image","asset":{"_ref":"image-bbf0e002b88fd9c3b2fcbd032f60f114bc93eed0-1980x990-png","_type":"reference"}},"plaintextBody":"We've previously explored the foundations of Experiment Driven Design and A/B Testing. Today we'll dig into A/B Testing with Python because analysis can be easily automated with existing open source python libraries. In this post we will explore their usage with an example. To orient the reader, we will state a few definitions to anchor the example:\n\nControl Group: current user interface.\nExperiment Group: rearranged point annotation button.\n\nH0: The mean of the annotation time for the control group is the same as the mean of the annotation time for the experiment group; there is no effect from rearranging the point annotation button.\n\nH1: The mean of the annotation time for the control group is different from the mean of the annotation time for the experiment group; there is an observable effect from rearranging the point annotation button.\n\nLet us assume that we ran an A/B Test feature experiment for two weeks. The UI modifications consisted of rearranging a button used in the process of drawing polygons around objects Let us assume these were recorded annotation times per image in minutes, for users of each variant (it can be represented as a python list):\n\nA. Control group (original arrangement):\n\nvariant_a = [150, 195, 120, 160, 97, 20, 100, 121, 250, 300, 80, 75, 100, 196, 147, 120, 100, 190, 57, 100, 157, 186, 91, 190, 210, 222, 192, 243, 99, 151]\n\n\n\nB. Experiment group (rearranged button):\n\nvariant_b = [120, 110, 96, 99, 87, 55, 43, 83, 200, 100, 125, 140, 75, 91, 141, 121, 250, 35, 94, 65, 85, 67, 93, 161, 35, 34, 111, 124, 85, 103]\n\n\n\n1. Run the t-test from the scipy.stats module of scipy (a mathematical, scientific and engineering library).\n\n\nimport scipy.stats as stats\n\nt, p = stats.ttest_ind(variant_a, variant_b, equal_var=False)\n\n\n\n2. Calculate the degrees of freedom according to Welch’s t-test definition which is the one implemented in stats.ttest_ind\n\n# For illustrative details see Wikipedia\n\n\ns1 = np.std(variant_a)\ns2 = np.std(variant_b)\nn1 = len(variant_a)\nn2 = len(variant_b)\n\ndf = np.floor(((((s1 ** 2) / n1) + ((s2 ** 2) / n2)) ** 2) /\n(((s1 ** 4) / ((n1 ** 2) * (n1 - 1))) + ((s2 ** 4) / ((n2 ** 2) * (n2 - 1)))))\n\n\n\n3. Now, using the same scipy.stats library, get the t-critical value for 95% or an alpha of 0.05 (1 - confidence level) from the t distribution’s ppf (percent point function) function and evaluate the t statistic from the previous step. If it falls in the range [-t-critical, t-critical] then H0 cannot be rejected, if it is outside, then we can reject H0 in favor of H1:\n\nalpha = 0.05\nt_critical_value = stats.t.ppf(1 - (alpha/2), df)\nnull_hypothesis = bool(t_critical_value \u003e= t_value \u003e= -t_critical_value)\n\n\n\n4. The confidence interval of variant_b (experiment) will help us visualize the difference between the two variants. If the mean of the control group doesn’t fall inside of this interval then the means of the two groups are significantly apart from each other, which suggests that the results are statistically significant.\n\ns = np.std(variant_b)\nx = np.mean(variant_b)\nn = len(variant_b)\nrho = (t_critical_value * s) / np.sqrt(n)\nconf_int = x - rho, x + rho\n\n\n\n\n\n5. Statistical power is the probability that the test correctly rejects the null hypothesis, in other words, the probability of a true positive result. This is only useful when the null hypothesis is rejected. A low value of power could be an indication that the sample size is not big enough yet to validate the results. To calculate the statistical power we use the class TTestIndPower from the module statsmodels.stats.power (https://www.statsmodels.org/stable/stats.html?highlight=power#module-statsmodels.stats.power) of the statsmodel (https://www.statsmodels.org/) library.\n\n\nfrom statsmodels.stats.power import TTestIndPower\n\n# Effect size based on Cohen’s d formula: https://en.wikipedia.org/wiki/Effect_size#Cohen's_d (https://en.wikipedia.org/wiki/Effect_size#Cohen's_d)\n\nx1 = np.mean(variant_a)\nx2 = np.mean(variant_b)\ns1 = np.std(variant_a)\ns2 = np.std(variant_b)\nn1 = len(variant_a)\nn2 = len(variant_b)\n\ns = np.sqrt((((n1 - 1) * (s1 ** 2)) + ((n2 - 1) * (s2 ** 2))) / (n1 + n2 - 2))\neffect = np.abs((x1 - x2) / s)\n\npower = TTestIndPower().power(effect, nobs1=n1, ratio=n2 / n1, df=(n1 + n2 - 2), alpha=alpha)\n\n\n\n6. Plot the sample distributions with confidence intervals as a visual aid using matplotlib library.\n\n\nimport matplotlib.pyplot as plt\n\n# Control\nfig, ax = plt.subplots(figsize=(12,6))\nxA = np.linspace(40, x1 + 3*s1, 100)\nyA = stats.norm(loc=x1, scale=s1).pdf(xA)\nax.plot(xA, yA, c='red', label='Variant A Distribution')\nax.axvline(x=x1, c='red', alpha=0.5, linestyle='--', label='Variant A')\n\n# Experimental\nxB = np.linspace(40, x2 + 3*s2, 100)\nyB = stats.norm(loc=x2, scale=s2).pdf(xB)\nax.plot(xB, yB, c='blue', label='Variant B Distribution')\nax.axvline(x=x2, c='blue', alpha=0.5, linestyle='--', label='Variant B')\n\n# Confidence interval\nax.axvline(conf_int[0], c='green', linestyle='--', alpha=0.5)\nax.axvline(conf_int[1], c='green', linestyle='--', alpha=0.5, label='Confidence Interval')\n\nplt.xlabel('Annotation Time')\nplt.ylabel('Percent of Tasks per Annotation Time')\nplt.title('Annotation Time Distributions')\nplt.legend()\nplt.show()\n\n\n\n","slug":{"_type":"slug","current":"experiment-driven-development-part-3"},"tags":[{"_key":"2iLUnerV","label":"Sama Engineering","value":"Sama Engineering"}],"title":"Part 3: A/B Testing with Python"},{"_createdAt":"2021-03-08T21:41:38Z","author":{"_id":"40a70383-c941-405c-ae5b-f0aba421ee53","avatar":{"_type":"image","asset":{"_ref":"image-e0fe681e594567792ac79048513fe955cc770f54-518x518-svg","_type":"reference"}},"bio":"Rafael and Juan are both senior members of Sama R\u0026D where they focus on Data Engineering and Data Science initiatives that help boost operational efficiency and achieve the highest quality.","name":"Rafael Alfaro \u0026 Juan Esquivel","slug":{"_type":"slug","current":"rafael-alfaro-and-juan-esquivel"}},"config":{"description":"In this series of three we’ll go into Experiment Driven Development and A/B Testing. EDD is fact-based development: based on evidence, not intuition.","openGraphImage":null,"title":"Part 2: A/B Testing"},"estimatedReadingTime":4,"featured_image":{"_type":"image","asset":{"_ref":"image-bbf0e002b88fd9c3b2fcbd032f60f114bc93eed0-1980x990-png","_type":"reference"}},"plaintextBody":"After last week's intro into Experiment Driven Development at Sama, we'll go further into A/B Testing today. A/B Testing is a randomized experiment method to compare how two populations behave in a controlled environment and determine whether the variation of some target metrics defined are significant or not, to determine that the experiment yields better results than the alternative.\n\nWe say that a baseline sample (variation A), which normally refers to some existing system, is compared against an experimental treatment (variation B). In software development, samples drawn from the two populations will be used to analyze the metrics associated with the usage of features. We generally want to make sure that any new feature has a positive impact: improved usability, lower duration to finish a process, etc. We should aim to have data to back up our claims that a feature has benefits, otherwise it would be fair to question why we want to deploy a new feature.\n\nOne way of evaluating an A/B experiment is through the use of a t-test which works well when we expect the distribution to be normal and it also allows us to not worry about the unknown standard deviation of our data. Note, however, that population distributions are not always expected to be normal, of course, and the t-test can be replaced by some other appropriate hypothesis test, depending on the distribution of the data, e.g. Kolmogovor-Smirnov. In our case, we want to determine if the means of the two data samples are significantly different from each other, with a given confidence level (90%, 95% and 99% are commonly used values).\n\nThe framework of the experiment revolves around the definition of a hypothesis for an A/B Test as follows:\n\nH0: The mean of the baseline metric is the same as the mean of the experiment metric; there is no effect from the treatment (variation) of the experiment, thus the two means belong to the same population.\nH1: The mean of the baseline metric is different from the mean of the experiment metric; there is an observable effect from the treatment (variation) of the experiment metric and the two means belong to different populations.\n\nWe then define the timeline for the feature/process experiment, run the experiment and collect the observations from the samples of the two variants. We should have a notion in terms of how long we want to run this to collect enough information (we will treat this as out of scope on this piece, however).\n\nIn order to perform the t-test evaluation, we need per sample sizes (N), means (X) and the standard deviations (s) to calculate the statistic t and the degrees of freedom (v). This is calculated as follows (using Welch’s t-test for independent variables with unequal variances and unequal sample sizes):\n\nOnce the statistic and degrees of freedom are calculated, along with an (1-confidence level), we can evaluate our hypothesis against the t-distribution table to determine whether or not the populations are different.\n\nIf our t statistic is less than the value from the table, given the degrees of freedom and the significance level, we can reject the null hypothesis as there is enough evidence to determine that sample means are from different populations. That would mean our new feature is really different from the control and we can release it, if the direction of the variation is in line with our objectives (e.g. lower means when we want to lower durations is good).\n\nThere are other more nuanced circumstances that we can address with a similar framework. For instance, we may want to test two variants of a new feature side by side. We may also want to use a slightly different statistical tool than a t-test, depending on what our interests are. What is important is the test-driven culture that should be fostered within organizations to have a data-drive approach to justify the release of new features.\n\nNext up: A/B Testing with Python.","slug":{"_type":"slug","current":"experiment-driven-development-part-2"},"tags":[{"_key":"FSfjH4D2","label":"Sama Engineering","value":"Sama Engineering"}],"title":"Part 2: A/B Testing"},{"_createdAt":"2021-03-02T05:05:17Z","author":{"_id":"40a70383-c941-405c-ae5b-f0aba421ee53","avatar":{"_type":"image","asset":{"_ref":"image-e0fe681e594567792ac79048513fe955cc770f54-518x518-svg","_type":"reference"}},"bio":"Rafael and Juan are both senior members of Sama R\u0026D where they focus on Data Engineering and Data Science initiatives that help boost operational efficiency and achieve the highest quality.","name":"Rafael Alfaro \u0026 Juan Esquivel","slug":{"_type":"slug","current":"rafael-alfaro-and-juan-esquivel"}},"config":{"description":"In this series of three we’ll go into Experiment Driven Development. EDD is fact-based development: based on evidence, not intuition.","openGraphImage":null,"title":"Part 1: Experiment Driven Development"},"estimatedReadingTime":3,"featured_image":{"_type":"image","asset":{"_ref":"image-bbf0e002b88fd9c3b2fcbd032f60f114bc93eed0-1980x990-png","_type":"reference"}},"plaintextBody":"In this series of three we’ll go into Experiment Driven Development and A/B testing. The opposite of developing features based on anecdotes heard in stories from the CEO’s next-door neighbor, EDD seeks proof and is iterative. EDD can be defined as fact-based development: development based on evidence gathered from the field, not intuition.\n\nIn EDD every new feature or process implemented is validated through a formal experiment design process, which looks to test a hypothesis that describes the status quo of the feature. Example hypotheses could range from \"Making a button bigger does not impact clicks\" all the way to \"Making a web app responsive does not increase visitation\" compared. In statistical terms, the base statement is referred to as the null hypothesis (H0), the status quo, and then an alternative hypothesis(H1) is proposed. The null hypothesis will usually state that the change introduced by the experiment will not affect the current behavior while the alternative supports that there is in fact a change.\n\nThe alternative hypothesis is a prediction of what is expected to happen before running the experiment. It can be a bold statement, not an open question and it should have three parts:\n\nThe variable (if we add/change/remove...): the change that the experiment will measure against the current state of the feature/process.\n\nThe desired result (then we expected to see...): what we expect to see after the change is introduced, a qualitative difference between the current state and new state.\n\nThe rationale behind the prediction (because we have seen that...): prior knowledge that has led you to come up with the current hypothesis (from prior observation).\n\nFor example, one can define the pair of hypotheses for a new registration form in a website as:\n\nH0: Changing the registration form from multiple to single page will not impact the current user registration rate.\n\nH1: Changing the registration from multiple to single page will increase the current user registration rate by 5% because we have previously seen that there is a 5% abandon rate on the multi page form format.\n\n\n\nEDD is based on A/B Testing, which is a randomized experiment method to compare two variants of a single variable. In this case, a baseline metric is compared thanks to the definition control (status quo) and treatment (new feature) groups in order to determine if the variation has a significant impact or not. Ideally, most decisions to release a feature would be based on the results given by A/B Tests. At Sama, we want to find viable ideas or fail fast. Instead of developing a monolithic solution and pushing a release, we iterate through experiments, evaluating how features perform and, most importantly, if and how customers use them.\n\nNext up: A/B Testing and A/B Testing with Python.","slug":{"_type":"slug","current":"experiment-driven-development-part-1"},"tags":[{"_key":"sZmqu6EC","label":"Sama Engineering","value":"Sama Engineering"}],"title":"Part 1: Experiment Driven Development"},{"_createdAt":"2021-02-01T20:53:26Z","author":{"_id":"e9e6679d-3ed9-4cd2-a5a5-cfbff31e1057","avatar":{"_type":"image","asset":{"_ref":"image-e33a218a0ab19114b971463e566b1d1cbdb2e6cd-512x512-webp","_type":"reference"}},"bio":"Mathieu is a Senior Software Engineer at Sama. He has been developing software for more than two decades, with a deep passion for DevOps, CI/CD, Infrastructure as Code, Kubernetes and everything Cloud Native. A joyful father of four, Mathieu loves working with people, learning from them, sharing his love of software engineering, coaching and bringing the best out of everyone, including a smile!","name":"Mathieu Frenette","slug":{"_type":"slug","current":"mathieu-frenette"}},"config":{"description":"Introducing Factotum: an MIT-licensed, open source, kubernetes-oriented, general purpose docker container for devs/devops and custom CI/CD pipelines.","openGraphImage":null,"title":"Factotum: Containerizing DevOps Tools for Cloud Native Engineering and CI/CD"},"estimatedReadingTime":4,"featured_image":{"_type":"image","asset":{"_ref":"image-19ef3f125b8ee47727e9f94dc3aff7ed08a4d78c-720x360-png","_type":"reference"}},"plaintextBody":"Our Cloud Journey\n\nLike most companies making the transition to the cloud today, one of the biggest challenges we face in empowering our engineering teams to adopt cloud-native technologies, such as Kubernetes and CI/CD, is the high barrier to entry of simply setting up their local machines with a unified set of tools and configs to interact with those cloud environments. As DevOps, we would ideally like all our colleagues to easily have access to the same tools and environments, and to even extend that to our CI/CD pipelines, which have no reason to run different versions of those tools from our development machines.\n\nContainers are a natural go-to for the job. However, while they're great at encapsulating many tools with specific versions and repeatable, predictable outcomes, containers are designed with remote services and jobs in mind, rather than day-to-day use as a local work environment.\n\nWhen you start to use containers as a daily working tool, you quickly stumble on many roadblocks. You need to master Docker CLI commands and flags to launch your container in various conditions, environment variables, volume mounts and port mappings. The syntax is different depending if you already started your container in the past, or if it's already running and you just want to open a few extra shells into it. What if you need to access multiple kubernetes clusters in parallel, each with its own container? And don't forget that if you modify any config files within your container, those will be discarded the next time you rebuild and launch a fresh copy of your image! Finally, if you want to share the same tools and configs with your colleagues and (gasp!) even your CI/CD pipeline, you're in for an extra ride!\n\nNaively patching up some Dockerfile with your desired tools is not the end of the road. For us, it was just the beginning.\n\n\nThe Process\n\nWe have long tinkered with the idea of packaging up a neat multi-purpose Docker container that would handle most use cases and make it seamless to setup and interact with different Kubernetes clusters. Starting with a few prototypes and then some inspiration from Cloud Posse's Geodesic container—which does a great job of streamlining the installation and launching of the container— our experiments finally evolved into a tool generic and mature enough to be shared with the community!\n\nOur goal has been to share such a tool with the DevOps community and, thanks to the folks at Sama, this vision has become a reality. Let me introduce you to an MIT-licensed, open source, kubernetes-oriented, general purpose docker container for devs/devops and custom CI/CD pipelines, that we affectionately called \"Factotum\" (from Latin, basically meaning an employee who does all kinds of work).\n\nCheck out the source on GitHub\n\nWhat to Know Before You Begin\n\nEven if you can try the vanilla build of Factotum as is from GitHub and Docker Hub, please understand that Factotum is really intended to be customized and made your own in order to leverage its full potential. If you settle to try it, it is worth forking the repo, customizing the Dockerfile and following the instructions in README.md. While that process of setting up your own customized build of Factotum can be rather involved, be assured that using, maintaining, upgrading and sharing it with your teammates afterwards is intended to be as straightforward as possible—it just takes that little initial effort! And, if you encounter any issues or can't figure how to set it up correctly, don't hesitate to file an issue in the GitHub repo and give us feedback.\n\nHappy factotum'ing.","slug":{"_type":"slug","current":"devops-tools-for-cloud-native-engineering"},"tags":[{"_key":"8AQmCtzZ","label":"Sama Engineering","value":"Sama Engineering"},{"_key":"Gl5fCrPJ","label":"Featured","value":"Featured"}],"title":"Factotum: Containerizing DevOps Tools for Cloud Native Engineering and CI/CD"},{"_createdAt":"2021-01-19T17:04:40Z","author":{"_id":"7aaa2439-b7e5-45f9-8aee-1fbf3c9b5fb8","avatar":{"_type":"image","asset":{"_ref":"image-0a1ace27b14b286beed42f8a189b8d4c9f8d5e71-512x512-webp","_type":"reference"}},"bio":"Dimitri is a software developer specializing in computer vision. Currently a machine learning developer at Sama, Dimitri has developed machine learning based products for the entertainment and image processing industries. He holds a Masters degree in Electrical Engineering from McGill University, where he performed research on active object recognition. He is passionate about the use of technology in order to combat income inequality and climate change. Outside of work, he can be found playing beach volleyball or table tennis depending on the time of year.","name":"Dimitri Gallos","slug":{"_type":"slug","current":"dimitri-gallos"}},"config":{"description":"The Sama MLOps Pipeline: At Sama, we decided to build our own automated training pipeline in order to limit costs, and to avoid tying ourselves to a particular cloud provider.","openGraphImage":null,"title":"The Sama MLOps Pipeline: Automating Model Training on the Cloud"},"estimatedReadingTime":3,"featured_image":{"_type":"image","asset":{"_ref":"image-04641081798c41caebebefa44685828d80b7434f-1200x675-png","_type":"reference"}},"plaintextBody":"Training computer vision models are notoriously computationally intensive, often requiring multiple GPUs. It's therefore usually not performed locally. One of the challenges when it comes to launching training jobs on the cloud or private GPU clusters is dealing with all the required manual steps. For example, when using AWS, ML engineers need to spin-up an EC2 instance manually to launch a training job, and then manually decommission it once the training job is completed. \n\nAlthough commercial tools do exist to automate this process (for example, SageMaker or DataBricks), at Sama we decided to build our own automated training pipeline in order to limit costs, and to avoid tying ourselves to a particular cloud provider.\n\nOur pipeline allows our ML Engineers and Scientists to launch a training job on the cloud by simply pushing the code they developed locally to a predefined git branch. This is very simple to achieve using a modern CI/CD platform like Codefresh. A Codefresh “trigger” can be set to track commits to specific git branches of a repository. Once a commit is pushed to a target branch, a Codefresh pipeline is triggered. The pipeline is just a workflow defined in a yaml file that executes the following steps :\n\nClone the tracked git repository, as well as any other repos required (in our case we have a separate repo for all our ML related tools).\n\nBuild a Docker image with all the project specific dependencies.\n\nDeploy the training job on the GPU cluster.\n\nSend a slack message to a channel that tracks all the training jobs whenever the results are ready or if there is an error.\n\nThe specific implementation of step 3 above depends on the particular frameworks and libraries that are used to train the models and track their performance, as well as the cloud provider. In our team, we use Kubernetes to orchestrate the creation and decommission of the instances. We also use mlflow to manage the ML lifecycle, which has built-in Kubernetes deployment support. So for us, this step simply reduces to doing some cloud provider specific configuration and running an mlflow experiment with Kubernetes as the backend.\n\n\n\nSummary of the Sama automated training pipeline: from pushing the code to Github to running the training job on AWS.\n\n\n\nAside from the obvious time savings, the advantage of this setup is that it is fully configurable and can be made to work with any cloud provider, or even a private GPU cluster. As an added bonus, it enforces experiments to be separated in different git commits, which we find is good practice.","slug":{"_type":"slug","current":"part-1-automating-model-training-on-the-cloud"},"tags":[{"_key":"OdrqBpR4","label":"Sama Engineering","value":"Sama Engineering"},{"_key":"Yw0P8Jjj","label":"Training Data","value":"Training Data"},{"_key":"08tVZdgm","label":"MLOps","value":"MLOps"},{"_key":"eMmu9s8R","label":"Featured","value":"Featured"}],"title":"The Sama MLOps Pipeline: Automating Model Training on the Cloud"},{"_createdAt":"2020-12-15T21:43:21Z","author":{"_id":"a3099d34-9595-4978-b517-e508196414c1","avatar":{"_type":"image","asset":{"_ref":"image-6643136d6c33f77b8e49366c166642ca5dafba8d-500x500-webp","_type":"reference"}},"bio":"Frédéric is a researcher and team leader with over 15 years of R\u0026D experience in machine learning, AI, NLP, speech recognition, and computer vision. Currently Head of AI at Sama, he has worked on building ML-based products in multiple industries from Healthcare to Retail, in large companies and startups. He cares about the impact of technology, and outside of work, you can often see him on a bicycle or on skis.","name":"Frederic Ratle","slug":{"_type":"slug","current":"frederic-ratle"}},"config":{"description":"In this article we summarize an approach that we have developed to speed up polygonal instance segmentation using machine learning.","openGraphImage":null,"title":"Fast Vector Annotation with Machine Learning Assisted Annotation"},"estimatedReadingTime":8,"featured_image":{"_type":"image","asset":{"_ref":"image-6abd2f846119ba50a8325787f99ec3aeec68ffff-1076x605-png","_type":"reference"}},"plaintextBody":"At Sama, Vector Annotation of objects using polygons is a task that our expert annotators spend a great deal of time on. This is especially true for projects involving autonomous vehicles, where it is typical to apply instance segmentation to label scenes comprising hundreds of frames, each with multiple objects (vehicles, pedestrians, traffic signs, etc.) like you see in Figure 1.\n\nFigure 1. Example of Polygonal Annotation in Sama.\n\n\n\nIn this post, we summarize an approach that we have developed to speed up polygonal instance segmentation using machine learning. This approach was presented earlier this year at the CVPR Workshop on Scalability in Autonomous Driving, and the ICML Workshop on Human-in-the-Loop Learning.\n\nFew-Click Annotation\n\nBuilding instance segmentation Deep Learning (DL) models for autonomous vehicles requires a significant amount of labeled data. The use of Machine Learning (ML) for producing pre-annotations to be reviewed by human annotators, whether in an interactive setting or as a pre-processing procedure, is a very popular approach for scaling up labeling while controlling the costs.\n\nMultiple approaches have been suggested for machine-assisted instance segmentation. These typically consist of a DL-based segmentation of the object(s) integrated into a human-in-the-loop system. The human can interact with the system by correcting the model output, initializing the model with one or several clicks, or a combination of those steps. Examples of such systems include Polygon-RNN++ [1], DELSE [7], DEXTR [3], and CurveGCN [2]. Those systems all present good results, but some open questions remain:\n\nDo these methods perform well when a production-level accuracy is required, as when working for a customer project?\n\nDoes the choice of annotation tool influence the results? The gains to be made by using ML depend on how difficult it is for humans to draw polygons in the provided UI. Here we used our optimized drawing tool for polygons, which is part of our labeling platform.\n\nML integration is not usually approached from a human-centric perspective. Beyond the optimization of traditional metrics like IoU, what interactions are most desirable and how should we present the output of the model to annotators?\n\nOur method relies on combining the well-known DEXTR [3] approach with a raster-to-polygon algorithm, to make the result more easily editable. This is not unlike what other tools (such as CVAT) have implemented, though we have optimized this approach for our specific use cases using A/B testing.\n\nThe Model\n\nOur instance segmentation model is based on the well-known Deep Extreme Cut (DEXTR) approach [3], along with a raster-to-polygon conversion algorithm that yields high quality polygons whose vertices are sampled in a way that reproduces human drawing patterns. The model uses the few clicks provided by human annotators at inference time. The steps are described in Figure 2.\n\nFigure 2. An overview of the approach.\n\n\n\nRegarding the model itself, we adopted a custom version of the UNet [5] along with an EfficientNet backbone [6] (instead of the ResNet backbone used in the paper).\n\nIn our experience, for human annotators to produce good instance segmentation masks efficiently, a polygon annotation tool should be used. As such, we needed to convert the raster masks produced by our model to high quality polygons. To add to the challenge, humans tend to produce sparse polygons, adding vertices only when necessary. We therefore adopted a raster-to-polygon procedure that minimizes the number of output vertices.\n\nA/B Testing the Approach\n\nAt Sama, we use A/B testing as much as possible to systematically refine and improve our new features. To this end, we have developed a flexible testing infrastructure that can ingest and aggregate data from multiple internal processes and is made available to anyone within the organization.\n\nThis framework measures the statistical impact of proposed changes on our efficiency metrics (such as drawing time or shape adjustment time). The significance of observed differences on a given efficiency metric is evaluated using statistical tests.\n\nToy A/B Tests\n\nWe conducted an A/B test of the method using a synthetic automotive dataset called SYNTHIA-AL [8]. The dataset's images and corresponding annotations were generated from video streams at 25 frames per second (FPS). Figure 3 shows SYNTHIA image examples, along with their segmentation (done manually and with the Few-Click tool).\n\nFigure 3. SYNTHIA example images, along with their manual and semi-automated annotations.\n\n\n\nThe test, applied only to motor vehicles, reproduced realistic annotation guidelines, namely:\n\nThe drawn polygon needs to be within 2 pixels of the edge of the vehicle.\n\nAll vehicles down to 10 pixels (height or width) need to be annotated.\n\nFollowing this test, we found a nearly 3-fold reduction in annotation time. On the other hand, we also found that on some of the more complex shapes, annotators were spending quite some time manually adjusting the ML output. DEXTR's authors originally showed that the segmentation can be improved with additional clicks beyond the four initial ones. We therefore extended our few-click tool to allow online refinement of the polygons by considering modifications to their vertices as extra clicks. At train time we simulated the corrective clicks by considering the point of greatest deviation between predicted mask and ground truth as illustrated in Figure 4.\n\nProblem: DEXTR’s 4 extreme clicks are not always sufficient.\n\nObservation: DEXTR trained on 4 clicks benefits from additional clicks.\n\nSolution: Fine-tune DEXTR model with additional clicks for hard samples as established by IoU at train time.\n\nFigure 4. Integrating additional clicks in the training process.\n\n\n\nUsing this method, annotators are able to re-trigger the model inference with an additional click, instead of manually adjusting the output. We proceeded to a second toy A/B test, and results showed that we could obtain a theoretical efficiency gain of up to 3.5x on vehicles using the improved method.\n\nDownload our paper on Human-Centric Efficiency Improvements in Image Annotation for Autonomous Driving here and stay tuned to hear more about our latest advances!\n\n\n\nReferences\n\nAcuna, D., Ling, H., Kar, A., and Fidler, S. Efficient annotation of segmentation datasets with polygon-rnn++. In CVPR, 2018.\n\nLing, H., Gao, J., Kar, A., Chen, W., and Fidler, S. Fast interactive object annotation with curve-gcn. In CVPR, 2019.\n\nManinis, K.-K., Caelles, S., Pont-Tuset, J., and Van Gool, L. Deep extreme cut: From extreme points to object segmentation. In Computer Vision and Pattern Recognition (CVPR), 2018.\n\nPapadopoulos, D., Uijlings, J., Keller, F., and Ferrari, V. Extreme clicking for efficient object annotation. In ICCV, 2017.\n\nRonneberger, O., Fischer, P., and Brox, T. U-net: Convolutional networks for biomedical image segmentation. CoRR, abs/1505.04597, 2015. URL http://arxiv. org/abs/1505.04597.\n\nTan, M. and Le, Q. V. Efficientnet: Rethinking model scaling for convolutional neural networks. CoRR, abs/1905.11946, 2019. URL http://arxiv.org/ abs/1905.11946.\n\nWang, Z., Acuna, D., Ling, H., Kar, A., and Fidler, S. Object instance annotation with deep extreme level set evolution. In CVPR, 2019.\n\nZolfaghari Bengar, J., Gonzalez-Garcia, A., Villalonga, G., Raducanu, B., Aghdam, H. H., Mozerov, M., Lopez, A. M., and van de Weijer, J. Temporal coherence for active learning in videos. arXiv preprint arXiv:1908.11757, 2019.\n\nThis post was written by Frederic Ratle and Martine Bertrand.","slug":{"_type":"slug","current":"fast-vector-annotation"},"tags":[{"_key":"fJGSmFCx","label":"Vector Annotation","value":"Vector Annotation"},{"_key":"21OOfbwx","label":"Polygons","value":"Polygons"},{"_key":"SPABaoXN","label":"Sama Engineering","value":"Sama Engineering"},{"_key":"O5nmmFbm","label":"Featured","value":"Featured"}],"title":"Fast Vector Annotation with Machine Learning Assisted Annotation"},{"_createdAt":"2020-11-16T23:15:17Z","author":{"_id":"f972de8a-10c1-45e3-97c9-ac490eaceabe","avatar":{"_type":"image","asset":{"_ref":"image-4aa17073cfd70d2e8f7d8ed85325c14cb1519577-692x691-jpg","_type":"reference"}},"bio":"Loic has over 20 years of industry experience in the Cloud services and AI industry. At Sama he works as the VP of Research \u0026 Development. His experience includes Fortune 500 Companies such as Salesforce.com, Unity Technologies, and AT\u0026T where he led the development of large scale AI, data analytics, and cloud solutions. Loic received his MS in computer science from UTBM, France.","name":"Loic Juillard","slug":{"_type":"slug","current":"loic-juillard"}},"config":{"description":"Sama was a partner of the McGill Engineering Hackathon, the largest annual hackathon run by the McGill Electrical, Computer, and Software Engineering StudentÃƒÂ¢Ã¢â€šÂ¬Ã¢â€žÂ¢ Society.","openGraphImage":null,"title":"Code.Jam(2020)-McGill Hackathon: and the winner is A Virtual Fitting Room"},"estimatedReadingTime":3,"featured_image":{"_type":"image","asset":{"_ref":"image-8b71517603a306e0f80ea070e3d0d532f0039105-1024x512-png","_type":"reference"}},"plaintextBody":"For the second consecutive year, Sama was a Terabyte partner of the McGill Engineering Hackathon, the largest annual hackathon run by the McGill Electrical, Computer, and Software Engineering Student’ Society. This as part of our close partnership with McGill University and the broader Montreal Machine learning Technology community.\n\nIn this year defined by COVID-19, the CodeJam team opted for the very fitting “Digital by Default” theme. Staying on topic, we proposed our very own challenge with an “Online Retail and Shopping Smart App”, wherein students would get to interact with a custom fashion segmentation API trained on our iMaterialist open dataset.\n\nThe participation was incredible! Out of 27 teams, 9 tackled our challenge. The submissions were split into two categories:\n\nRecommendation Engine: “I have seen someone wear this, where can I find it?”\n\nThe Virtual Fitting Room: “How would this look on me”\n\nMost recommendation approaches involved extracting one or multiple pieces of clothing using the segmentation API and querying an image repository for similar items. The models were producing good recommendations when the piece of clothing was well defined. Results were less accurate when the quality of the source image segmentation was approximate. A number of factors such as the type of clothes, occlusion (hair, jewelry, etc.), and ambient picture attributes affect segmentation and produce an approximate product match.\n\n\n\nMy Wardrobe\n\nTeam “GradientBoys” took on the task of virtually showing clothes on a subject, a virtual fitting room of sort. They implemented a complex pipeline that involved segmenting the subject picture (person looking to try the clothes), extracting the style of clothing mask, and segmenting the article of clothing from the library. This was followed by clever usage of the OpenPose model for keypoint identification that allowed to extract a set of local and global distortions to modify the new piece of clothing to fit the subject. Completely taking the in-person shopping experience out of the equation, trying on clothes has never been this smart. Perhaps even more impressive considering it was built in less than 36 hours.\n\nAwesome work, team GradientBoys, and thank you McGill, and all of CodeJam Student Execs for organizing this amazing event. Looking forward to the years to come!","slug":{"_type":"slug","current":"codejam-2020-mcgill-hackathon"},"tags":[{"_key":"Fd3ZhNBx","label":"Sama Engineering","value":"Sama Engineering"},{"_key":"3M2wKXav","label":"Events","value":"Events"}],"title":"Code.Jam(2020)-McGill Hackathon: and the winner is A Virtual Fitting Room"},{"_createdAt":"2019-12-20T02:00:00Z","author":{"_id":"97dc2368-fffb-4c41-82aa-5a9cbe2ec670","avatar":{"_type":"image","asset":{"_ref":"image-af58425525bb33d8cffdc1f1b10f02bf1e4faf57-1916x2028-jpg","_type":"reference"}},"bio":"Sharon is the Content Marketing Manager at Sama where she's responsible for telling the story behind the company's impact sourcing mission and human-powered training data solutions. Sharon holds a MS in Integrated Marketing Communications and is passionate about helping social enterprises transform abstract concepts into results-driven marketing.","name":"Sharon L. Hadden","slug":{"_type":"slug","current":"sharon-l-hadden"}},"config":{"description":"In this interview, we chat with Head of AI at Samasource about AI trends to expect in 2020, as well as frequently asked questions about AI and machine learning.","openGraphImage":null,"title":"8 Answers to Your Questions About AI and Machine Learning"},"estimatedReadingTime":null,"featured_image":{"_type":"image","asset":{"_ref":"image-ade4117797bfbff2e90f48d6ad558ab992aca273-3423x2283-jpg","_type":"reference"}},"plaintextBody":null,"slug":null,"tags":[{"_key":"Y7bAcGrE","label":"Machine Learning","value":"Machine Learning"},{"_key":"qhgHNaG5","label":"AI","value":"AI"},{"_key":"0PqR2xB7","label":"Best of","value":"Best of"},{"_key":"NoohHt2W","label":"Sama Engineering","value":"Sama Engineering"}],"title":"8 Answers to Your Questions About AI and Machine Learning"},{"_createdAt":"2019-12-02T19:00:00Z","author":{"_id":"1a59f036-e3fe-4f02-9a34-688ce45de143","avatar":{"_type":"image","asset":{"_ref":"image-7d8f236ba010dd4927d0c5a93368bdce1f712843-390x390-webp","_type":"reference"}},"bio":"Currently a Project Manager at Sama, Taylor Rouleau has a passion for ensuring ethical and sustainable practices in tech. After 5 years leading production teams for our customers, Taylor's expertise is applied internally in our Project Management Office. She heads up efforts to maintain our industry-leading data training processes with a special focus on Security \u0026 Compliance.","name":"Taylor Rouleau","slug":{"_type":"slug","current":"taylor-rouleau"}},"config":{"description":"Samasource was proud to sponsor CodeJam 2019, an annual hackathon at McGill University, from November 15 - 17, 2019.","openGraphImage":null,"title":"Highlights from McGill CodeJam 2019"},"estimatedReadingTime":null,"featured_image":{"_type":"image","asset":{"_ref":"image-980fdc38382a1cc5d9c462b19141b595b5d9ea31-974x460-png","_type":"reference"}},"plaintextBody":null,"slug":null,"tags":[{"_key":"FYGgyErZ","label":"Sama Engineering","value":"Sama Engineering"},{"_key":"bymHQxr3","label":"Events","value":"Events"}],"title":"Highlights from McGill CodeJam 2019"}],"morePosts":[],"slug":"sama-engineering","tagName":"Sama Engineering","pageConfig":{"title":"Sama Blog | Training Data, AI and Impact Sourcing Insights","description":"From machine learning to training data strategy, the Sama blog covers research, news and other AI trends from thought leaders across the globe."}}},"__N_SSG":true},"page":"/blog/tag/[slug]","query":{"slug":"sama-engineering"},"buildId":"6obM5ETMXaNFf2HCFynGI","isFallback":false,"dynamicIds":[4941,425,3551],"gsp":true,"appGip":true,"scriptLoader":[]}</script></body></html>