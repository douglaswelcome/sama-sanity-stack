{"pageProps":{"config":{"footerNav":{"items":[{"_key":"f255606f8f25","_type":"navDropdownMenu","items":[{"_key":"76389ad94cbb","_type":"navItem","title":"Autonomous Transportation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"training-data-for-autonomous-driving"}}}},{"_key":"5f64a8d6a69d","_type":"navItem","title":"E-Commerce","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"training-data-for-ecommerce"}}}},{"_key":"f10e54ae04d0","_type":"navItem","title":"AR/VR","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"training-data-for-ar-vr"}}}},{"_key":"fd729b522a77","_type":"navItem","title":"Data Quality","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"data-quality"}}}}],"title":"Guides","url":null},{"_key":"681ef7d8763a","_type":"navDropdownMenu","items":[{"_key":"6238a422b667","_type":"navItem","title":"Our Story","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-story"}}}},{"_key":"258985d6d46b","_type":"navItem","title":"Our Team","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-team"}}}},{"_key":"e0a76077324a","_type":"navItem","title":"Our Mission","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"mission-vision-values"}}}},{"_key":"239e49661b0d","_type":"navItem","title":"Careers","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"careers"}}}},{"_key":"e005a740cd80","_type":"navItem","title":"Contact","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"company-contact"}}}}],"title":"Company","url":null}]},"logo":{"asset":{"_createdAt":"2021-10-29T18:38:04Z","_id":"image-e20f8cc53e5f74df10ae9a822edb7ec2c4d00f02-2380x636-svg","_rev":"yuZxWYwFNB6KJB4TM9NtaY","_type":"sanity.imageAsset","_updatedAt":"2021-10-29T18:38:04Z","assetId":"e20f8cc53e5f74df10ae9a822edb7ec2c4d00f02","extension":"svg","metadata":{"_type":"sanity.imageMetadata","dimensions":{"_type":"sanity.imageDimensions","aspectRatio":3.742138364779874,"height":636,"width":2380},"hasAlpha":true,"isOpaque":false,"lqip":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAYAAABFA8wzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAr0lEQVQYlU3QyUoDQBAE0HeIEjeixAVyESRI3BNFJSZxAU/+/wdJQSEehu6Zqa6uKnjBGz7xgTuc4gAj7LWe4LD9cc8Y+9jBUed84QGrEt/gEleYY9Ylr3jGU/tV77fFLirId0nWBYYgoACi+r3D6YPN0vwFm4VxmNlgfkK4qcLUZdVMcdHB+75FzWPfzzCpxXNcFxuOP2uxnhNLASaX5LjbnJJf6jYG2PpXh812/AvSEQ+GGZqgYgAAAABJRU5ErkJggg==","palette":{"_type":"sanity.imagePalette","darkMuted":{"_type":"sanity.imagePaletteSwatch","background":"#040404","foreground":"#fff","population":100.29,"title":"#fff"},"darkVibrant":{"_type":"sanity.imagePaletteSwatch","background":"#424242","foreground":"#fff","population":0,"title":"#fff"},"dominant":{"_type":"sanity.imagePaletteSwatch","background":"#040404","foreground":"#fff","population":100.29,"title":"#fff"},"lightMuted":{"_type":"sanity.imagePaletteSwatch","background":"#4c4c4c","foreground":"#fff","population":0,"title":"#fff"},"lightVibrant":{"_type":"sanity.imagePaletteSwatch","background":"#bcbcbc","foreground":"#000","population":0,"title":"#fff"},"muted":{"_type":"sanity.imagePaletteSwatch","background":"#4c4c4c","foreground":"#fff","population":0,"title":"#fff"},"vibrant":{"_type":"sanity.imagePaletteSwatch","background":"#7f7f7f","foreground":"#fff","population":0,"title":"#fff"}}},"mimeType":"image/svg+xml","originalFilename":"image.svg","path":"images/76e3r62u/production/e20f8cc53e5f74df10ae9a822edb7ec2c4d00f02-2380x636.svg","sha1hash":"ae6a56857a230101a883a9b93974923879775bc9","size":2009,"uploadId":"mtOtmqAQnCEIG5cEqXZ1YAOCuqHJ4X3g","url":"https://cdn.sanity.io/images/76e3r62u/production/e20f8cc53e5f74df10ae9a822edb7ec2c4d00f02-2380x636.svg"}},"mainNav":{"items":[{"_key":"58c18e9aa9ea","_type":"navDropdownMenu","items":[{"_key":"b5b5b8bee78b","_type":"navCat","items":[{"_key":"0e80156a2f1a","_type":"navItem","title":"How it Works","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"how-it-works"}}}},{"_key":"40bacee029b4","_type":"navItem","title":"Video Annotation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"video-annotation"}}}},{"_key":"32650ef07503","_type":"navItem","title":"Image Annotation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"image-annotation"}}}},{"_key":"fe9137cd0167","_type":"navItem","title":"3D & LiDAR Annotation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"3d-lidar"}}}},{"_key":"d9a1316d400a","_type":"navItem","title":"Natural Language Processing","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"natural-language-processing"}}}},{"_key":"ac12c7c5d70a","_type":"navItem","title":"Data Curation (Beta)","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"data-curation"}}}}],"title":"Platform","url":null},{"_key":"37ff4fa913bd","_type":"navCat","items":[{"_key":"6026b1a9314e","_type":"navItem","title":"Semantic Segmentation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"semantic-segmentation"}}}},{"_key":"f4611b19b406","_type":"navItem","title":"Polygons","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"polygons"}}}},{"_key":"5155d874d6c8","_type":"navItem","title":"Bounding Boxes","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"bounding-boxes"}}}},{"_key":"9ef3c1e21e74","_type":"navItem","title":"Key Points","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"key-points"}}}},{"_key":"314d4c00d351","_type":"navItem","title":"Cuboids","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"cuboids"}}}},{"_key":"8e17a6388d74","_type":"navItem","title":"Lines & Arrows","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"lines-and-arrows"}}}}],"title":"Shapes","url":null}],"title":"Platform","url":null},{"_key":"112867ca4d03","_type":"navDropdownMenu","items":[{"_key":"22699c7e06cb","_type":"navItem","items":null,"title":"Transportation & Navigation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"transportation-navigation"}}}},{"_key":"122ae5928d6d","_type":"navItem","items":null,"title":"Retail & E-Commerce","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"retail-ecommerce"}}}},{"_key":"7bb234b69fb0","_type":"navItem","items":null,"title":"Consumer & Media","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"consumer-media"}}}},{"_key":"33e6a886b39d","_type":"navItem","items":null,"title":"Biotech & Medtech","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"biotech-medtech"}}}},{"_key":"d095b2619c4e","_type":"navItem","items":null,"title":"Robotics & Manufacturing","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"robotics-and-manufacturing"}}}},{"_key":"2c4b82a94d79","_type":"navItem","items":null,"title":"Food & Agriculture","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"training-data-food-agriculture"}}}}],"title":"Industries","url":null},{"_key":"c47e8763a906","_type":"navDropdownMenu","items":[{"_key":"1d563df30b3f","_type":"navItem","items":null,"title":"Quality","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"quality-training-data"}}}},{"_key":"041725f35d96","_type":"navItem","items":null,"title":"Security","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"security-and-trust"}}}},{"_key":"fd64ede25798","_type":"navItem","items":null,"title":"Ethical AI","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-impact"}}}},{"_key":"398dcbb1c95d","_type":"navItem","items":null,"title":"Compare","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"compare"}}}},{"_key":"93bdfdd87879","_type":"navItem","items":null,"title":"Partners","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"partners"}}}}],"title":"Why Sama","url":null},{"_key":"1d38bf63df54","_type":"navDropdownMenu","items":[{"_key":"be81659b38a5","_type":"navItem","items":null,"title":"API Documentation","url":{"_type":"link","externalUrl":"https://docs.sama.com/reference/overview","internalLink":null}},{"_key":"2cec80e94962","_type":"navItem","items":null,"title":"Blog","url":{"_type":"link","internalLink":null,"internalLink_custom":"/blog"}},{"_key":"09e284fcb1d3","_type":"navItem","items":null,"title":"Events","url":{"_type":"link","internalLink":null,"internalLink_custom":"/events"}}],"title":"Resources","url":null},{"_key":"dbee93713c19","_type":"navDropdownMenu","items":[{"_key":"12d594a568bf","_type":"navItem","items":null,"title":"Our Story","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-story"}}}},{"_key":"ce36540a102d","_type":"navItem","items":null,"title":"Our Team","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-team"}}}},{"_key":"34fc328e8022","_type":"navItem","items":null,"title":"Careers","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"careers"}}}},{"_key":"c1fe2961020a","_type":"navItem","items":null,"title":"Contact","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"company-contact"}}}},{"_key":"ebd81873e538","_type":"navItem","items":null,"title":"Press","url":{"_type":"link","internalLink":null,"internalLink_custom":"/press"}}],"title":"Company","url":null}],"nav_cta":{"_type":"button","link":{"_type":"link","internalLink":{"_ref":"136788cb-06a6-4f27-b75b-07faf403bfa6","_type":"reference"}},"title":"Request a Demo","type":"secondary"}}},"data":{"firstLoad":[{"_createdAt":"2021-12-07T00:18:48Z","author":{"_id":"e8a1f3c6-0b07-4638-93d5-61a0924f32e3","avatar":{"_type":"image","asset":{"_ref":"image-2f8efc599a377bd580d0ae12f022a15e7e1acacd-632x676-webp","_type":"reference"}},"bio":"Amanda is the Content Marketing Manager at Sama, where each day she gets to learn about AI and how it’s transforming industry. She’s passionate about technology but periodically tries to get away from her computer to explore more analog things like collage and quilting.","name":"Amanda Durepos","slug":{"_type":"slug","current":"amanda-durepos"}},"config":{"description":"Learn how Volumental partnered with Sama to accurately label the datasets that fuel the computer vision technology for their mobile foot scanning app.","openGraphImage":null,"title":"Accurate Data Labeling Powers the Volumental Shoe Recommendation App — Helping Retailers Convert Mobile Customers"},"estimatedReadingTime":7,"featured_image":{"_type":"image","asset":{"_ref":"image-ae9f62c210539de6ed2b60b71efa4be6b90021c6-1920x960-png","_type":"reference"}},"plaintextBody":"Volumental produces shoe recommendations for millions of shoppers by leveraging a combination of 3D foot scans, retail purchase data, and AI. Their team partnered with Sama to label the datasets that fuel the computer vision technology for their mobile foot scanning app — one piece of Volumental’s technology suite which empowers retailers and brands to create frictionless and more personalized experiences for their customers, both in-store and online.\n\nOrdering shoes online can feel like a gamble. How many of us have anticipated the arrival of a fresh pair of sneakers, only to have to promptly return them due to poor fit? According to one study, about 52% of us have experienced that disappointment.\n\nShoe size labels can be a poor indicator of actual fit, both across categories of footwear and even within the same brand. And with an estimated $428 billion in merchandise returned to retailers in 2020, there exists a huge opportunity for retailers and brands to do some damage control.\n\nFor Sweden-based Volumental, the answer isn’t to solve for consistency or standardization within the shoe manufacturing process, but rather to leverage AI to deliver more accurate fit recommendations: an industry segment they are dubbing FitTech™.\n\n\n\nAI can help deliver more delightful, personalized retail experiences\n\n\nFor many years, Volumental has been outfitting shoe retailers with in-store scanners which capture 3D scans of customers’ feet within seconds. These scans are cross-referenced with their extensive database of retail purchase data to deliver product recommendations to shoppers, based on accurate foot measurements and the purchase behavior of consumers with similar feet.\n\nThis technology empowers shoppers to make good buying decisions, but it also supplies retailers with data-driven insights to help them provide more personalized recommendations to consumers both in-store and online.\n\nArmed with millions of foot scans and a database of purchase behavior from customers of nearly 100 of the world’s top retailers and brands, Volumental then set out to tackle the challenge plaguing e-commerce stores and shoe-wearers everywhere: online returns due to poor fit.\n\n\n\n(Image source: Volumental website.)\n\nThe Volumental mobile app delivers the same benefits to consumers, but this time, from the comfort of their homes. The user experience is seamless: take a few photos of your feet from key angles and receive accurate foot measurements along with data-backed recommendations for shoes that are sure to fit like a glove.\n\nData labeling challenges for high-precision foot scanning\n\n\nThe Volumental mobile app user experience may be straightforward, but the challenge of developing this technology was not. To deliver a seamless experience in the app, Volumental had to solve a range of technical problems.\n\nWhile the LiDAR capabilities that come equipped in modern-day smartphones work well to make many AR experiences more accurate and realistic, they are not useful for foot scanning. Existing AR frameworks on the market did not provide the level of accuracy required for Volumental’s mobile foot scanner, so they set out to build their own proprietary models.\n\n\n\nThese images of Volumental employees’ feet show the difference between foot scans reconstructed with sensors native to modern smartphones (left) vs the level of precision required to train their own proprietary models: pixel-perfect masks (right). (Source.)\n\n\nTo obtain the high-accuracy segmented images they needed to power their mobile scanning, Volumental began the search for a data labeling partner. They knew that the dataset had to adhere to an extremely high standard of quality if their mobile solution was to deliver the seamless experience their users were accustomed to in-store.\n\nMikael Andersson, Sr Product Owner at Volumental explained why this requirement was imperative:\n\n“For our mobile app, we needed extremely precise segmented data because we knew that every missed pixel would easily add up to millimeters of lost accuracy.” \n\nIn addition to a high standard of label quality, the data labeling project would also require annotators to know how to handle edge cases such as shadows, low-contrast light, and occlusions. These exceptions needed to be handled with consistency if the training data was to make Volumental’s algorithms behave predictably. For these edge cases, and to ensure that their solution would be able to scale without compromising quality, Volumental needed tight feedback loops to keep their models high-performing. \n\nTo meet all these requirements, Volumental partnered with Sama to deliver high-precision segmented labels for their datasets. Mikael explains:\n\n“Having worked with different cloud providers where the staff doing the actual work was always very hidden from us, we appreciated the transparency Sama gave us. They were communicative and very easy to work with from data collection to project management.”\n\nDelivering a delightful and uncompromisingly accurate experience to their users was important to Volumental, but so was social sustainability. As CMO Brent Hollowell explained, building a mass-market experience that is representative of the world must include diverse and representative datasets:\n\n“At the core of our interest in social sustainability are inclusivity and cultural diversity. Diversity of data is the strength of our AI-powered Fit Engine and it's also what helps us succeed as a company.”\n\nPartnering with Sama assured Volumental that the diversity of their datasets would be accurately represented in their models: to deliver hyper-personalized experiences to delight their users across the globe.\n\n\n\nBetter labels lead to better business outcomes\n\n\nIn part thanks to accurately labeled data, Volumental is creating more delightful omnichannel shopping experiences for consumers. Accurate 3D foot scans are just one piece of the puzzle: combined with their extensive database of purchase behavior and proprietary ML algorithms, Volumental can deliver hyper-personalized recommendations to consumers.\n\nThese recommendations don’t only provide better shopping experiences for users, they remove friction from the buying process and result in fewer online returns. The end result? Happy, loyal customers and ultimately, more revenue for retailers and brands — all thanks to AI-powered fit recommendations.","slug":{"_type":"slug","current":"volumental-shoe-sizing-app"},"tags":[{"label":"Case Studies","value":"Case Studies"}],"title":"Accurate Data Labeling Powers the Volumental Shoe Recommendation App — Helping Retailers Convert Mobile Customers"},{"_createdAt":"2021-10-13T13:21:47Z","author":{"_id":"e8a1f3c6-0b07-4638-93d5-61a0924f32e3","avatar":{"_type":"image","asset":{"_ref":"image-2f8efc599a377bd580d0ae12f022a15e7e1acacd-632x676-webp","_type":"reference"}},"bio":"Amanda is the Content Marketing Manager at Sama, where each day she gets to learn about AI and how it’s transforming industry. She’s passionate about technology but periodically tries to get away from her computer to explore more analog things like collage and quilting.","name":"Amanda Durepos","slug":{"_type":"slug","current":"amanda-durepos"}},"config":{"description":"Find out how accurately labeled data is helping PolyPerception provide material recovery facilities with better visibility into their waste streams.","openGraphImage":null,"title":"How More Accurate Data Labeling is Helping PolyPerception Advocate for Responsible Waste Management"},"estimatedReadingTime":8,"featured_image":{"_type":"image","asset":{"_ref":"image-5b774da87e817474525a389529a9ea674aa54a11-4167x2084-png","_type":"reference"}},"plaintextBody":"PolyPerception provides an AI-powered waste management platform to plastics and material recovery facilities. Their technology tracks each individual piece of waste at an object level. This gives the facilities visibility into their waste streams so they can operate more efficiently and responsibly. The team has partnered with Sama to help fuel this technology, to further their mission of empowering stakeholders across waste management—from recyclers to municipalities to legislators—to make more sustainable decisions about waste and its impact on the environment.\n\nThe challenge of visibility in the waste management industry\n\n\nAs the volume of discarded waste continues to grow globally each year, so has the pressure on our landfills, resources, and environment. With waste disposal technology, infrastructure, and regulators struggling to catch up, one significant barrier blocks the way: visibility.\n\nOn average, 8 tonnes of waste passes through a waste sorting facility every hour. If this sounds like an almost inconceivable amount of waste, that’s because it is. For the operators of sorting centers, understanding and documenting the waste passing through each day remains a major challenge, forcing the waste management industry to operate with a lot of blind spots. \n\nTo circumvent this and better understand the makeup of the waste passing through, many facilities implement a sampling process, but sample sizes are typically small. Though 8 tonnes of waste passes through a facility every hour, sampling is often only done once a week. Even representative sample sets can be skewed by the subjectivity of human bias, making consistency a challenge.\n\nThese factors lead to datasets that don’t often show the full picture, forcing waste management facilities to largely operate on human intuition; a less-than-ideal approach to the decision-making required to meet federal regulations and to cut operational costs.\n\nChanging packaging trends and regulations\n\n\nThe sheer volume of waste passing through a facility is not the only obstacle for sorting center operators. In the world of waste management, tons of other parameters are constantly changing, transforming the efficiency and economics of the process.\n\nFor starters, brands often change their packaging in ways that impact how it’s sorted and where that packaging finally ends up. For example, Heinz is currently using a multi-layer PET bottle with a non-recyclable barrier, but this is soon slated to change in Europe. These changes often happen suddenly and without warning, giving facilities little time to react to make sure these bottles now end up in the appropriate output stream — and therefore at the right recycling facility.\n\nPackaging also varies from region to region. If a facility onboards a new source of waste, they may not understand regional differences, and their machines may not be optimized to sort materials accordingly. Slight margins of error are amplified when you consider the number of sorting steps and the sheer volumes processed.\n\nKeeping up with shifting packaging trends is only compounded by regulations that are also constantly in flux, and differ from one country to the next. All these variables from the outside require sorting facilities to constantly optimize their processes and plan strategically, but this is hard without quantifiable data.\n\n\nAccurate data labeling plays a crucial role\n\n\nThis is where PolyPerception comes in: to give operators in facilities continuous visibility into their waste flow systems by adding cameras to monitor the end-to-end process. This means tracking each piece of waste at an object level. Traceability and transparency allow these facilities to operate more efficiently, bringing them better commercial terms and preparing them to tackle new legislation and packaging trends.\n\nIn order to deliver actionable insights and quantitative data to their clients, PolyPerception set out to build a robust multi-object tracking model, but quickly found that the accurate labeling of data would play a key role.\n\nCrucially, they needed a labeling solution that could accurately label waste objects that travel quickly on conveyor belts in facilities with less-than-ideal lighting conditions. But they also needed a partner who could effectively annotate millions of waste objects while accounting for a wide range of packaging types, materials, processing speeds, and processing conditions.\n\nRafael Hautekiet, CEO of PolyPerception, was delighted by how feedback loops with Sama’s managed workforce of annotators resulted in better quality data for their model – annotations with an average Quality Score of 99%:\n\n“The team quickly learned to distinguish between waste objects, which differ greatly from region to region. Communication channels remained open for feedback, and we had a continuous open discussion about how the efforts were progressing.”\n\nThis line of open communication was important to PolyPerception when they were evaluating different data labeling partners. They wanted to feel like annotators were an extension of their own team, both to maintain visibility into the labeling process and to ensure that the many nuances of their labeling needs were being met.\n\nWhat more reliable, quantifiable data can do for waste management\n\n\nFor PolyPerception, accurate data in waste management has cascading effects for society – a rising tide to lift all boats. With more reliable data:\n\nRecyclers can better understand the composition of their input waste streams, allowing them to reach higher recycling rates, meet federal and state regulations while also cutting costs. \n\nMunicipalities and government agencies can confidently establish data-backed regulations that will have positive lasting impacts.\n\nConsumers can be better informed of how their actions have a direct and measurable impact on the world around us.\n\nThe economic, social, and environmental benefits of the above are too numerous to list, but they are at the core of PolyPerception’s longer-term vision: of empowering stakeholders across waste management to make more impactful decisions, to move the world toward a circular future.\n\nTo PolyPerception COO Parshva Mehta, accurately labeled data plays a small but important part in this ambitious undertaking. This is why it was important for PolyPerception to do data labeling a different way: to work with a provider whose values aligned with theirs, and with their mission to make the world a better place. In Parshva’s words:\n\n“There’s a possibility to make an impact on legislation and on the environment, but not without accurately labeled data. We appreciate that Sama started out by disrupting the status quo and by having a strong social mission. We really resonate with this.”\n\n\n","slug":{"_type":"slug","current":"/polyperception-case-study"},"tags":[{"_key":"qRJxxe50","label":"Case Studies","value":"Case Studies"}],"title":"How More Accurate Data Labeling is Helping PolyPerception Advocate for Responsible Waste Management"},{"_createdAt":"2021-06-24T16:00:00Z","author":{"_id":"e8a1f3c6-0b07-4638-93d5-61a0924f32e3","avatar":{"_type":"image","asset":{"_ref":"image-2f8efc599a377bd580d0ae12f022a15e7e1acacd-632x676-webp","_type":"reference"}},"bio":"Amanda is the Content Marketing Manager at Sama, where each day she gets to learn about AI and how it’s transforming industry. She’s passionate about technology but periodically tries to get away from her computer to explore more analog things like collage and quilting.","name":"Amanda Durepos","slug":{"_type":"slug","current":"amanda-durepos"}},"config":{"description":"Project Guideline by Google partnered with Sama to help people who are blind run without a guide, using only a smartphone, headphones, and a yellow guideline.","openGraphImage":null,"title":"How Sama's Accurate AI is Helping Blind Runners Run Independently"},"estimatedReadingTime":5,"featured_image":{"_type":"image","asset":{"_ref":"image-080a7046afcb7bb25b5af2d55d55883944f1c5eb-3334x1668-png","_type":"reference"}},"plaintextBody":"Project Guideline is an early-stage research project by Google that explores how on-device machine learning can help people with reduced vision to walk and run for exercise independently. The team has partnered with Sama to help fuel their experimental technology; allowing people who are blind and low vision to use a mobile phone, headphones, and a yellow guideline painted on the ground run without a guide.\n\n\n\nOverview\n\n\n\nIt started with a pointed question during a Google hackathon in the fall of 2019. Thomas Panek, an avid runner and CEO of Guiding Eyes for the Blind, posed the question to a group of designers and engineers:\n\n“Would it be possible to help a blind runner navigate, independently?”\n\nPanek, who is blind himself, has completed more than twenty marathons, including five Boston Marathons. While he’s had guide dogs and volunteer human guides to run with him throughout the years, he’s always had to follow—even though his legs and lungs had the capacity to go faster.\n\nIt quickly took off from there. By end of day, the team had a working prototype. Less than a year later, Panek was able to run independently for the first time in more than two decades.\n\nRead the full case study here. \n\n\n\nThe Challenge\n\n\n\nThe machine learning algorithm developed by Google requires only a line painted on a pedestrian path. Runners wear a regular Android phone in a harness around the waist and count on the camera to feed imagery to the algorithm, which identifies the painted line. The algorithm is tasked with detecting whether the line is to the runner’s left, right, or center, so audio signals can be sent to the runner to guide them to stay on track.\n\nFor humans, it’s fairly straightforward to recognize a line and follow it. For a machine learning model, it isn’t that easy. Imagine the running motion: as you start moving your feet you step from left to right, introducing a shake that can make the guideline blurry. Moving outdoors to Panek’s preferred running location, you introduce even more variables. The model must be able to handle a wide range of weather and lighting conditions, or objects like fallen leaves blocking the guideline.\n\n\n\nThe Solution\n\n\n\nSama’s expert annotators draw precise polygons around the single solid yellow lines and a single center line in the images. To do this, the Sama team underwent an intensive training process and continues to meet with Google’s engineers each week to check in on quality, discuss edge cases, and receive new instructions. Thus, with enough examples to learn from, the algorithm is trained to distinguish the pixels in the yellow line from everything else.\n\nBut quality AI starts with quality data. And quality data has to be diverse. The Project Guideline data needed to encompass every imaginable scenario that a runner might encounter. In Panek’s case, we quickly noticed that we had to include the runner’s hand blocking the guideline. This was solved by having our annotators infer the position of the line behind the hand—a great example of something that is easy for a human to do but rather difficult for a computer. By continuously adding these variations to the dataset, the model is getting smarter over time. \n\nFueling the cutting-edge technology that helps a blind man run without assistance truly is the stuff that dreams are made of. Sama’s annotators, the experts giving artificial intelligence its intelligence, love being a part of Project Guideline. Bridget Nattabi, who has worked on this project since its kickoff in July 2020, shares her thoughts:\n\n“Working on this project has allowed me to grow and master polygon annotation with high efficiency and accuracy. I also feel honored to be part of a team that is creating a life-changing navigation experience for the blind. It’s heartwarming to consider that what I do gives people a chance to navigate the world without a guide just like any sighted individual would.”\n\nA word from Project Guideline\n\n“Sama was a force multiplier for us and a key success factor for our project. They delivered high-quality annotated data on time, listened to our feedback, and were very flexible in accommodating our requests.”\n-Xuan Yang, Computer Vision Researcher at Google\n\nRead the full case study here. \n","slug":{"_type":"slug","current":"google-project-guideline"},"tags":[{"_key":"3slAcWy7","label":"Case Studies","value":"Case Studies"}],"title":"How Sama's Accurate AI is Helping Blind Runners Run Independently"},{"_createdAt":"2021-05-10T15:00:00Z","author":{"_id":"e8a1f3c6-0b07-4638-93d5-61a0924f32e3","avatar":{"_type":"image","asset":{"_ref":"image-2f8efc599a377bd580d0ae12f022a15e7e1acacd-632x676-webp","_type":"reference"}},"bio":"Amanda is the Content Marketing Manager at Sama, where each day she gets to learn about AI and how it’s transforming industry. She’s passionate about technology but periodically tries to get away from her computer to explore more analog things like collage and quilting.","name":"Amanda Durepos","slug":{"_type":"slug","current":"amanda-durepos"}},"config":{"description":"Tribe Dynamics helps customers get better ROI from influencer programs. Find out how partnering with Sama helped Tribe better serve clients and expand into new markets.","openGraphImage":null,"title":"How Sama Powers Tribe Dynamics to Measure Your Influencer Marketing Efforts"},"estimatedReadingTime":6,"featured_image":{"_type":"image","asset":{"_ref":"image-df166412c7473ff8223b8e439246245a9dc8ce2d-3334x1668-png","_type":"reference"}},"plaintextBody":"Tribe Dynamics launched in 2012 to help countless leading global brands operationalize, scale, and measure their internal influencer programs—all in a single influencer marketing software platform. Since 2017, the Sama team has powered this technology, training Tribe’s machine learning algorithm and increasing reporting capabilities by 350% to date, helping to build robust influencer communities for a fast-growing, global portfolio of brands.\n\nWhile influencer marketing isn’t a new concept, it has become wildly popular in the past few years. It’s a type of marketing that uses endorsements and product mentions from influencers—tastemakers who have a dedicated social following and are viewed as experts within their niche. Influencer marketing works because of the high amount of trust that influencers have built up with their following. Recommendations from influencers also serve as a form of social proof to a brand’s potential customers.\n\nBut how do you measure who talks about you and how you compare against competitors?\n\nThis is where Tribe Dynamics comes in. The universe of what they track consists of two parts. First, a growing database of over 2,500 brands, including social handles and colloquial ways of discussing the different brands. You can imagine brands missing out on key conversations if they fail to capture slang or abbreviations like #ABH, referring to the popular cosmetics company Anastasia Beverly Hills. The second part involves the influencers who live in their ambassador relationship management system. Here, the profiles and online activities of 200,000 influencers are stored and sorted by the various industries and interests. When combining this list of brands with the group of influencers, Tribe delivers a powerful collection of social posts mentioning your brand—one that truly identifies your most passionate influencer community. \n\n\n\nThe Challenge\n\n\n\nTribe Dynamics’ direct users are marketing teams tasked with measuring the ROI of their influencer program. They want to track their share of the conversation versus their market share benchmark to assess how well they’re doing against competitors and identify their most effective influencers. In short, they need Tribe Dynamics to help them cut through the noise and make data-driven decisions.\n\n\n\nHere’s an example; if a post is talking about Benefit Cosmetics and the company is tagged as such, it’s typically an easy find. However, it becomes more complicated when the algorithm needs to detect the difference between “I love this blush from Benefit” and “The benefit of using blush,” where one is a brand mention and the other a tutorial.\n\nMarketing teams also need to be able to judge the quality of an influencer’s performance and avoid spending budget on fraudulent influencers. Tribe Dynamics allows them to see who their top drivers are for Earned Media Value (EMV), a proprietary metric that measures the value of third-party digital content created about a brand, and surface the right influencers. After all, the hardest working influencers may be people they don’t even know about yet.\n\nTribe Dynamics’ machine learning algorithm catches 95% of the mentions for some brands and 60% for others, and the team relies on Sama as part of their ecosystem to deliver full accuracy.\n\n\n\nDownload the full case study here. \n\n\nThe Solution\n\n\n\nSama’s expert annotators assume the tasks of locating, extracting, and tagging key brand mentions in the posts generated by Tribe Dynamics. This human-in-the-loop intervention consistently reaches a quality SLA of >99%, enabling the algorithm to become more intelligent over time.\n\nSama handles 60-70% of the monthly vetting tasks: identifying brand mentions and common language ways of talking about a brand that the algorithm isn’t yet trained on.\n\nThis continuous vetting also helps overcome model drift. In the fast-moving world of social media, training a machine learning model is not a single, finite stage in the process. Even after it’s deployed in a production environment, this steady stream of new training data—and continuous vetting—ensures the model’s predictive accuracy over time.\n\nIts success shows in the numbers:\n\nThe volume of data Tribe Dynamics is able to provide their clients has grown almost 4x—from 700 brands in 2018 to 2,600 brands this year.\n\nSama has been key to this growth.\n\n\n\nA Word from Tribe Dynamics\n\n\n\nAs almost all of the expansion involves vetting, Sama has been a valuable resource in Tribe’s international expansion.\n\n“We’ve launched in over a dozen markets in two to three years. That, without support, would’ve crushed our internal teams. Sama was able to take on additional workload quickly and efficiently. It has been a notable piece of our successful global business,” says Clare Bruzek, VP of Operations.\n\nSama has become part of the architecture of the company. When Tribe Dynamics decides to expand into different markets, Sama is integral in the scoping of these new opportunities. “It’s the only sustainable vetting option for our international expansion. We now provide international data on 1,250 brands to 94 clients across 12 global markets, making up 30% of our revenue.”\n\nBruzek shares:\n\n“Working with Sama has made a demonstrable impact in our ability not only to service our current clients better, but also to expand our services to new types of clients and new markets. We have only been able to meet client needs in that way because of what Sama has been able to achieve.”\n\nDownload the full case study here. ","slug":{"_type":"slug","current":"tribe-dynamics-case-study"},"tags":[{"_key":"a68HDnn3","label":"Case Studies","value":"Case Studies"}],"title":"How Sama Powers Tribe Dynamics to Measure Your Influencer Marketing Efforts"},{"_createdAt":"2019-11-25T19:00:00Z","author":{"_id":"97dc2368-fffb-4c41-82aa-5a9cbe2ec670","avatar":{"_type":"image","asset":{"_ref":"image-af58425525bb33d8cffdc1f1b10f02bf1e4faf57-1916x2028-jpg","_type":"reference"}},"bio":"Sharon is the Content Marketing Manager at Sama where she's responsible for telling the story behind the company's impact sourcing mission and human-powered training data solutions. Sharon holds a MS in Integrated Marketing Communications and is passionate about helping social enterprises transform abstract concepts into results-driven marketing.","name":"Sharon L. Hadden","slug":{"_type":"slug","current":"sharon-l-hadden"}},"config":{"description":"In this interview, we chat with Taylor Rouleau, Project Manager at Sama on how Walmart Labs used AI to improve their retail item coverage.","openGraphImage":null,"title":"How Walmart Labs Used AI to Improve Retail Item Coverage"},"estimatedReadingTime":null,"featured_image":{"_type":"image","asset":{"_ref":"image-0dda25b386d198579da4a9acc6e67c0ec1dfb06f-1000x667-jpg","_type":"reference"}},"plaintextBody":null,"slug":null,"tags":[{"_key":"pujip4Jo","label":"Case Studies","value":"Case Studies"}],"title":"How Walmart Labs Used AI to Improve Retail Item Coverage"},{"_createdAt":"2019-06-06T02:48:23Z","author":{"_id":"97dc2368-fffb-4c41-82aa-5a9cbe2ec670","avatar":{"_type":"image","asset":{"_ref":"image-af58425525bb33d8cffdc1f1b10f02bf1e4faf57-1916x2028-jpg","_type":"reference"}},"bio":"Sharon is the Content Marketing Manager at Sama where she's responsible for telling the story behind the company's impact sourcing mission and human-powered training data solutions. Sharon holds a MS in Integrated Marketing Communications and is passionate about helping social enterprises transform abstract concepts into results-driven marketing.","name":"Sharon L. Hadden","slug":{"_type":"slug","current":"sharon-l-hadden"}},"config":{"description":"AI-enabled products come with their share of challenges. Here's how Vulcan partnered with Sama to use artificial intelligence for wildlife conservation.","openGraphImage":null,"title":"How Vulcan is Using AI for Wildlife Conservation"},"estimatedReadingTime":null,"featured_image":{"_type":"image","asset":{"_ref":"image-72a27932f674f6ebfb6d90744a43bead1069a121-2250x1500-jpg","_type":"reference"}},"plaintextBody":null,"slug":null,"tags":[{"_key":"GIh9aQR1","label":"Case Studies","value":"Case Studies"}],"title":"How Vulcan is Using AI for Wildlife Conservation"},{"_createdAt":"2018-05-11T16:00:00Z","author":{"_id":"6dd25391-26af-42ff-a2a2-f0778ce1b002","avatar":{"_type":"image","asset":{"_ref":"image-4e1c47984bb16cb0370855b6272663d6744216d3-450x450-jpg","_type":"reference"}},"bio":"Currently a Senior Product Manager at Sama, Audrey guides cross-functional teams to create thoughtful product solutions. She has guided teams of designers and engineers at HUGE Inc. and NBCUniversal, and monitored user analytics at the Wall Street Journal. With a BA in history from Harvard, an MA in anthropology from Columbia and an MBA from UNC Chapel Hill KFBS, Audrey is passionate a using technology and data analytics facilitate social impact and environmental solutions through technology.","name":"Audrey Boguchwal","slug":{"_type":"slug","current":"audrey-boguchwal"}},"config":{"description":"We'll showcase how SamaÃƒÂ¢Ã¢â€šÂ¬Ã¢â€žÂ¢s web research and data cleaning services help create training data for Quid to build their NLP-powered data platform.","openGraphImage":null,"title":"How Quid Creates Reliable Business Intelligence"},"estimatedReadingTime":null,"featured_image":{"_type":"image","asset":{"_ref":"image-df12378ee9ac92007db6ab4b43e58310688aeb2a-1125x1500-jpg","_type":"reference"}},"plaintextBody":null,"slug":null,"tags":[{"_key":"1EAOekEr","label":"Case Studies","value":"Case Studies"}],"title":"How Quid Creates Reliable Business Intelligence"}],"morePosts":[],"slug":"case-studies","tagName":"Case Studies","pageConfig":{"title":"Sama Blog | Training Data, AI and Impact Sourcing Insights","description":"From machine learning to training data strategy, the Sama blog covers research, news and other AI trends from thought leaders across the globe."}}},"__N_SSG":true}