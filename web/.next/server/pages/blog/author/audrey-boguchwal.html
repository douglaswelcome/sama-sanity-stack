<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"/><meta name="viewport" content="initial-scale=1.0, width=device-width, viewport-fit=cover"/><title>Sama Blog | Training Data, AI and Impact Sourcing Insights</title><link rel="canonical" href="https://sama.com/blog/author/audrey-boguchwal"/><meta name="description" content="From machine learning to training data strategy, the Sama blog covers research, news and other AI trends from thought leaders across the globe."/><meta property="og:type" content="website"/><meta property="og:description" content="From machine learning to training data strategy, the Sama blog covers research, news and other AI trends from thought leaders across the globe."/><meta property="og:title" content="Sama Blog | Training Data, AI and Impact Sourcing Insights"/><meta property="og:url" content="https://sama.com/blog/author/audrey-boguchwal"/><meta name="twitter:card" content="summary"/><meta property="twitter:description" content="From machine learning to training data strategy, the Sama blog covers research, news and other AI trends from thought leaders across the globe."/><meta property="twitter:title" content="Sama Blog | Training Data, AI and Impact Sourcing Insights"/><meta name="twitter:domain" content="www.sama.com"/><meta name="msapplication-TileColor" content="#28282a"/><link rel="manifest" href="/manifest.json"/><meta name="theme-color" content="#ffffff"/><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"/><link rel="shortcut icon" href="/favicon.ico"/><meta name="next-head-count" content="19"/><link rel="preload" href="/_next/static/css/35450a5637aed3694e2d.css" as="style"/><link rel="stylesheet" href="/_next/static/css/35450a5637aed3694e2d.css" data-n-g=""/><link rel="preload" href="/_next/static/css/e645d61c44e14da49343.css" as="style"/><link rel="stylesheet" href="/_next/static/css/e645d61c44e14da49343.css" data-n-p=""/><link rel="preload" href="/_next/static/css/ba5da1bbd47cc5381e38.css" as="style"/><link rel="stylesheet" href="/_next/static/css/ba5da1bbd47cc5381e38.css"/><link rel="preload" href="/_next/static/css/6fb72abf7150f9f8f764.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6fb72abf7150f9f8f764.css"/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-a40ef1678bae11e696dba45124eadd70.js"></script><script defer="" src="/_next/static/chunks/1776.a4a235ae76c170a56e16.js"></script><script defer="" src="/_next/static/chunks/4934.37651fffe4e244d39030.js"></script><script defer="" src="/_next/static/chunks/1952.82cfb62f4589642e5656.js"></script><script defer="" src="/_next/static/chunks/3551.489d89a23d509b64ee09.js"></script><script src="/_next/static/chunks/webpack-4df03cf8ee667457d80d.js" defer=""></script><script src="/_next/static/chunks/framework-bdc1b4e5e48979e16d36.js" defer=""></script><script src="/_next/static/chunks/main-04be5b8b279d67174a77.js" defer=""></script><script src="/_next/static/chunks/pages/_app-8b37b83a9f5e9f7f90ae.js" defer=""></script><script src="/_next/static/chunks/commons-9184af50b88be5157a55.js" defer=""></script><script src="/_next/static/chunks/pages/blog/author/%5Bslug%5D-629fa490e01cd1aa2592.js" defer=""></script><script src="/_next/static/YWzTCZqh_Y7EMW0L5W93M/_buildManifest.js" defer=""></script><script src="/_next/static/YWzTCZqh_Y7EMW0L5W93M/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="container"><header class="header_outer__yu9q7 "><nav class="umoja-l-grid--12 header_wrapper__3Ghzm"><a class="header_logo__eiLSq" href="/"></a><button class="header_hamburger__1ZcbZ" type="button"><span class="header_hamburger_box__RZ7CY"><span class="header_hamburger_box_inner__1PmWZ"></span></span></button><ul class="header_navBar__37eSJ"><li class="header_navItem__1HiGN"><p class="header_navItem_label__fN3Cy">Platform</p><div class="header_dropDown__6NxUb"><div class="header_dropDown_group__2BZXC"><p class="header_dropdown_group_label__tmND8">Platform</p><a class="header_navLink__1ARu5" href="/how-it-works">How it Works</a><a class="header_navLink__1ARu5" href="/video-annotation">Video Annotation</a><a class="header_navLink__1ARu5" href="/image-annotation">Image Annotation</a><a class="header_navLink__1ARu5" href="/3d-lidar">3D &amp; LiDAR Annotation</a><a class="header_navLink__1ARu5" href="/natural-language-processing">Natural Language Processing</a><a class="header_navLink__1ARu5" href="/data-curation">Data Curation (Beta)</a></div><div class="header_dropDown_group__2BZXC"><p class="header_dropdown_group_label__tmND8">Shapes</p><a class="header_navLink__1ARu5" href="/semantic-segmentation">Semantic Segmentation</a><a class="header_navLink__1ARu5" href="/polygons">Polygons</a><a class="header_navLink__1ARu5" href="/bounding-boxes">Bounding Boxes</a><a class="header_navLink__1ARu5" href="/key-points">Key Points</a><a class="header_navLink__1ARu5" href="/cuboids">Cuboids</a><a class="header_navLink__1ARu5" href="/lines-and-arrows">Lines &amp; Arrows</a></div></div></li><li class="header_navItem__1HiGN"><p class="header_navItem_label__fN3Cy">Industries</p><div class="header_dropDown__6NxUb"><a class="header_navLink__1ARu5" href="/transportation-navigation">Transportation &amp; Navigation</a><a class="header_navLink__1ARu5" href="/retail-ecommerce">Retail &amp; E-Commerce</a><a class="header_navLink__1ARu5" href="/consumer-media">Consumer &amp; Media</a><a class="header_navLink__1ARu5" href="/biotech-medtech">Biotech &amp; Medtech</a><a class="header_navLink__1ARu5" href="/robotics-and-manufacturing">Robotics &amp; Manufacturing</a><a class="header_navLink__1ARu5" href="/training-data-food-agriculture">Food &amp; Agriculture</a></div></li><li class="header_navItem__1HiGN"><p class="header_navItem_label__fN3Cy">Why Sama</p><div class="header_dropDown__6NxUb"><a class="header_navLink__1ARu5" href="/quality-training-data">Quality</a><a class="header_navLink__1ARu5" href="/security-and-trust">Security</a><a class="header_navLink__1ARu5" href="/our-impact">Ethical AI</a><a class="header_navLink__1ARu5" href="/compare">Compare</a><a class="header_navLink__1ARu5" href="/partners">Partners</a></div></li><li class="header_navItem__1HiGN"><p class="header_navItem_label__fN3Cy">Resources</p><div class="header_dropDown__6NxUb"><a href="https://docs.sama.com/reference/overview" class="header_navLink__1ARu5" target="_blank" rel="noopener">API Documentation</a><a class="header_navLink__1ARu5" href="/blog">Blog</a><a class="header_navLink__1ARu5" href="/events">Events</a></div></li><li class="header_navItem__1HiGN"><p class="header_navItem_label__fN3Cy">Company</p><div class="header_dropDown__6NxUb"><a class="header_navLink__1ARu5" href="/our-story">Our Story</a><a class="header_navLink__1ARu5" href="/our-team">Our Team</a><a class="header_navLink__1ARu5" href="/careers">Careers</a><a class="header_navLink__1ARu5" href="/company-contact">Contact</a><a class="header_navLink__1ARu5" href="/press">Press</a></div></li></ul><div class="header_cta__3J8I7"><a class="button_wrapper__3lRbv button__secondary__1pZ5q button__small__2kIwW" href="/[object%20Object]"><button class="button_btn__1qxP1"><h3 class="button_text__3_sCS">Request a Demo</h3></button></a></div></nav></header><main class="content"><section class="umoja-l-grid-section umoja-u-bg--white"><div class="umoja-l-grid--12"><div class="blog-author_headshot__14bF2"><div style="display:block;overflow:hidden;position:relative;box-sizing:border-box;margin:0"><div style="display:block;box-sizing:border-box;padding-top:100%"></div><img alt="" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="responsive" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img alt="" sizes="100vw" srcSet="https://cdn.sanity.io/images/76e3r62u/production/4e1c47984bb16cb0370855b6272663d6744216d3-450x450.jpg?w=640&amp;q=75&amp;fit=clip&amp;auto=format 640w, https://cdn.sanity.io/images/76e3r62u/production/4e1c47984bb16cb0370855b6272663d6744216d3-450x450.jpg?w=750&amp;q=75&amp;fit=clip&amp;auto=format 750w, https://cdn.sanity.io/images/76e3r62u/production/4e1c47984bb16cb0370855b6272663d6744216d3-450x450.jpg?w=828&amp;q=75&amp;fit=clip&amp;auto=format 828w, https://cdn.sanity.io/images/76e3r62u/production/4e1c47984bb16cb0370855b6272663d6744216d3-450x450.jpg?w=1080&amp;q=75&amp;fit=clip&amp;auto=format 1080w, https://cdn.sanity.io/images/76e3r62u/production/4e1c47984bb16cb0370855b6272663d6744216d3-450x450.jpg?w=1200&amp;q=75&amp;fit=clip&amp;auto=format 1200w, https://cdn.sanity.io/images/76e3r62u/production/4e1c47984bb16cb0370855b6272663d6744216d3-450x450.jpg?w=1920&amp;q=75&amp;fit=clip&amp;auto=format 1920w, https://cdn.sanity.io/images/76e3r62u/production/4e1c47984bb16cb0370855b6272663d6744216d3-450x450.jpg?w=2048&amp;q=75&amp;fit=clip&amp;auto=format 2048w, https://cdn.sanity.io/images/76e3r62u/production/4e1c47984bb16cb0370855b6272663d6744216d3-450x450.jpg?w=3840&amp;q=75&amp;fit=clip&amp;auto=format 3840w" src="https://cdn.sanity.io/images/76e3r62u/production/4e1c47984bb16cb0370855b6272663d6744216d3-450x450.jpg?w=3840&amp;q=75&amp;fit=clip&amp;auto=format" decoding="async" data-nimg="responsive" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" loading="lazy"/></noscript></div></div><div class="blog-author_copy__Q1Si8"><p class="blog-author_intro__3nDS5">Words by:</p><h1>Audrey Boguchwal</h1><p class="blog-author_bio__dDQEk">Currently a Senior Product Manager at Sama, Audrey guides cross-functional teams to create thoughtful product solutions. She has guided teams of designers and engineers at HUGE Inc. and NBCUniversal, and monitored user analytics at the Wall Street Journal. With a BA in history from Harvard, an MA in anthropology from Columbia and an MBA from UNC Chapel Hill KFBS, Audrey is passionate a using technology and data analytics facilitate social impact and environmental solutions through technology.</p></div></div></section><section class="umoja-l-grid-section umoja-u-bg--white"><div class="umoja-l-grid--12 umoja-l-grid-gap--row-1"><div class="blog-post_postCard__i0O-O"><a class="blog-post_postCard_image__3k8eA" href="/[object%20Object]"><div style="display:block;overflow:hidden;position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;margin:0"><img alt="" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img alt="" sizes="100vw" srcSet="https://cdn.sanity.io/images/76e3r62u/production/7eb4854393afff7be19269b7e8414936e411403f-5506x3671.jpg?w=640&amp;q=75&amp;fit=clip&amp;auto=format 640w, https://cdn.sanity.io/images/76e3r62u/production/7eb4854393afff7be19269b7e8414936e411403f-5506x3671.jpg?w=750&amp;q=75&amp;fit=clip&amp;auto=format 750w, https://cdn.sanity.io/images/76e3r62u/production/7eb4854393afff7be19269b7e8414936e411403f-5506x3671.jpg?w=828&amp;q=75&amp;fit=clip&amp;auto=format 828w, https://cdn.sanity.io/images/76e3r62u/production/7eb4854393afff7be19269b7e8414936e411403f-5506x3671.jpg?w=1080&amp;q=75&amp;fit=clip&amp;auto=format 1080w, https://cdn.sanity.io/images/76e3r62u/production/7eb4854393afff7be19269b7e8414936e411403f-5506x3671.jpg?w=1200&amp;q=75&amp;fit=clip&amp;auto=format 1200w, https://cdn.sanity.io/images/76e3r62u/production/7eb4854393afff7be19269b7e8414936e411403f-5506x3671.jpg?w=1920&amp;q=75&amp;fit=clip&amp;auto=format 1920w, https://cdn.sanity.io/images/76e3r62u/production/7eb4854393afff7be19269b7e8414936e411403f-5506x3671.jpg?w=2048&amp;q=75&amp;fit=clip&amp;auto=format 2048w, https://cdn.sanity.io/images/76e3r62u/production/7eb4854393afff7be19269b7e8414936e411403f-5506x3671.jpg?w=3840&amp;q=75&amp;fit=clip&amp;auto=format 3840w" src="https://cdn.sanity.io/images/76e3r62u/production/7eb4854393afff7be19269b7e8414936e411403f-5506x3671.jpg?w=3840&amp;q=75&amp;fit=clip&amp;auto=format" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" loading="lazy"/></noscript></div></a><div class="blog-post_postCard_data__2vfn3"><a class="blog-post_postCard_tag__9RTi-" href="/[object%20Object]">Product</a><a href="/[object%20Object]"><h3>Object Tracking with Frame Level-Labeling</h3></a><p class="blog-post_postCard_date__hrDMA blog-post_postCard_date__noAuthor__F9yyw">April 2, 2020<!-- --> | 3 Min Read</p></div></div><div class="blog-post_postCard__i0O-O"><a class="blog-post_postCard_image__3k8eA" href="/[object%20Object]"><div style="display:block;overflow:hidden;position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;margin:0"><img alt="" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img alt="" sizes="100vw" srcSet="https://cdn.sanity.io/images/76e3r62u/production/70afee37d4e99e8fac42e758c436c2f61d991a7d-1904x797.jpg?w=640&amp;q=75&amp;fit=clip&amp;auto=format 640w, https://cdn.sanity.io/images/76e3r62u/production/70afee37d4e99e8fac42e758c436c2f61d991a7d-1904x797.jpg?w=750&amp;q=75&amp;fit=clip&amp;auto=format 750w, https://cdn.sanity.io/images/76e3r62u/production/70afee37d4e99e8fac42e758c436c2f61d991a7d-1904x797.jpg?w=828&amp;q=75&amp;fit=clip&amp;auto=format 828w, https://cdn.sanity.io/images/76e3r62u/production/70afee37d4e99e8fac42e758c436c2f61d991a7d-1904x797.jpg?w=1080&amp;q=75&amp;fit=clip&amp;auto=format 1080w, https://cdn.sanity.io/images/76e3r62u/production/70afee37d4e99e8fac42e758c436c2f61d991a7d-1904x797.jpg?w=1200&amp;q=75&amp;fit=clip&amp;auto=format 1200w, https://cdn.sanity.io/images/76e3r62u/production/70afee37d4e99e8fac42e758c436c2f61d991a7d-1904x797.jpg?w=1920&amp;q=75&amp;fit=clip&amp;auto=format 1920w, https://cdn.sanity.io/images/76e3r62u/production/70afee37d4e99e8fac42e758c436c2f61d991a7d-1904x797.jpg?w=2048&amp;q=75&amp;fit=clip&amp;auto=format 2048w, https://cdn.sanity.io/images/76e3r62u/production/70afee37d4e99e8fac42e758c436c2f61d991a7d-1904x797.jpg?w=3840&amp;q=75&amp;fit=clip&amp;auto=format 3840w" src="https://cdn.sanity.io/images/76e3r62u/production/70afee37d4e99e8fac42e758c436c2f61d991a7d-1904x797.jpg?w=3840&amp;q=75&amp;fit=clip&amp;auto=format" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" loading="lazy"/></noscript></div></a><div class="blog-post_postCard_data__2vfn3"><a class="blog-post_postCard_tag__9RTi-" href="/[object%20Object]">Product</a><a href="/[object%20Object]"><h3>Keep it Secret, Keep it Safe: Announcing the PII Data Anonymizer</h3></a><p class="blog-post_postCard_date__hrDMA blog-post_postCard_date__noAuthor__F9yyw">March 26, 2020<!-- --> | 3 Min Read</p></div></div><div class="blog-post_postCard__i0O-O"><a class="blog-post_postCard_image__3k8eA" href="/[object%20Object]"><div style="display:block;overflow:hidden;position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;margin:0"><img alt="" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img alt="" sizes="100vw" srcSet="https://cdn.sanity.io/images/76e3r62u/production/df3e88916d772584990f79eaa76fbbf00fb8c830-3872x2592.jpg?w=640&amp;q=75&amp;fit=clip&amp;auto=format 640w, https://cdn.sanity.io/images/76e3r62u/production/df3e88916d772584990f79eaa76fbbf00fb8c830-3872x2592.jpg?w=750&amp;q=75&amp;fit=clip&amp;auto=format 750w, https://cdn.sanity.io/images/76e3r62u/production/df3e88916d772584990f79eaa76fbbf00fb8c830-3872x2592.jpg?w=828&amp;q=75&amp;fit=clip&amp;auto=format 828w, https://cdn.sanity.io/images/76e3r62u/production/df3e88916d772584990f79eaa76fbbf00fb8c830-3872x2592.jpg?w=1080&amp;q=75&amp;fit=clip&amp;auto=format 1080w, https://cdn.sanity.io/images/76e3r62u/production/df3e88916d772584990f79eaa76fbbf00fb8c830-3872x2592.jpg?w=1200&amp;q=75&amp;fit=clip&amp;auto=format 1200w, https://cdn.sanity.io/images/76e3r62u/production/df3e88916d772584990f79eaa76fbbf00fb8c830-3872x2592.jpg?w=1920&amp;q=75&amp;fit=clip&amp;auto=format 1920w, https://cdn.sanity.io/images/76e3r62u/production/df3e88916d772584990f79eaa76fbbf00fb8c830-3872x2592.jpg?w=2048&amp;q=75&amp;fit=clip&amp;auto=format 2048w, https://cdn.sanity.io/images/76e3r62u/production/df3e88916d772584990f79eaa76fbbf00fb8c830-3872x2592.jpg?w=3840&amp;q=75&amp;fit=clip&amp;auto=format 3840w" src="https://cdn.sanity.io/images/76e3r62u/production/df3e88916d772584990f79eaa76fbbf00fb8c830-3872x2592.jpg?w=3840&amp;q=75&amp;fit=clip&amp;auto=format" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" loading="lazy"/></noscript></div></a><div class="blog-post_postCard_data__2vfn3"><a class="blog-post_postCard_tag__9RTi-" href="/[object%20Object]">Events</a><a href="/[object%20Object]"><h3>Fighting AI Bias by Obtaining High-Quality Training Data</h3></a><p class="blog-post_postCard_date__hrDMA blog-post_postCard_date__noAuthor__F9yyw">February 4, 2020<!-- --> | 4 Min Read</p></div></div><div class="blog-post_postCard__i0O-O"><a class="blog-post_postCard_image__3k8eA" href="/[object%20Object]"><div style="display:block;overflow:hidden;position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;margin:0"><img alt="" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img alt="" sizes="100vw" srcSet="https://cdn.sanity.io/images/76e3r62u/production/31269a4f01b8e495d1ec30a473f063a4957254c6-5760x3840.jpg?w=640&amp;q=75&amp;fit=clip&amp;auto=format 640w, https://cdn.sanity.io/images/76e3r62u/production/31269a4f01b8e495d1ec30a473f063a4957254c6-5760x3840.jpg?w=750&amp;q=75&amp;fit=clip&amp;auto=format 750w, https://cdn.sanity.io/images/76e3r62u/production/31269a4f01b8e495d1ec30a473f063a4957254c6-5760x3840.jpg?w=828&amp;q=75&amp;fit=clip&amp;auto=format 828w, https://cdn.sanity.io/images/76e3r62u/production/31269a4f01b8e495d1ec30a473f063a4957254c6-5760x3840.jpg?w=1080&amp;q=75&amp;fit=clip&amp;auto=format 1080w, https://cdn.sanity.io/images/76e3r62u/production/31269a4f01b8e495d1ec30a473f063a4957254c6-5760x3840.jpg?w=1200&amp;q=75&amp;fit=clip&amp;auto=format 1200w, https://cdn.sanity.io/images/76e3r62u/production/31269a4f01b8e495d1ec30a473f063a4957254c6-5760x3840.jpg?w=1920&amp;q=75&amp;fit=clip&amp;auto=format 1920w, https://cdn.sanity.io/images/76e3r62u/production/31269a4f01b8e495d1ec30a473f063a4957254c6-5760x3840.jpg?w=2048&amp;q=75&amp;fit=clip&amp;auto=format 2048w, https://cdn.sanity.io/images/76e3r62u/production/31269a4f01b8e495d1ec30a473f063a4957254c6-5760x3840.jpg?w=3840&amp;q=75&amp;fit=clip&amp;auto=format 3840w" src="https://cdn.sanity.io/images/76e3r62u/production/31269a4f01b8e495d1ec30a473f063a4957254c6-5760x3840.jpg?w=3840&amp;q=75&amp;fit=clip&amp;auto=format" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" loading="lazy"/></noscript></div></a><div class="blog-post_postCard_data__2vfn3"><a class="blog-post_postCard_tag__9RTi-" href="/[object%20Object]">Product</a><a href="/[object%20Object]"><h3>Revamped 2D Vector Segmentation</h3></a><p class="blog-post_postCard_date__hrDMA blog-post_postCard_date__noAuthor__F9yyw">July 11, 2019<!-- --> | 2 Min Read</p></div></div><div class="blog-post_postCard__i0O-O"><a class="blog-post_postCard_image__3k8eA" href="/[object%20Object]"><div style="display:block;overflow:hidden;position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;margin:0"><img alt="" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img alt="" sizes="100vw" srcSet="https://cdn.sanity.io/images/76e3r62u/production/1184784eeedb6464bcb4703dda418de157e6b21c-2250x1500.jpg?w=640&amp;q=75&amp;fit=clip&amp;auto=format 640w, https://cdn.sanity.io/images/76e3r62u/production/1184784eeedb6464bcb4703dda418de157e6b21c-2250x1500.jpg?w=750&amp;q=75&amp;fit=clip&amp;auto=format 750w, https://cdn.sanity.io/images/76e3r62u/production/1184784eeedb6464bcb4703dda418de157e6b21c-2250x1500.jpg?w=828&amp;q=75&amp;fit=clip&amp;auto=format 828w, https://cdn.sanity.io/images/76e3r62u/production/1184784eeedb6464bcb4703dda418de157e6b21c-2250x1500.jpg?w=1080&amp;q=75&amp;fit=clip&amp;auto=format 1080w, https://cdn.sanity.io/images/76e3r62u/production/1184784eeedb6464bcb4703dda418de157e6b21c-2250x1500.jpg?w=1200&amp;q=75&amp;fit=clip&amp;auto=format 1200w, https://cdn.sanity.io/images/76e3r62u/production/1184784eeedb6464bcb4703dda418de157e6b21c-2250x1500.jpg?w=1920&amp;q=75&amp;fit=clip&amp;auto=format 1920w, https://cdn.sanity.io/images/76e3r62u/production/1184784eeedb6464bcb4703dda418de157e6b21c-2250x1500.jpg?w=2048&amp;q=75&amp;fit=clip&amp;auto=format 2048w, https://cdn.sanity.io/images/76e3r62u/production/1184784eeedb6464bcb4703dda418de157e6b21c-2250x1500.jpg?w=3840&amp;q=75&amp;fit=clip&amp;auto=format 3840w" src="https://cdn.sanity.io/images/76e3r62u/production/1184784eeedb6464bcb4703dda418de157e6b21c-2250x1500.jpg?w=3840&amp;q=75&amp;fit=clip&amp;auto=format" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" loading="lazy"/></noscript></div></a><div class="blog-post_postCard_data__2vfn3"><a class="blog-post_postCard_tag__9RTi-" href="/[object%20Object]">Best of</a><a href="/[object%20Object]"><h3>Highlights from the 2019 Embedded Vision Summit</h3></a><p class="blog-post_postCard_date__hrDMA blog-post_postCard_date__noAuthor__F9yyw">June 5, 2019<!-- --> | 5 Min Read</p></div></div><div class="blog-post_postCard__i0O-O"><a class="blog-post_postCard_image__3k8eA" href="/[object%20Object]"><div style="display:block;overflow:hidden;position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;margin:0"><img alt="" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img alt="" sizes="100vw" srcSet="https://cdn.sanity.io/images/76e3r62u/production/f9a4a7493982c6bf1be96e8260df8a98e4467b28-2250x1500.jpg?w=640&amp;q=75&amp;fit=clip&amp;auto=format 640w, https://cdn.sanity.io/images/76e3r62u/production/f9a4a7493982c6bf1be96e8260df8a98e4467b28-2250x1500.jpg?w=750&amp;q=75&amp;fit=clip&amp;auto=format 750w, https://cdn.sanity.io/images/76e3r62u/production/f9a4a7493982c6bf1be96e8260df8a98e4467b28-2250x1500.jpg?w=828&amp;q=75&amp;fit=clip&amp;auto=format 828w, https://cdn.sanity.io/images/76e3r62u/production/f9a4a7493982c6bf1be96e8260df8a98e4467b28-2250x1500.jpg?w=1080&amp;q=75&amp;fit=clip&amp;auto=format 1080w, https://cdn.sanity.io/images/76e3r62u/production/f9a4a7493982c6bf1be96e8260df8a98e4467b28-2250x1500.jpg?w=1200&amp;q=75&amp;fit=clip&amp;auto=format 1200w, https://cdn.sanity.io/images/76e3r62u/production/f9a4a7493982c6bf1be96e8260df8a98e4467b28-2250x1500.jpg?w=1920&amp;q=75&amp;fit=clip&amp;auto=format 1920w, https://cdn.sanity.io/images/76e3r62u/production/f9a4a7493982c6bf1be96e8260df8a98e4467b28-2250x1500.jpg?w=2048&amp;q=75&amp;fit=clip&amp;auto=format 2048w, https://cdn.sanity.io/images/76e3r62u/production/f9a4a7493982c6bf1be96e8260df8a98e4467b28-2250x1500.jpg?w=3840&amp;q=75&amp;fit=clip&amp;auto=format 3840w" src="https://cdn.sanity.io/images/76e3r62u/production/f9a4a7493982c6bf1be96e8260df8a98e4467b28-2250x1500.jpg?w=3840&amp;q=75&amp;fit=clip&amp;auto=format" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" loading="lazy"/></noscript></div></a><div class="blog-post_postCard_data__2vfn3"><a class="blog-post_postCard_tag__9RTi-" href="/[object%20Object]">Events</a><a href="/[object%20Object]"><h3>4 Training Data Strategies to Avoid Bias</h3></a><p class="blog-post_postCard_date__hrDMA blog-post_postCard_date__noAuthor__F9yyw">May 20, 2019<!-- --> | 4 Min Read</p></div></div><div class="blog-post_postCard__i0O-O"><a class="blog-post_postCard_image__3k8eA" href="/[object%20Object]"><div style="display:block;overflow:hidden;position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;margin:0"><img alt="" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img alt="" sizes="100vw" srcSet="https://cdn.sanity.io/images/76e3r62u/production/df12378ee9ac92007db6ab4b43e58310688aeb2a-1125x1500.jpg?w=640&amp;q=75&amp;fit=clip&amp;auto=format 640w, https://cdn.sanity.io/images/76e3r62u/production/df12378ee9ac92007db6ab4b43e58310688aeb2a-1125x1500.jpg?w=750&amp;q=75&amp;fit=clip&amp;auto=format 750w, https://cdn.sanity.io/images/76e3r62u/production/df12378ee9ac92007db6ab4b43e58310688aeb2a-1125x1500.jpg?w=828&amp;q=75&amp;fit=clip&amp;auto=format 828w, https://cdn.sanity.io/images/76e3r62u/production/df12378ee9ac92007db6ab4b43e58310688aeb2a-1125x1500.jpg?w=1080&amp;q=75&amp;fit=clip&amp;auto=format 1080w, https://cdn.sanity.io/images/76e3r62u/production/df12378ee9ac92007db6ab4b43e58310688aeb2a-1125x1500.jpg?w=1200&amp;q=75&amp;fit=clip&amp;auto=format 1200w, https://cdn.sanity.io/images/76e3r62u/production/df12378ee9ac92007db6ab4b43e58310688aeb2a-1125x1500.jpg?w=1920&amp;q=75&amp;fit=clip&amp;auto=format 1920w, https://cdn.sanity.io/images/76e3r62u/production/df12378ee9ac92007db6ab4b43e58310688aeb2a-1125x1500.jpg?w=2048&amp;q=75&amp;fit=clip&amp;auto=format 2048w, https://cdn.sanity.io/images/76e3r62u/production/df12378ee9ac92007db6ab4b43e58310688aeb2a-1125x1500.jpg?w=3840&amp;q=75&amp;fit=clip&amp;auto=format 3840w" src="https://cdn.sanity.io/images/76e3r62u/production/df12378ee9ac92007db6ab4b43e58310688aeb2a-1125x1500.jpg?w=3840&amp;q=75&amp;fit=clip&amp;auto=format" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" loading="lazy"/></noscript></div></a><div class="blog-post_postCard_data__2vfn3"><a class="blog-post_postCard_tag__9RTi-" href="/[object%20Object]">Case Studies</a><a href="/[object%20Object]"><h3>How Quid Creates Reliable Business Intelligence</h3></a><p class="blog-post_postCard_date__hrDMA blog-post_postCard_date__noAuthor__F9yyw">May 11, 2018<!-- --> | 1 Min Read</p></div></div><div class="blog-post_postCard__i0O-O"><a class="blog-post_postCard_image__3k8eA" href="/[object%20Object]"><div style="display:block;overflow:hidden;position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;margin:0"><img alt="" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img alt="" sizes="100vw" srcSet="https://cdn.sanity.io/images/76e3r62u/production/73eb0ced8bf91c8bd71f48061438e8d61ce0f8b6-597x398.png?w=640&amp;q=75&amp;fit=clip&amp;auto=format 640w, https://cdn.sanity.io/images/76e3r62u/production/73eb0ced8bf91c8bd71f48061438e8d61ce0f8b6-597x398.png?w=750&amp;q=75&amp;fit=clip&amp;auto=format 750w, https://cdn.sanity.io/images/76e3r62u/production/73eb0ced8bf91c8bd71f48061438e8d61ce0f8b6-597x398.png?w=828&amp;q=75&amp;fit=clip&amp;auto=format 828w, https://cdn.sanity.io/images/76e3r62u/production/73eb0ced8bf91c8bd71f48061438e8d61ce0f8b6-597x398.png?w=1080&amp;q=75&amp;fit=clip&amp;auto=format 1080w, https://cdn.sanity.io/images/76e3r62u/production/73eb0ced8bf91c8bd71f48061438e8d61ce0f8b6-597x398.png?w=1200&amp;q=75&amp;fit=clip&amp;auto=format 1200w, https://cdn.sanity.io/images/76e3r62u/production/73eb0ced8bf91c8bd71f48061438e8d61ce0f8b6-597x398.png?w=1920&amp;q=75&amp;fit=clip&amp;auto=format 1920w, https://cdn.sanity.io/images/76e3r62u/production/73eb0ced8bf91c8bd71f48061438e8d61ce0f8b6-597x398.png?w=2048&amp;q=75&amp;fit=clip&amp;auto=format 2048w, https://cdn.sanity.io/images/76e3r62u/production/73eb0ced8bf91c8bd71f48061438e8d61ce0f8b6-597x398.png?w=3840&amp;q=75&amp;fit=clip&amp;auto=format 3840w" src="https://cdn.sanity.io/images/76e3r62u/production/73eb0ced8bf91c8bd71f48061438e8d61ce0f8b6-597x398.png?w=3840&amp;q=75&amp;fit=clip&amp;auto=format" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" loading="lazy"/></noscript></div></a><div class="blog-post_postCard_data__2vfn3"><a class="blog-post_postCard_tag__9RTi-" href="/[object%20Object]">Ethical AI</a><a href="/[object%20Object]"><h3>Better Algorithms, Better Lives: Reducing Poverty Through Training Data</h3></a><p class="blog-post_postCard_date__hrDMA blog-post_postCard_date__noAuthor__F9yyw">May 24, 2017<!-- --> | 4 Min Read</p></div></div><div class="blog-post_postCard__i0O-O"><a class="blog-post_postCard_image__3k8eA" href="/[object%20Object]"><div style="display:block;overflow:hidden;position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;margin:0"><img alt="" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img alt="" sizes="100vw" srcSet="https://cdn.sanity.io/images/76e3r62u/production/bde2f64018e50b7615f188245cc00fe516e84936-693x462.jpg?w=640&amp;q=75&amp;fit=clip&amp;auto=format 640w, https://cdn.sanity.io/images/76e3r62u/production/bde2f64018e50b7615f188245cc00fe516e84936-693x462.jpg?w=750&amp;q=75&amp;fit=clip&amp;auto=format 750w, https://cdn.sanity.io/images/76e3r62u/production/bde2f64018e50b7615f188245cc00fe516e84936-693x462.jpg?w=828&amp;q=75&amp;fit=clip&amp;auto=format 828w, https://cdn.sanity.io/images/76e3r62u/production/bde2f64018e50b7615f188245cc00fe516e84936-693x462.jpg?w=1080&amp;q=75&amp;fit=clip&amp;auto=format 1080w, https://cdn.sanity.io/images/76e3r62u/production/bde2f64018e50b7615f188245cc00fe516e84936-693x462.jpg?w=1200&amp;q=75&amp;fit=clip&amp;auto=format 1200w, https://cdn.sanity.io/images/76e3r62u/production/bde2f64018e50b7615f188245cc00fe516e84936-693x462.jpg?w=1920&amp;q=75&amp;fit=clip&amp;auto=format 1920w, https://cdn.sanity.io/images/76e3r62u/production/bde2f64018e50b7615f188245cc00fe516e84936-693x462.jpg?w=2048&amp;q=75&amp;fit=clip&amp;auto=format 2048w, https://cdn.sanity.io/images/76e3r62u/production/bde2f64018e50b7615f188245cc00fe516e84936-693x462.jpg?w=3840&amp;q=75&amp;fit=clip&amp;auto=format 3840w" src="https://cdn.sanity.io/images/76e3r62u/production/bde2f64018e50b7615f188245cc00fe516e84936-693x462.jpg?w=3840&amp;q=75&amp;fit=clip&amp;auto=format" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" loading="lazy"/></noscript></div></a><div class="blog-post_postCard_data__2vfn3"><a class="blog-post_postCard_tag__9RTi-" href="/[object%20Object]">Ethical AI</a><a href="/[object%20Object]"><h3>How Samasource Moves People Out of Poverty with Digital Work</h3></a><p class="blog-post_postCard_date__hrDMA blog-post_postCard_date__noAuthor__F9yyw">May 15, 2017<!-- --> | 3 Min Read</p></div></div></div></section></main><footer class="footer_wrapper__2VAfJ"><div class="umoja-l-grid--12"><div class="footer_upper__2a6XG"><div><h4>Newsletter</h4><p>Subscribe today and be the first to receive the latest from Sama.</p></div><div class="footer_upper_right__cpliC"><div><p class="footer_nav_head__1keQK">Guides</p><a class="footer_nav_link__X1RNI" href="/training-data-for-autonomous-driving">Autonomous Transportation</a><a class="footer_nav_link__X1RNI" href="/training-data-for-ecommerce">E-Commerce</a><a class="footer_nav_link__X1RNI" href="/training-data-for-ar-vr">AR/VR</a><a class="footer_nav_link__X1RNI" href="/data-quality">Data Quality</a></div><div><p class="footer_nav_head__1keQK">Company</p><a class="footer_nav_link__X1RNI" href="/our-story">Our Story</a><a class="footer_nav_link__X1RNI" href="/our-team">Our Team</a><a class="footer_nav_link__X1RNI" href="/mission-vision-values">Our Mission</a><a class="footer_nav_link__X1RNI" href="/careers">Careers</a><a class="footer_nav_link__X1RNI" href="/company-contact">Contact</a></div></div></div><div class="footer_middle__iiTSJ"><div class="footer_middle_left__3ff78"><a href="/"></a></div><div class="footer_middle_right__2b-lC"><div class="footer_social__1NFfV"><a href="https://www.facebook.com/samaartificialintelligence" class="footer_social_icon__wI2OK" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 35.1 64.89"><title>facebook</title><g id="fb3209c8-23d4-4288-984d-a2b8f32b7f0c" data-name="Layer 2"><g id="ba1a815d-13f1-45f9-9321-18e9a3cfa5db" data-name="Layer 1"><path d="M35.1,11.26V1.36A1.35,1.35,0,0,0,33.76,0H25.35A15.34,15.34,0,0,0,14,4.35C11.24,7.2,9.78,11.22,9.78,16v7.34H1.34A1.34,1.34,0,0,0,0,24.66V35.32a1.35,1.35,0,0,0,1.34,1.35H9.78V63.55a1.34,1.34,0,0,0,1.34,1.34h11a1.34,1.34,0,0,0,1.34-1.34V36.67h9.87a1.35,1.35,0,0,0,1.34-1.35V24.66a1.37,1.37,0,0,0-.7-1.18,1.47,1.47,0,0,0-.67-.16H23.49V17.1c0-1.72.25-2.69.84-3.37s1.88-1.13,3.77-1.13h5.66A1.34,1.34,0,0,0,35.1,11.26Z"></path></g></g></svg></a><a href="https://www.instagram.com/sama_ai_" class="footer_social_icon__wI2OK" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 57 57"><title>insta</title><g id="ef02a3ef-c0d3-4be7-9d4e-2c42263777a3" data-name="Layer 2"><g id="a0a92778-6c5c-4e06-a08f-641546580dd0" data-name="Layer 1"><circle cx="28.5" cy="28.5" r="9.24"></circle><path d="M41.57,0H15.43A15.45,15.45,0,0,0,0,15.43V41.57A15.45,15.45,0,0,0,15.43,57H41.57A15.45,15.45,0,0,0,57,41.57V15.43A15.45,15.45,0,0,0,41.57,0ZM28.5,42.74A14.24,14.24,0,1,1,42.74,28.5,14.26,14.26,0,0,1,28.5,42.74ZM44.46,17a5,5,0,1,1,5-5A5,5,0,0,1,44.46,17Z"></path></g></g></svg></a><a href="https://twitter.com/SamaAI" class="footer_social_icon__wI2OK" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 62 51.19"><title>twitter</title><g id="e7743e55-1863-47ad-a995-4b7f1f924f07" data-name="Layer 2"><g id="ec8c6fd9-2f52-4507-9a24-804bc60dbc33" data-name="Layer 1"><path d="M23.59,51.19c-10.35,0-18.53-1.81-22.44-5l-.07-.06L1,46.1a3.19,3.19,0,0,1-.84-3.35l0-.1a3.24,3.24,0,0,1,3-2,26.57,26.57,0,0,0,7.06-1,13.45,13.45,0,0,1-7.07-8.16,2.92,2.92,0,0,1,1-3.38,3.06,3.06,0,0,1,.88-.45,19.52,19.52,0,0,1-4-7.18l0-.08,0-.09a3,3,0,0,1,1.4-3.23,3,3,0,0,1,1.43-.4,15.15,15.15,0,0,1-1.14-3.49A14.59,14.59,0,0,1,4.24,3.47l.38-.77a2.15,2.15,0,0,1,3.44-.56l.7.7c5.53,5.81,10.49,8.56,19.06,10.44a15.17,15.17,0,0,1,4.1-8.75A14.39,14.39,0,0,1,42.19,0h0c2.84,0,6.36,1.62,8.49,2.77,1.83-.6,4-1.53,6.32-2.51a2.88,2.88,0,0,1,3.22.57,2.85,2.85,0,0,1,.62,3.11c-.17.47-.36.92-.57,1.36a3.07,3.07,0,0,1,.84.58,3.13,3.13,0,0,1,.78,2.92l0,.1a11.92,11.92,0,0,1-4.78,6.56C56.73,35.23,41.84,51.19,23.59,51.19Z"></path></g></g></svg></a><a href="https://www.linkedin.com/company/sama-ai/" class="footer_social_icon__wI2OK" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 59.71 60.79"><title>linkedin</title><g id="bd073dff-b6ea-4cf0-bfeb-c3ce392ee6a5" data-name="Layer 2"><g id="f6b6eb77-7c10-4e27-a3d0-6f8b14e97f2e" data-name="Layer 1"><path d="M59.65,60.79l-12.35,0,0-19.36c0-4.62-.07-10.56-6.41-10.58s-7.44,5-7.45,10.21l0,19.7-12.36,0,.09-40.95,11.87,0v6.57h.16c1.66-3.13,5.7-6.42,11.73-6.41,12.51,0,14.81,8.28,14.79,19l-.05,21.85Z"></path><path d="M7.17,14.35a7.18,7.18,0,1,1,7.18-7.18A7.17,7.17,0,0,1,7.17,14.35Z"></path><rect x="0.98" y="19.8" width="12.39" height="40.95"></rect></g></g></svg></a><a href="https://www.youtube.com/c/SamaAI" class="footer_social_icon__wI2OK" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 65 44.63"><title>youtube</title><g id="b03ac260-8029-40d4-832d-1f2d757db2d5" data-name="Layer 2"><g id="eca1bfe4-f0ec-4c24-9169-be6d2f8b24b5" data-name="Layer 1"><path d="M55,0H10A10,10,0,0,0,0,10V34.63a10,10,0,0,0,10,10H55a10,10,0,0,0,10-10V10A10,10,0,0,0,55,0ZM40.89,24.41,28.3,31.18a2.31,2.31,0,0,1-3.41-2V15.48a2.3,2.3,0,0,1,3.42-2l12.6,6.89a2.31,2.31,0,0,1,0,4.06Z"></path></g></g></svg></a></div></div></div><div class="footer_lower__1z3Av"><div class="footer_lower_left__141hE"><a class="footer_nav_link__X1RNI" href="/terms-of-service">Terms</a><a class="footer_nav_link__X1RNI" href="/privacy-policy">Privacy</a><a class="footer_nav_link__X1RNI" href="/quality-and-information-policy">Quality &amp; Information</a></div><div class="footer_lower_right__22vMw"><h6>Copyright Â© <!-- -->0<!-- --> Sama Inc.</h6><h6>All rights reserved.</h6></div></div></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"config":{"footerNav":{"items":[{"_key":"f255606f8f25","_type":"navDropdownMenu","items":[{"_key":"76389ad94cbb","_type":"navItem","title":"Autonomous Transportation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"training-data-for-autonomous-driving"}}}},{"_key":"5f64a8d6a69d","_type":"navItem","title":"E-Commerce","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"training-data-for-ecommerce"}}}},{"_key":"f10e54ae04d0","_type":"navItem","title":"AR/VR","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"training-data-for-ar-vr"}}}},{"_key":"fd729b522a77","_type":"navItem","title":"Data Quality","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"data-quality"}}}}],"title":"Guides","url":null},{"_key":"681ef7d8763a","_type":"navDropdownMenu","items":[{"_key":"6238a422b667","_type":"navItem","title":"Our Story","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-story"}}}},{"_key":"258985d6d46b","_type":"navItem","title":"Our Team","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-team"}}}},{"_key":"e0a76077324a","_type":"navItem","title":"Our Mission","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"mission-vision-values"}}}},{"_key":"239e49661b0d","_type":"navItem","title":"Careers","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"careers"}}}},{"_key":"e005a740cd80","_type":"navItem","title":"Contact","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"company-contact"}}}}],"title":"Company","url":null}]},"logo":{"asset":{"_createdAt":"2021-12-09T21:42:35Z","_id":"image-4f4e2f86a8fad952c02dffffd7008aa35f83c850-2380x636-svg","_rev":"7Z7VDk3xHzg51hvomGzc99","_type":"sanity.imageAsset","_updatedAt":"2021-12-09T21:42:35Z","assetId":"4f4e2f86a8fad952c02dffffd7008aa35f83c850","extension":"svg","metadata":{"_type":"sanity.imageMetadata","blurHash":"D009jvfQfQfQfQfQfQfQfQfQ","dimensions":{"_type":"sanity.imageDimensions","aspectRatio":3.742138364779874,"height":636,"width":2380},"hasAlpha":true,"isOpaque":false,"lqip":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAYAAABFA8wzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAr0lEQVQYlU3QyUoDQBAE0HeIEjeixAVyESRI3BNFJSZxAU/+/wdJQSEehu6Zqa6uKnjBGz7xgTuc4gAj7LWe4LD9cc8Y+9jBUed84QGrEt/gEleYY9Ylr3jGU/tV77fFLirId0nWBYYgoACi+r3D6YPN0vwFm4VxmNlgfkK4qcLUZdVMcdHB+75FzWPfzzCpxXNcFxuOP2uxnhNLASaX5LjbnJJf6jYG2PpXh812/AvSEQ+GGZqgYgAAAABJRU5ErkJggg==","palette":{"_type":"sanity.imagePalette","darkMuted":{"_type":"sanity.imagePaletteSwatch","background":"#040404","foreground":"#fff","population":100.29,"title":"#fff"},"darkVibrant":{"_type":"sanity.imagePaletteSwatch","background":"#424242","foreground":"#fff","population":0,"title":"#fff"},"dominant":{"_type":"sanity.imagePaletteSwatch","background":"#040404","foreground":"#fff","population":100.29,"title":"#fff"},"lightMuted":{"_type":"sanity.imagePaletteSwatch","background":"#4c4c4c","foreground":"#fff","population":0,"title":"#fff"},"lightVibrant":{"_type":"sanity.imagePaletteSwatch","background":"#bcbcbc","foreground":"#000","population":0,"title":"#fff"},"muted":{"_type":"sanity.imagePaletteSwatch","background":"#4c4c4c","foreground":"#fff","population":0,"title":"#fff"},"vibrant":{"_type":"sanity.imagePaletteSwatch","background":"#7f7f7f","foreground":"#fff","population":0,"title":"#fff"}}},"mimeType":"image/svg+xml","originalFilename":"e20f8cc53e5f74df10ae9a822edb7ec2c4d00f02-2380x636.svg","path":"images/76e3r62u/production/4f4e2f86a8fad952c02dffffd7008aa35f83c850-2380x636.svg","sha1hash":"4f4e2f86a8fad952c02dffffd7008aa35f83c850","size":2009,"uploadId":"jTUF9DIFqAwpLJ0GcI9bRqb17D69QQlN","url":"https://cdn.sanity.io/images/76e3r62u/production/4f4e2f86a8fad952c02dffffd7008aa35f83c850-2380x636.svg"}},"mainNav":{"items":[{"_key":"58c18e9aa9ea","_type":"navDropdownMenu","items":[{"_key":"b5b5b8bee78b","_type":"navCat","items":[{"_key":"0e80156a2f1a","_type":"navItem","title":"How it Works","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"how-it-works"}}}},{"_key":"40bacee029b4","_type":"navItem","title":"Video Annotation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"video-annotation"}}}},{"_key":"32650ef07503","_type":"navItem","title":"Image Annotation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"image-annotation"}}}},{"_key":"fe9137cd0167","_type":"navItem","title":"3D \u0026 LiDAR Annotation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"3d-lidar"}}}},{"_key":"d9a1316d400a","_type":"navItem","title":"Natural Language Processing","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"natural-language-processing"}}}},{"_key":"ac12c7c5d70a","_type":"navItem","title":"Data Curation (Beta)","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"data-curation"}}}}],"title":"Platform","url":null},{"_key":"37ff4fa913bd","_type":"navCat","items":[{"_key":"6026b1a9314e","_type":"navItem","title":"Semantic Segmentation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"semantic-segmentation"}}}},{"_key":"f4611b19b406","_type":"navItem","title":"Polygons","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"polygons"}}}},{"_key":"5155d874d6c8","_type":"navItem","title":"Bounding Boxes","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"bounding-boxes"}}}},{"_key":"9ef3c1e21e74","_type":"navItem","title":"Key Points","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"key-points"}}}},{"_key":"314d4c00d351","_type":"navItem","title":"Cuboids","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"cuboids"}}}},{"_key":"8e17a6388d74","_type":"navItem","title":"Lines \u0026 Arrows","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"lines-and-arrows"}}}}],"title":"Shapes","url":null}],"title":"Platform","url":null},{"_key":"112867ca4d03","_type":"navDropdownMenu","items":[{"_key":"22699c7e06cb","_type":"navItem","items":null,"title":"Transportation \u0026 Navigation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"transportation-navigation"}}}},{"_key":"122ae5928d6d","_type":"navItem","items":null,"title":"Retail \u0026 E-Commerce","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"retail-ecommerce"}}}},{"_key":"7bb234b69fb0","_type":"navItem","items":null,"title":"Consumer \u0026 Media","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"consumer-media"}}}},{"_key":"33e6a886b39d","_type":"navItem","items":null,"title":"Biotech \u0026 Medtech","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"biotech-medtech"}}}},{"_key":"d095b2619c4e","_type":"navItem","items":null,"title":"Robotics \u0026 Manufacturing","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"robotics-and-manufacturing"}}}},{"_key":"2c4b82a94d79","_type":"navItem","items":null,"title":"Food \u0026 Agriculture","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"training-data-food-agriculture"}}}}],"title":"Industries","url":null},{"_key":"c47e8763a906","_type":"navDropdownMenu","items":[{"_key":"1d563df30b3f","_type":"navItem","items":null,"title":"Quality","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"quality-training-data"}}}},{"_key":"041725f35d96","_type":"navItem","items":null,"title":"Security","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"security-and-trust"}}}},{"_key":"fd64ede25798","_type":"navItem","items":null,"title":"Ethical AI","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-impact"}}}},{"_key":"398dcbb1c95d","_type":"navItem","items":null,"title":"Compare","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"compare"}}}},{"_key":"93bdfdd87879","_type":"navItem","items":null,"title":"Partners","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"partners"}}}}],"title":"Why Sama","url":null},{"_key":"1d38bf63df54","_type":"navDropdownMenu","items":[{"_key":"be81659b38a5","_type":"navItem","items":null,"title":"API Documentation","url":{"_type":"link","externalUrl":"https://docs.sama.com/reference/overview","internalLink":null}},{"_key":"2cec80e94962","_type":"navItem","items":null,"title":"Blog","url":{"_type":"link","internalLink":null,"internalLink_custom":"/blog"}},{"_key":"09e284fcb1d3","_type":"navItem","items":null,"title":"Events","url":{"_type":"link","internalLink":null,"internalLink_custom":"/events"}}],"title":"Resources","url":null},{"_key":"dbee93713c19","_type":"navDropdownMenu","items":[{"_key":"12d594a568bf","_type":"navItem","items":null,"title":"Our Story","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-story"}}}},{"_key":"ce36540a102d","_type":"navItem","items":null,"title":"Our Team","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-team"}}}},{"_key":"34fc328e8022","_type":"navItem","items":null,"title":"Careers","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"careers"}}}},{"_key":"c1fe2961020a","_type":"navItem","items":null,"title":"Contact","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"company-contact"}}}},{"_key":"ebd81873e538","_type":"navItem","items":null,"title":"Press","url":{"_type":"link","internalLink":null,"internalLink_custom":"/press"}}],"title":"Company","url":null}],"nav_cta":{"_type":"button","link":{"_type":"link","internalLink":{"_ref":"136788cb-06a6-4f27-b75b-07faf403bfa6","_type":"reference"}},"title":"Request a Demo","type":"secondary"}}},"data":{"author":{"_id":"6dd25391-26af-42ff-a2a2-f0778ce1b002","avatar":{"_type":"image","asset":{"_ref":"image-4e1c47984bb16cb0370855b6272663d6744216d3-450x450-jpg","_type":"reference"}},"bio":"Currently a Senior Product Manager at Sama, Audrey guides cross-functional teams to create thoughtful product solutions. She has guided teams of designers and engineers at HUGE Inc. and NBCUniversal, and monitored user analytics at the Wall Street Journal. With a BA in history from Harvard, an MA in anthropology from Columbia and an MBA from UNC Chapel Hill KFBS, Audrey is passionate a using technology and data analytics facilitate social impact and environmental solutions through technology.","firstLoad":[{"_createdAt":"2020-04-02T20:30:00Z","author":{"_id":"6dd25391-26af-42ff-a2a2-f0778ce1b002","avatar":{"_type":"image","asset":{"_ref":"image-4e1c47984bb16cb0370855b6272663d6744216d3-450x450-jpg","_type":"reference"}},"bio":"Currently a Senior Product Manager at Sama, Audrey guides cross-functional teams to create thoughtful product solutions. She has guided teams of designers and engineers at HUGE Inc. and NBCUniversal, and monitored user analytics at the Wall Street Journal. With a BA in history from Harvard, an MA in anthropology from Columbia and an MBA from UNC Chapel Hill KFBS, Audrey is passionate a using technology and data analytics facilitate social impact and environmental solutions through technology.","name":"Audrey Boguchwal","slug":{"_type":"slug","current":"audrey-boguchwal"}},"estimatedReadingTime":3,"featured_image":{"_type":"image","asset":{"_ref":"image-7eb4854393afff7be19269b7e8414936e411403f-5506x3671-jpg","_type":"reference"}},"meta_description":"SamaHub's video and 3D object tracking with frame level labeling assists companies in quickly building models that better reflect real-world behavior.","openGraphImage":null,"plaintextBody":"We live in an ever-changing world, where AI-enabled technology has become a new normal for society. To assist top organizations in their efforts to build smarter computer vision algorithms, weâve rolled out a new release for video and 3D object-tracking in our leading data annotation platform.\n\nThere are a number of applications that use computer vision to track how the world, and the objects in it, change overtime. For a self-driving car to navigate safely, it needs to track other moving objects on the road and make predictions about their future movement, so it can plan its driving path.\n\nAR and VR applications like video games need to track the motion of individual people to create a seamless digital experience. These vision applications have something in common: they all seek to understand the change in position, behavior and characteristics of unique objects over time.\n\nObject tracking annotationÂ offers object tracking capabilities for complex scenarios, including path planning, traffic light status, sentiment analysis, etc.\n\nThis frame-level labeling technology allows unique objects to be dynamically tracked across a video or a sequence of 3D point cloud data from a Lidar sensor. Change in position and pose are captured with annotation shapes like cuboids, polygons and bounding boxes.\n\nSamaÂ supports custom label taxonomies for both the main object class (person, car, etc.) and dynamic labeling for other object characteristics that change over time, such as visibility percentage of an object or a specific set of characteristics like emotions. Samaâs built-in automated interpolation between video frames helps ensure efficient, high quality labeled training data for a variety of object tracking use cases.\n\nFor over 10 years, SamaÂ has delivered turnkey, high-quality training data and validation to train the world's leading AI technologies. Video and 3D object tracking are no exception, and this update for video object tracking annotation in 2D RGB video and 3D Lidar data will continue to assist organizations in quickly building models that better reflect real-world behavior.\n\nSama has deep expertise working with training data for object tracking use cases across a variety of industries including autonomous vehicles, AR/VR, retail and e-commerce, communications, media and entertainment, to name just a few.\n\nDownload our solution brief to learn more about our secure training data annotation platform, or contact our team here.","seo_title":"Object Tracking with Frame Level-Labeling","slug":{"_type":"slug","current":"object-tracking-in-samahub-with-frame-level-labeling"},"tags":[{"_key":"OjIX5QKU","label":"Product","value":"Product"},{"_key":"2ZGxEWq0","label":"Video Annotation","value":"Video Annotation"},{"_key":"iBmdS1VE","label":"Training Data","value":"Training Data"},{"_key":"uZYhm6jx","label":"Data Annotation","value":"Data Annotation"}],"title":"Object Tracking with Frame Level-Labeling"},{"_createdAt":"2020-03-26T16:49:42Z","author":{"_id":"6dd25391-26af-42ff-a2a2-f0778ce1b002","avatar":{"_type":"image","asset":{"_ref":"image-4e1c47984bb16cb0370855b6272663d6744216d3-450x450-jpg","_type":"reference"}},"bio":"Currently a Senior Product Manager at Sama, Audrey guides cross-functional teams to create thoughtful product solutions. She has guided teams of designers and engineers at HUGE Inc. and NBCUniversal, and monitored user analytics at the Wall Street Journal. With a BA in history from Harvard, an MA in anthropology from Columbia and an MBA from UNC Chapel Hill KFBS, Audrey is passionate a using technology and data analytics facilitate social impact and environmental solutions through technology.","name":"Audrey Boguchwal","slug":{"_type":"slug","current":"audrey-boguchwal"}},"estimatedReadingTime":3,"featured_image":{"_type":"image","asset":{"_ref":"image-70afee37d4e99e8fac42e758c436c2f61d991a7d-1904x797-jpg","_type":"reference"}},"meta_description":"Samasource is excited to launch the PII Data Anonymizer for video training data. This technology enables obscuring of sensitive information in training data.","openGraphImage":null,"plaintextBody":"Sama is excited to launch the PII Data Anonymizer as part of our platform for video training data. This technology enables obscuring of sensitive, personally identifying information (PII) in training data.\n\nIn light of new laws like GDPR and CCPA, itâs important for companies building AI and ML technologies to carefully manage data with PII information. Obscuring PII helps SamaÂ and our customers work to protect privacy.\n\nSamaâs PII Data Anonymizer helps make more data available to train AI by keeping personally identifying information safe across a variety of data sources: People in camera images from retail spaces and public places, street-level images of people and license plates captured by vehicles, smart city applications on public transit and more.\n\nApplications for anonymization range from autonomous transportation, detailed customer demographics, customer data like clothing and emotion, people counters, and security.\n\nThis deep learning pre-annotation technology allows SamaÂ to obscure faces and vehicle license plates that appear in data without the need for any human intervention. That means that private information remains private and is never seen by another person.\n\n\n\nWhen SamaÂ receives customer data, it can be run through our anonymizer technology service before any labeling occurs. The service would automatically detect faces and license plates and obscure them, as well as blur faces and license plates so they are not recognizable.\n\nAlternatively, it can replace faces and license plates with realistic computer-generated avatars. This AI-generated content creates training data that looks like real-time data when people and vehicles are the primary objects of interest for the algorithm.\n\nUnlike manual blurring, Samaâs PII Data Anonymizer is run without a human examining the data, which contributes to the privacy of PII data. It is built on deep learning and is run within our technology platform, ensuring that customer data never leaves Samaâs secure cloud environment.\n\nFrom pilots to multi-year projects, SamaÂ securely trains and validates computer vision and NLP models. We work on a range of use cases ranging from e-commerce to autonomous transportation, manufacturing, navigation, retail, AR/VR, and biotech. If your goal is to quickly build smarter AI, contact our team to discuss your training data needs.","seo_title":"Keep it Secret, Keep it Safe: Announcing the PII Data Anonymizer","slug":{"_type":"slug","current":"keep-it-secret-keep-it-safe-announcing-the-pii-data-anonymizer"},"tags":[{"_key":"4C8kDRnD","label":"Product","value":"Product"},{"_key":"sCm7cDGc","label":"Security \u0026 Trust","value":"Security \u0026 Trust"},{"_key":"w6zwqXk4","label":"Anonymization","value":"Anonymization"}],"title":"Keep it Secret, Keep it Safe: Announcing the PII Data Anonymizer"},{"_createdAt":"2020-02-04T22:15:39Z","author":{"_id":"6dd25391-26af-42ff-a2a2-f0778ce1b002","avatar":{"_type":"image","asset":{"_ref":"image-4e1c47984bb16cb0370855b6272663d6744216d3-450x450-jpg","_type":"reference"}},"bio":"Currently a Senior Product Manager at Sama, Audrey guides cross-functional teams to create thoughtful product solutions. She has guided teams of designers and engineers at HUGE Inc. and NBCUniversal, and monitored user analytics at the Wall Street Journal. With a BA in history from Harvard, an MA in anthropology from Columbia and an MBA from UNC Chapel Hill KFBS, Audrey is passionate a using technology and data analytics facilitate social impact and environmental solutions through technology.","name":"Audrey Boguchwal","slug":{"_type":"slug","current":"audrey-boguchwal"}},"estimatedReadingTime":4,"featured_image":{"_type":"image","asset":{"_ref":"image-df3e88916d772584990f79eaa76fbbf00fb8c830-3872x2592-jpg","_type":"reference"}},"meta_description":"During the REWORK Deep Learning Summit, Sama shared how top organizations obtain secure, high-quality training data, fighting AI bias in the process.","openGraphImage":null,"plaintextBody":"I recently presented a talk at the ReWork Deep Learning Summit titled, âFighting AI Bias: How to Obtain Secure, High-Quality Training Data,\" but I think itâs equally important this knowledge is also shared outside of the summit.\n\nBias can make its way into your model at any stage of the training data lifecycle, potentially compromising the accuracy and performance of your algorithms. And as more organizations develop their own AI and ML programs, the necessity of superior quality data is even more pertinent.\n\nImpact of Biased Data in Computer Vision\n\nAI bias can creep in at any stage of the training data lifecycle, and bias presents itself most commonly in three categories: dataset bias, training bias and algorithmic bias.\n\nDataset bias is as you might expectâthe data does not provide enough information for the model to learn the problem, or itâs unrepresentative of reality in some way. Training bias is the result of poor quality or inconsistent data labeling, and lastly, algorithmic bias occurs when the algorithm itself makes poor predictions or produces poor results.\n\nModels trained on biased data not only produce inaccurate algorithms, they also present ethical, legal and safety problems. And in some cases, biased data in computer vision can perpetuate historical, negative stereotypes across race and gender.\n\nLeft unchecked, algorithms trained on biased data greatly impact the lives of people using the very technologies meant to enhance their everyday experiences.\n\n\n\nCountering Bias in Training Data\n\nCountering bias in training data starts by having an effective training data strategy.\n\nLast year at Embedded Vision Summit, I presented a talk on practical training data strategies to avoid bias, sharing four ways to mitigate unwanted bias in training data. \n\nI want to echo my thoughts here that an effective training data strategy makes for a strong defense against AI bias. Fighting bias in training data means determining your data needs, developing training rules to cover known uses cases, and diversifying data to cover edge cases.\n\nAs your model learns, countering bias means evolving rules and sourcing more data when neededâall while keeping apprised of legal and ethical sourcing considerations.\n\nObtaining Superior Quality Datasets\n\nTop organizations understand that if they want smarter models, they need ethically sourced, quality data (https://www.samasource.com/quality-scale). Your quality requirements might vary, depending on your model, but the fact remains that diverse, high-quality data helps counter AI bias.\n\nFor over a decade, hundreds of organizations, including 25% of the Fortune 50 have relied on Samasource to deliver secure, high-quality training data and model validation for machine learning.\n\nWeâve helped organizations like Walmart improve their retail item coverage, and others like Vulcan Inc., improve turnaround time to process training datasets. Weâve even partnered with organizations like Cornell Tech to produce an open-source dataset of our own.Â \n\nHere are a few things to keep in mind when sourcing superior quality datasets:\n\nBe aware of local privacy and property laws as you collect data.\n\nEnsure you have legal user consent for data capture.\n\nStay informed of the security protocols of facilities processing your training data.\n\nWhen possible, stay informed of the working conditions of the workers labeling your data, and support that pay living wages and benefits.\n\nFrom pilots to multi-year projects, SamasourceÂ securely trains and validates computer vision and NLP models. We work on a range of use cases ranging from e-commerce to autonomous transportation, manufacturing, navigation, retail, AR/VR, and biotech, and if your goal is to build smarter AI, contact our team to discuss your training data needs.Â ","seo_title":"Fighting AI Bias by Obtaining High-Quality Training Data","slug":{"_type":"slug","current":"fighting-ai-bias-by-obtaining-high-quality-training-data"},"tags":[{"_key":"JOSMV7ei","label":"Events","value":"Events"},{"_key":"X1b43vej","label":"Training Data","value":"Training Data"},{"_key":"zoYY0bth","label":"Data Quality","value":"Data Quality"},{"_key":"8v2jDpFA","label":"AI Bias","value":"AI Bias"}],"title":"Fighting AI Bias by Obtaining High-Quality Training Data"},{"_createdAt":"2019-07-11T22:00:00Z","author":{"_id":"6dd25391-26af-42ff-a2a2-f0778ce1b002","avatar":{"_type":"image","asset":{"_ref":"image-4e1c47984bb16cb0370855b6272663d6744216d3-450x450-jpg","_type":"reference"}},"bio":"Currently a Senior Product Manager at Sama, Audrey guides cross-functional teams to create thoughtful product solutions. She has guided teams of designers and engineers at HUGE Inc. and NBCUniversal, and monitored user analytics at the Wall Street Journal. With a BA in history from Harvard, an MA in anthropology from Columbia and an MBA from UNC Chapel Hill KFBS, Audrey is passionate a using technology and data analytics facilitate social impact and environmental solutions through technology.","name":"Audrey Boguchwal","slug":{"_type":"slug","current":"audrey-boguchwal"}},"estimatedReadingTime":2,"featured_image":{"_type":"image","asset":{"_ref":"image-31269a4f01b8e495d1ec30a473f063a4957254c6-5760x3840-jpg","_type":"reference"}},"meta_description":"Samasource's revamped toolset for 2D image vector segmentation is ideal for computer vision projects using vector shapes to structure training data.","openGraphImage":null,"plaintextBody":"Sama is pleased to announce production availability of our revamped toolset for 2D image vector segmentation using bounding boxes, polygons and lines.\n\nThe vector toolset is ideal for computer vision projects using vector shapes to structure training data for detection, classification, labeling and object tracking projects.\n\nThe new vector toolset is an update to our previous offering for annotating 2D images. The new tools contain UX enhancements and new features designed to further improve annotation efficiency and accuracy for our expert workforce.\n\nHoused in Samaâs proprietary platform, the toolset leverages existing Hub capabilities for work prioritization and quality management, to deliver the highest quality training data every time.\n\nQUALITY\n\nThe new vector toolset is optimized for quality. The annotation workspace has a larger image display and more precise drawing tools enabling Samaâs workforce to annotate with an even greater degree of accuracy.\n\nThe toolset gives individual annotators direct access to image and shape adjustment options (such as shape opacity), instead of restricting these options to the admin control panel.\n\nNow, individual annotators can adjust settings to get the best view of every unique image while annotating.\n\nEFFICIENCY\n\nThe toolset is also optimized for efficiency. The larger image, new keyboard hotkeys and more intelligent zoom features help reduce time spent panning and adjusting an image.\n\nWhatâs more, the toolset is built on a modern codebase that helps streamline development for new features built by Samaâs dedicated engineering team.\n\n\n\nCONSIDERING A 2D VECTOR SEGMENTATION PROJECT?\n\n\nFrom autonomous vehicle applications to high tech e-commerce initiatives, SamaÂ has the annotation technology to put your project on track for success. Drop us a line, and request a demo of the new toolset in action.","seo_title":"Revamped 2D Vector Segmentation","slug":{"_type":"slug","current":"revamped-2d-vector-segmentation-on-samahub"},"tags":[{"_key":"oc26gThR","label":"Product","value":"Product"},{"_key":"8Uhzi08N","label":"Vector Annotation","value":"Vector Annotation"},{"_key":"W46d0x8z","label":"Training Data","value":"Training Data"},{"_key":"NwhOkizM","label":"Data Annotation","value":"Data Annotation"},{"_key":"46Go0q8m","label":"Data Quality","value":"Data Quality"}],"title":"Revamped 2D Vector Segmentation"},{"_createdAt":"2019-06-05T14:21:10Z","author":{"_id":"6dd25391-26af-42ff-a2a2-f0778ce1b002","avatar":{"_type":"image","asset":{"_ref":"image-4e1c47984bb16cb0370855b6272663d6744216d3-450x450-jpg","_type":"reference"}},"bio":"Currently a Senior Product Manager at Sama, Audrey guides cross-functional teams to create thoughtful product solutions. She has guided teams of designers and engineers at HUGE Inc. and NBCUniversal, and monitored user analytics at the Wall Street Journal. With a BA in history from Harvard, an MA in anthropology from Columbia and an MBA from UNC Chapel Hill KFBS, Audrey is passionate a using technology and data analytics facilitate social impact and environmental solutions through technology.","name":"Audrey Boguchwal","slug":{"_type":"slug","current":"audrey-boguchwal"}},"estimatedReadingTime":5,"featured_image":{"_type":"image","asset":{"_ref":"image-1184784eeedb6464bcb4703dda418de157e6b21c-2250x1500-jpg","_type":"reference"}},"meta_description":"Samasource exhibited and presented at the venerable 2019 Embedded Vision Summit in Santa Clara, California.","openGraphImage":null,"plaintextBody":"Last week, Sama exhibited and presented at the venerable Embedded Vision Summit in Santa Clara, California.\n\nEmbedded Vision Alliance has hosted EBS since 2012, bringing together technology providers across industries who are enabling innovative and practical applications for computer vision.\n\nThis year for the first time, I represented SamaÂ at the talks and presented a technical talk about Training Data Strategy: Avoiding Bias and Legal and Ethical Sourcing Considerations. Take a look at my related blog post for more details. \n\nAI at the Edge\n\nOn the exhibition floor, the hottest topic was AI at the edge and edge computing. AI at the edge brings AI into small, powerful computer chips located directly in devices, such as phones.\n\nWith the computing happening in the device itself, AI devices no longer need to send data back to the cloud. AI at the edge enables remote and distributed applications, such as using a cell phone to diagnose crop diseases on rural farms.\n\nFor Sama, AI at the edge means new, flexible applications for computer vision that might require new training data strategies and solutions.\n\nHigh quality training data annotation continues to be a high priority need for companies developing AI and computer vision. The challenge remains: high quality data at a reasonable cost and timeline.\n\nBlending highly trained workforces with annotation automation and auto-labeling can make significant gains in efficiency.Â Samaâs expert, experienced workforce combined with our technology continues to be an offering that is well-positioned to help address these problems with real-world data.\n\nPHOTO: Computer vision in action on the showcase floor recognizes Audrey's face\n\nData Capture\n\nAt the SamaÂ booth, we had many great conversations about data capture.Â Attendees who stopped by our booth also asked questions about semantic segmentation and smarter video interpolation.\n\nThough computer vision has advanced in many ways, data capture remains a challenge - particularly as algorithms become more sophisticated and require bespoke data sourcing.\n\nThatâs one of the many reasons why SamaÂ plans to expand our data capture offering.\n\n\n\nPHOTO: Wendy Gonzales (left), Audrey Boguchwal and Heather Gadonniew at theÂ SamaÂ booth\n\nData Bias\n\nTowards the end of the two-day event, I presented on training data strategy in the Technical Insights II Track.\n\nIn my presentation, I discussed approaches to training data strategy for avoiding data bias and considering legal and ethical sourcing issues. Data can be biased if it does not represent reality accurately: it is missing examples of use cases, or doesnât have enough examples of use cases (even if a few are present).\n\nBiased data can result in poor algorithm performance if an algorithm simply doesnât work as designed. Even worse, biased data can cause problems if say, a facial recognition algorithm identifies the wrong person as a criminal, or an autonomous vehicle algorithm fails to detect the presence of a cyclist.\n\nI also discussed legal and ethical sourcing considerations: knowing regional laws and considering privacy and other gray areas when sourcing data. Weâll update this blog post to link to the video of my presentation when EBS posts it. Also be sure to check out my related blog post for more details.\n\nPHOTO: Audrey mid-sentence while presenting on training data strategy\n\n2019 Women in Vision Reception\n\nWeÂ were invited to attend the first Women in Vision Reception ever held at EBS. It was inspiring to hear the exciting work in which other women are involved. We hope to attend future receptions!\n\n\n\nPHOTO: Women in Vision Reception group photo\n\n\nAs always, SamaÂ continuously seeks to be ahead of the training data market. We are always researching the latest technologies, applications and business cases to be able to offer the most comprehensive training data solutions and strategies.\n\nOur time at the Embedded Vision Summit 2019 gave us an inside look into the computer vision industriesâ current needs and challenges. We canât wait to see whatâs next!","seo_title":"Highlights from the 2019 Embedded Vision Summit","slug":{"_type":"slug","current":"highlights-from-the-2019-embedded-vision-summit"},"tags":[{"_key":"2Ur4O0La","label":"Best of","value":"Best of"},{"_key":"8FMbOtTY","label":"Events","value":"Events"}],"title":"Highlights from the 2019 Embedded Vision Summit"},{"_createdAt":"2019-05-20T18:30:00Z","author":{"_id":"6dd25391-26af-42ff-a2a2-f0778ce1b002","avatar":{"_type":"image","asset":{"_ref":"image-4e1c47984bb16cb0370855b6272663d6744216d3-450x450-jpg","_type":"reference"}},"bio":"Currently a Senior Product Manager at Sama, Audrey guides cross-functional teams to create thoughtful product solutions. She has guided teams of designers and engineers at HUGE Inc. and NBCUniversal, and monitored user analytics at the Wall Street Journal. With a BA in history from Harvard, an MA in anthropology from Columbia and an MBA from UNC Chapel Hill KFBS, Audrey is passionate a using technology and data analytics facilitate social impact and environmental solutions through technology.","name":"Audrey Boguchwal","slug":{"_type":"slug","current":"audrey-boguchwal"}},"estimatedReadingTime":4,"featured_image":{"_type":"image","asset":{"_ref":"image-f9a4a7493982c6bf1be96e8260df8a98e4467b28-2250x1500-jpg","_type":"reference"}},"meta_description":"During Embedded Vision Summit 2019, Audrey Boguchwal will share four training data strategies that help AI teams avoid training data bias.","openGraphImage":null,"plaintextBody":"According to a new McKinsey Global Survey, adoption ofÂ artificial intelligence continues to advance, but the same foundational barriers still remain when trying to create value from AI at scale.\n\nAmong the challenges to successfully adopt AI is bias in data and algorithms. Audrey Boguchwal,Â Senior Product Manager at Sama shares four practical approaches to training data strategy that can help AI teams avoid the effects of training data bias.Â \n\n\n\nThe Impact of Biased Data\n\n\nModels trained on biased data can be less accurate, resulting in insufficient training for your algorithm. Recent studies have shown that biased data can result inÂ problems with facial recognition used in identification, surveillance, and law enforcement. Biased data can also perpetuate historical, negative stereotypes across race and gender.Â \n\nEnsuring that reality is always represented in your data is a constructive way to minimize the impact of data bias, however,Â a clear training data strategy to legally and ethically source the data AI requires is fundamental for developing smarter models.\n\n\n\nAvoid Data Bias with a Practical Training Data Strategy\n\nClearly articulate your end training goal and know what data is needed to get to it. When you start with the end goal in mind, you're primed to think through the skill set, tool set and milestones needed to achieve your training goal.Â For example, for object classifiers, your training data strategyÂ might include preprocessing data to capture bias or offset dataset bias. You recognize that images may look similar before you begin data collection and make a plan to considerÂ transformations i.e. flip or automatically crop images so they vary.\n\nMap out ways bias can enter data and proactively source data to avoid it. Keep in mind that humans are inherently biased, so eliminating all forms of bias is near impossible.Â Rigorously examine your own biases and the biases of those providing data/information to you.\n\nAvoidÂ selection bias by varying search terms and data sources, and avoid negative set bias by varying data i.e. collect data that contains background scenes in addition to objects of interest.Â Test before and after training, on a wide range of data. If in the end, you find your model to be of low variance and high bias, use cross-validation to influence the degree of flexibility of your model. Methods like cross dataset generalization can also help determine how reliant your model is on the \"native\" dataset, when compared to other representative datasets.\n\nEnsure data represents reality for your training goal in quantity and diversity, and replenish data often. High-tech, automotive, retail-- there isn't a single industry adopting AI that shows signs of stagnating growth.Â Refresh data often to stay ahead of trends. Use more than one training set, especially if it's a stock set.Â Success comes from being iterative, source and label new data as the world changes.\n\nAn effective training data strategy can help you determine ways to mitigate unwanted bias.Â Audrey Boguchwal, Senior Product Manager at SamaÂ will present \"Practical Approaches to Training Data Strategy: Bias, Legal and Ethical Considerations this year at the 2019 Embedded Vision Summit conference.\n\nAudrey's presentation will expand on the four strategies to avoid training data bias in this post by exploring use-cases that show how unintended bias can creep into datasets, sharing tests to detect dataset bias, and outlining legal and ethical data sourcing considerations.\n\nIf you'll be attending Embedded Vision Summit, stop by booth #621 to discuss your training data needs with the SamaÂ team, or click below to request a demo of our cloud-based data annotation platform.","seo_title":"4 Training Data Strategies to Avoid Bias","slug":{"_type":"slug","current":"4-training-data-strategies-to-avoid-bias"},"tags":[{"_key":"79xbZuT2","label":"Events","value":"Events"},{"_key":"hX284VAD","label":"Training Data","value":"Training Data"},{"_key":"VrBfZ9C5","label":"AI Bias","value":"AI Bias"}],"title":"4 Training Data Strategies to Avoid Bias"},{"_createdAt":"2018-05-11T16:00:00Z","author":{"_id":"6dd25391-26af-42ff-a2a2-f0778ce1b002","avatar":{"_type":"image","asset":{"_ref":"image-4e1c47984bb16cb0370855b6272663d6744216d3-450x450-jpg","_type":"reference"}},"bio":"Currently a Senior Product Manager at Sama, Audrey guides cross-functional teams to create thoughtful product solutions. She has guided teams of designers and engineers at HUGE Inc. and NBCUniversal, and monitored user analytics at the Wall Street Journal. With a BA in history from Harvard, an MA in anthropology from Columbia and an MBA from UNC Chapel Hill KFBS, Audrey is passionate a using technology and data analytics facilitate social impact and environmental solutions through technology.","name":"Audrey Boguchwal","slug":{"_type":"slug","current":"audrey-boguchwal"}},"estimatedReadingTime":1,"featured_image":{"_type":"image","asset":{"_ref":"image-df12378ee9ac92007db6ab4b43e58310688aeb2a-1125x1500-jpg","_type":"reference"}},"meta_description":"We'll showcase how Sama's web research and data cleaning services help create training data for Quid to build their NLP-powered data platform.","openGraphImage":null,"plaintextBody":"Weâve written before about Samaâs proprietary online software that we use to connect low-income individuals to digital work. Weâve also shared how our image annotation service creates training data for a computer vision client.\n\nIn this post, Iâll showcase how Samaâs web research and data cleaning services help create training data for longtime client Quid to build their natural language processing-powered data platform.\n\n\nHow does Quid create business intelligence?\n\n\nQuid is working to ingest the world's collective intelligence. Their goal? Help business decision makers quickly gain the insights they need to make more informed decisions. Quidâs product is a platform that searches, analyzes and visualizes data to deliver key insights. Customers bring questions such as, âWhat does the current landscape look like for financial technology?â For each question, Quid creates a custom visual interactive map from raw business data: documents and articles.\n\nThis visual map was generated in response to a question about the current global fintech landscape.\n\nTo read the entire case study, download the PDF here!","seo_title":"How Quid Creates Reliable Business Intelligence","slug":{"_type":"slug","current":"how-does-quid-create-reliable-business-intelligence"},"tags":[{"_key":"1EAOekEr","label":"Case Studies","value":"Case Studies"}],"title":"How Quid Creates Reliable Business Intelligence"},{"_createdAt":"2017-05-24T21:33:56Z","author":{"_id":"6dd25391-26af-42ff-a2a2-f0778ce1b002","avatar":{"_type":"image","asset":{"_ref":"image-4e1c47984bb16cb0370855b6272663d6744216d3-450x450-jpg","_type":"reference"}},"bio":"Currently a Senior Product Manager at Sama, Audrey guides cross-functional teams to create thoughtful product solutions. She has guided teams of designers and engineers at HUGE Inc. and NBCUniversal, and monitored user analytics at the Wall Street Journal. With a BA in history from Harvard, an MA in anthropology from Columbia and an MBA from UNC Chapel Hill KFBS, Audrey is passionate a using technology and data analytics facilitate social impact and environmental solutions through technology.","name":"Audrey Boguchwal","slug":{"_type":"slug","current":"audrey-boguchwal"}},"estimatedReadingTime":4,"featured_image":{"_type":"image","asset":{"_ref":"image-73eb0ced8bf91c8bd71f48061438e8d61ce0f8b6-597x398-png","_type":"reference"}},"meta_description":"Better Algorithms, Better Lives: Reducing Poverty Through Training Data","openGraphImage":null,"plaintextBody":"Last time, we explained how Sama our online software, to connect low-income people to digital work. Now weâll spotlight one of our clients to show how our image annotation work can be used in machine learning to train image recognition algorithms.\n\nMarkable came to SamaÂ for help training their state-of-the-art image recognition technology that identifies fashion products in photos and videos. With Markableâs tech in place, viewers can click on clothing they see while watching TV shows and Markable will generate matching product results. Check out Markableâs demo to see how it works.\n\nTo create image recognition technology, engineers develop a machine learning program that learns to identify objects of interest from training data. For Markable, the training data is photographs of fashion products, clearly labeled so when the algorithm encounters an unknown product, it can infer what it is based on trained examples. This process is called âsupervised learningâ because the algorithm is given examples structured specifically for training. A high-quality training data set for a vision algorithm consists of tens of thousands of images in which objects are outlined and labeled according to the desired classification. The accuracy of the training data is important as an algorithm trained with inconsistently labeled data wonât learn patterns and wonât be able to identify objects.\n\nHow do all those training data images get labeled accurately and quickly enough to get Markableâs tech to customers? Thatâs where SamaÂ comes in. As part of our image annotation service, we have a trained, scalable workforce and the right tools to label thousands of images for training data, efficiently and accurately. We balance stringent quality requirements with on-time deliveries to ensure clients like Markable can stick to their project timelines.\n\nSama worked closely with Markable to understand the projectâs annotation requirements and refine them for ambiguous images. Markable provided SamaÂ with source images and then we trained a dedicated team of workers how to draw boxes around the objects of interest and label them. For Markable, SamaÂ workers learned to identify every minor visible detail, such as heel-length of a shoe, to ensure exceptional data quality. Samaâs on-site quality analysts inspect a sample of annotated images daily to ensure quality, asking workers to redo any images that donât meet client standards.\n\nHereâs what image annotation work looks like in the Hub. Agents draw bounding boxes (or tight outlines) around each object and then use a menu to add labels. In the for-presentation-only image below, a worker has labeled the shirt, pants and is labeling boots with a multi-level menu. SamaÂ can set up label data entry to meet a variety of project needs: text entry, selection from a dropdown, or search for a label from a list, to name a few.\n\nWith Samaâs workers, Markable has been able to improve their algorithm and better serve their customers. They wrote to us: âWith the help of Sama's annotation, we were able to surpass previous state-of-the-art accuracy on the largest open-source fashion e-commerce dataset. We had a great experience in working with SamaÂ and we will continue working with them in future.â\n\nSamaâs client relationships are a win-win: clients provide our workers with life-changing job opportunities and workers help clients achieve their business goals, even on the trickiest projects.\n\nIn our third and final post, weâll show you how Samaâs workers take on a web research project.","seo_title":"Better Algorithms, Better Lives: Reducing Poverty Through Training Data","slug":{"_type":"slug","current":"better-algorithms-better-lives-reducing-poverty-through-training-data"},"tags":[{"_key":"Bx4Do9xK","label":"Ethical AI","value":"Ethical AI"},{"_key":"Rx6gXgmn","label":"Impact","value":"Impact"},{"_key":"iujrQUVj","label":"Use Cases","value":"Use Cases"},{"_key":"v5mZqxPX","label":"Data Annotation","value":"Data Annotation"}],"title":"Better Algorithms, Better Lives: Reducing Poverty Through Training Data"},{"_createdAt":"2017-05-15T23:51:58Z","author":{"_id":"6dd25391-26af-42ff-a2a2-f0778ce1b002","avatar":{"_type":"image","asset":{"_ref":"image-4e1c47984bb16cb0370855b6272663d6744216d3-450x450-jpg","_type":"reference"}},"bio":"Currently a Senior Product Manager at Sama, Audrey guides cross-functional teams to create thoughtful product solutions. She has guided teams of designers and engineers at HUGE Inc. and NBCUniversal, and monitored user analytics at the Wall Street Journal. With a BA in history from Harvard, an MA in anthropology from Columbia and an MBA from UNC Chapel Hill KFBS, Audrey is passionate a using technology and data analytics facilitate social impact and environmental solutions through technology.","name":"Audrey Boguchwal","slug":{"_type":"slug","current":"audrey-boguchwal"}},"estimatedReadingTime":3,"featured_image":{"_type":"image","asset":{"_ref":"image-bde2f64018e50b7615f188245cc00fe516e84936-693x462-jpg","_type":"reference"}},"meta_description":"How exactly does Sama move people out of poverty?","openGraphImage":null,"plaintextBody":"If youâre reading this, you probably already know that Samaâs mission is to connect low-income people to digital work. And, if youâre like the majority of people reading this, the details of how exactly we do that are probably a little fuzzy. This post will dispel the mystery!\n\nSama developed an in-house SaaS (software as a service) platform that enables us to send work from our clients to workers at our delivery centers in Kenya, Uganda and India. SamaÂ is the linchpin in our model, as it allows our project managers, agents, and clients to access the work being done, while also allowing us to closely monitor quality and provide feedback for continuous improvements.\n\nAs a SaaS platform, the Hub can be accessed securely from anywhere - our San Francisco headquarters to our SamaÂ Center in Nairobi, Kenya. To support the Hub, we have a full time, dedicated engineering team that help the Hub evolve to meet changing client needs and continuously improve worker efficiency.\n\nDuring our sales cycle,Â SamaÂ meets with clients to better understand their data services needs. When a contract is in place, a project manager will partner with the client to design a Hub project workflow that satisfies project requirements, a quality strategy to check work, a training plan and a delivery schedule.\n\nOn Hub, project managers then upload data from clients that our workers will clean, use as the basis for research, annotate or supplement. Next, they custom-design the task layout and workflow that workers will see when they log in to complete tasks. From question types and dependency logic to an easy-to-read layout, the Hub can accommodate a range of project needs.\n\nOnce the project is set up, workers complete specialized training to learn the new workflow. Throughout training, workers are coached by on-site team leaders and evaluated by quality analysts until their work is at or above the clientâs desired SLA for quality. The SLA is the service level agreement, that is, the level of quality agreed upon in the clientâs contract with Sama. When training is complete, workers begin production tasks on the Hub. During production, coaching continues to maintain quality. QAs use the Hub to check task quality and send back tasks that are below quality standards for rework. Once work is completed, it can be downloaded from the Hub or delivered directly to the client via API.\n\nIn future posts, weâll go in-depth in two case studies to see how SamaÂ completes work for different verticals: web research and image annotation for machine learning and computer vision applications, and how the Hub is an integral part of our process.\n\nStay tuned!","seo_title":"How Samasource Moves People Out of Poverty with Digital Work","slug":{"_type":"slug","current":"how-exactly-does-samasource-move-people-out-of-poverty"},"tags":[{"_key":"Z2i2Xm9p","label":"Ethical AI","value":"Ethical AI"},{"_key":"NE08Dk4r","label":"Impact","value":"Impact"},{"_key":"mwOWz5qA","label":"Data Annotation","value":"Data Annotation"}],"title":"How Samasource Moves People Out of Poverty with Digital Work"}],"morePosts":[],"name":"Audrey Boguchwal","slug":{"_type":"slug","current":"audrey-boguchwal"}},"pageConfig":{"title":"Sama Blog | Training Data, AI and Impact Sourcing Insights","description":"From machine learning to training data strategy, the Sama blog covers research, news and other AI trends from thought leaders across the globe."}}},"__N_SSG":true},"page":"/blog/author/[slug]","query":{"slug":"audrey-boguchwal"},"buildId":"YWzTCZqh_Y7EMW0L5W93M","isFallback":false,"dynamicIds":[4941,425,3551],"gsp":true,"appGip":true,"scriptLoader":[]}</script></body></html>