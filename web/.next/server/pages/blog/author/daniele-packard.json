{"pageProps":{"config":{"footerNav":{"items":[{"_key":"f255606f8f25","_type":"navDropdownMenu","items":[{"_key":"76389ad94cbb","_type":"navItem","title":"Autonomous Transportation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"training-data-for-autonomous-driving"}}}},{"_key":"5f64a8d6a69d","_type":"navItem","title":"E-Commerce","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"training-data-for-ecommerce"}}}},{"_key":"f10e54ae04d0","_type":"navItem","title":"AR/VR","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"training-data-for-ar-vr"}}}},{"_key":"fd729b522a77","_type":"navItem","title":"Data Quality","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"data-quality"}}}}],"title":"Guides","url":null},{"_key":"681ef7d8763a","_type":"navDropdownMenu","items":[{"_key":"6238a422b667","_type":"navItem","title":"Our Story","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-story"}}}},{"_key":"258985d6d46b","_type":"navItem","title":"Our Team","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-team"}}}},{"_key":"e0a76077324a","_type":"navItem","title":"Our Mission","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"mission-vision-values"}}}},{"_key":"239e49661b0d","_type":"navItem","title":"Careers","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"careers"}}}},{"_key":"e005a740cd80","_type":"navItem","title":"Contact","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"company-contact"}}}}],"title":"Company","url":null}]},"logo":{"asset":{"_createdAt":"2021-12-09T21:42:35Z","_id":"image-4f4e2f86a8fad952c02dffffd7008aa35f83c850-2380x636-svg","_rev":"7Z7VDk3xHzg51hvomGzc99","_type":"sanity.imageAsset","_updatedAt":"2021-12-09T21:42:35Z","assetId":"4f4e2f86a8fad952c02dffffd7008aa35f83c850","extension":"svg","metadata":{"_type":"sanity.imageMetadata","blurHash":"D009jvfQfQfQfQfQfQfQfQfQ","dimensions":{"_type":"sanity.imageDimensions","aspectRatio":3.742138364779874,"height":636,"width":2380},"hasAlpha":true,"isOpaque":false,"lqip":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAYAAABFA8wzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAr0lEQVQYlU3QyUoDQBAE0HeIEjeixAVyESRI3BNFJSZxAU/+/wdJQSEehu6Zqa6uKnjBGz7xgTuc4gAj7LWe4LD9cc8Y+9jBUed84QGrEt/gEleYY9Ylr3jGU/tV77fFLirId0nWBYYgoACi+r3D6YPN0vwFm4VxmNlgfkK4qcLUZdVMcdHB+75FzWPfzzCpxXNcFxuOP2uxnhNLASaX5LjbnJJf6jYG2PpXh812/AvSEQ+GGZqgYgAAAABJRU5ErkJggg==","palette":{"_type":"sanity.imagePalette","darkMuted":{"_type":"sanity.imagePaletteSwatch","background":"#040404","foreground":"#fff","population":100.29,"title":"#fff"},"darkVibrant":{"_type":"sanity.imagePaletteSwatch","background":"#424242","foreground":"#fff","population":0,"title":"#fff"},"dominant":{"_type":"sanity.imagePaletteSwatch","background":"#040404","foreground":"#fff","population":100.29,"title":"#fff"},"lightMuted":{"_type":"sanity.imagePaletteSwatch","background":"#4c4c4c","foreground":"#fff","population":0,"title":"#fff"},"lightVibrant":{"_type":"sanity.imagePaletteSwatch","background":"#bcbcbc","foreground":"#000","population":0,"title":"#fff"},"muted":{"_type":"sanity.imagePaletteSwatch","background":"#4c4c4c","foreground":"#fff","population":0,"title":"#fff"},"vibrant":{"_type":"sanity.imagePaletteSwatch","background":"#7f7f7f","foreground":"#fff","population":0,"title":"#fff"}}},"mimeType":"image/svg+xml","originalFilename":"e20f8cc53e5f74df10ae9a822edb7ec2c4d00f02-2380x636.svg","path":"images/76e3r62u/production/4f4e2f86a8fad952c02dffffd7008aa35f83c850-2380x636.svg","sha1hash":"4f4e2f86a8fad952c02dffffd7008aa35f83c850","size":2009,"uploadId":"jTUF9DIFqAwpLJ0GcI9bRqb17D69QQlN","url":"https://cdn.sanity.io/images/76e3r62u/production/4f4e2f86a8fad952c02dffffd7008aa35f83c850-2380x636.svg"}},"mainNav":{"items":[{"_key":"58c18e9aa9ea","_type":"navDropdownMenu","items":[{"_key":"b5b5b8bee78b","_type":"navCat","items":[{"_key":"0e80156a2f1a","_type":"navItem","title":"How it Works","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"how-it-works"}}}},{"_key":"40bacee029b4","_type":"navItem","title":"Video Annotation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"video-annotation"}}}},{"_key":"32650ef07503","_type":"navItem","title":"Image Annotation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"image-annotation"}}}},{"_key":"fe9137cd0167","_type":"navItem","title":"3D & LiDAR Annotation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"3d-lidar"}}}},{"_key":"d9a1316d400a","_type":"navItem","title":"Natural Language Processing","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"natural-language-processing"}}}},{"_key":"ac12c7c5d70a","_type":"navItem","title":"Data Curation (Beta)","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"data-curation"}}}}],"title":"Platform","url":null},{"_key":"37ff4fa913bd","_type":"navCat","items":[{"_key":"6026b1a9314e","_type":"navItem","title":"Semantic Segmentation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"semantic-segmentation"}}}},{"_key":"f4611b19b406","_type":"navItem","title":"Polygons","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"polygons"}}}},{"_key":"5155d874d6c8","_type":"navItem","title":"Bounding Boxes","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"bounding-boxes"}}}},{"_key":"9ef3c1e21e74","_type":"navItem","title":"Key Points","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"key-points"}}}},{"_key":"314d4c00d351","_type":"navItem","title":"Cuboids","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"cuboids"}}}},{"_key":"8e17a6388d74","_type":"navItem","title":"Lines & Arrows","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"lines-and-arrows"}}}}],"title":"Shapes","url":null}],"title":"Platform","url":null},{"_key":"112867ca4d03","_type":"navDropdownMenu","items":[{"_key":"22699c7e06cb","_type":"navItem","items":null,"title":"Transportation & Navigation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"transportation-navigation"}}}},{"_key":"122ae5928d6d","_type":"navItem","items":null,"title":"Retail & E-Commerce","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"retail-ecommerce"}}}},{"_key":"7bb234b69fb0","_type":"navItem","items":null,"title":"Consumer & Media","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"consumer-media"}}}},{"_key":"33e6a886b39d","_type":"navItem","items":null,"title":"Biotech & Medtech","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"biotech-medtech"}}}},{"_key":"d095b2619c4e","_type":"navItem","items":null,"title":"Robotics & Manufacturing","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"robotics-and-manufacturing"}}}},{"_key":"2c4b82a94d79","_type":"navItem","items":null,"title":"Food & Agriculture","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"training-data-food-agriculture"}}}}],"title":"Industries","url":null},{"_key":"c47e8763a906","_type":"navDropdownMenu","items":[{"_key":"1d563df30b3f","_type":"navItem","items":null,"title":"Quality","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"quality-training-data"}}}},{"_key":"041725f35d96","_type":"navItem","items":null,"title":"Security","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"security-and-trust"}}}},{"_key":"fd64ede25798","_type":"navItem","items":null,"title":"Ethical AI","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-impact"}}}},{"_key":"398dcbb1c95d","_type":"navItem","items":null,"title":"Compare","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"compare"}}}},{"_key":"93bdfdd87879","_type":"navItem","items":null,"title":"Partners","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"partners"}}}}],"title":"Why Sama","url":null},{"_key":"1d38bf63df54","_type":"navDropdownMenu","items":[{"_key":"be81659b38a5","_type":"navItem","items":null,"title":"API Documentation","url":{"_type":"link","externalUrl":"https://docs.sama.com/reference/overview","internalLink":null}},{"_key":"2cec80e94962","_type":"navItem","items":null,"title":"Blog","url":{"_type":"link","internalLink":null,"internalLink_custom":"/blog"}},{"_key":"09e284fcb1d3","_type":"navItem","items":null,"title":"Events","url":{"_type":"link","internalLink":null,"internalLink_custom":"/events"}}],"title":"Resources","url":null},{"_key":"dbee93713c19","_type":"navDropdownMenu","items":[{"_key":"12d594a568bf","_type":"navItem","items":null,"title":"Our Story","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-story"}}}},{"_key":"ce36540a102d","_type":"navItem","items":null,"title":"Our Team","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-team"}}}},{"_key":"34fc328e8022","_type":"navItem","items":null,"title":"Careers","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"careers"}}}},{"_key":"c1fe2961020a","_type":"navItem","items":null,"title":"Contact","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"company-contact"}}}},{"_key":"ebd81873e538","_type":"navItem","items":null,"title":"Press","url":{"_type":"link","internalLink":null,"internalLink_custom":"/press"}}],"title":"Company","url":null}],"nav_cta":{"_type":"button","link":{"_type":"link","internalLink":{"_ref":"136788cb-06a6-4f27-b75b-07faf403bfa6","_type":"reference"}},"title":"Request a Demo","type":"secondary"}}},"data":{"author":{"_id":"ba12f1d5-b083-4eb7-929d-7e1639ef64c5","avatar":{"_type":"image","asset":{"_ref":"image-f1fd7fbcc4633299cdbedddba22cb44e24f17317-518x518-svg","_type":"reference"}},"bio":"Daniele is a Sales Operations and Engineering Senior Manager for Sama working with teams in EMEA and APAC.","firstLoad":[{"_createdAt":"2017-12-18T20:37:13Z","author":{"_id":"ba12f1d5-b083-4eb7-929d-7e1639ef64c5","avatar":{"_type":"image","asset":{"_ref":"image-f1fd7fbcc4633299cdbedddba22cb44e24f17317-518x518-svg","_type":"reference"}},"bio":"Daniele is a Sales Operations and Engineering Senior Manager for Sama working with teams in EMEA and APAC.","name":"Daniele Packard","slug":{"_type":"slug","current":"daniele-packard"}},"estimatedReadingTime":4,"featured_image":{"_type":"image","asset":{"_ref":"image-34e0689c14c9330dffeed72f7c6cbef59e2f9ad5-1500x1504-jpg","_type":"reference"}},"meta_description":"The best way for a computer to gain knowledge is to start by showing it exactly what it is you want it to do. For this, we use training data.","openGraphImage":null,"plaintextBody":"Historically, to get a computer to do something, you had to explicitly program it to execute a series of steps to accomplish your desired task. This would include everything from the most simple of arithmetic skills to manipulating objects in a complex digital world like what you see in video games.\n\nMachine learning is a fast-developing field of computer science that allows computers to complete exercises they have not been explicitly programmed to do such as, react to new or unforeseen situations and to then learn from this new input dataset. Not only does this create an entirely novel and potentially more efficient process to have computers engage with the world, but it has also opened the door to applications once thought to be too complex to be achieved with traditional computer science (hello, autonomous vehicles!).\n\nHow does it work? Training data.\n\nThe best way for a computer to gain knowledge is to start by showing it exactly what it is you want it to do. To do this, we use training data, the input the machine learning algorithm references and learns from. The computer will use this to look for patterns, extrapolate connections, create rules, and ultimately learn how to accomplish what it is you are trying to achieve.\n\nThe level of complexity and nuance needed in your training dataset depends on the desired goal. For example, a model that gives a binary yes/no to whether a dog is in an image will need input training images that are categorized as having a dog or not. Whereas, a model that needs to tell you not only whether a dog is in an image, but also show you where the animal is, will need training images where the location of the dog is specified.\n\nDifferent industries and applications have very different training data needs. A financial company trying to automate fraud detection will need appropriately categorized examples of where fraud did and did not happen. Meanwhile, a biomedical company looking to automate medical image analysis will need a doctor to label images (although it has been shown that for certain applications, pigeons and machine learning can help medical image analysis!).\n\nAs a user of digital products you are creating training data all the time, often without even realizing it. When you tell your fitness app your preferences you are contributing to a machine learning model. When, in your inbox, you flag certain messages as spam, you are creating training data for your spam filter algorithm.\n\nThe need for high quality data training sets is ubiquitously recognized and the counterproductive effects of bad data introduced to your model can be succinctly summarized with “garbage in, garbage out”. Essentially meaning that less than stellar training data, which inaccurately represents what you want your model to achieve, will yield an equally poorly performing model.\n\nYour training data also needs to be diverse enough to meet all the potential scenarios your model will or may encounter in order to avoid creating biasses. For example, a model created to process the age of a person using training data composed of only images of adults and their respective ages will be clueless when presented with the image of a child. Biases can cause a benign oversight or cause errors that are dangerous or even socially controversial.\n\nUltimately, the need for training data is growing in parallel with the applications of machine learning. While some are researching ways to minimize the need for training data or generate it digitally, there is growing evidence and research validating how important high volumes of training data can be. And though the degree to which training data will be essential to the future of AI is up for debate, it will surely continue to play an important role in machine learning.\n\n*There are various types of machine learning. For the purpose of this blog article, we are discussing supervised machine learning.","seo_title":"What is Training Data?","slug":{"_type":"slug","current":"what-is-training-data"},"tags":[{"_key":"4Phssued","label":"Training Data","value":"Training Data"}],"title":"What is Training Data?"},{"_createdAt":"2017-03-21T20:31:18Z","author":{"_id":"ba12f1d5-b083-4eb7-929d-7e1639ef64c5","avatar":{"_type":"image","asset":{"_ref":"image-f1fd7fbcc4633299cdbedddba22cb44e24f17317-518x518-svg","_type":"reference"}},"bio":"Daniele is a Sales Operations and Engineering Senior Manager for Sama working with teams in EMEA and APAC.","name":"Daniele Packard","slug":{"_type":"slug","current":"daniele-packard"}},"estimatedReadingTime":4,"featured_image":{"_type":"image","asset":{"_ref":"image-e7af72154b4cdac45f8526a3934f9ac612e23d37-513x321-jpg","_type":"reference"}},"meta_description":"3 Computer Vision Applications You Haven't Heard Of... Yet","openGraphImage":null,"plaintextBody":"From the looming reality of fully autonomous vehicles to a farmer in Japan using TensorFlow to sort cucumbers, computer vision machine learning is becoming an increasingly accessible and ubiquitous phenomenon. As a service provider in this space, Sama has a unique view into the breadth of computer vision applications. While certain applications of machine learning are prevalent in mainstream media (e.g. autonomous vehicles), there are equally interesting and lesser-known applications that are similarly revolutionary:\n\n\n\n1. Environmental\n\nSatellites orbiting the earth have been collecting comprehensive image data sets of the globe for decades. With recent advancement in computer vision, these images can be efficiently and automatically combed for valuable information. By applying deep learning models to sets of satellite imagery, companies like Orbital Insight can extract data on global surface water levels, informing communities, planners, and policymakers in making critical decisions about water resources.\n\n\n\nFigure 1 San Luis Reservoir. Left: Raw image. Middle: Landsat 8 water mask. Right: Orbital insight water mask. Orbital Insights, 2015\n\n\n2. Biomedical\n\nImage analysis in the medical field is a time-consuming process; using computer vision machine learning to automate portions of this analysis could help make the process more efficient and less costly for the general public. A bottleneck to progress in this field has been the lack of training data, which requires specialists to create (though there’s evidence that specialists can be substituted by pigeons!) and the data is typically confidential. The availability of large datasets with diagnostic labels, such as the Alzheimer’s Disease Neuroimaging Initiative (ADNI), has paved the way for new applications, using computer vision machine learning to provide early diagnosis of Alzheimer’s disease.\n\n\n3.Agricultural\n\nThe advancement of drone and computer vision technology has both lowered the cost of gathering huge sets of aerial imagery, and also increased our ability to intelligently extract information from that imagery. These technologies together can help farmers identify crop diseases or predict crop yields, automating a process where the alternative was manual inspection. In collaboration with Paul Allen towards his Great Elephant Census project, Sama facilitated the creation of a computer vision machine learning model used to track and count elephants as a part of anti-poaching efforts.\n\n\n\nElephant Sanctuary in Kenya, Sama, 2016\n\nUltimately applications of computer vision machine learning are limited only by human imagination. We look forward to seeing what applications this evolving technology will create, and are thrilled to count ourselves as part of this thriving community.\n\nIf you want to learn more about the future of practical computer vision, please join us at the Embedded Vision Summit, being held in Santa Clara from May 1-3. It’s the preeminent event for anyone adding computer vision capabilities to their products. We’ll be participating in the Vision Technology Showcase and invite you to stop by our booth.\n\nThe event is designed to inspire you to use vision technology in new ways and to empower you with the practical know-how you need to integrate vision capabilities into your products. Over three days and four tracks, you’ll meet innovators, luminaries, and colleagues in this fast-growing field.\n\nSama Sales team at Embedded Vision Summit, 2016","seo_title":"3 Computer Vision Applications You Haven't Heard Of...Yet","slug":{"_type":"slug","current":"3-computer-vision-applications-you-havent-heard-of-yet"},"tags":[{"_key":"zGqHljfi","label":"AI","value":"AI"},{"_key":"QcKBgjbl","label":"Events","value":"Events"},{"_key":"mpmDlNYK","label":"Computer Vision","value":"Computer Vision"}],"title":"3 Computer Vision Applications You Haven't Heard Of...Yet"}],"morePosts":[],"name":"Daniele Packard","slug":{"_type":"slug","current":"daniele-packard"}},"pageConfig":{"title":"Sama Blog | Training Data, AI and Impact Sourcing Insights","description":"From machine learning to training data strategy, the Sama blog covers research, news and other AI trends from thought leaders across the globe."}}},"__N_SSG":true}