{"pageProps":{"config":{"footerNav":{"items":[{"_key":"f255606f8f25","_type":"navDropdownMenu","items":[{"_key":"76389ad94cbb","_type":"navItem","title":"Autonomous Transportation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"training-data-for-autonomous-driving"}}}},{"_key":"5f64a8d6a69d","_type":"navItem","title":"E-Commerce","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"training-data-for-ecommerce"}}}},{"_key":"f10e54ae04d0","_type":"navItem","title":"AR/VR","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"training-data-for-ar-vr"}}}},{"_key":"fd729b522a77","_type":"navItem","title":"Data Quality","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"data-quality"}}}}],"title":"Guides","url":null},{"_key":"681ef7d8763a","_type":"navDropdownMenu","items":[{"_key":"6238a422b667","_type":"navItem","title":"Our Story","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-story"}}}},{"_key":"258985d6d46b","_type":"navItem","title":"Our Team","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-team"}}}},{"_key":"e0a76077324a","_type":"navItem","title":"Our Mission","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"mission-vision-values"}}}},{"_key":"239e49661b0d","_type":"navItem","title":"Careers","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"careers"}}}},{"_key":"e005a740cd80","_type":"navItem","title":"Contact","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"company-contact"}}}}],"title":"Company","url":null}]},"logo":{"asset":{"_createdAt":"2021-10-29T18:38:04Z","_id":"image-e20f8cc53e5f74df10ae9a822edb7ec2c4d00f02-2380x636-svg","_rev":"yuZxWYwFNB6KJB4TM9NtaY","_type":"sanity.imageAsset","_updatedAt":"2021-10-29T18:38:04Z","assetId":"e20f8cc53e5f74df10ae9a822edb7ec2c4d00f02","extension":"svg","metadata":{"_type":"sanity.imageMetadata","dimensions":{"_type":"sanity.imageDimensions","aspectRatio":3.742138364779874,"height":636,"width":2380},"hasAlpha":true,"isOpaque":false,"lqip":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAYAAABFA8wzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAr0lEQVQYlU3QyUoDQBAE0HeIEjeixAVyESRI3BNFJSZxAU/+/wdJQSEehu6Zqa6uKnjBGz7xgTuc4gAj7LWe4LD9cc8Y+9jBUed84QGrEt/gEleYY9Ylr3jGU/tV77fFLirId0nWBYYgoACi+r3D6YPN0vwFm4VxmNlgfkK4qcLUZdVMcdHB+75FzWPfzzCpxXNcFxuOP2uxnhNLASaX5LjbnJJf6jYG2PpXh812/AvSEQ+GGZqgYgAAAABJRU5ErkJggg==","palette":{"_type":"sanity.imagePalette","darkMuted":{"_type":"sanity.imagePaletteSwatch","background":"#040404","foreground":"#fff","population":100.29,"title":"#fff"},"darkVibrant":{"_type":"sanity.imagePaletteSwatch","background":"#424242","foreground":"#fff","population":0,"title":"#fff"},"dominant":{"_type":"sanity.imagePaletteSwatch","background":"#040404","foreground":"#fff","population":100.29,"title":"#fff"},"lightMuted":{"_type":"sanity.imagePaletteSwatch","background":"#4c4c4c","foreground":"#fff","population":0,"title":"#fff"},"lightVibrant":{"_type":"sanity.imagePaletteSwatch","background":"#bcbcbc","foreground":"#000","population":0,"title":"#fff"},"muted":{"_type":"sanity.imagePaletteSwatch","background":"#4c4c4c","foreground":"#fff","population":0,"title":"#fff"},"vibrant":{"_type":"sanity.imagePaletteSwatch","background":"#7f7f7f","foreground":"#fff","population":0,"title":"#fff"}}},"mimeType":"image/svg+xml","originalFilename":"image.svg","path":"images/76e3r62u/production/e20f8cc53e5f74df10ae9a822edb7ec2c4d00f02-2380x636.svg","sha1hash":"ae6a56857a230101a883a9b93974923879775bc9","size":2009,"uploadId":"mtOtmqAQnCEIG5cEqXZ1YAOCuqHJ4X3g","url":"https://cdn.sanity.io/images/76e3r62u/production/e20f8cc53e5f74df10ae9a822edb7ec2c4d00f02-2380x636.svg"}},"mainNav":{"items":[{"_key":"58c18e9aa9ea","_type":"navDropdownMenu","items":[{"_key":"b5b5b8bee78b","_type":"navCat","items":[{"_key":"0e80156a2f1a","_type":"navItem","title":"How it Works","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"how-it-works"}}}},{"_key":"40bacee029b4","_type":"navItem","title":"Video Annotation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"video-annotation"}}}},{"_key":"32650ef07503","_type":"navItem","title":"Image Annotation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"image-annotation"}}}},{"_key":"fe9137cd0167","_type":"navItem","title":"3D & LiDAR Annotation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"3d-lidar"}}}},{"_key":"d9a1316d400a","_type":"navItem","title":"Natural Language Processing","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"natural-language-processing"}}}},{"_key":"ac12c7c5d70a","_type":"navItem","title":"Data Curation (Beta)","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"data-curation"}}}}],"title":"Platform","url":null},{"_key":"37ff4fa913bd","_type":"navCat","items":[{"_key":"6026b1a9314e","_type":"navItem","title":"Semantic Segmentation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"semantic-segmentation"}}}},{"_key":"f4611b19b406","_type":"navItem","title":"Polygons","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"polygons"}}}},{"_key":"5155d874d6c8","_type":"navItem","title":"Bounding Boxes","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"bounding-boxes"}}}},{"_key":"9ef3c1e21e74","_type":"navItem","title":"Key Points","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"key-points"}}}},{"_key":"314d4c00d351","_type":"navItem","title":"Cuboids","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"cuboids"}}}},{"_key":"8e17a6388d74","_type":"navItem","title":"Lines & Arrows","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"lines-and-arrows"}}}}],"title":"Shapes","url":null}],"title":"Platform","url":null},{"_key":"112867ca4d03","_type":"navDropdownMenu","items":[{"_key":"22699c7e06cb","_type":"navItem","items":null,"title":"Transportation & Navigation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"transportation-navigation"}}}},{"_key":"122ae5928d6d","_type":"navItem","items":null,"title":"Retail & E-Commerce","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"retail-ecommerce"}}}},{"_key":"7bb234b69fb0","_type":"navItem","items":null,"title":"Consumer & Media","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"consumer-media"}}}},{"_key":"33e6a886b39d","_type":"navItem","items":null,"title":"Biotech & Medtech","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"biotech-medtech"}}}},{"_key":"d095b2619c4e","_type":"navItem","items":null,"title":"Robotics & Manufacturing","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"robotics-and-manufacturing"}}}},{"_key":"2c4b82a94d79","_type":"navItem","items":null,"title":"Food & Agriculture","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"training-data-food-agriculture"}}}}],"title":"Industries","url":null},{"_key":"c47e8763a906","_type":"navDropdownMenu","items":[{"_key":"1d563df30b3f","_type":"navItem","items":null,"title":"Quality","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"quality-training-data"}}}},{"_key":"041725f35d96","_type":"navItem","items":null,"title":"Security","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"security-and-trust"}}}},{"_key":"fd64ede25798","_type":"navItem","items":null,"title":"Ethical AI","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-impact"}}}},{"_key":"398dcbb1c95d","_type":"navItem","items":null,"title":"Compare","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"compare"}}}},{"_key":"93bdfdd87879","_type":"navItem","items":null,"title":"Partners","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"partners"}}}}],"title":"Why Sama","url":null},{"_key":"1d38bf63df54","_type":"navDropdownMenu","items":[{"_key":"be81659b38a5","_type":"navItem","items":null,"title":"API Documentation","url":{"_type":"link","externalUrl":"https://docs.sama.com/reference/overview","internalLink":null}},{"_key":"2cec80e94962","_type":"navItem","items":null,"title":"Blog","url":{"_type":"link","internalLink":null,"internalLink_custom":"/blog"}},{"_key":"09e284fcb1d3","_type":"navItem","items":null,"title":"Events","url":{"_type":"link","internalLink":null,"internalLink_custom":"/events"}}],"title":"Resources","url":null},{"_key":"dbee93713c19","_type":"navDropdownMenu","items":[{"_key":"12d594a568bf","_type":"navItem","items":null,"title":"Our Story","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-story"}}}},{"_key":"ce36540a102d","_type":"navItem","items":null,"title":"Our Team","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-team"}}}},{"_key":"34fc328e8022","_type":"navItem","items":null,"title":"Careers","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"careers"}}}},{"_key":"c1fe2961020a","_type":"navItem","items":null,"title":"Contact","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"company-contact"}}}},{"_key":"ebd81873e538","_type":"navItem","items":null,"title":"Press","url":{"_type":"link","internalLink":null,"internalLink_custom":"/press"}}],"title":"Company","url":null}],"nav_cta":{"_type":"button","link":{"_type":"link","internalLink":{"_ref":"136788cb-06a6-4f27-b75b-07faf403bfa6","_type":"reference"}},"title":"Request a Demo","type":"secondary"}},"title":"Sama"},"data":{"author":{"_id":"10ead718-57e1-41a8-b846-da3c81cc323a","avatar":{"_type":"image","asset":{"_ref":"image-a4c79da81bb1e23ce10fba84ea2cba5efe67a2a5-200x200-webp","_type":"reference"}},"bio":"Currently a Director of Product Management at Sama, Saul is passionate about the intersection of technology and social impact. He manages Sama’s data labelling products to ensure high quality training data efficiently and reliably reaches our customers. Experienced in both product and professional services, Saul is a proven leader who takes a data driven approach to expanding Sama’s capabilities and features. When not at work, you can usually find Saul enjoying the outdoors and spending time with his family.","firstLoad":[{"_createdAt":"2021-07-29T17:14:55Z","author":{"_id":"10ead718-57e1-41a8-b846-da3c81cc323a","avatar":{"_type":"image","asset":{"_ref":"image-a4c79da81bb1e23ce10fba84ea2cba5efe67a2a5-200x200-webp","_type":"reference"}},"bio":"Currently a Director of Product Management at Sama, Saul is passionate about the intersection of technology and social impact. He manages Sama’s data labelling products to ensure high quality training data efficiently and reliably reaches our customers. Experienced in both product and professional services, Saul is a proven leader who takes a data driven approach to expanding Sama’s capabilities and features. When not at work, you can usually find Saul enjoying the outdoors and spending time with his family.","name":"Saul Miller","slug":{"_type":"slug","current":"saul-miller"}},"estimatedReadingTime":7,"featured_image":{"_type":"image","asset":{"_ref":"image-65b7fac1b60586a0a7b9ff75006684e2c2467f1e-1800x900-png","_type":"reference"}},"plaintextBody":"Your machine learning model is only as good as the data it’s trained on. And with 80% of AI project time being spent training the large volume of data necessary to train a model, efficiency improvements early on in the process are sure to have compounding effects.\n\nAt Sama, we have a dedicated Machine Learning team working at the forefront of AI research to identify optimization opportunities just like this, so we can develop advanced annotation tools to smooth the path to production for our clients. One of the papers the team presented at last year’s CVPR—Human-Centric Efficiency Improvements in Image Annotation for Autonomous Driving—shared an approach to speeding up polygonal instance segmentation using ML.\n\nToday, this technology has been incorporated into our platform to make our clients’ labeling process more efficient.\n\nWe call it ML Assisted Annotation powered by our MICROMODEL technology, and it’s already helping clients predictably get higher quality training data in half the time.\n\nRead on for an overview of ML Assisted Annotation powered by MICROMODEL technology how it can help you develop models that are more scalable, robust and accurate – and can be brought into production more quickly.\n\nWhat is ML Assisted Annotation powered by MICROMODEL technology?\n\n\nML Assisted Annotation (MAA) powered by MICROMODEL technology is an architecture that allows Sama to expedite the labeling process by drawing from a library of models trained on specific use cases. MAA can be used to generate high-quality pre-labeled annotations, which annotators validate to help them continuously improve over time.\n\nThis powerful combination of skilled annotators and an AI-powered platform allows us to deliver a high standard of label quality to our customers every time, along with efficiency improvements and quicker time to market.\n\nHow it works\n\nIn order to understand how MAA works, we first need to discuss the DEXTR model. DEXTR, or “Deep Extreme Cut,” is a publicly available object segmentation model for images and videos. \n\n\n\nWe’ve outlined the DEXTR model and our approach in detail in this post.\n\n\n\nMany ML methods like DEXTR have been suggested to speed up the process of instance segmentation, but these are not typically tested in a high-scale production environment, nor are ML outputs easily edited by human annotators. This makes it difficult to confidently reach the label quality standards required to run a model in production.\n\nMAA combines the well-known DEXTR approach with a raster-to-polygon algorithm to make results easily editable by a human in the loop. We’ve found that this approach—which pairs skilled annotators with ML-powered automation—significantly increases labeling efficiency and quality.\n\nLet’s see what that looks like in practice, using an example from the Autonomous Vehicle industry.\n\nMachine-Assisted Polygon Annotation\n\n\n\nWhen an annotator logs into the Sama annotation platform, they are presented with this workspace. In this example, the workspace is customized to allow the annotator to draw instance segmentation polygons around each of these vehicles:\n\n\n\nYou’ll notice that there are several vehicles in this image. In a manual context, it could take a human several hours to deliver high-quality annotations of every single vehicle:\n\nWhat the manual annotation process would look like (sped up significantly): several clicks are required to draw a polygon around each of the vehicles.\n\n\n\nThis process is significantly accelerated with Machine-Assisted Polygon Annotation.\n\nThe model allows the annotator to use a crosshair tool to identify only four extreme points: left, right, top and bottom boundaries. These four clicks are the only inputs needed to create a heat map that is then sent to the inference server, returning an accurate prediction of a raster mask.\n\n\n\nWith Machine-Assisted Polygon Annotation, annotators only need to perform four clicks to produce an accurate raster mask prediction.\n\n\n\nMachine-Assisted Polygon Editing\n\n\n\nA polygon prediction can then be further refined by an annotator by switching into editing mode. This enables annotators to label precisely and ensure that high-quality requirements are met without compromise.\n\n\n\nIn this example, the raster mask prediction is edited by the annotator to ensure precise and high-quality labels.\n\n\n\nThis mode also enables annotators to use more than four extreme points in order to produce even more accurate predictions. A fifth user input point can easily be added, with the model immediately incorporating the new input to update its prediction.\n\nIf an ML model struggles to identify specific shapes, annotators can add a few more inference points to help result in a more accurate prediction, and then refine that prediction manually to ensure high-quality labels.\n\nResults from ML Assisted Annotation powered by MICROMODEL technology\n\n\nOur clients are already seeing impressive results from MAA powered by MICROMODEL technology:\n\nPredictably producing 94-98% IOU (Intersection over Union) accuracy\nBecause our models are pre-trained on specific use cases for better performance out of the gate, our clients are seeing a quicker time to accuracy.\n\n2-4x more efficient annotation process\nYou can clearly see above that using MAA over a more manual polygon labeling approach results in significant time savings. But it’s also an iterative process with a human annotator in the loop; modifications to the predictions get fed back into the training data pipeline to retrain the model, enabling it to perform better predictions over time.\n\n\nQuicker time to market\nThe end result for our clients is faster iterations and a quicker time to market. A more efficient annotation process results in more data returned quickly, and ultimately a significantly shorter path to production.\n\nWhat’s more: increasing the efficiency of this labor-intensive manual data annotation process reduces the barrier to entry for more ML teams... and not just those with large R&D budgets. Technology like this can also help democratize data labeling by driving down cost, so we can see even more deserving companies leverage AI to drive value for their business.\n\nSmall teams who are getting started with labeling may not have yet defined what type of annotations they need, or how much data they need to be successful. MAA can help them iterate more quickly, developing models in short increments rather than in large, cumbersome workstreams. The end result is a quicker time to value, and ultimately, to market — for organizations of all shapes and sizes.\n\nLearn more about ML Assisted Annotation powered by MICROMODEL technology by watching our recent webinar here, or reading more about it here.","slug":{"_type":"slug","current":"ml-assisted-annotation-micromodels"},"tags":[{"_key":"giPx682h","label":"Machine Learning","value":"Machine Learning"},{"_key":"JOgmW0AV","label":"Data Annotation","value":"Data Annotation"},{"_key":"45fExC0n","label":"Autonomous Transportation","value":"Autonomous Transportation"}],"title":"ML Assisted Annotation Powered by MicroModels"},{"_createdAt":"2021-06-08T14:17:40Z","author":{"_id":"10ead718-57e1-41a8-b846-da3c81cc323a","avatar":{"_type":"image","asset":{"_ref":"image-a4c79da81bb1e23ce10fba84ea2cba5efe67a2a5-200x200-webp","_type":"reference"}},"bio":"Currently a Director of Product Management at Sama, Saul is passionate about the intersection of technology and social impact. He manages Sama’s data labelling products to ensure high quality training data efficiently and reliably reaches our customers. Experienced in both product and professional services, Saul is a proven leader who takes a data driven approach to expanding Sama’s capabilities and features. When not at work, you can usually find Saul enjoying the outdoors and spending time with his family.","name":"Saul Miller","slug":{"_type":"slug","current":"saul-miller"}},"estimatedReadingTime":3,"featured_image":{"_type":"image","asset":{"_ref":"image-cb41c540ba989cd0258ef2f70cf6ce1bc99f2793-3334x1668-png","_type":"reference"}},"plaintextBody":"TLDR; After a decade of successful text annotation projects, we’re launching our ML-powered NLP Annotation Tool.\n\n\n\nIf you work in AI, you know just how hard Natural Language Processing (NLP) problems can be to solve. Though the study of NLP dates back to the 1950s, AI practitioners and researchers are still grappling with the many ambiguities and complexities of language.\n\nHumans intuitively know that words can have different meanings depending on context, and that they can acquire new meanings over time. But capturing all these nuances and incorporating them into an ML model is about as difficult as it sounds.\n\nFor every additional variable that must be accounted for in a model, there is an equal number of opportunities for NLP models to fail. Even a small margin of error can have huge consequences. A lack of varied perspectives or proper inputs can corrupt a data set, create bias, and have serious downstream consequences.\n\nThe only way to navigate this ambiguity is with large, high-quality data sets annotated by a diverse set of labelers.\n\nQuickly bring high-performing NLP models into production\n\nTraditional approaches to labeling Natural Language Processing data – especially using crowdsourced and self-service labeling platforms – often slow the path to production. Inexperienced labelers and the lack of a continuous feedback loop can result in poor quality data sets and time-consuming iteration cycles.\n\nWith Sama, you can get started quickly with self-service and scale over time, or work with our directly managed workforce of annotators trained on your specific needs and best practices for your industry. This bespoke approach enables us to deliver high-performing data sets for your projects, so you can analyze and draw insight from unstructured data for a multitude of NLP use cases – from product review analysis, to document summarization and understanding, to misinformation detection and much more.\n\n>> Learn more about how Sama can help make training data for NLP your competitive advantage\n\n\nOur ML-assisted labeling platform uses active learning to quickly share high precision predictions, automating away simple labels and freeing annotators to create more and higher quality labels. Built-in QA and human in the loop capabilities allow edge cases to be raised early in the process for quicker iteration cycles.\n\nThis powerful combination of skilled annotators and an AI-powered platform allows us to deliver a high standard of label quality to our customers every time, along with efficiency improvements and quicker time to market.\n\nLaunch your Natural Language Processing projects more quickly and efficiently\n\nThe field of Natural Language Processing has made significant progress in the last few years – but there’s plenty of distance still to go.\n\nWherever you want to go next with NLP, let Sama get you there faster.\n\n>> Learn more about how Sama can help make training data for NLP your competitive advantage","slug":{"_type":"slug","current":"natural-language-processing-annotation"},"tags":[{"_key":"WOb8dgoC","label":"NLP","value":"NLP"}],"title":"Quickly Bring Your NLP Models into Production with AI-Powered Annotation"},{"_createdAt":"2020-11-23T16:48:22Z","author":{"_id":"10ead718-57e1-41a8-b846-da3c81cc323a","avatar":{"_type":"image","asset":{"_ref":"image-a4c79da81bb1e23ce10fba84ea2cba5efe67a2a5-200x200-webp","_type":"reference"}},"bio":"Currently a Director of Product Management at Sama, Saul is passionate about the intersection of technology and social impact. He manages Sama’s data labelling products to ensure high quality training data efficiently and reliably reaches our customers. Experienced in both product and professional services, Saul is a proven leader who takes a data driven approach to expanding Sama’s capabilities and features. When not at work, you can usually find Saul enjoying the outdoors and spending time with his family.","name":"Saul Miller","slug":{"_type":"slug","current":"saul-miller"}},"estimatedReadingTime":3,"featured_image":{"_type":"image","asset":{"_ref":"image-0ea3313b4d00bb103e8441964eeb3968dfee2947-1144x644-png","_type":"reference"}},"plaintextBody":"As a leader in high-quality training data, Sama supports clients across various use cases and applications. The ability to identify specific keypoint landmarks and track their relationship to one another is unlocking some of the most interesting developments in computer vision technology. This includes motion tracking like human pose identification for virtual fitness trainers or sports analytics. It also includes facial landmarks for emotion analysis, facial verification security, or driver alertness detection. It could also include hand gesture control for AR/VR or sign language transcription.\n\nWe are thrilled to announce our support for custom keypoint shapes in our training data platform trusted by the world's leading AI teams, for vector image and video annotation. While Sama has long supported other vector shapes like bounding boxes, polygons, and cuboids, these keypoint use cases require custom shapes that have a predefined number and order of points. Sama can now be configured to support skeletons, hands, eyelids or any other complex custom shape. Each keypoint can have its own label, color, and connection to other points. Multiple keypoint shapes are supported on the same annotation project.\n\n\nOptimizing for Quality and Efficiency\n\nThis new capability optimizes quality and efficiency in producing ground truth training data for our clients. Our expert annotators have a facilitated drawing experience where the shape builds itself as they annotate each point. The correct label for each point is inferred from the order that it is placed so no extra time is spent assigning labels to each point. We see quality improvement from visualizing the annotations as a cohesive connected shape instead of as free standing individual points. The custom keypoint shape also always has the same number and order of points—this means that no points could ever be omitted or mislabeled. In addition to the quality benefits, our A/B testing showed an 27% decrease in annotation time on a skeleton image annotation workflow over individual points.\n\nCompleted annotation data is returned to our clients in a structured delivery format that contains information about each point, its relative order in the array and its connection to other points.\n\nIf you're currently working on a computer vision algorithm that requires high quality keypoint annotations on images or videos, make sure to read more on our platform page or get in touch with an expert to discuss your training data needs.","slug":{"_type":"slug","current":"custom-keypoint-shapes"},"tags":[{"_key":"T7HkzkJx","label":"Product","value":"Product"},{"_key":"j9XlG6o5","label":"Keypoints","value":"Keypoints"},{"_key":"o2UoWoaC","label":"Video Annotation","value":"Video Annotation"},{"_key":"3GbpMBcq","label":"Vector Annotation","value":"Vector Annotation"}],"title":"Custom Keypoint Shapes for Vector Image & Video Annotation"}],"morePosts":[],"name":"Saul Miller","slug":{"_type":"slug","current":"saul-miller"}}}},"__N_SSG":true}