{"pageProps":{"config":{"footerNav":{"items":[{"_key":"f255606f8f25","_type":"navDropdownMenu","items":[{"_key":"76389ad94cbb","_type":"navItem","title":"Autonomous Transportation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"training-data-for-autonomous-driving"}}}},{"_key":"5f64a8d6a69d","_type":"navItem","title":"E-Commerce","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"training-data-for-ecommerce"}}}},{"_key":"f10e54ae04d0","_type":"navItem","title":"AR/VR","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"training-data-for-ar-vr"}}}},{"_key":"fd729b522a77","_type":"navItem","title":"Data Quality","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"data-quality"}}}}],"title":"Guides","url":null},{"_key":"681ef7d8763a","_type":"navDropdownMenu","items":[{"_key":"6238a422b667","_type":"navItem","title":"Our Story","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-story"}}}},{"_key":"258985d6d46b","_type":"navItem","title":"Our Team","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-team"}}}},{"_key":"e0a76077324a","_type":"navItem","title":"Our Mission","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"mission-vision-values"}}}},{"_key":"239e49661b0d","_type":"navItem","title":"Careers","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"careers"}}}},{"_key":"e005a740cd80","_type":"navItem","title":"Contact","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"company-contact"}}}}],"title":"Company","url":null}]},"logo":{"asset":{"_createdAt":"2021-12-09T21:42:35Z","_id":"image-4f4e2f86a8fad952c02dffffd7008aa35f83c850-2380x636-svg","_rev":"7Z7VDk3xHzg51hvomGzc99","_type":"sanity.imageAsset","_updatedAt":"2021-12-09T21:42:35Z","assetId":"4f4e2f86a8fad952c02dffffd7008aa35f83c850","extension":"svg","metadata":{"_type":"sanity.imageMetadata","blurHash":"D009jvfQfQfQfQfQfQfQfQfQ","dimensions":{"_type":"sanity.imageDimensions","aspectRatio":3.742138364779874,"height":636,"width":2380},"hasAlpha":true,"isOpaque":false,"lqip":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAYAAABFA8wzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAr0lEQVQYlU3QyUoDQBAE0HeIEjeixAVyESRI3BNFJSZxAU/+/wdJQSEehu6Zqa6uKnjBGz7xgTuc4gAj7LWe4LD9cc8Y+9jBUed84QGrEt/gEleYY9Ylr3jGU/tV77fFLirId0nWBYYgoACi+r3D6YPN0vwFm4VxmNlgfkK4qcLUZdVMcdHB+75FzWPfzzCpxXNcFxuOP2uxnhNLASaX5LjbnJJf6jYG2PpXh812/AvSEQ+GGZqgYgAAAABJRU5ErkJggg==","palette":{"_type":"sanity.imagePalette","darkMuted":{"_type":"sanity.imagePaletteSwatch","background":"#040404","foreground":"#fff","population":100.29,"title":"#fff"},"darkVibrant":{"_type":"sanity.imagePaletteSwatch","background":"#424242","foreground":"#fff","population":0,"title":"#fff"},"dominant":{"_type":"sanity.imagePaletteSwatch","background":"#040404","foreground":"#fff","population":100.29,"title":"#fff"},"lightMuted":{"_type":"sanity.imagePaletteSwatch","background":"#4c4c4c","foreground":"#fff","population":0,"title":"#fff"},"lightVibrant":{"_type":"sanity.imagePaletteSwatch","background":"#bcbcbc","foreground":"#000","population":0,"title":"#fff"},"muted":{"_type":"sanity.imagePaletteSwatch","background":"#4c4c4c","foreground":"#fff","population":0,"title":"#fff"},"vibrant":{"_type":"sanity.imagePaletteSwatch","background":"#7f7f7f","foreground":"#fff","population":0,"title":"#fff"}}},"mimeType":"image/svg+xml","originalFilename":"e20f8cc53e5f74df10ae9a822edb7ec2c4d00f02-2380x636.svg","path":"images/76e3r62u/production/4f4e2f86a8fad952c02dffffd7008aa35f83c850-2380x636.svg","sha1hash":"4f4e2f86a8fad952c02dffffd7008aa35f83c850","size":2009,"uploadId":"jTUF9DIFqAwpLJ0GcI9bRqb17D69QQlN","url":"https://cdn.sanity.io/images/76e3r62u/production/4f4e2f86a8fad952c02dffffd7008aa35f83c850-2380x636.svg"}},"mainNav":{"items":[{"_key":"58c18e9aa9ea","_type":"navDropdownMenu","items":[{"_key":"b5b5b8bee78b","_type":"navCat","items":[{"_key":"0e80156a2f1a","_type":"navItem","title":"How it Works","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"how-it-works"}}}},{"_key":"40bacee029b4","_type":"navItem","title":"Video Annotation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"video-annotation"}}}},{"_key":"32650ef07503","_type":"navItem","title":"Image Annotation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"image-annotation"}}}},{"_key":"fe9137cd0167","_type":"navItem","title":"3D & LiDAR Annotation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"3d-lidar"}}}},{"_key":"d9a1316d400a","_type":"navItem","title":"Natural Language Processing","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"natural-language-processing"}}}},{"_key":"ac12c7c5d70a","_type":"navItem","title":"Data Curation (Beta)","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"data-curation"}}}}],"title":"Platform","url":null},{"_key":"37ff4fa913bd","_type":"navCat","items":[{"_key":"6026b1a9314e","_type":"navItem","title":"Semantic Segmentation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"semantic-segmentation"}}}},{"_key":"f4611b19b406","_type":"navItem","title":"Polygons","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"polygons"}}}},{"_key":"5155d874d6c8","_type":"navItem","title":"Bounding Boxes","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"bounding-boxes"}}}},{"_key":"9ef3c1e21e74","_type":"navItem","title":"Key Points","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"key-points"}}}},{"_key":"314d4c00d351","_type":"navItem","title":"Cuboids","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"cuboids"}}}},{"_key":"8e17a6388d74","_type":"navItem","title":"Lines & Arrows","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"lines-and-arrows"}}}}],"title":"Shapes","url":null}],"title":"Platform","url":null},{"_key":"112867ca4d03","_type":"navDropdownMenu","items":[{"_key":"22699c7e06cb","_type":"navItem","items":null,"title":"Transportation & Navigation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"transportation-navigation"}}}},{"_key":"122ae5928d6d","_type":"navItem","items":null,"title":"Retail & E-Commerce","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"retail-ecommerce"}}}},{"_key":"7bb234b69fb0","_type":"navItem","items":null,"title":"Consumer & Media","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"consumer-media"}}}},{"_key":"33e6a886b39d","_type":"navItem","items":null,"title":"Biotech & Medtech","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"biotech-medtech"}}}},{"_key":"d095b2619c4e","_type":"navItem","items":null,"title":"Robotics & Manufacturing","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"robotics-and-manufacturing"}}}},{"_key":"2c4b82a94d79","_type":"navItem","items":null,"title":"Food & Agriculture","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"training-data-food-agriculture"}}}}],"title":"Industries","url":null},{"_key":"c47e8763a906","_type":"navDropdownMenu","items":[{"_key":"1d563df30b3f","_type":"navItem","items":null,"title":"Quality","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"quality-training-data"}}}},{"_key":"041725f35d96","_type":"navItem","items":null,"title":"Security","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"security-and-trust"}}}},{"_key":"fd64ede25798","_type":"navItem","items":null,"title":"Ethical AI","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-impact"}}}},{"_key":"398dcbb1c95d","_type":"navItem","items":null,"title":"Compare","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"compare"}}}},{"_key":"93bdfdd87879","_type":"navItem","items":null,"title":"Partners","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"partners"}}}}],"title":"Why Sama","url":null},{"_key":"1d38bf63df54","_type":"navDropdownMenu","items":[{"_key":"be81659b38a5","_type":"navItem","items":null,"title":"API Documentation","url":{"_type":"link","externalUrl":"https://docs.sama.com/reference/overview","internalLink":null}},{"_key":"2cec80e94962","_type":"navItem","items":null,"title":"Blog","url":{"_type":"link","internalLink":null,"internalLink_custom":"/blog"}},{"_key":"09e284fcb1d3","_type":"navItem","items":null,"title":"Events","url":{"_type":"link","internalLink":null,"internalLink_custom":"/events"}}],"title":"Resources","url":null},{"_key":"dbee93713c19","_type":"navDropdownMenu","items":[{"_key":"12d594a568bf","_type":"navItem","items":null,"title":"Our Story","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-story"}}}},{"_key":"ce36540a102d","_type":"navItem","items":null,"title":"Our Team","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-team"}}}},{"_key":"34fc328e8022","_type":"navItem","items":null,"title":"Careers","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"careers"}}}},{"_key":"c1fe2961020a","_type":"navItem","items":null,"title":"Contact","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"company-contact"}}}},{"_key":"ebd81873e538","_type":"navItem","items":null,"title":"Press","url":{"_type":"link","internalLink":null,"internalLink_custom":"/press"}}],"title":"Company","url":null}],"nav_cta":{"_type":"button","link":{"_type":"link","internalLink":{"_ref":"136788cb-06a6-4f27-b75b-07faf403bfa6","_type":"reference"}},"title":"Request a Demo","type":"secondary"}}},"data":{"author":{"_id":"40a70383-c941-405c-ae5b-f0aba421ee53","avatar":{"_type":"image","asset":{"_ref":"image-f1fd7fbcc4633299cdbedddba22cb44e24f17317-518x518-svg","_type":"reference"}},"bio":"Rafael and Juan are both senior members of Sama R&D where they focus on Data Engineering and Data Science initiatives that help boost operational efficiency and achieve the highest quality.","firstLoad":[{"_createdAt":"2021-03-17T03:58:33Z","author":{"_id":"40a70383-c941-405c-ae5b-f0aba421ee53","avatar":{"_type":"image","asset":{"_ref":"image-f1fd7fbcc4633299cdbedddba22cb44e24f17317-518x518-svg","_type":"reference"}},"bio":"Rafael and Juan are both senior members of Sama R&D where they focus on Data Engineering and Data Science initiatives that help boost operational efficiency and achieve the highest quality.","name":"Rafael Alfaro & Juan Esquivel","slug":{"_type":"slug","current":"rafael-alfaro-and-juan-esquivel"}},"config":{"description":"In this series of three we’ll go into Experiment Driven Development and A/B Testing. EDD is fact-based development: based on evidence, not intuition.","openGraphImage":null,"title":"Part 3: A/B Testing with Python"},"estimatedReadingTime":6,"featured_image":{"_type":"image","asset":{"_ref":"image-bbf0e002b88fd9c3b2fcbd032f60f114bc93eed0-1980x990-png","_type":"reference"}},"plaintextBody":"We've previously explored the foundations of Experiment Driven Design and A/B Testing. Today we'll dig into A/B Testing with Python because analysis can be easily automated with existing open source python libraries. In this post we will explore their usage with an example. To orient the reader, we will state a few definitions to anchor the example:\n\nControl Group: current user interface.\nExperiment Group: rearranged point annotation button.\n\nH0: The mean of the annotation time for the control group is the same as the mean of the annotation time for the experiment group; there is no effect from rearranging the point annotation button.\n\nH1: The mean of the annotation time for the control group is different from the mean of the annotation time for the experiment group; there is an observable effect from rearranging the point annotation button.\n\nLet us assume that we ran an A/B Test feature experiment for two weeks. The UI modifications consisted of rearranging a button used in the process of drawing polygons around objects Let us assume these were recorded annotation times per image in minutes, for users of each variant (it can be represented as a python list):\n\nA. Control group (original arrangement):\n\nvariant_a = [150, 195, 120, 160, 97, 20, 100, 121, 250, 300, 80, 75, 100, 196, 147, 120, 100, 190, 57, 100, 157, 186, 91, 190, 210, 222, 192, 243, 99, 151]\n\n\n\nB. Experiment group (rearranged button):\n\nvariant_b = [120, 110, 96, 99, 87, 55, 43, 83, 200, 100, 125, 140, 75, 91, 141, 121, 250, 35, 94, 65, 85, 67, 93, 161, 35, 34, 111, 124, 85, 103]\n\n\n\n1. Run the t-test from the scipy.stats module of scipy (a mathematical, scientific and engineering library).\n\n\nimport scipy.stats as stats\n\nt, p = stats.ttest_ind(variant_a, variant_b, equal_var=False)\n\n\n\n2. Calculate the degrees of freedom according to Welch’s t-test definition which is the one implemented in stats.ttest_ind\n\n# For illustrative details see Wikipedia\n\n\ns1 = np.std(variant_a)\ns2 = np.std(variant_b)\nn1 = len(variant_a)\nn2 = len(variant_b)\n\ndf = np.floor(((((s1 ** 2) / n1) + ((s2 ** 2) / n2)) ** 2) /\n(((s1 ** 4) / ((n1 ** 2) * (n1 - 1))) + ((s2 ** 4) / ((n2 ** 2) * (n2 - 1)))))\n\n\n\n3. Now, using the same scipy.stats library, get the t-critical value for 95% or an alpha of 0.05 (1 - confidence level) from the t distribution’s ppf (percent point function) function and evaluate the t statistic from the previous step. If it falls in the range [-t-critical, t-critical] then H0 cannot be rejected, if it is outside, then we can reject H0 in favor of H1:\n\nalpha = 0.05\nt_critical_value = stats.t.ppf(1 - (alpha/2), df)\nnull_hypothesis = bool(t_critical_value >= t_value >= -t_critical_value)\n\n\n\n4. The confidence interval of variant_b (experiment) will help us visualize the difference between the two variants. If the mean of the control group doesn’t fall inside of this interval then the means of the two groups are significantly apart from each other, which suggests that the results are statistically significant.\n\ns = np.std(variant_b)\nx = np.mean(variant_b)\nn = len(variant_b)\nrho = (t_critical_value * s) / np.sqrt(n)\nconf_int = x - rho, x + rho\n\n\n\n\n\n5. Statistical power is the probability that the test correctly rejects the null hypothesis, in other words, the probability of a true positive result. This is only useful when the null hypothesis is rejected. A low value of power could be an indication that the sample size is not big enough yet to validate the results. To calculate the statistical power we use the class TTestIndPower from the module statsmodels.stats.power (https://www.statsmodels.org/stable/stats.html?highlight=power#module-statsmodels.stats.power) of the statsmodel (https://www.statsmodels.org/) library.\n\n\nfrom statsmodels.stats.power import TTestIndPower\n\n# Effect size based on Cohen’s d formula: https://en.wikipedia.org/wiki/Effect_size#Cohen's_d (https://en.wikipedia.org/wiki/Effect_size#Cohen's_d)\n\nx1 = np.mean(variant_a)\nx2 = np.mean(variant_b)\ns1 = np.std(variant_a)\ns2 = np.std(variant_b)\nn1 = len(variant_a)\nn2 = len(variant_b)\n\ns = np.sqrt((((n1 - 1) * (s1 ** 2)) + ((n2 - 1) * (s2 ** 2))) / (n1 + n2 - 2))\neffect = np.abs((x1 - x2) / s)\n\npower = TTestIndPower().power(effect, nobs1=n1, ratio=n2 / n1, df=(n1 + n2 - 2), alpha=alpha)\n\n\n\n6. Plot the sample distributions with confidence intervals as a visual aid using matplotlib library.\n\n\nimport matplotlib.pyplot as plt\n\n# Control\nfig, ax = plt.subplots(figsize=(12,6))\nxA = np.linspace(40, x1 + 3*s1, 100)\nyA = stats.norm(loc=x1, scale=s1).pdf(xA)\nax.plot(xA, yA, c='red', label='Variant A Distribution')\nax.axvline(x=x1, c='red', alpha=0.5, linestyle='--', label='Variant A')\n\n# Experimental\nxB = np.linspace(40, x2 + 3*s2, 100)\nyB = stats.norm(loc=x2, scale=s2).pdf(xB)\nax.plot(xB, yB, c='blue', label='Variant B Distribution')\nax.axvline(x=x2, c='blue', alpha=0.5, linestyle='--', label='Variant B')\n\n# Confidence interval\nax.axvline(conf_int[0], c='green', linestyle='--', alpha=0.5)\nax.axvline(conf_int[1], c='green', linestyle='--', alpha=0.5, label='Confidence Interval')\n\nplt.xlabel('Annotation Time')\nplt.ylabel('Percent of Tasks per Annotation Time')\nplt.title('Annotation Time Distributions')\nplt.legend()\nplt.show()\n\n\n\n","slug":{"_type":"slug","current":"experiment-driven-development-part-3"},"tags":[{"_key":"2iLUnerV","label":"Sama Engineering","value":"Sama Engineering"}],"title":"Part 3: A/B Testing with Python"},{"_createdAt":"2021-03-08T21:41:38Z","author":{"_id":"40a70383-c941-405c-ae5b-f0aba421ee53","avatar":{"_type":"image","asset":{"_ref":"image-f1fd7fbcc4633299cdbedddba22cb44e24f17317-518x518-svg","_type":"reference"}},"bio":"Rafael and Juan are both senior members of Sama R&D where they focus on Data Engineering and Data Science initiatives that help boost operational efficiency and achieve the highest quality.","name":"Rafael Alfaro & Juan Esquivel","slug":{"_type":"slug","current":"rafael-alfaro-and-juan-esquivel"}},"config":{"description":"In this series of three we’ll go into Experiment Driven Development and A/B Testing. EDD is fact-based development: based on evidence, not intuition.","openGraphImage":null,"title":"Part 2: A/B Testing"},"estimatedReadingTime":4,"featured_image":{"_type":"image","asset":{"_ref":"image-bbf0e002b88fd9c3b2fcbd032f60f114bc93eed0-1980x990-png","_type":"reference"}},"plaintextBody":"After last week's intro into Experiment Driven Development at Sama, we'll go further into A/B Testing today. A/B Testing is a randomized experiment method to compare how two populations behave in a controlled environment and determine whether the variation of some target metrics defined are significant or not, to determine that the experiment yields better results than the alternative.\n\nWe say that a baseline sample (variation A), which normally refers to some existing system, is compared against an experimental treatment (variation B). In software development, samples drawn from the two populations will be used to analyze the metrics associated with the usage of features. We generally want to make sure that any new feature has a positive impact: improved usability, lower duration to finish a process, etc. We should aim to have data to back up our claims that a feature has benefits, otherwise it would be fair to question why we want to deploy a new feature.\n\nOne way of evaluating an A/B experiment is through the use of a t-test which works well when we expect the distribution to be normal and it also allows us to not worry about the unknown standard deviation of our data. Note, however, that population distributions are not always expected to be normal, of course, and the t-test can be replaced by some other appropriate hypothesis test, depending on the distribution of the data, e.g. Kolmogovor-Smirnov. In our case, we want to determine if the means of the two data samples are significantly different from each other, with a given confidence level (90%, 95% and 99% are commonly used values).\n\nThe framework of the experiment revolves around the definition of a hypothesis for an A/B Test as follows:\n\nH0: The mean of the baseline metric is the same as the mean of the experiment metric; there is no effect from the treatment (variation) of the experiment, thus the two means belong to the same population.\nH1: The mean of the baseline metric is different from the mean of the experiment metric; there is an observable effect from the treatment (variation) of the experiment metric and the two means belong to different populations.\n\nWe then define the timeline for the feature/process experiment, run the experiment and collect the observations from the samples of the two variants. We should have a notion in terms of how long we want to run this to collect enough information (we will treat this as out of scope on this piece, however).\n\nIn order to perform the t-test evaluation, we need per sample sizes (N), means (X) and the standard deviations (s) to calculate the statistic t and the degrees of freedom (v). This is calculated as follows (using Welch’s t-test for independent variables with unequal variances and unequal sample sizes):\n\nOnce the statistic and degrees of freedom are calculated, along with an (1-confidence level), we can evaluate our hypothesis against the t-distribution table to determine whether or not the populations are different.\n\nIf our t statistic is less than the value from the table, given the degrees of freedom and the significance level, we can reject the null hypothesis as there is enough evidence to determine that sample means are from different populations. That would mean our new feature is really different from the control and we can release it, if the direction of the variation is in line with our objectives (e.g. lower means when we want to lower durations is good).\n\nThere are other more nuanced circumstances that we can address with a similar framework. For instance, we may want to test two variants of a new feature side by side. We may also want to use a slightly different statistical tool than a t-test, depending on what our interests are. What is important is the test-driven culture that should be fostered within organizations to have a data-drive approach to justify the release of new features.\n\nNext up: A/B Testing with Python.","slug":{"_type":"slug","current":"experiment-driven-development-part-2"},"tags":[{"_key":"FSfjH4D2","label":"Sama Engineering","value":"Sama Engineering"}],"title":"Part 2: A/B Testing"},{"_createdAt":"2021-03-02T05:05:17Z","author":{"_id":"40a70383-c941-405c-ae5b-f0aba421ee53","avatar":{"_type":"image","asset":{"_ref":"image-f1fd7fbcc4633299cdbedddba22cb44e24f17317-518x518-svg","_type":"reference"}},"bio":"Rafael and Juan are both senior members of Sama R&D where they focus on Data Engineering and Data Science initiatives that help boost operational efficiency and achieve the highest quality.","name":"Rafael Alfaro & Juan Esquivel","slug":{"_type":"slug","current":"rafael-alfaro-and-juan-esquivel"}},"config":{"description":"In this series of three we’ll go into Experiment Driven Development. EDD is fact-based development: based on evidence, not intuition.","openGraphImage":null,"title":"Part 1: Experiment Driven Development"},"estimatedReadingTime":3,"featured_image":{"_type":"image","asset":{"_ref":"image-bbf0e002b88fd9c3b2fcbd032f60f114bc93eed0-1980x990-png","_type":"reference"}},"plaintextBody":"In this series of three we’ll go into Experiment Driven Development and A/B testing. The opposite of developing features based on anecdotes heard in stories from the CEO’s next-door neighbor, EDD seeks proof and is iterative. EDD can be defined as fact-based development: development based on evidence gathered from the field, not intuition.\n\nIn EDD every new feature or process implemented is validated through a formal experiment design process, which looks to test a hypothesis that describes the status quo of the feature. Example hypotheses could range from \"Making a button bigger does not impact clicks\" all the way to \"Making a web app responsive does not increase visitation\" compared. In statistical terms, the base statement is referred to as the null hypothesis (H0), the status quo, and then an alternative hypothesis(H1) is proposed. The null hypothesis will usually state that the change introduced by the experiment will not affect the current behavior while the alternative supports that there is in fact a change.\n\nThe alternative hypothesis is a prediction of what is expected to happen before running the experiment. It can be a bold statement, not an open question and it should have three parts:\n\nThe variable (if we add/change/remove...): the change that the experiment will measure against the current state of the feature/process.\n\nThe desired result (then we expected to see...): what we expect to see after the change is introduced, a qualitative difference between the current state and new state.\n\nThe rationale behind the prediction (because we have seen that...): prior knowledge that has led you to come up with the current hypothesis (from prior observation).\n\nFor example, one can define the pair of hypotheses for a new registration form in a website as:\n\nH0: Changing the registration form from multiple to single page will not impact the current user registration rate.\n\nH1: Changing the registration from multiple to single page will increase the current user registration rate by 5% because we have previously seen that there is a 5% abandon rate on the multi page form format.\n\n\n\nEDD is based on A/B Testing, which is a randomized experiment method to compare two variants of a single variable. In this case, a baseline metric is compared thanks to the definition control (status quo) and treatment (new feature) groups in order to determine if the variation has a significant impact or not. Ideally, most decisions to release a feature would be based on the results given by A/B Tests. At Sama, we want to find viable ideas or fail fast. Instead of developing a monolithic solution and pushing a release, we iterate through experiments, evaluating how features perform and, most importantly, if and how customers use them.\n\nNext up: A/B Testing and A/B Testing with Python.","slug":{"_type":"slug","current":"experiment-driven-development-part-1"},"tags":[{"_key":"sZmqu6EC","label":"Sama Engineering","value":"Sama Engineering"}],"title":"Part 1: Experiment Driven Development"}],"morePosts":[],"name":"Rafael Alfaro & Juan Esquivel","slug":{"_type":"slug","current":"rafael-alfaro-and-juan-esquivel"}},"pageConfig":{"title":"Sama Blog | Training Data, AI and Impact Sourcing Insights","description":"From machine learning to training data strategy, the Sama blog covers research, news and other AI trends from thought leaders across the globe."}}},"__N_SSG":true}