<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="initial-scale=1.0, width=device-width, viewport-fit=cover"/><title>Sama - Make Training Data Your Competitive Advantage</title><meta name="next-head-count" content="3"/><link rel="preload" href="/_next/static/css/bd60e2be2420db639f1f.css" as="style"/><link rel="stylesheet" href="/_next/static/css/bd60e2be2420db639f1f.css" data-n-g=""/><link rel="preload" href="/_next/static/css/d95f2d9767a87b0a5b1a.css" as="style"/><link rel="stylesheet" href="/_next/static/css/d95f2d9767a87b0a5b1a.css" data-n-p=""/><link rel="preload" href="/_next/static/css/0d4bd6b9e4f2c8d7d433.css" as="style"/><link rel="stylesheet" href="/_next/static/css/0d4bd6b9e4f2c8d7d433.css"/><link rel="preload" href="/_next/static/css/3b03d00d40d80e105549.css" as="style"/><link rel="stylesheet" href="/_next/static/css/3b03d00d40d80e105549.css"/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-a40ef1678bae11e696dba45124eadd70.js"></script><script defer="" src="/_next/static/chunks/4941.396c0967ba3841708a1e.js"></script><script defer="" src="/_next/static/chunks/4934.37651fffe4e244d39030.js"></script><script defer="" src="/_next/static/chunks/1952.cb24443f59b3778be77b.js"></script><script defer="" src="/_next/static/chunks/3551.e6d3a24e74ae2a11cefe.js"></script><script src="/_next/static/chunks/webpack-6348a078840007e7b18d.js" defer=""></script><script src="/_next/static/chunks/framework-bdc1b4e5e48979e16d36.js" defer=""></script><script src="/_next/static/chunks/main-6409a04df91a58e5134b.js" defer=""></script><script src="/_next/static/chunks/pages/_app-943b963555c2fbbc0438.js" defer=""></script><script src="/_next/static/chunks/commons-38d39b8714d89582ab40.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-2b78b938dce9efe93b0d.js" defer=""></script><script src="/_next/static/YkvXBy-diZpsGMy3AZGNl/_buildManifest.js" defer=""></script><script src="/_next/static/YkvXBy-diZpsGMy3AZGNl/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="container"><header class="header_outer__yu9q7 "><nav class="umoja-l-grid--12 header_wrapper__3Ghzm"><a class="header_logo__eiLSq" href="/"></a><button class="header_hamburger__1ZcbZ" type="button"><span class="header_hamburger_box__RZ7CY"><span class="header_hamburger_box_inner__1PmWZ"></span></span></button><ul class="header_navBar__37eSJ"><li class="header_navItem__1HiGN"><p class="header_navItem_label__fN3Cy">Platform</p><div class="header_dropDown__6NxUb"><div class="header_dropDown_group__2BZXC"><p class="header_dropdown_group_label__tmND8">Platform</p><a class="header_navLink__1ARu5" href="/how-it-works">How it Works</a><a class="header_navLink__1ARu5" href="/video-annotation">Video Annotation</a><a class="header_navLink__1ARu5" href="/image-annotation">Image Annotation</a><a class="header_navLink__1ARu5" href="/3d-lidar">3D &amp; LiDAR Annotation</a><a class="header_navLink__1ARu5" href="/natural-language-processing">Natural Language Processing</a><a class="header_navLink__1ARu5" href="/data-curation">Data Curation (Beta)</a></div><div class="header_dropDown_group__2BZXC"><p class="header_dropdown_group_label__tmND8">Shapes</p><a class="header_navLink__1ARu5" href="/semantic-segmentation">Semantic Segmentation</a><a class="header_navLink__1ARu5" href="/polygons">Polygons</a><a class="header_navLink__1ARu5" href="/bounding-boxes">Bounding Boxes</a><a class="header_navLink__1ARu5" href="/key-points">Key Points</a><a class="header_navLink__1ARu5" href="/cuboids">Cuboids</a><a class="header_navLink__1ARu5" href="/lines-and-arrows">Lines &amp; Arrows</a></div></div></li><li class="header_navItem__1HiGN"><p class="header_navItem_label__fN3Cy">Industries</p><div class="header_dropDown__6NxUb"><a class="header_navLink__1ARu5" href="/transportation-navigation">Transportation &amp; Navigation</a><a class="header_navLink__1ARu5" href="/retail-ecommerce">Retail &amp; E-Commerce</a><a class="header_navLink__1ARu5" href="/consumer-media">Consumer &amp; Media</a><a class="header_navLink__1ARu5" href="/biotech-medtech">Biotech &amp; Medtech</a><a class="header_navLink__1ARu5" href="/robotics-and-manufacturing">Robotics &amp; Manufacturing</a><a class="header_navLink__1ARu5" href="/training-data-food-agriculture">Food &amp; Agriculture</a></div></li><li class="header_navItem__1HiGN"><p class="header_navItem_label__fN3Cy">Why Sama</p><div class="header_dropDown__6NxUb"><a class="header_navLink__1ARu5" href="/quality-training-data">Quality</a><a class="header_navLink__1ARu5" href="/security-and-trust">Security</a><a class="header_navLink__1ARu5" href="/our-impact">Ethical AI</a><a class="header_navLink__1ARu5" href="/compare">Compare</a><a class="header_navLink__1ARu5" href="/partners">Partners</a></div></li><li class="header_navItem__1HiGN"><p class="header_navItem_label__fN3Cy">Resources</p><div class="header_dropDown__6NxUb"><a href="https://docs.sama.com/reference/overview" class="header_navLink__1ARu5" target="_blank">API Documentation</a><a class="header_navLink__1ARu5" href="/blog">Blog</a><a class="header_navLink__1ARu5" href="/events">Events</a></div></li><li class="header_navItem__1HiGN"><p class="header_navItem_label__fN3Cy">Company</p><div class="header_dropDown__6NxUb"><a class="header_navLink__1ARu5" href="/our-story">Our Story</a><a class="header_navLink__1ARu5" href="/our-team">Our Team</a><a class="header_navLink__1ARu5" href="/careers">Careers</a><a class="header_navLink__1ARu5" href="/company-contact">Contact</a><a class="header_navLink__1ARu5" href="/press">Press</a></div></li></ul><div class="header_cta__3J8I7"><a class="button_wrapper__3lRbv button__secondary__1pZ5q button__small__2kIwW" href="/[object%20Object]"><button class="button_btn__1qxP1"><h3 class="button_text__3_sCS">Request a Demo</h3></button></a></div></nav></header><main class="content"><section class="umoja-l-grid-section umoja-u-bg--white"><div class="umoja-l-grid--12 umoja-l-grid-align--center"><div class="blog-hero-post_wrap__1KbfB"><div class="blog-hero-post_left__2zn39"><h1>New Podcast Episode: Making AI Development Global with Google&#x27;s Laurence Moroney</h1><a class="blog-hero-post_author__28uii" href="/[object%20Object]">Amanda Durepos</a><p class="blog-hero-post_date__hVvVU">August 10, 2021<!-- --> | <!-- -->45 Min Read</p></div><div class="blog-hero-post_right__AAryF"><div style="display:block;overflow:hidden;position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;margin:0"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img sizes="100vw" srcSet="https://cdn.sanity.io/images/76e3r62u/production/1502043edcf701cb4267cb2f6d7c6edf8e0e0cad-2500x1313.png?w=640&amp;q=75&amp;fit=clip&amp;auto=format 640w, https://cdn.sanity.io/images/76e3r62u/production/1502043edcf701cb4267cb2f6d7c6edf8e0e0cad-2500x1313.png?w=750&amp;q=75&amp;fit=clip&amp;auto=format 750w, https://cdn.sanity.io/images/76e3r62u/production/1502043edcf701cb4267cb2f6d7c6edf8e0e0cad-2500x1313.png?w=828&amp;q=75&amp;fit=clip&amp;auto=format 828w, https://cdn.sanity.io/images/76e3r62u/production/1502043edcf701cb4267cb2f6d7c6edf8e0e0cad-2500x1313.png?w=1080&amp;q=75&amp;fit=clip&amp;auto=format 1080w, https://cdn.sanity.io/images/76e3r62u/production/1502043edcf701cb4267cb2f6d7c6edf8e0e0cad-2500x1313.png?w=1200&amp;q=75&amp;fit=clip&amp;auto=format 1200w, https://cdn.sanity.io/images/76e3r62u/production/1502043edcf701cb4267cb2f6d7c6edf8e0e0cad-2500x1313.png?w=1920&amp;q=75&amp;fit=clip&amp;auto=format 1920w, https://cdn.sanity.io/images/76e3r62u/production/1502043edcf701cb4267cb2f6d7c6edf8e0e0cad-2500x1313.png?w=2048&amp;q=75&amp;fit=clip&amp;auto=format 2048w, https://cdn.sanity.io/images/76e3r62u/production/1502043edcf701cb4267cb2f6d7c6edf8e0e0cad-2500x1313.png?w=3840&amp;q=75&amp;fit=clip&amp;auto=format 3840w" src="https://cdn.sanity.io/images/76e3r62u/production/1502043edcf701cb4267cb2f6d7c6edf8e0e0cad-2500x1313.png?w=3840&amp;q=75&amp;fit=clip&amp;auto=format" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" loading="lazy"/></noscript></div></div></div></div></section><section class="umoja-l-grid-section umoja-u-bg--white"><div class="umoja-l-grid--12 blog-post_body__2CyGF"><div class="blog-post_share__2sAqL"><div class="blog-post_share_track__3nibH"><a class="blog-post_share_button__2ZGXI blog-post_share_button__facebook__2V_7U" href="https://www.facebook.com/sharer/sharer.php?u=https://www.sama.com//blog/%2Fpodcast-google-global-ai-development"></a><a class="blog-post_share_button__2ZGXI blog-post_share_button__twitter__3lhXm" href="https://twitter.com/intent/tweet?text=Check%20out%20this%20great%20blog%20post%20I%20just%20read&amp;url=https://www.sama.com//blog/%2Fpodcast-google-global-ai-development"></a><a class="blog-post_share_button__2ZGXI blog-post_share_button__linkedin__34so0" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://www.sama.com//blog/%2Fpodcast-google-global-ai-development&amp;title=New Podcast Episode: Making AI Development Global with Google&#x27;s Laurence Moroney&amp;source=https://www.sama.com/&amp;summary=Check%20out%20this%20great%20blog%20post%20I%20just%20read"></a></div></div><div class="blog-post_content__1Q3Gg richText_inner__37NFR undefined"><p>Many of the exciting advances in AI have resulted from well-funded companies and research departments, stocked with high-performance computers and every shiny toy the AI practitioner could want. But according to Laurence Moroney, Lead AI Advocate at Google, that’s not the only way to develop artificial intelligence.</p><p></p><blockquote>So these students got together and they realized... if they take a picture of the sky, they have data. If they measure the air quality on the sensor, they have a label.</blockquote><p>Laurence joined our podcast, <a href="https://www.howaihappens.com/" target="_blank" rel="noopener">How AI Happens</a>, to share examples of exciting advances in AI that are happening all over the world, many with no more than basic mobile devices. Laurence and his team have made it their mission to evangelize the opportunity of AI and work towards democratizing access to the technology’s development, a mission they accomplish via <a href="https://www.coursera.org/instructor/lmoroney" target="_blank" rel="noopener">MooCs</a>, <a href="https://www.youtube.com/tensorflow" target="_blank" rel="noopener">YouTube</a>, and a <a href="https://www.amazon.com/Laurence-Moroney/e/B001ILFKMS%3Fref=dbs_a_mng_rwt_scns_share" target="_blank" rel="noopener">series of books</a> on AI development. </p><p>In this episode, Laurence shares the nature of AI hype cycles, how AI practitioners can navigate them within their own organizations, and some of the amazing opportunities coming into play when access to AI &amp; ML is made global. You can stream the full episode below, tune in via <a href="https://howaihappens.com/" target="_blank" rel="noopener">your favorite podcasting app</a>, or read the whole transcript below.</p><p><strong><em>(audio embed)</em></strong></p><p><em>Transcript:</em></p><p>0:00:00.0 Laurence Moroney: And then when they fed this back through an intention mechanism, they realized they didn&#x27;t build a camouflage detector, they built a cloudy sky detector.</p><p>0:00:12.2 Rob Stevenson: Welcome to &#x27;How AI Happens&#x27;, a podcast where experts explain their work at the cutting edge of artificial intelligence. You&#x27;ll hear from AI researchers, data scientists and machine learning engineers, as they get technical about the most exciting developments in their field and the challenges they&#x27;re facing along the way. I&#x27;m your host, Rob Stevenson, and we are about to learn how AI happens.</p><p>0:00:42.0 RS: You don&#x27;t have to be an AI expert to be skeptical about all the hype surrounding artificial intelligence and machine learning. Every company claims they have it, every sales deck mentions it, and worse, the media act as if the rise of the machines is happening sometime in late 2022. But amidst this hype cycle, those in the know understand the opportunity has never been greater. Enter Laurence Moroney. He&#x27;s an industry veteran who has authored several books on AI development and even advises British Parliament on their AI approach. His mission in his role at Google is to evangelize the opportunity of AI and work towards democratizing access to the development of this technology.</p><p>0:01:25.3 LM: I&#x27;m an AI lead at Google, so I lead the developer advocacy team, and our job is really to help inform and inspire the world around machine learning, artificial intelligence, deep learning and all that good stuff. So working with developers, working with communities, universities, all of those kind of folks to really help scale out the message and the opportunity that&#x27;s there with AI.</p><p>0:01:47.4 RS: Laurence joined the podcast to discuss the nature of AI hype cycles, how AI practitioners can navigate those cycles within their own organizations, and some of the amazing opportunities coming into play when access to AI and ML is made global.</p><p>0:02:01.8 LM: As for my background, I was doing developer advocacy for a few years prior to Google, at places like Microsoft, a wonderful start-up in Israel, called Main Soft, and at Reuters, the news agency, kind of doing an internal advocacy role there, and then prior to that, the typical software engineer, all of those kind of things. Although my background at school was actually physics, my degree was in physics, but I came to the realization that nobody hires physicists, or very few people hire them, and I guess I wasn&#x27;t good enough a physicist to be hired, so I ended up in this wonderful field instead.</p><p>0:02:37.9 RS: It&#x27;s interesting, you&#x27;re the second individual I&#x27;ve spoken to, who got their start in physics and now have a career in AI. Is that a natural progression? What do you think is the link there?</p><p>0:02:48.2 LM: I honestly... I don&#x27;t think there is a natural progression, it&#x27;s probably just a happy coincidence and maybe you&#x27;re over-fitting in your audience. Sorry, AI joke there. For me, my path to AI actually came... It was really interesting that... &#x27;cause when I first graduated college as a physicist, and it was in the UK, and it was in the middle of the worst recession that they had had since World War II. The current one, obviously, &#x27;cause of COVID, is even worse. But back then, this was a pretty bad one, there was no kind of jobs or anything. And the government launched an initiative in 1992, the UK government, that they were gonna put together a cohort of 20 people to become AI specialists who could maybe be form the backbone of trying to help industry through AI and all of that kind of thing. And they needed people who were smart, but unemployed, and I at least fit one of those criteria, and I was unemployed, but we kinda did this battery of tests, it was like these kind of strange movies kind of thing, and I was accepted into the cohorts, which was really, really cool. And then I guess I got bitten by the AI bug then.</p><p>0:03:53.7 LM: But in 1992, trying to do any kind of AI program was intensely difficult, it really didn&#x27;t have any practical use. We were learning the languages like Prolog and LISP, and there was no industrial use for them, but there was some really fun academic stuff that you could do. But in the end, the program failed completely, but the potential was there, and I gotta give credit to the UK government, of figuring this out back in 1992. They were a little bit early, but it was really cool that they did it. It&#x27;s funny that recently, in the last couple of years, I&#x27;ve been doing briefs to the UK governments, around AI, and I was like, &quot;Hey, do you know about that program?&quot; And of course, the MPs there, they&#x27;re all long gone, the ones that did it. And the current ones were like, &quot;Did we really do that? That&#x27;s awesome.&quot; I guess that&#x27;s what got me bit by the bug and that led me down a career of programming and software engineering, to get me where I am today.</p><p>0:04:45.9 RS: I&#x27;m interested to hear that you are spreading this message of the opportunity of AI, but then you also see all of these companies who are sort of saying they have AI or using AI in their messaging. Is there a gap of actual technology there? What is the difference between the reality of the technology and maybe the hype surrounding it?</p><p>0:05:04.7 LM: Yeah, it&#x27;s a great question. And by the fact that there&#x27;s so many people doing this and waving around the AI magic pixie dust, hoping for customers or VC funding, that... If nothing else, that is a signal that this technology does have legs. The question is, does it get lost in the hype cycle or do we bust out of the hype cycle and start doing something really interesting? I always like to talk about, there&#x27;s the... Gartner has this hype cycle curve, where you start with the peak of inflated expectations, and then you drop into something called the trough of disillusionment, and then once you&#x27;re in the through of disillusionment, that&#x27;s when you can really understand what the technology is and then you start climbing up through the plateau of productivity. And the kind of behavior that you&#x27;re talking about just means that we&#x27;re kind of on the wrong side at the moment, of this peak of inflated expectations. Part of what I&#x27;d like to describe my job as, is to do some quantum tunneling through that peak and end up in the trough of disillusionment. So I&#x27;m a professional disillusioner.</p><p>0:06:02.9 LM: And then once you get into that and you understand what the technology actually is and what it does, then you can start being really useful with it. Obviously, you can look to the past to be able to predict the future. And in my career, there have been two massive tectonic shifts in computing. The first was really the widespread advent of the web and internet technology. The second was the smartphone. And if you think about, exactly the same thing happened in both those cases. I&#x27;ll talk about the smartphone, which is the more recent one. So the hype cycle at the time was like, &quot;Throw away your desktop PC, throw away your laptop. You&#x27;ll be able to do everything on your phone.&quot; And it&#x27;s like, &quot;Forget about Office Suites, forget about programming environments, all of these kind of things. You&#x27;re gonna get your phone, you&#x27;re gonna plug it into a station on your desk and a big monitor will magically appear and it&#x27;ll change how work is done.&quot; Well, that didn&#x27;t happen. That to me, was a great example of the hype around the smartphone. But the smart phone still was a massive revolutionary technology that created a tectonic shift in the industry. I saw a stat, the largest creator of jobs in Western Europe during COVID, was the smartphone ecosystem. So not just people building smartphone applications, but people using them, and all of the stuff around that, like delivery services and all that type of stuff.</p><p>0:07:23.8 LM: So we could see, that revolution started in 2007, and even now, 14 years later, the economy is benefiting greatly from it. The web revolution, the same thing, there was a whole ton of hype around the web, every shop in existence will go out of business, libraries will close. There was disruption and there were changes as a result of the web, but of course there was, I believe, an overall net gain. So when you start seeing these kind of things like when the hype first came in, but the people who were able to see through the hype and to be able to do something reasonable and productive when they fell into the trough of disillusionment, created whole new industries. Google came out as a result of the web, Amazon, Facebook, the Apple are the highest market cap company in the world right now, and that came as a result of the smartphone revolution. So there&#x27;s so much that can happen when you can understand the actual limitations, start building to them and then rise up through that plateau of productivity as it&#x27;s called in the Gartner Hype Cycle.</p><p>0:08:28.1 LM: And that&#x27;s really what I&#x27;m here to do, that&#x27;s my role at Google, is to help people who are technically savvy to understand, &quot;Here&#x27;s the possibility of things that you can do. Here&#x27;s what you need to communicate within your business,&quot; and so when your product managers or when your CEO is wanting to wave that AI magic pixie dust, that kind of stuff, then it&#x27;s the case, well, you can be the person who&#x27;s got the expertise, who&#x27;s able to say, &quot;I know this domain, and here&#x27;s where AI can be used in this domain for real.&quot; And it might be nice to attract attention through marketing or through VC, but when you build a real product and you start building a real market around that, that&#x27;s when the business can take off.</p><p>0:09:09.7 RS: So if I&#x27;m an AI practitioner and I am contending with the hype around AI, or the example you gave of the CEO who&#x27;s white boarding, &quot;Can we do this with AI?&quot; How can I level set expectations? There seems to be this little bit of education necessary, to make sure that people are steeped in reality when it comes to, &quot;What can this technology do? And what can you reasonably expect within your organization?&quot;</p><p>0:09:34.5 LM: Yeah, I think effective communication is the number one tool, managing upwards like that is the number one tool. I&#x27;ve had a number of those conversations with folks who just thought that they can wave their arms and say, &quot;AI,&quot; and then find a programmer who could build the AI for them as they envisage it. But then to kinda just talk them through, &quot;Well, this is how it actually works, this is what it actually is. And if you wanna reach these goals, here&#x27;s the kind of work that you would need to do, to be able to reach them.&quot; And often, it&#x27;s setting lower goals and having a plan to be able to reach those lower goals and then use that as a plateau to go further and further and further. And I find in general, like CEO speak or CXO speak, they like that, instead of a yes person going, &quot;Yes, we can do whatever your vision is,&quot; that kind of thing, to actually be able to say, &quot;Well, here&#x27;s a plan for how we can get to a very profitable future. It may not be the vision that you have, but it&#x27;s concrete,&quot; and often, the folks in that level see themselves as the inspirational folks who get the plan moving in that direction by setting the goal and setting the long-term vision.</p><p>0:10:45.8 LM: And when somebody can communicate up like that to say it&#x27;s like, &quot;Well, we can&#x27;t reach the exact nirvana that you&#x27;re specifying, but we can build great products to do A, B, C and D, not all the way A through Z, and we can do it in this time frame,&quot; that, having that level of expertise to be able to speak to that comfortably and realistically, ends up being, I think, a great gift for everybody. If we go back to the conversation of what AI is and what AI isn&#x27;t, is that I always like to draw this diagram that I say, &quot;Okay, here&#x27;s traditional programming,&quot; and traditional programming, I draw it as a box, and that box is saying, &quot;You&#x27;re putting rules in, you&#x27;re putting data in and you&#x27;re getting answers out.&quot; This is what programmers and the software department in your company have been doing since the dawn of software time, and the case is, what a programmer does is, they have to figure out how to express those rules in the programming language, so computers can do the work.</p><p>0:11:36.2 LM: So for example, a very simple thing, like in financial services, there&#x27;s a ratio called the price over earnings ratio, that&#x27;s often a good one to determine the value of a company or one of the signals to determine the value of a company. And that&#x27;s a very simple rule. Get the data of the price, get the data of the earnings, divide one by the other, and then you get an answer. There&#x27;s obviously far more complex ones than that, but I like to use that one as a simple example. And you hire programmers because they know how to express those rules in a programming language and run them in an infrastructure. In the machine learning and AI world, I flip the axis around on that box. So instead of you trying to figure out the rules, you give the machine the answers and the data, and you have it figure out the rules. So for something like price over earnings, it&#x27;s overkill, you don&#x27;t need to do it. But what if there are patterns in your data that you don&#x27;t see?</p><p>0:12:26.5 LM: There are things about this company, and you can get a wealth of data around a company that you&#x27;re doing an analysis on, and you can see that this company has done extremely well in the stock market, but you have no idea why, and this company has done extremely well, and you have no idea why, and then these bunch have done badly and you&#x27;ve no idea why. So then you have the answers, they&#x27;ve done well, they&#x27;ve done badly. You have the data, and the idea behind machine learning and AI is then, you can build a system that can do that pattern matching of the answers to the data and figure out what the rules are, to be able to do that.</p><p>0:13:01.1 LM: So for you to do that effectively, you need good data scientists. It&#x27;s not just, you get a shovel and you throw the data into the machine and something magic happens. You have your data scientists to try and make this as efficient as possible by picking the columns in the database or maybe doing feature crosses on those columns, where multiply this one by this one, that kind of thing. And the same way as your coders today, they&#x27;re not just typing on a keyboard and stuff magically appears, they are figuring out the rules, they&#x27;re figuring how to scale them. And that&#x27;s really where the magic of good data science department applies, and so you&#x27;ve got skilled people who know the domain data, who know how to build models, so that the data is being used efficiently, so you can train a model in a couple of hours instead of a couple of decades, and that kind of thing. So it&#x27;s like, that&#x27;s where those folks, beyond trendy, really, really can show massive value for the company. And I&#x27;d say the same analogy, if you can get a programmer to build an effective program that runs your business in a day or a week, as opposed to an ineffective programmer who takes years to do the same task.</p><p>0:14:07.6 LM: The same kind of thing can be applied with data scientists, that they can figure out which parts of the data to shovel, which parts not to shovel, they can figure out how to label those answers and all of those kind of things, so that the machine learning engineer can do their job effectively.</p><p>0:14:21.7 LM: The way I generally like to define AI itself is, when you make a machine that responds the same way that an intelligent being would respond. So computer vision is a good example of that, is that if I show you a picture of a cat... If I show you a picture of my pet, you would say, &quot;That is a dog.&quot; Showing a computer a picture of my pets, prior to AI machine learning, deep learning, it would see a whole bunch of pixels and it has no parsing of the content, other than white pixels, blue pixels, those kind of things. When you start using machine learning and deep learning to then kind of train a computer to understand the difference between a cat and a dog, and then I show it this picture of my pets, and the computer will say, &quot;That&#x27;s a dog.&quot; Now, the computer is responding in the same way as an intelligent being would respond, and that to me, is what artificial intelligence is all about. So you play it a sound, and instead of it saying, &quot;Here&#x27;s a number of audio levels,&quot; it&#x27;s actually able to determine your speech and to determine what you&#x27;re saying, the same way as an intelligent being would. That to me, is artificial intelligence.</p><p>0:15:31.6 LM: There are lots of ways that you can get there. Machine learning, deep learning are probably the most efficient way for things like computer vision, for audio processing, for tax processing and those types of things. So if we think about it and what it is... In terms of what it is and what it&#x27;s not, it&#x27;s not this magic thing that you can just say, &quot;We&#x27;re gonna... Like in a Dilbert cartoon, we&#x27;re gonna say, &quot;Let&#x27;s put machine learning and artificial intelligence into our product and we get an upgrade.&quot; It doesn&#x27;t really work like that.</p><p>0:15:58.7 RS: The training is in the interest of an inference. When your technology can make an inference, an accurate inference, it has mimicked human cognition, right?</p><p>0:16:06.5 LM: Yeah, exactly. And the nice thing is then, it can even go beyond human cognition, and let me give an example of this, that blows my mind. And so we worked on a project for diabetic retinopathy, at Google, where diabetic retinopathy is the world&#x27;s leading cause of blindness. And the thing about it is that, it&#x27;s easy to diagnose and it&#x27;s easy to cure with early diagnosis. India has the world&#x27;s second largest population, but it has a shortage of over 100 thousand qualified ophthalmologists. So we worked with doctors and hospitals in India to gather lots and lots of retina scans, to see... We&#x27;d label these retina scans... Data plus answers. We&#x27;d label these, based on those five different buckets, no diabetic retinopathy, all the way up to severe, and trained a machine learning model on this, to be able to be an artificial intelligence to respond the way an ophthalmologist would, and it ended up, like the publications that we did in various journals, showed that it was at least equivalent to a qualified ophthalmologist and often better. And so, that&#x27;s the first mind-blowing part.</p><p>0:17:13.5 LM: But then the second mind-blowing part, and the one that really hooked my interest in this was then a scientist within Google was looking at the data and realized, we don&#x27;t just have labels of the diagnosis, we also have labels of the person&#x27;s birth gender, or the person&#x27;s age, or the person&#x27;s blood pressure.</p><p>0:17:33.6 LM: Now, an ophthalmologist can look at the scan of an eye and see blood clots and determine do they have diabetic retinopathy or not, but an ophthalmologist can&#x27;t look at that scan and pick their age, or pick their gender. And so what if you have all of this data, you have your answers, you have your data, what if we could feed this into a model and do it? And it ended up, they trained a model that was 98% accurate in picking the assigned gender at birth, which is as good as, if not better than the average human, but obviously much better than a human looking at a retina, that kind of thing. It would be 50-50, it would be a coin flip. But it was 90% accurate, and it was also able to predict their age, with a mean average error of about three years.</p><p>0:18:19.1 LM: And a few times in the past, I&#x27;ve told this story to an audience and I&#x27;d asked the audience to guess my age, and on average, the audience was... The mean average error from the audience was way more than that, and they&#x27;re looking at me, they&#x27;re looking at my gray hair, they&#x27;re looking at my mannerisms, they&#x27;re not looking at my retina, and they&#x27;re still getting it even more wrong than this was... Again, looking at the retina. So we talk about human cognition and that kind of stuff, but in some ways, doing this kind of pattern recognition, we can go beyond human cognition, with examples like that one. If you have the data and if you have the labels that it&#x27;s possible now for a machine to be able to do the matching of that data to that label and spot patterns that you as a human, wouldn&#x27;t previously spot, and then there&#x27;s massive, untold opportunities in that. So again, if we get down into that trust of disillusionment, and part of that is, I&#x27;m saying Machine Learning is fancy pattern matching.</p><p>[chuckle]</p><p>0:19:13.8 LM: And that kind of thing. There&#x27;s nothing magical about it. And then when you understand that and you say, &quot;Well, I have this wealth of data in my business, can I find new business opportunities with this?&quot; And the answer to that, then is potentially, yes. In the same way as that scientist at Google was able to build a system to be able to predict somebody&#x27;s age from a retina scan, which nobody knows how you can look at a retina and determine an age. From the model that they built, so you can now do an audit of that, and there&#x27;s something called attention mechanisms, so you can see where the computer is paying attention to, to be able to derive what it is in a retina that let&#x27;s you pick somebody&#x27;s age. But it&#x27;s like those are the kind of things that now, that the brute-force aspect of sheer compute power, doing that kind of pattern matching allows you to come up with these new scenarios that will rise you up through that plateau of productivity.</p><p></p><p>0:20:07.3 RS: Yes, so you said it was an attention mechanism? And this allows you to clue in on, this is the variables that it was taking into account to result in this insight?</p><p></p><p>0:20:18.1 LM: Yeah. Exactly, exactly. I teach it in one of my Coursera courses. I do advanced computer vision. And there&#x27;s one really fun example that we go through in that one, it&#x27;s not the retina one, that one is a little bit too complex, but there&#x27;s a very famous machine learning exercise, which is pictures of cats and dogs that I was talking about earlier on, and how you train a computer to be able to recognize the difference between a cat and a dog. And you build a machine learning model in the course that can quite accurately tell the difference between a cat and a dog. But then you also do the attention mechanism stuff on that. And it turns out the primary difference that in this case, the computer was looking at, to pick the difference between a cat and a dog was the eyes. Sometimes you think, &quot;Oh the cat has pointy ears, the dog has floppy ears, for the most part&quot; or &quot;Their noses look differently&quot;, but for the most part, when this model was actually working to pick the difference, it was like those were the features that it had zeroed in on and so then I was able to learn from that and go, &quot;Aha, so now when I build a model, maybe I should focus on the eyes to be more efficient&quot;, that type of thing.</p><p>0:21:16.7 RS: Yes, it strikes me as a crucial mechanism in removing harmful biases, for example, from a black box AI, from being able to look under the hood and say, &quot;Okay, this is what it was looking at to get this insight&quot;. That can help remove a lot of this fear and a lot of these potentially, harmful biases or incorrect assumptions that technology would make.</p><p>0:21:41.9 LM: Yeah, yeah, exactly. And there&#x27;s a technique, it&#x27;s also called... There&#x27;s a thing that you can build, called a class activation map, and the idea with the class activation map is, you&#x27;re seeing what the computer was paying attention to. A funny story about them, the US Army, realized that maybe computer vision could be used to see things and images that humans couldn&#x27;t see. And say take for example, on the battlefield, what about being able to see a camouflaged tank? That like a human could look at it, camouflage is designed to fool the human eye, but what if you could have a machine be able to detect like a camouflage camouflaged tank? So they did an experiment where they got a bunch of data scientists and a bunch of machine learning engineers and they gave them a tank, and they said, &quot;Hey, you go out into the woods and one day take a whole bunch of pictures of this tank un-camouflaged&quot;, and then the following day, they got the camouflage nets, and they put the camouflage nets on the tank and take a whole bunch of pictures of this tank camouflaged. And so build a model off of this one to see if you can pick a camouflage tank or a non-camouflage one, and they did what all good data scientists do, they had a training set of data, they had a test set of data, they had a validation set.</p><p>0:22:54.3 LM: They built their model, they ran it and it was like 99% plus accurate. And they were like, &quot;Oh my gosh, we have built something that can really, really change the course of the battlefield&quot;. They presented that to the Army, the Army loved it, and then they took it out and tested it and it failed completely.</p><p>0:23:10.8 RS: Oh no. [chuckle]</p><p>0:23:12.5 LM: And the reason why it failed completely was that, they took the pictures of the un-camouflaged tank one day, and they took the pictures of the camouflaged tank on another day. And on the day that they took the camouflaged tank, the sky was cloudy, and on the other day they had a blue sky, and then when they fed this back through an intention mechanism, they realized they didn&#x27;t build a camouflage detector. They built a cloudy sky detector. [chuckle] So with the black box element of this kind of thing, it&#x27;s easy to think that these are hard to debug and that kind of stuff, but they&#x27;re not necessarily that difficult to debug if you understand how they&#x27;re architected, and if I gave the elevator pitch for how you to do this, when you train an AI system or a machine learning system, you&#x27;re flowing data one way and doing back prop the other way, but when you wanna do these attention mechanisms, those kind of things, it&#x27;s just the way of flowing data in the other direction and effectively de-compiling it. If you&#x27;re going through convolutions, you&#x27;re de-convoluting it and that kind of stuff, and you can get a pretty good estimate for how the computer is looking at your data.</p><p></p><p>0:24:12.1 RS: What is the difference between a classification map and an attention mechanism?</p><p></p><p>0:24:15.6 LM: A class activation map is a...</p><p></p><p>0:24:17.1 RS: Yeah. Thank you.</p><p></p><p>0:24:18.3 LM: So it&#x27;s a case of when you build a Convolutional Neural Network in particular, you&#x27;re learning filters that can isolate features in a map, and a class activation map is where you just figure out where those features are on, you light it up on a diagram with a heat map or something like that. And that is a type of attention mechanism. There are also other ways of you being able to pick out attention within a machine learning model or something like that. Class activation maps are a very common one that are used in Computer Vision. Anything that you do, Convolutional Neural Networks, to be able to identify features, there are... Sometimes also use used Convolutions for sequence maps, so if you wanna predict weather in the future or something like that, you may use a one-dimensional convolution on that, and you can potentially have a class activation map there where it spots like, &quot;Hey, when you got a spike followed by a dip&quot;, in this kind of thing, then that&#x27;s usually followed by something else. But typically, it would be in an image-based one, it&#x27;s where it&#x27;s most commonly used.</p><p>0:25:17.6 RS: I like how you mentioned the examples of the smartphone and understanding Hype Cycles, I&#x27;m curious if there are any lessons you think we can learn from the way that, that sort of technology was deployed and iterated upon that we can correct or do better with... As AI is sort of spread to the world.</p><p>0:25:35.7 LM: The first part is letting people realize that they are in a hype cycle, we&#x27;ve been in hype cycles before. The people who were successful, were the ones... Or initially successful, at least, were the ones who saw through that, and this is what they did to see through it. Exposure to the platform, exposure to the technology, trying out new and exciting and different things, there&#x27;s a whole graveyard of failed apps on Android and iOS, which laid the framework and the pathway for those apps that were successful. So really being those kind of early adopters, having that, try what you can, learn, iterate, continue. That&#x27;s what&#x27;s led to success, and I think that&#x27;s the same kind of thing that can lead to success in the AI space.</p><p>0:26:19.2 LM: One of the advantages of the AI space, is that the amount of investment that you have to make to be successful is a lot less than the amount of investment you might have previously had to make to become the big mobile app developer or to become the big website, and as a result, you don&#x27;t necessarily have to be housed in the traditional areas on centers of excellence and success. So if we can try to democratize AI as much as possible by making it as available to as many people as possible so that they can seize opportunities that the rest of us may not actually think about, that could pave the way to success for them and for everybody else also. For every success, there&#x27;s probably going to be a 100 failures, and it&#x27;s really understanding that, realizing that, but I would rather have a 101,000 people do something so that there&#x27;s a thousand successes and 100,000 failures, than have 1001 people do it where there&#x27;s only one success, if my math add up. I told you I&#x27;m not very good at math.</p><p>[chuckle]</p><p>0:27:23.4 RS: Yeah, the one... Yeah, I think that adds up. Of course, the YouTube channel and the MOOCS, and a lot of the content that you produce is any in the interest... It&#x27;s accessible anywhere. Someone who has internet access can learn from an expert, such as yourself. I do worry though, at what point is there a breakdown in terms of the hardware and the ability to actually design this technology? Does one need access to cloud computing and a work horse of a laptop to be able to play in this field?</p><p>0:27:53.3 LM: To be able to get started and play in this field, absolutely no. To be able to go huge in this field, you do need access to high-end hardware like GPUs and TPUs and that kind of thing. So to split those two audiences for the Getting Started one, that&#x27;s where we&#x27;ve been very carefully focused on easy high-level APIs that will run in Python, which is easy to install and use, that you can do on any laptop with the a CPU so that you can get up and running and kick the tires with these kind of things and to make that as quick and easy as possible for anybody to do. When you go beyond that though, and you start trying to train bigger models, not everybody has access to GPUs, not everybody has access to TPUs. So part of our strategy there was, we have this thing called Google Colab, and Google Colab is an in the browser notebook that runs with a Google Cloud back-end that can provide you free access to a GPU or a TPU. Obviously it&#x27;s limited, but it&#x27;s pretty generous. It&#x27;s many hours of training that you can get for that, and all you need is a browser and a web connection to be able to do that, if you don&#x27;t already have the hardware.</p><p>0:29:00.3 LM: So that&#x27;s the one first part of the offering. The another part of the offering though, is that when we start thinking about where do your models execute? Okay, so that many models are gonna be built to execute in data centers, the likes of Google or Amazon or Microsoft or on... But that&#x27;s not the only area of opportunity, we can see that the area of opportunity on mobile handheld devices, embedded systems and all those kind of things is possibly even larger. And with the price of them dropping sharply, the hardware to build a phone is getting cheaper, the hardware to build embedded systems is getting cheaper. Then as long as we have an ecosystem of tools that will allow you to build for them with as low a dollar cost of entry as possible, as low an intellectual cost of entry as possible, those kind of things, that&#x27;s when those markets can be seeded and those markets can grow. And like I said, I think we can all benefit. Let me share one example, &#x27;cause there&#x27;s a great project that... It was a couple of years ago, that was built by a bunch of high school and college students in India. And it&#x27;s called Air Cognizer, I think that&#x27;s the right phrase.</p><p>0:30:09.6 LM: And it&#x27;s on the YouTube web... The TensorFlow YouTube website. And what they did was that they realized that in their city in India, there was extensive air pollution. And you know what it&#x27;s like, we all probably are encountering and nowadays with fires nearby, I live in Washington, so every year we have to start looking at air quality because of forest fires. But what they realized was that, when you look at air quality and you see it on the news, or you see it on a website, that&#x27;s the air quality at a sensor, which is being operated by somebody. Now that might be 20-30 miles from where you live, and the air quality where you live might be severely worse. Elderly parents that they had and grandparents were afraid to go out because they don&#x27;t know the air quality and they could get sick. So these students got together and they realized if they get a sensor to measure the air quality, and they get a phone, a cheap Android phone with a camera on it, if they take a picture of the sky, they have data. If they measure the air quality on the sensor, they have a label, and if they go all over their city and they take lots of these pictures and lots of these sensors, you do that basic pattern matching to kind of build a model where you&#x27;re saying, &quot;Well, when the sky looks like this, the pollution is like this&quot;.</p><p>0:31:27.8 LM: And they turned that into an app, and now lots of folks in India can use that app where they can just take a photo of the sky and see a good prediction of the air quality near them, instead of looking at the news and seeing an air quality indicator that could be 20, 30, 40 miles away. And it&#x27;s like little things like that, little innovations like that, because these were high school and college students, they don&#x27;t have a lot of money, they&#x27;re not forming a startup where they&#x27;re hiring developers to do this kind of thing, the equipment for them to do that, was basic laptops that they had, the data? They generated the data themselves because they had the sensor and they had a cell phone where they could take a picture of the sky, they were able to build a model for this using the open source ecosystem, and they were able to deploy it for free to Android phones.</p><p>0:32:12.5 LM: These kind of things, when I talk about really lowering that bar so we could raise the floor, but now it&#x27;s like, &quot;Well, the rest of the world can benefit from what they learned&quot;, because we now have the same problem in the West because of forest fires. And I could potentially go out and do the same thing to build an Air Cognizer for Washington State without needing to invest millions of dollars in a start-up to do so. So when you bust through that hype cycle and you understand how this works, then you can think like that, and that&#x27;s what they did, they thought like that, and boom, they came up with this really cool solution.</p><p>0:32:42.8 RS: This is the focus of your, about to be published, new book. Is that correct?</p><p>0:32:47.1 LM: Yep, so it&#x27;s an AI and Machine Learning for On-Device Development is my upcoming book. I originally was gonna create this mega-book for O&#x27;Reilly called AI and Machine Learning for Coders. We realized this weighed too much for one book.</p><p>[chuckle]</p><p>0:33:02.4 LM: So last year, I released the AI and Machine Learning for Coders, and now this year, it&#x27;s kind of like the complimentary book/sequel, which is a AI and Machine Learning for On-Device Development. So it&#x27;s really showing you how, as a mobile developer, you can start using models on Android, on iOS and a little sprinkling of doing it in a server with remote access or doing it on things like Raspberry Pi. It&#x27;s packed with lots of examples of things like, you take a picture, here&#x27;s how you can detect a face in the picture. Or here&#x27;s how you can count the number of objects in the picture, like maybe you&#x27;re building an app that&#x27;s counting traffic, driving past your house. How do you count the number of cars? Those kind of examples... So I try to get very hands-on with them, of like, here&#x27;s basically how this stuff works on your device. As of today, you don&#x27;t train models on the device, you use models on the device. So the concept of my first book, AI and Machine Learning for Coders, or my first book in the series was really, &quot;Here&#x27;s how you build the models&quot;, and then the second book is, &quot;Okay, when you have models or there are off the shelf models available, here&#x27;s how you use them, or here&#x27;s how you can customize them to actually use them on your device&quot;.</p><p>0:34:16.9 RS: Okay, so the model is not constructed locally? The model is accessed?</p><p>0:34:20.9 LM: Yeah. As of today, trying to train a model on a mobile device, it&#x27;s just going to be very hostile towards your battery because model training is very intensive. We are doing a lot of work on making that better, but as of today... Yeah, as a developer, you&#x27;re better off training a model in the cloud with something like Colab, or on your developer workstation and then deploying it to your device.</p><p>0:34:46.4 RS: Yes.</p><p>0:34:47.3 LM: But that&#x27;s changing. That is changing.</p><p>0:34:48.1 RS: Yeah. Well, fans of this podcast will remember our episode with Sama CEO, Wendy Gonzalez, who was speaking about this similar kind of problem of, &quot;How do we democratize access to AI?&quot; and I can envision an approach to that, which is just drop a 100 copies of your book and a 100 Android devices, just anywhere in the world and let a rip, right?</p><p>0:35:10.2 LM: Yeah, yeah, please do. I&#x27;d love to see the results.</p><p>0:35:16.8 RS: Laurence has published all manner of content about the realities an opportunities of AI, both philosophical and technical. In the episode description, you&#x27;ll find links to his MOOCs, books, and the TensorFlow YouTube channel where he frequently contributes. You can also find Laurence&#x27;s resources on the new, How AI Happens, LinkedIn group. Here, we&#x27;ll post all the research and resources mentioned by our guests and give you the opportunity to rub shoulders and ask follow-up questions with the experts you hear featured on the show. Just search How AI Happens on LinkedIn and say, hello. How AI Happens is brought to you by Sama. Sama provides accurate data for ambitious AI. Specializing in image, video and sensor data annotation and validation for Machine Learning algorithms in industries such as transportation, retail, e-commerce, media, MedTech, robotics and agriculture. For more information, head to sama.com.</p></div></div></section><section class="umoja-l-grid-section umoja-u-bg--white"><div class="umoja-l-grid--12"><div class="blog-post-footer_tags__yEMl0"><h3 class="blog-post-footer_intro__1dGYr">Filed Under:</h3><a class="blog-post-footer_tag__UlZZ0" href="/[object%20Object]">Ethical AI</a><a class="blog-post-footer_tag__UlZZ0" href="/[object%20Object]">Podcast</a></div><div class="blog-post-footer_author__1Qqrq"><h3 class="blog-post-footer_intro__1dGYr">Words by:</h3><div class="blog-post-footer_author_inner__1tFQc"><div class="blog-post-footer_author_headshot__d-1KT"><div style="display:block;overflow:hidden;position:relative;box-sizing:border-box;margin:0"><div style="display:block;box-sizing:border-box;padding-top:106.9620253164557%"></div><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="responsive" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img sizes="100vw" srcSet="https://cdn.sanity.io/images/76e3r62u/production/2f8efc599a377bd580d0ae12f022a15e7e1acacd-632x676.webp?w=640&amp;q=75&amp;fit=clip&amp;auto=format 640w, https://cdn.sanity.io/images/76e3r62u/production/2f8efc599a377bd580d0ae12f022a15e7e1acacd-632x676.webp?w=750&amp;q=75&amp;fit=clip&amp;auto=format 750w, https://cdn.sanity.io/images/76e3r62u/production/2f8efc599a377bd580d0ae12f022a15e7e1acacd-632x676.webp?w=828&amp;q=75&amp;fit=clip&amp;auto=format 828w, https://cdn.sanity.io/images/76e3r62u/production/2f8efc599a377bd580d0ae12f022a15e7e1acacd-632x676.webp?w=1080&amp;q=75&amp;fit=clip&amp;auto=format 1080w, https://cdn.sanity.io/images/76e3r62u/production/2f8efc599a377bd580d0ae12f022a15e7e1acacd-632x676.webp?w=1200&amp;q=75&amp;fit=clip&amp;auto=format 1200w, https://cdn.sanity.io/images/76e3r62u/production/2f8efc599a377bd580d0ae12f022a15e7e1acacd-632x676.webp?w=1920&amp;q=75&amp;fit=clip&amp;auto=format 1920w, https://cdn.sanity.io/images/76e3r62u/production/2f8efc599a377bd580d0ae12f022a15e7e1acacd-632x676.webp?w=2048&amp;q=75&amp;fit=clip&amp;auto=format 2048w, https://cdn.sanity.io/images/76e3r62u/production/2f8efc599a377bd580d0ae12f022a15e7e1acacd-632x676.webp?w=3840&amp;q=75&amp;fit=clip&amp;auto=format 3840w" src="https://cdn.sanity.io/images/76e3r62u/production/2f8efc599a377bd580d0ae12f022a15e7e1acacd-632x676.webp?w=3840&amp;q=75&amp;fit=clip&amp;auto=format" decoding="async" data-nimg="responsive" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" loading="lazy"/></noscript></div></div><div class="blog-post-footer_author_bio__2z8Kp"><a href="/[object%20Object]"><h4>Amanda Durepos</h4></a><p>Amanda is the Content Marketing Manager at Sama, where each day she gets to learn about AI and how it’s transforming industry. She’s passionate about technology but periodically tries to get away from her computer to explore more analog things like collage and quilting.</p></div></div></div></div></section><section class="umoja-l-grid-section umoja-l-grid-section--flat-top umoja-u-bg--white"><div class="umoja-l-grid--12"><h3 class="blog-post_relatedPosts__19WKQ">Related Posts:</h3><div class="blog-smallCard-row_post__in_Mm"><a class="blog-smallCard-row_imgWrap__36jhQ" href="/[object%20Object]"><div style="display:block;overflow:hidden;position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;margin:0"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img sizes="100vw" srcSet="https://cdn.sanity.io/images/76e3r62u/production/ae9f62c210539de6ed2b60b71efa4be6b90021c6-1920x960.png?w=640&amp;q=75&amp;fit=clip&amp;auto=format 640w, https://cdn.sanity.io/images/76e3r62u/production/ae9f62c210539de6ed2b60b71efa4be6b90021c6-1920x960.png?w=750&amp;q=75&amp;fit=clip&amp;auto=format 750w, https://cdn.sanity.io/images/76e3r62u/production/ae9f62c210539de6ed2b60b71efa4be6b90021c6-1920x960.png?w=828&amp;q=75&amp;fit=clip&amp;auto=format 828w, https://cdn.sanity.io/images/76e3r62u/production/ae9f62c210539de6ed2b60b71efa4be6b90021c6-1920x960.png?w=1080&amp;q=75&amp;fit=clip&amp;auto=format 1080w, https://cdn.sanity.io/images/76e3r62u/production/ae9f62c210539de6ed2b60b71efa4be6b90021c6-1920x960.png?w=1200&amp;q=75&amp;fit=clip&amp;auto=format 1200w, https://cdn.sanity.io/images/76e3r62u/production/ae9f62c210539de6ed2b60b71efa4be6b90021c6-1920x960.png?w=1920&amp;q=75&amp;fit=clip&amp;auto=format 1920w, https://cdn.sanity.io/images/76e3r62u/production/ae9f62c210539de6ed2b60b71efa4be6b90021c6-1920x960.png?w=2048&amp;q=75&amp;fit=clip&amp;auto=format 2048w, https://cdn.sanity.io/images/76e3r62u/production/ae9f62c210539de6ed2b60b71efa4be6b90021c6-1920x960.png?w=3840&amp;q=75&amp;fit=clip&amp;auto=format 3840w" src="https://cdn.sanity.io/images/76e3r62u/production/ae9f62c210539de6ed2b60b71efa4be6b90021c6-1920x960.png?w=3840&amp;q=75&amp;fit=clip&amp;auto=format" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" loading="lazy"/></noscript></div></a><div class="blog-smallCard-row_post_info__3V7Qy"><a href="/[object%20Object]"><h4>Accurate Data Labeling Powers the Volumental Shoe Recommendation App — Helping Retailers Convert Mobile Customers</h4></a><a class="blog-smallCard-row_tag__33FrA" href="/[object%20Object]">Case Studies</a></div></div><div class="blog-smallCard-row_post__in_Mm"><a class="blog-smallCard-row_imgWrap__36jhQ" href="/[object%20Object]"><div style="display:block;overflow:hidden;position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;margin:0"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img sizes="100vw" srcSet="https://cdn.sanity.io/images/76e3r62u/production/0434b713b7dcba1cdf98eff0eb50d7cb3d5fb008-1500x908.jpg?w=640&amp;q=75&amp;fit=clip&amp;auto=format 640w, https://cdn.sanity.io/images/76e3r62u/production/0434b713b7dcba1cdf98eff0eb50d7cb3d5fb008-1500x908.jpg?w=750&amp;q=75&amp;fit=clip&amp;auto=format 750w, https://cdn.sanity.io/images/76e3r62u/production/0434b713b7dcba1cdf98eff0eb50d7cb3d5fb008-1500x908.jpg?w=828&amp;q=75&amp;fit=clip&amp;auto=format 828w, https://cdn.sanity.io/images/76e3r62u/production/0434b713b7dcba1cdf98eff0eb50d7cb3d5fb008-1500x908.jpg?w=1080&amp;q=75&amp;fit=clip&amp;auto=format 1080w, https://cdn.sanity.io/images/76e3r62u/production/0434b713b7dcba1cdf98eff0eb50d7cb3d5fb008-1500x908.jpg?w=1200&amp;q=75&amp;fit=clip&amp;auto=format 1200w, https://cdn.sanity.io/images/76e3r62u/production/0434b713b7dcba1cdf98eff0eb50d7cb3d5fb008-1500x908.jpg?w=1920&amp;q=75&amp;fit=clip&amp;auto=format 1920w, https://cdn.sanity.io/images/76e3r62u/production/0434b713b7dcba1cdf98eff0eb50d7cb3d5fb008-1500x908.jpg?w=2048&amp;q=75&amp;fit=clip&amp;auto=format 2048w, https://cdn.sanity.io/images/76e3r62u/production/0434b713b7dcba1cdf98eff0eb50d7cb3d5fb008-1500x908.jpg?w=3840&amp;q=75&amp;fit=clip&amp;auto=format 3840w" src="https://cdn.sanity.io/images/76e3r62u/production/0434b713b7dcba1cdf98eff0eb50d7cb3d5fb008-1500x908.jpg?w=3840&amp;q=75&amp;fit=clip&amp;auto=format" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" loading="lazy"/></noscript></div></a><div class="blog-smallCard-row_post_info__3V7Qy"><a href="/[object%20Object]"><h4>Orbisk’s Sama-Powered Food Waste Solution Named to Fast Company’s First-Ever List of the Next Big Things in Tech</h4></a><a class="blog-smallCard-row_tag__33FrA" href="/[object%20Object]">Awards</a></div></div><div class="blog-smallCard-row_post__in_Mm"><a class="blog-smallCard-row_imgWrap__36jhQ" href="/[object%20Object]"><div style="display:block;overflow:hidden;position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;margin:0"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img sizes="100vw" srcSet="https://cdn.sanity.io/images/76e3r62u/production/1502043edcf701cb4267cb2f6d7c6edf8e0e0cad-2500x1313.png?w=640&amp;q=75&amp;fit=clip&amp;auto=format 640w, https://cdn.sanity.io/images/76e3r62u/production/1502043edcf701cb4267cb2f6d7c6edf8e0e0cad-2500x1313.png?w=750&amp;q=75&amp;fit=clip&amp;auto=format 750w, https://cdn.sanity.io/images/76e3r62u/production/1502043edcf701cb4267cb2f6d7c6edf8e0e0cad-2500x1313.png?w=828&amp;q=75&amp;fit=clip&amp;auto=format 828w, https://cdn.sanity.io/images/76e3r62u/production/1502043edcf701cb4267cb2f6d7c6edf8e0e0cad-2500x1313.png?w=1080&amp;q=75&amp;fit=clip&amp;auto=format 1080w, https://cdn.sanity.io/images/76e3r62u/production/1502043edcf701cb4267cb2f6d7c6edf8e0e0cad-2500x1313.png?w=1200&amp;q=75&amp;fit=clip&amp;auto=format 1200w, https://cdn.sanity.io/images/76e3r62u/production/1502043edcf701cb4267cb2f6d7c6edf8e0e0cad-2500x1313.png?w=1920&amp;q=75&amp;fit=clip&amp;auto=format 1920w, https://cdn.sanity.io/images/76e3r62u/production/1502043edcf701cb4267cb2f6d7c6edf8e0e0cad-2500x1313.png?w=2048&amp;q=75&amp;fit=clip&amp;auto=format 2048w, https://cdn.sanity.io/images/76e3r62u/production/1502043edcf701cb4267cb2f6d7c6edf8e0e0cad-2500x1313.png?w=3840&amp;q=75&amp;fit=clip&amp;auto=format 3840w" src="https://cdn.sanity.io/images/76e3r62u/production/1502043edcf701cb4267cb2f6d7c6edf8e0e0cad-2500x1313.png?w=3840&amp;q=75&amp;fit=clip&amp;auto=format" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" loading="lazy"/></noscript></div></a><div class="blog-smallCard-row_post_info__3V7Qy"><a href="/[object%20Object]"><h4>New Podcast Episode: Facebook&#x27;s Manohar Paluri Makes Machines See</h4></a><a class="blog-smallCard-row_tag__33FrA" href="/[object%20Object]">Podcast</a></div></div></div></section></main><footer class="footer_wrapper__2VAfJ"><div class="umoja-l-grid--12"><div class="footer_upper__2a6XG"><div><h4>Newsletter</h4><p>Subscribe today and be the first to receive the latest from Sama.</p></div><div class="footer_upper_right__cpliC"><div><p class="footer_nav_head__1keQK">Guides</p><a class="footer_nav_link__X1RNI" href="/training-data-for-autonomous-driving">Autonomous Transportation</a><a class="footer_nav_link__X1RNI" href="/training-data-for-ecommerce">E-Commerce</a><a class="footer_nav_link__X1RNI" href="/training-data-for-ar-vr">AR/VR</a><a class="footer_nav_link__X1RNI" href="/data-quality">Data Quality</a></div><div><p class="footer_nav_head__1keQK">Company</p><a class="footer_nav_link__X1RNI" href="/our-story">Our Story</a><a class="footer_nav_link__X1RNI" href="/our-team">Our Team</a><a class="footer_nav_link__X1RNI" href="/mission-vision-values">Our Mission</a><a class="footer_nav_link__X1RNI" href="/careers">Careers</a><a class="footer_nav_link__X1RNI" href="/company-contact">Contact</a></div></div></div><div class="footer_middle__iiTSJ"><div class="footer_middle_left__3ff78"><a href="/"></a></div><div class="footer_middle_right__2b-lC"><div class="footer_social__1NFfV"><a href="https://www.facebook.com/samaartificialintelligence" class="footer_social_icon__wI2OK" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 35.1 64.89"><title>facebook</title><g id="fb3209c8-23d4-4288-984d-a2b8f32b7f0c" data-name="Layer 2"><g id="ba1a815d-13f1-45f9-9321-18e9a3cfa5db" data-name="Layer 1"><path d="M35.1,11.26V1.36A1.35,1.35,0,0,0,33.76,0H25.35A15.34,15.34,0,0,0,14,4.35C11.24,7.2,9.78,11.22,9.78,16v7.34H1.34A1.34,1.34,0,0,0,0,24.66V35.32a1.35,1.35,0,0,0,1.34,1.35H9.78V63.55a1.34,1.34,0,0,0,1.34,1.34h11a1.34,1.34,0,0,0,1.34-1.34V36.67h9.87a1.35,1.35,0,0,0,1.34-1.35V24.66a1.37,1.37,0,0,0-.7-1.18,1.47,1.47,0,0,0-.67-.16H23.49V17.1c0-1.72.25-2.69.84-3.37s1.88-1.13,3.77-1.13h5.66A1.34,1.34,0,0,0,35.1,11.26Z"></path></g></g></svg></a><a href="https://www.instagram.com/sama_ai_" class="footer_social_icon__wI2OK" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 57 57"><title>insta</title><g id="ef02a3ef-c0d3-4be7-9d4e-2c42263777a3" data-name="Layer 2"><g id="a0a92778-6c5c-4e06-a08f-641546580dd0" data-name="Layer 1"><circle cx="28.5" cy="28.5" r="9.24"></circle><path d="M41.57,0H15.43A15.45,15.45,0,0,0,0,15.43V41.57A15.45,15.45,0,0,0,15.43,57H41.57A15.45,15.45,0,0,0,57,41.57V15.43A15.45,15.45,0,0,0,41.57,0ZM28.5,42.74A14.24,14.24,0,1,1,42.74,28.5,14.26,14.26,0,0,1,28.5,42.74ZM44.46,17a5,5,0,1,1,5-5A5,5,0,0,1,44.46,17Z"></path></g></g></svg></a><a href="https://twitter.com/SamaAI" class="footer_social_icon__wI2OK" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 62 51.19"><title>twitter</title><g id="e7743e55-1863-47ad-a995-4b7f1f924f07" data-name="Layer 2"><g id="ec8c6fd9-2f52-4507-9a24-804bc60dbc33" data-name="Layer 1"><path d="M23.59,51.19c-10.35,0-18.53-1.81-22.44-5l-.07-.06L1,46.1a3.19,3.19,0,0,1-.84-3.35l0-.1a3.24,3.24,0,0,1,3-2,26.57,26.57,0,0,0,7.06-1,13.45,13.45,0,0,1-7.07-8.16,2.92,2.92,0,0,1,1-3.38,3.06,3.06,0,0,1,.88-.45,19.52,19.52,0,0,1-4-7.18l0-.08,0-.09a3,3,0,0,1,1.4-3.23,3,3,0,0,1,1.43-.4,15.15,15.15,0,0,1-1.14-3.49A14.59,14.59,0,0,1,4.24,3.47l.38-.77a2.15,2.15,0,0,1,3.44-.56l.7.7c5.53,5.81,10.49,8.56,19.06,10.44a15.17,15.17,0,0,1,4.1-8.75A14.39,14.39,0,0,1,42.19,0h0c2.84,0,6.36,1.62,8.49,2.77,1.83-.6,4-1.53,6.32-2.51a2.88,2.88,0,0,1,3.22.57,2.85,2.85,0,0,1,.62,3.11c-.17.47-.36.92-.57,1.36a3.07,3.07,0,0,1,.84.58,3.13,3.13,0,0,1,.78,2.92l0,.1a11.92,11.92,0,0,1-4.78,6.56C56.73,35.23,41.84,51.19,23.59,51.19Z"></path></g></g></svg></a><a href="https://www.linkedin.com/company/sama-ai/" class="footer_social_icon__wI2OK" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 59.71 60.79"><title>linkedin</title><g id="bd073dff-b6ea-4cf0-bfeb-c3ce392ee6a5" data-name="Layer 2"><g id="f6b6eb77-7c10-4e27-a3d0-6f8b14e97f2e" data-name="Layer 1"><path d="M59.65,60.79l-12.35,0,0-19.36c0-4.62-.07-10.56-6.41-10.58s-7.44,5-7.45,10.21l0,19.7-12.36,0,.09-40.95,11.87,0v6.57h.16c1.66-3.13,5.7-6.42,11.73-6.41,12.51,0,14.81,8.28,14.79,19l-.05,21.85Z"></path><path d="M7.17,14.35a7.18,7.18,0,1,1,7.18-7.18A7.17,7.17,0,0,1,7.17,14.35Z"></path><rect x="0.98" y="19.8" width="12.39" height="40.95"></rect></g></g></svg></a><a href="https://www.youtube.com/c/SamaAI" class="footer_social_icon__wI2OK" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 65 44.63"><title>youtube</title><g id="b03ac260-8029-40d4-832d-1f2d757db2d5" data-name="Layer 2"><g id="eca1bfe4-f0ec-4c24-9169-be6d2f8b24b5" data-name="Layer 1"><path d="M55,0H10A10,10,0,0,0,0,10V34.63a10,10,0,0,0,10,10H55a10,10,0,0,0,10-10V10A10,10,0,0,0,55,0ZM40.89,24.41,28.3,31.18a2.31,2.31,0,0,1-3.41-2V15.48a2.3,2.3,0,0,1,3.42-2l12.6,6.89a2.31,2.31,0,0,1,0,4.06Z"></path></g></g></svg></a></div></div></div><div class="footer_lower__1z3Av"><div class="footer_lower_left__141hE"><a class="footer_nav_link__X1RNI" href="/terms-of-service">Terms</a><a class="footer_nav_link__X1RNI" href="/privacy-policy">Privacy</a><a class="footer_nav_link__X1RNI" href="/quality-and-information-policy">Quality &amp; Information</a></div><div class="footer_lower_right__22vMw"><h6>Copyright © <!-- -->0<!-- --> Sama Inc.</h6><h6>All rights reserved.</h6></div></div></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"config":{"footerNav":{"items":[{"_key":"f255606f8f25","_type":"navDropdownMenu","items":[{"_key":"76389ad94cbb","_type":"navItem","title":"Autonomous Transportation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"training-data-for-autonomous-driving"}}}},{"_key":"5f64a8d6a69d","_type":"navItem","title":"E-Commerce","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"training-data-for-ecommerce"}}}},{"_key":"f10e54ae04d0","_type":"navItem","title":"AR/VR","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"training-data-for-ar-vr"}}}},{"_key":"fd729b522a77","_type":"navItem","title":"Data Quality","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"data-quality"}}}}],"title":"Guides","url":null},{"_key":"681ef7d8763a","_type":"navDropdownMenu","items":[{"_key":"6238a422b667","_type":"navItem","title":"Our Story","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-story"}}}},{"_key":"258985d6d46b","_type":"navItem","title":"Our Team","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-team"}}}},{"_key":"e0a76077324a","_type":"navItem","title":"Our Mission","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"mission-vision-values"}}}},{"_key":"239e49661b0d","_type":"navItem","title":"Careers","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"careers"}}}},{"_key":"e005a740cd80","_type":"navItem","title":"Contact","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"company-contact"}}}}],"title":"Company","url":null}]},"logo":{"asset":{"_createdAt":"2021-10-29T18:38:04Z","_id":"image-e20f8cc53e5f74df10ae9a822edb7ec2c4d00f02-2380x636-svg","_rev":"yuZxWYwFNB6KJB4TM9NtaY","_type":"sanity.imageAsset","_updatedAt":"2021-10-29T18:38:04Z","assetId":"e20f8cc53e5f74df10ae9a822edb7ec2c4d00f02","extension":"svg","metadata":{"_type":"sanity.imageMetadata","dimensions":{"_type":"sanity.imageDimensions","aspectRatio":3.742138364779874,"height":636,"width":2380},"hasAlpha":true,"isOpaque":false,"lqip":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAYAAABFA8wzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAr0lEQVQYlU3QyUoDQBAE0HeIEjeixAVyESRI3BNFJSZxAU/+/wdJQSEehu6Zqa6uKnjBGz7xgTuc4gAj7LWe4LD9cc8Y+9jBUed84QGrEt/gEleYY9Ylr3jGU/tV77fFLirId0nWBYYgoACi+r3D6YPN0vwFm4VxmNlgfkK4qcLUZdVMcdHB+75FzWPfzzCpxXNcFxuOP2uxnhNLASaX5LjbnJJf6jYG2PpXh812/AvSEQ+GGZqgYgAAAABJRU5ErkJggg==","palette":{"_type":"sanity.imagePalette","darkMuted":{"_type":"sanity.imagePaletteSwatch","background":"#040404","foreground":"#fff","population":100.29,"title":"#fff"},"darkVibrant":{"_type":"sanity.imagePaletteSwatch","background":"#424242","foreground":"#fff","population":0,"title":"#fff"},"dominant":{"_type":"sanity.imagePaletteSwatch","background":"#040404","foreground":"#fff","population":100.29,"title":"#fff"},"lightMuted":{"_type":"sanity.imagePaletteSwatch","background":"#4c4c4c","foreground":"#fff","population":0,"title":"#fff"},"lightVibrant":{"_type":"sanity.imagePaletteSwatch","background":"#bcbcbc","foreground":"#000","population":0,"title":"#fff"},"muted":{"_type":"sanity.imagePaletteSwatch","background":"#4c4c4c","foreground":"#fff","population":0,"title":"#fff"},"vibrant":{"_type":"sanity.imagePaletteSwatch","background":"#7f7f7f","foreground":"#fff","population":0,"title":"#fff"}}},"mimeType":"image/svg+xml","originalFilename":"image.svg","path":"images/76e3r62u/production/e20f8cc53e5f74df10ae9a822edb7ec2c4d00f02-2380x636.svg","sha1hash":"ae6a56857a230101a883a9b93974923879775bc9","size":2009,"uploadId":"mtOtmqAQnCEIG5cEqXZ1YAOCuqHJ4X3g","url":"https://cdn.sanity.io/images/76e3r62u/production/e20f8cc53e5f74df10ae9a822edb7ec2c4d00f02-2380x636.svg"}},"mainNav":{"items":[{"_key":"58c18e9aa9ea","_type":"navDropdownMenu","items":[{"_key":"b5b5b8bee78b","_type":"navCat","items":[{"_key":"0e80156a2f1a","_type":"navItem","title":"How it Works","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"how-it-works"}}}},{"_key":"40bacee029b4","_type":"navItem","title":"Video Annotation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"video-annotation"}}}},{"_key":"32650ef07503","_type":"navItem","title":"Image Annotation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"image-annotation"}}}},{"_key":"fe9137cd0167","_type":"navItem","title":"3D \u0026 LiDAR Annotation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"3d-lidar"}}}},{"_key":"d9a1316d400a","_type":"navItem","title":"Natural Language Processing","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"natural-language-processing"}}}},{"_key":"ac12c7c5d70a","_type":"navItem","title":"Data Curation (Beta)","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"data-curation"}}}}],"title":"Platform","url":null},{"_key":"37ff4fa913bd","_type":"navCat","items":[{"_key":"6026b1a9314e","_type":"navItem","title":"Semantic Segmentation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"semantic-segmentation"}}}},{"_key":"f4611b19b406","_type":"navItem","title":"Polygons","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"polygons"}}}},{"_key":"5155d874d6c8","_type":"navItem","title":"Bounding Boxes","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"bounding-boxes"}}}},{"_key":"9ef3c1e21e74","_type":"navItem","title":"Key Points","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"key-points"}}}},{"_key":"314d4c00d351","_type":"navItem","title":"Cuboids","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"cuboids"}}}},{"_key":"8e17a6388d74","_type":"navItem","title":"Lines \u0026 Arrows","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"lines-and-arrows"}}}}],"title":"Shapes","url":null}],"title":"Platform","url":null},{"_key":"112867ca4d03","_type":"navDropdownMenu","items":[{"_key":"22699c7e06cb","_type":"navItem","items":null,"title":"Transportation \u0026 Navigation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"transportation-navigation"}}}},{"_key":"122ae5928d6d","_type":"navItem","items":null,"title":"Retail \u0026 E-Commerce","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"retail-ecommerce"}}}},{"_key":"7bb234b69fb0","_type":"navItem","items":null,"title":"Consumer \u0026 Media","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"consumer-media"}}}},{"_key":"33e6a886b39d","_type":"navItem","items":null,"title":"Biotech \u0026 Medtech","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"biotech-medtech"}}}},{"_key":"d095b2619c4e","_type":"navItem","items":null,"title":"Robotics \u0026 Manufacturing","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"robotics-and-manufacturing"}}}},{"_key":"2c4b82a94d79","_type":"navItem","items":null,"title":"Food \u0026 Agriculture","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"training-data-food-agriculture"}}}}],"title":"Industries","url":null},{"_key":"c47e8763a906","_type":"navDropdownMenu","items":[{"_key":"1d563df30b3f","_type":"navItem","items":null,"title":"Quality","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"quality-training-data"}}}},{"_key":"041725f35d96","_type":"navItem","items":null,"title":"Security","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"security-and-trust"}}}},{"_key":"fd64ede25798","_type":"navItem","items":null,"title":"Ethical AI","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-impact"}}}},{"_key":"398dcbb1c95d","_type":"navItem","items":null,"title":"Compare","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"compare"}}}},{"_key":"93bdfdd87879","_type":"navItem","items":null,"title":"Partners","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"partners"}}}}],"title":"Why Sama","url":null},{"_key":"1d38bf63df54","_type":"navDropdownMenu","items":[{"_key":"be81659b38a5","_type":"navItem","items":null,"title":"API Documentation","url":{"_type":"link","externalUrl":"https://docs.sama.com/reference/overview","internalLink":null}},{"_key":"2cec80e94962","_type":"navItem","items":null,"title":"Blog","url":{"_type":"link","internalLink":null,"internalLink_custom":"/blog"}},{"_key":"09e284fcb1d3","_type":"navItem","items":null,"title":"Events","url":{"_type":"link","internalLink":null,"internalLink_custom":"/events"}}],"title":"Resources","url":null},{"_key":"dbee93713c19","_type":"navDropdownMenu","items":[{"_key":"12d594a568bf","_type":"navItem","items":null,"title":"Our Story","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-story"}}}},{"_key":"ce36540a102d","_type":"navItem","items":null,"title":"Our Team","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-team"}}}},{"_key":"34fc328e8022","_type":"navItem","items":null,"title":"Careers","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"careers"}}}},{"_key":"c1fe2961020a","_type":"navItem","items":null,"title":"Contact","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"company-contact"}}}},{"_key":"ebd81873e538","_type":"navItem","items":null,"title":"Press","url":{"_type":"link","internalLink":null,"internalLink_custom":"/press"}}],"title":"Company","url":null}],"nav_cta":{"_type":"button","link":{"_type":"link","internalLink":{"_ref":"136788cb-06a6-4f27-b75b-07faf403bfa6","_type":"reference"}},"title":"Request a Demo","type":"secondary"}},"title":"Sama"},"data":{"post":{"_createdAt":"2021-08-10T18:08:48Z","author":{"_id":"e8a1f3c6-0b07-4638-93d5-61a0924f32e3","avatar":{"_type":"image","asset":{"_ref":"image-2f8efc599a377bd580d0ae12f022a15e7e1acacd-632x676-webp","_type":"reference"}},"bio":"Amanda is the Content Marketing Manager at Sama, where each day she gets to learn about AI and how it’s transforming industry. She’s passionate about technology but periodically tries to get away from her computer to explore more analog things like collage and quilting.","name":"Amanda Durepos","slug":{"_type":"slug","current":"amanda-durepos"}},"body":[{"_key":"4ca56999b9f7","_type":"block","children":[{"_key":"d6e75efc66cf","_type":"span","marks":[],"text":"Many of the exciting advances in AI have resulted from well-funded companies and research departments, stocked with high-performance computers and every shiny toy the AI practitioner could want. But according to Laurence Moroney, Lead AI Advocate at Google, that’s not the only way to develop artificial intelligence."}],"markDefs":[],"style":"normal"},{"_key":"a6d6eb0e6433","_type":"block","children":[{"_key":"a983816d59c30","_type":"span","marks":[],"text":""}],"markDefs":[],"style":"normal"},{"_key":"924100ac38a0","_type":"block","children":[{"_key":"8e137860d5350","_type":"span","marks":[],"text":"So these students got together and they realized... if they take a picture of the sky, they have data. If they measure the air quality on the sensor, they have a label."}],"markDefs":[],"style":"blockquote"},{"_key":"45628542c8e0","_type":"block","children":[{"_key":"7e7db38809560","_type":"span","marks":[],"text":"Laurence joined our podcast, "},{"_key":"06635fdb6090","_type":"span","marks":["bbd27f8cc4d7"],"text":"How AI Happens"},{"_key":"99819d206a97","_type":"span","marks":[],"text":", to share examples of exciting advances in AI that are happening all over the world, many with no more than basic mobile devices. Laurence and his team have made it their mission to evangelize the opportunity of AI and work towards democratizing access to the technology’s development, a mission they accomplish via "},{"_key":"356ad7077087","_type":"span","marks":["f62b1e22f6e5"],"text":"MooCs"},{"_key":"031a6d6ab208","_type":"span","marks":[],"text":", "},{"_key":"ae4097003431","_type":"span","marks":["8200df421d90"],"text":"YouTube"},{"_key":"9fc4b1ce24a9","_type":"span","marks":[],"text":", and a "},{"_key":"f6eda5495166","_type":"span","marks":["4476f895926c"],"text":"series of books"},{"_key":"348f2cce7baa","_type":"span","marks":[],"text":" on AI development. "}],"markDefs":[{"_key":"f62b1e22f6e5","_type":"button_link","externalUrl":"https://www.coursera.org/instructor/lmoroney"},{"_key":"8200df421d90","_type":"button_link","externalUrl":"https://www.youtube.com/tensorflow"},{"_key":"4476f895926c","_type":"button_link","externalUrl":"https://www.amazon.com/Laurence-Moroney/e/B001ILFKMS%3Fref=dbs_a_mng_rwt_scns_share"},{"_key":"bbd27f8cc4d7","_type":"button_link","externalUrl":"https://www.howaihappens.com/"}],"style":"normal"},{"_key":"934080e881c6","_type":"block","children":[{"_key":"73c6bf77b6d00","_type":"span","marks":[],"text":"In this episode, Laurence shares the nature of AI hype cycles, how AI practitioners can navigate them within their own organizations, and some of the amazing opportunities coming into play when access to AI \u0026 ML is made global. You can stream the full episode below, tune in via "},{"_key":"9d4f5837c046","_type":"span","marks":["a3cfa747d338"],"text":"your favorite podcasting app"},{"_key":"b48b2b97a640","_type":"span","marks":[],"text":", or read the whole transcript below."}],"markDefs":[{"_key":"a3cfa747d338","_type":"button_link","externalUrl":"https://howaihappens.com/"}],"style":"normal"},{"_key":"4a1c1d1fd6d5","_type":"block","children":[{"_key":"0729ffa78689","_type":"span","marks":["em","strong"],"text":"(audio embed)"}],"markDefs":[],"style":"normal"},{"_key":"ef92e19f2010","_type":"block","children":[{"_key":"ace73c0a7a52","_type":"span","marks":["em"],"text":"Transcript:"}],"markDefs":[],"style":"normal"},{"_key":"516386a295fc","_type":"block","children":[{"_key":"b4469ed968470","_type":"span","marks":[],"text":"0:00:00.0 Laurence Moroney: And then when they fed this back through an intention mechanism, they realized they didn't build a camouflage detector, they built a cloudy sky detector."}],"markDefs":[],"style":"normal"},{"_key":"178425177066","_type":"block","children":[{"_key":"510b2e49ed4f0","_type":"span","marks":[],"text":"0:00:12.2 Rob Stevenson: Welcome to 'How AI Happens', a podcast where experts explain their work at the cutting edge of artificial intelligence. You'll hear from AI researchers, data scientists and machine learning engineers, as they get technical about the most exciting developments in their field and the challenges they're facing along the way. I'm your host, Rob Stevenson, and we are about to learn how AI happens."}],"markDefs":[],"style":"normal"},{"_key":"4e095c7f8b9c","_type":"block","children":[{"_key":"da0f5ddd5d480","_type":"span","marks":[],"text":"0:00:42.0 RS: You don't have to be an AI expert to be skeptical about all the hype surrounding artificial intelligence and machine learning. Every company claims they have it, every sales deck mentions it, and worse, the media act as if the rise of the machines is happening sometime in late 2022. But amidst this hype cycle, those in the know understand the opportunity has never been greater. Enter Laurence Moroney. He's an industry veteran who has authored several books on AI development and even advises British Parliament on their AI approach. His mission in his role at Google is to evangelize the opportunity of AI and work towards democratizing access to the development of this technology."}],"markDefs":[],"style":"normal"},{"_key":"b11dca696976","_type":"block","children":[{"_key":"68a5ea7ce24e0","_type":"span","marks":[],"text":"0:01:25.3 LM: I'm an AI lead at Google, so I lead the developer advocacy team, and our job is really to help inform and inspire the world around machine learning, artificial intelligence, deep learning and all that good stuff. So working with developers, working with communities, universities, all of those kind of folks to really help scale out the message and the opportunity that's there with AI."}],"markDefs":[],"style":"normal"},{"_key":"7b825532ac46","_type":"block","children":[{"_key":"d99683a8a7990","_type":"span","marks":[],"text":"0:01:47.4 RS: Laurence joined the podcast to discuss the nature of AI hype cycles, how AI practitioners can navigate those cycles within their own organizations, and some of the amazing opportunities coming into play when access to AI and ML is made global."}],"markDefs":[],"style":"normal"},{"_key":"7a746d712e9e","_type":"block","children":[{"_key":"61de76a2c84d0","_type":"span","marks":[],"text":"0:02:01.8 LM: As for my background, I was doing developer advocacy for a few years prior to Google, at places like Microsoft, a wonderful start-up in Israel, called Main Soft, and at Reuters, the news agency, kind of doing an internal advocacy role there, and then prior to that, the typical software engineer, all of those kind of things. Although my background at school was actually physics, my degree was in physics, but I came to the realization that nobody hires physicists, or very few people hire them, and I guess I wasn't good enough a physicist to be hired, so I ended up in this wonderful field instead."}],"markDefs":[],"style":"normal"},{"_key":"ecfc376de3e1","_type":"block","children":[{"_key":"2c7484db8cd40","_type":"span","marks":[],"text":"0:02:37.9 RS: It's interesting, you're the second individual I've spoken to, who got their start in physics and now have a career in AI. Is that a natural progression? What do you think is the link there?"}],"markDefs":[],"style":"normal"},{"_key":"7b1ff8241367","_type":"block","children":[{"_key":"0dcbe741084a0","_type":"span","marks":[],"text":"0:02:48.2 LM: I honestly... I don't think there is a natural progression, it's probably just a happy coincidence and maybe you're over-fitting in your audience. Sorry, AI joke there. For me, my path to AI actually came... It was really interesting that... 'cause when I first graduated college as a physicist, and it was in the UK, and it was in the middle of the worst recession that they had had since World War II. The current one, obviously, 'cause of COVID, is even worse. But back then, this was a pretty bad one, there was no kind of jobs or anything. And the government launched an initiative in 1992, the UK government, that they were gonna put together a cohort of 20 people to become AI specialists who could maybe be form the backbone of trying to help industry through AI and all of that kind of thing. And they needed people who were smart, but unemployed, and I at least fit one of those criteria, and I was unemployed, but we kinda did this battery of tests, it was like these kind of strange movies kind of thing, and I was accepted into the cohorts, which was really, really cool. And then I guess I got bitten by the AI bug then."}],"markDefs":[],"style":"normal"},{"_key":"77d9da0d4cfc","_type":"block","children":[{"_key":"d182626087940","_type":"span","marks":[],"text":"0:03:53.7 LM: But in 1992, trying to do any kind of AI program was intensely difficult, it really didn't have any practical use. We were learning the languages like Prolog and LISP, and there was no industrial use for them, but there was some really fun academic stuff that you could do. But in the end, the program failed completely, but the potential was there, and I gotta give credit to the UK government, of figuring this out back in 1992. They were a little bit early, but it was really cool that they did it. It's funny that recently, in the last couple of years, I've been doing briefs to the UK governments, around AI, and I was like, \"Hey, do you know about that program?\" And of course, the MPs there, they're all long gone, the ones that did it. And the current ones were like, \"Did we really do that? That's awesome.\" I guess that's what got me bit by the bug and that led me down a career of programming and software engineering, to get me where I am today."}],"markDefs":[],"style":"normal"},{"_key":"b8699be61052","_type":"block","children":[{"_key":"7634d42ae54b0","_type":"span","marks":[],"text":"0:04:45.9 RS: I'm interested to hear that you are spreading this message of the opportunity of AI, but then you also see all of these companies who are sort of saying they have AI or using AI in their messaging. Is there a gap of actual technology there? What is the difference between the reality of the technology and maybe the hype surrounding it?"}],"markDefs":[],"style":"normal"},{"_key":"ad386e769b2a","_type":"block","children":[{"_key":"2bde41e940dc0","_type":"span","marks":[],"text":"0:05:04.7 LM: Yeah, it's a great question. And by the fact that there's so many people doing this and waving around the AI magic pixie dust, hoping for customers or VC funding, that... If nothing else, that is a signal that this technology does have legs. The question is, does it get lost in the hype cycle or do we bust out of the hype cycle and start doing something really interesting? I always like to talk about, there's the... Gartner has this hype cycle curve, where you start with the peak of inflated expectations, and then you drop into something called the trough of disillusionment, and then once you're in the through of disillusionment, that's when you can really understand what the technology is and then you start climbing up through the plateau of productivity. And the kind of behavior that you're talking about just means that we're kind of on the wrong side at the moment, of this peak of inflated expectations. Part of what I'd like to describe my job as, is to do some quantum tunneling through that peak and end up in the trough of disillusionment. So I'm a professional disillusioner."}],"markDefs":[],"style":"normal"},{"_key":"5f593de42c71","_type":"block","children":[{"_key":"f5ae5db2e3bc0","_type":"span","marks":[],"text":"0:06:02.9 LM: And then once you get into that and you understand what the technology actually is and what it does, then you can start being really useful with it. Obviously, you can look to the past to be able to predict the future. And in my career, there have been two massive tectonic shifts in computing. The first was really the widespread advent of the web and internet technology. The second was the smartphone. And if you think about, exactly the same thing happened in both those cases. I'll talk about the smartphone, which is the more recent one. So the hype cycle at the time was like, \"Throw away your desktop PC, throw away your laptop. You'll be able to do everything on your phone.\" And it's like, \"Forget about Office Suites, forget about programming environments, all of these kind of things. You're gonna get your phone, you're gonna plug it into a station on your desk and a big monitor will magically appear and it'll change how work is done.\" Well, that didn't happen. That to me, was a great example of the hype around the smartphone. But the smart phone still was a massive revolutionary technology that created a tectonic shift in the industry. I saw a stat, the largest creator of jobs in Western Europe during COVID, was the smartphone ecosystem. So not just people building smartphone applications, but people using them, and all of the stuff around that, like delivery services and all that type of stuff."}],"markDefs":[],"style":"normal"},{"_key":"79b94777e66c","_type":"block","children":[{"_key":"a9224c0395c10","_type":"span","marks":[],"text":"0:07:23.8 LM: So we could see, that revolution started in 2007, and even now, 14 years later, the economy is benefiting greatly from it. The web revolution, the same thing, there was a whole ton of hype around the web, every shop in existence will go out of business, libraries will close. There was disruption and there were changes as a result of the web, but of course there was, I believe, an overall net gain. So when you start seeing these kind of things like when the hype first came in, but the people who were able to see through the hype and to be able to do something reasonable and productive when they fell into the trough of disillusionment, created whole new industries. Google came out as a result of the web, Amazon, Facebook, the Apple are the highest market cap company in the world right now, and that came as a result of the smartphone revolution. So there's so much that can happen when you can understand the actual limitations, start building to them and then rise up through that plateau of productivity as it's called in the Gartner Hype Cycle."}],"markDefs":[],"style":"normal"},{"_key":"946a1966803b","_type":"block","children":[{"_key":"b195f55d65310","_type":"span","marks":[],"text":"0:08:28.1 LM: And that's really what I'm here to do, that's my role at Google, is to help people who are technically savvy to understand, \"Here's the possibility of things that you can do. Here's what you need to communicate within your business,\" and so when your product managers or when your CEO is wanting to wave that AI magic pixie dust, that kind of stuff, then it's the case, well, you can be the person who's got the expertise, who's able to say, \"I know this domain, and here's where AI can be used in this domain for real.\" And it might be nice to attract attention through marketing or through VC, but when you build a real product and you start building a real market around that, that's when the business can take off."}],"markDefs":[],"style":"normal"},{"_key":"f61d6efe4b7a","_type":"block","children":[{"_key":"0d44e2b585c90","_type":"span","marks":[],"text":"0:09:09.7 RS: So if I'm an AI practitioner and I am contending with the hype around AI, or the example you gave of the CEO who's white boarding, \"Can we do this with AI?\" How can I level set expectations? There seems to be this little bit of education necessary, to make sure that people are steeped in reality when it comes to, \"What can this technology do? And what can you reasonably expect within your organization?\""}],"markDefs":[],"style":"normal"},{"_key":"767106232b2f","_type":"block","children":[{"_key":"3a9ed4624c4b0","_type":"span","marks":[],"text":"0:09:34.5 LM: Yeah, I think effective communication is the number one tool, managing upwards like that is the number one tool. I've had a number of those conversations with folks who just thought that they can wave their arms and say, \"AI,\" and then find a programmer who could build the AI for them as they envisage it. But then to kinda just talk them through, \"Well, this is how it actually works, this is what it actually is. And if you wanna reach these goals, here's the kind of work that you would need to do, to be able to reach them.\" And often, it's setting lower goals and having a plan to be able to reach those lower goals and then use that as a plateau to go further and further and further. And I find in general, like CEO speak or CXO speak, they like that, instead of a yes person going, \"Yes, we can do whatever your vision is,\" that kind of thing, to actually be able to say, \"Well, here's a plan for how we can get to a very profitable future. It may not be the vision that you have, but it's concrete,\" and often, the folks in that level see themselves as the inspirational folks who get the plan moving in that direction by setting the goal and setting the long-term vision."}],"markDefs":[],"style":"normal"},{"_key":"1889849dfce6","_type":"block","children":[{"_key":"2bd223e923bd0","_type":"span","marks":[],"text":"0:10:45.8 LM: And when somebody can communicate up like that to say it's like, \"Well, we can't reach the exact nirvana that you're specifying, but we can build great products to do A, B, C and D, not all the way A through Z, and we can do it in this time frame,\" that, having that level of expertise to be able to speak to that comfortably and realistically, ends up being, I think, a great gift for everybody. If we go back to the conversation of what AI is and what AI isn't, is that I always like to draw this diagram that I say, \"Okay, here's traditional programming,\" and traditional programming, I draw it as a box, and that box is saying, \"You're putting rules in, you're putting data in and you're getting answers out.\" This is what programmers and the software department in your company have been doing since the dawn of software time, and the case is, what a programmer does is, they have to figure out how to express those rules in the programming language, so computers can do the work."}],"markDefs":[],"style":"normal"},{"_key":"323a8e827ad5","_type":"block","children":[{"_key":"4c41852539020","_type":"span","marks":[],"text":"0:11:36.2 LM: So for example, a very simple thing, like in financial services, there's a ratio called the price over earnings ratio, that's often a good one to determine the value of a company or one of the signals to determine the value of a company. And that's a very simple rule. Get the data of the price, get the data of the earnings, divide one by the other, and then you get an answer. There's obviously far more complex ones than that, but I like to use that one as a simple example. And you hire programmers because they know how to express those rules in a programming language and run them in an infrastructure. In the machine learning and AI world, I flip the axis around on that box. So instead of you trying to figure out the rules, you give the machine the answers and the data, and you have it figure out the rules. So for something like price over earnings, it's overkill, you don't need to do it. But what if there are patterns in your data that you don't see?"}],"markDefs":[],"style":"normal"},{"_key":"326f550a2e3f","_type":"block","children":[{"_key":"772692e93e5f0","_type":"span","marks":[],"text":"0:12:26.5 LM: There are things about this company, and you can get a wealth of data around a company that you're doing an analysis on, and you can see that this company has done extremely well in the stock market, but you have no idea why, and this company has done extremely well, and you have no idea why, and then these bunch have done badly and you've no idea why. So then you have the answers, they've done well, they've done badly. You have the data, and the idea behind machine learning and AI is then, you can build a system that can do that pattern matching of the answers to the data and figure out what the rules are, to be able to do that."}],"markDefs":[],"style":"normal"},{"_key":"402efbc7ddaa","_type":"block","children":[{"_key":"738bd1f695460","_type":"span","marks":[],"text":"0:13:01.1 LM: So for you to do that effectively, you need good data scientists. It's not just, you get a shovel and you throw the data into the machine and something magic happens. You have your data scientists to try and make this as efficient as possible by picking the columns in the database or maybe doing feature crosses on those columns, where multiply this one by this one, that kind of thing. And the same way as your coders today, they're not just typing on a keyboard and stuff magically appears, they are figuring out the rules, they're figuring how to scale them. And that's really where the magic of good data science department applies, and so you've got skilled people who know the domain data, who know how to build models, so that the data is being used efficiently, so you can train a model in a couple of hours instead of a couple of decades, and that kind of thing. So it's like, that's where those folks, beyond trendy, really, really can show massive value for the company. And I'd say the same analogy, if you can get a programmer to build an effective program that runs your business in a day or a week, as opposed to an ineffective programmer who takes years to do the same task."}],"markDefs":[],"style":"normal"},{"_key":"8d9c79a9d56b","_type":"block","children":[{"_key":"9e0cccc9e1ca0","_type":"span","marks":[],"text":"0:14:07.6 LM: The same kind of thing can be applied with data scientists, that they can figure out which parts of the data to shovel, which parts not to shovel, they can figure out how to label those answers and all of those kind of things, so that the machine learning engineer can do their job effectively."}],"markDefs":[],"style":"normal"},{"_key":"83ca0ce2f150","_type":"block","children":[{"_key":"c6e99fe796d80","_type":"span","marks":[],"text":"0:14:21.7 LM: The way I generally like to define AI itself is, when you make a machine that responds the same way that an intelligent being would respond. So computer vision is a good example of that, is that if I show you a picture of a cat... If I show you a picture of my pet, you would say, \"That is a dog.\" Showing a computer a picture of my pets, prior to AI machine learning, deep learning, it would see a whole bunch of pixels and it has no parsing of the content, other than white pixels, blue pixels, those kind of things. When you start using machine learning and deep learning to then kind of train a computer to understand the difference between a cat and a dog, and then I show it this picture of my pets, and the computer will say, \"That's a dog.\" Now, the computer is responding in the same way as an intelligent being would respond, and that to me, is what artificial intelligence is all about. So you play it a sound, and instead of it saying, \"Here's a number of audio levels,\" it's actually able to determine your speech and to determine what you're saying, the same way as an intelligent being would. That to me, is artificial intelligence."}],"markDefs":[],"style":"normal"},{"_key":"24183aaf6d20","_type":"block","children":[{"_key":"8983b5cc6da30","_type":"span","marks":[],"text":"0:15:31.6 LM: There are lots of ways that you can get there. Machine learning, deep learning are probably the most efficient way for things like computer vision, for audio processing, for tax processing and those types of things. So if we think about it and what it is... In terms of what it is and what it's not, it's not this magic thing that you can just say, \"We're gonna... Like in a Dilbert cartoon, we're gonna say, \"Let's put machine learning and artificial intelligence into our product and we get an upgrade.\" It doesn't really work like that."}],"markDefs":[],"style":"normal"},{"_key":"c6ae0fc690d3","_type":"block","children":[{"_key":"a129d2990f750","_type":"span","marks":[],"text":"0:15:58.7 RS: The training is in the interest of an inference. When your technology can make an inference, an accurate inference, it has mimicked human cognition, right?"}],"markDefs":[],"style":"normal"},{"_key":"847e427a8785","_type":"block","children":[{"_key":"01e780931ec90","_type":"span","marks":[],"text":"0:16:06.5 LM: Yeah, exactly. And the nice thing is then, it can even go beyond human cognition, and let me give an example of this, that blows my mind. And so we worked on a project for diabetic retinopathy, at Google, where diabetic retinopathy is the world's leading cause of blindness. And the thing about it is that, it's easy to diagnose and it's easy to cure with early diagnosis. India has the world's second largest population, but it has a shortage of over 100 thousand qualified ophthalmologists. So we worked with doctors and hospitals in India to gather lots and lots of retina scans, to see... We'd label these retina scans... Data plus answers. We'd label these, based on those five different buckets, no diabetic retinopathy, all the way up to severe, and trained a machine learning model on this, to be able to be an artificial intelligence to respond the way an ophthalmologist would, and it ended up, like the publications that we did in various journals, showed that it was at least equivalent to a qualified ophthalmologist and often better. And so, that's the first mind-blowing part."}],"markDefs":[],"style":"normal"},{"_key":"55ced63cd01d","_type":"block","children":[{"_key":"57112a3d71920","_type":"span","marks":[],"text":"0:17:13.5 LM: But then the second mind-blowing part, and the one that really hooked my interest in this was then a scientist within Google was looking at the data and realized, we don't just have labels of the diagnosis, we also have labels of the person's birth gender, or the person's age, or the person's blood pressure."}],"markDefs":[],"style":"normal"},{"_key":"26303c34c697","_type":"block","children":[{"_key":"b1f3b5bc446f0","_type":"span","marks":[],"text":"0:17:33.6 LM: Now, an ophthalmologist can look at the scan of an eye and see blood clots and determine do they have diabetic retinopathy or not, but an ophthalmologist can't look at that scan and pick their age, or pick their gender. And so what if you have all of this data, you have your answers, you have your data, what if we could feed this into a model and do it? And it ended up, they trained a model that was 98% accurate in picking the assigned gender at birth, which is as good as, if not better than the average human, but obviously much better than a human looking at a retina, that kind of thing. It would be 50-50, it would be a coin flip. But it was 90% accurate, and it was also able to predict their age, with a mean average error of about three years."}],"markDefs":[],"style":"normal"},{"_key":"42e2e692bbb1","_type":"block","children":[{"_key":"693f274c076d0","_type":"span","marks":[],"text":"0:18:19.1 LM: And a few times in the past, I've told this story to an audience and I'd asked the audience to guess my age, and on average, the audience was... The mean average error from the audience was way more than that, and they're looking at me, they're looking at my gray hair, they're looking at my mannerisms, they're not looking at my retina, and they're still getting it even more wrong than this was... Again, looking at the retina. So we talk about human cognition and that kind of stuff, but in some ways, doing this kind of pattern recognition, we can go beyond human cognition, with examples like that one. If you have the data and if you have the labels that it's possible now for a machine to be able to do the matching of that data to that label and spot patterns that you as a human, wouldn't previously spot, and then there's massive, untold opportunities in that. So again, if we get down into that trust of disillusionment, and part of that is, I'm saying Machine Learning is fancy pattern matching."}],"markDefs":[],"style":"normal"},{"_key":"855696bf01e2","_type":"block","children":[{"_key":"9c82c4d838f40","_type":"span","marks":[],"text":"[chuckle]"}],"markDefs":[],"style":"normal"},{"_key":"45aa9060ef23","_type":"block","children":[{"_key":"140da3be06e20","_type":"span","marks":[],"text":"0:19:13.8 LM: And that kind of thing. There's nothing magical about it. And then when you understand that and you say, \"Well, I have this wealth of data in my business, can I find new business opportunities with this?\" And the answer to that, then is potentially, yes. In the same way as that scientist at Google was able to build a system to be able to predict somebody's age from a retina scan, which nobody knows how you can look at a retina and determine an age. From the model that they built, so you can now do an audit of that, and there's something called attention mechanisms, so you can see where the computer is paying attention to, to be able to derive what it is in a retina that let's you pick somebody's age. But it's like those are the kind of things that now, that the brute-force aspect of sheer compute power, doing that kind of pattern matching allows you to come up with these new scenarios that will rise you up through that plateau of productivity."}],"markDefs":[],"style":"normal"},{"_key":"633c88e55121","_type":"block","children":[{"_key":"62c5ad64b1530","_type":"span","marks":[],"text":""}],"markDefs":[],"style":"normal"},{"_key":"1ff02565b2e2","_type":"block","children":[{"_key":"688d692ce9320","_type":"span","marks":[],"text":"0:20:07.3 RS: Yes, so you said it was an attention mechanism? And this allows you to clue in on, this is the variables that it was taking into account to result in this insight?"}],"markDefs":[],"style":"normal"},{"_key":"6b244030a273","_type":"block","children":[{"_key":"c3e2e87ec2800","_type":"span","marks":[],"text":""}],"markDefs":[],"style":"normal"},{"_key":"331bc899a2f7","_type":"block","children":[{"_key":"9c7d6dd86bf80","_type":"span","marks":[],"text":"0:20:18.1 LM: Yeah. Exactly, exactly. I teach it in one of my Coursera courses. I do advanced computer vision. And there's one really fun example that we go through in that one, it's not the retina one, that one is a little bit too complex, but there's a very famous machine learning exercise, which is pictures of cats and dogs that I was talking about earlier on, and how you train a computer to be able to recognize the difference between a cat and a dog. And you build a machine learning model in the course that can quite accurately tell the difference between a cat and a dog. But then you also do the attention mechanism stuff on that. And it turns out the primary difference that in this case, the computer was looking at, to pick the difference between a cat and a dog was the eyes. Sometimes you think, \"Oh the cat has pointy ears, the dog has floppy ears, for the most part\" or \"Their noses look differently\", but for the most part, when this model was actually working to pick the difference, it was like those were the features that it had zeroed in on and so then I was able to learn from that and go, \"Aha, so now when I build a model, maybe I should focus on the eyes to be more efficient\", that type of thing."}],"markDefs":[],"style":"normal"},{"_key":"67e4704bda41","_type":"block","children":[{"_key":"361de0bbc2b20","_type":"span","marks":[],"text":"0:21:16.7 RS: Yes, it strikes me as a crucial mechanism in removing harmful biases, for example, from a black box AI, from being able to look under the hood and say, \"Okay, this is what it was looking at to get this insight\". That can help remove a lot of this fear and a lot of these potentially, harmful biases or incorrect assumptions that technology would make."}],"markDefs":[],"style":"normal"},{"_key":"ee84794c3adb","_type":"block","children":[{"_key":"85ee076038480","_type":"span","marks":[],"text":"0:21:41.9 LM: Yeah, yeah, exactly. And there's a technique, it's also called... There's a thing that you can build, called a class activation map, and the idea with the class activation map is, you're seeing what the computer was paying attention to. A funny story about them, the US Army, realized that maybe computer vision could be used to see things and images that humans couldn't see. And say take for example, on the battlefield, what about being able to see a camouflaged tank? That like a human could look at it, camouflage is designed to fool the human eye, but what if you could have a machine be able to detect like a camouflage camouflaged tank? So they did an experiment where they got a bunch of data scientists and a bunch of machine learning engineers and they gave them a tank, and they said, \"Hey, you go out into the woods and one day take a whole bunch of pictures of this tank un-camouflaged\", and then the following day, they got the camouflage nets, and they put the camouflage nets on the tank and take a whole bunch of pictures of this tank camouflaged. And so build a model off of this one to see if you can pick a camouflage tank or a non-camouflage one, and they did what all good data scientists do, they had a training set of data, they had a test set of data, they had a validation set."}],"markDefs":[],"style":"normal"},{"_key":"c4ce87daa2ca","_type":"block","children":[{"_key":"8632f773aadd0","_type":"span","marks":[],"text":"0:22:54.3 LM: They built their model, they ran it and it was like 99% plus accurate. And they were like, \"Oh my gosh, we have built something that can really, really change the course of the battlefield\". They presented that to the Army, the Army loved it, and then they took it out and tested it and it failed completely."}],"markDefs":[],"style":"normal"},{"_key":"0784cf09ae58","_type":"block","children":[{"_key":"cf0fe1256dcb0","_type":"span","marks":[],"text":"0:23:10.8 RS: Oh no. [chuckle]"}],"markDefs":[],"style":"normal"},{"_key":"4f54b7fb3a83","_type":"block","children":[{"_key":"87dce29c5aa70","_type":"span","marks":[],"text":"0:23:12.5 LM: And the reason why it failed completely was that, they took the pictures of the un-camouflaged tank one day, and they took the pictures of the camouflaged tank on another day. And on the day that they took the camouflaged tank, the sky was cloudy, and on the other day they had a blue sky, and then when they fed this back through an intention mechanism, they realized they didn't build a camouflage detector. They built a cloudy sky detector. [chuckle] So with the black box element of this kind of thing, it's easy to think that these are hard to debug and that kind of stuff, but they're not necessarily that difficult to debug if you understand how they're architected, and if I gave the elevator pitch for how you to do this, when you train an AI system or a machine learning system, you're flowing data one way and doing back prop the other way, but when you wanna do these attention mechanisms, those kind of things, it's just the way of flowing data in the other direction and effectively de-compiling it. If you're going through convolutions, you're de-convoluting it and that kind of stuff, and you can get a pretty good estimate for how the computer is looking at your data."}],"markDefs":[],"style":"normal"},{"_key":"0cfb417d27c1","_type":"block","children":[{"_key":"87ad97f7c8620","_type":"span","marks":[],"text":""}],"markDefs":[],"style":"normal"},{"_key":"461b2592ee0c","_type":"block","children":[{"_key":"2df68841cad20","_type":"span","marks":[],"text":"0:24:12.1 RS: What is the difference between a classification map and an attention mechanism?"}],"markDefs":[],"style":"normal"},{"_key":"5de538cf91cc","_type":"block","children":[{"_key":"94244a263fe90","_type":"span","marks":[],"text":""}],"markDefs":[],"style":"normal"},{"_key":"94af0d1d50b0","_type":"block","children":[{"_key":"e4b8b4b0d4370","_type":"span","marks":[],"text":"0:24:15.6 LM: A class activation map is a..."}],"markDefs":[],"style":"normal"},{"_key":"6416f6fb37eb","_type":"block","children":[{"_key":"fa929d397b190","_type":"span","marks":[],"text":""}],"markDefs":[],"style":"normal"},{"_key":"e7b120d82b61","_type":"block","children":[{"_key":"fb0836fe9e650","_type":"span","marks":[],"text":"0:24:17.1 RS: Yeah. Thank you."}],"markDefs":[],"style":"normal"},{"_key":"5236ddbc3940","_type":"block","children":[{"_key":"4363b50b76870","_type":"span","marks":[],"text":""}],"markDefs":[],"style":"normal"},{"_key":"d1a021004e95","_type":"block","children":[{"_key":"cf914159a2680","_type":"span","marks":[],"text":"0:24:18.3 LM: So it's a case of when you build a Convolutional Neural Network in particular, you're learning filters that can isolate features in a map, and a class activation map is where you just figure out where those features are on, you light it up on a diagram with a heat map or something like that. And that is a type of attention mechanism. There are also other ways of you being able to pick out attention within a machine learning model or something like that. Class activation maps are a very common one that are used in Computer Vision. Anything that you do, Convolutional Neural Networks, to be able to identify features, there are... Sometimes also use used Convolutions for sequence maps, so if you wanna predict weather in the future or something like that, you may use a one-dimensional convolution on that, and you can potentially have a class activation map there where it spots like, \"Hey, when you got a spike followed by a dip\", in this kind of thing, then that's usually followed by something else. But typically, it would be in an image-based one, it's where it's most commonly used."}],"markDefs":[],"style":"normal"},{"_key":"02593ec770dc","_type":"block","children":[{"_key":"3ff90b84b4930","_type":"span","marks":[],"text":"0:25:17.6 RS: I like how you mentioned the examples of the smartphone and understanding Hype Cycles, I'm curious if there are any lessons you think we can learn from the way that, that sort of technology was deployed and iterated upon that we can correct or do better with... As AI is sort of spread to the world."}],"markDefs":[],"style":"normal"},{"_key":"3b1a6175dead","_type":"block","children":[{"_key":"bd64c2fc08c90","_type":"span","marks":[],"text":"0:25:35.7 LM: The first part is letting people realize that they are in a hype cycle, we've been in hype cycles before. The people who were successful, were the ones... Or initially successful, at least, were the ones who saw through that, and this is what they did to see through it. Exposure to the platform, exposure to the technology, trying out new and exciting and different things, there's a whole graveyard of failed apps on Android and iOS, which laid the framework and the pathway for those apps that were successful. So really being those kind of early adopters, having that, try what you can, learn, iterate, continue. That's what's led to success, and I think that's the same kind of thing that can lead to success in the AI space."}],"markDefs":[],"style":"normal"},{"_key":"c502b8ebb976","_type":"block","children":[{"_key":"840e0e5d06320","_type":"span","marks":[],"text":"0:26:19.2 LM: One of the advantages of the AI space, is that the amount of investment that you have to make to be successful is a lot less than the amount of investment you might have previously had to make to become the big mobile app developer or to become the big website, and as a result, you don't necessarily have to be housed in the traditional areas on centers of excellence and success. So if we can try to democratize AI as much as possible by making it as available to as many people as possible so that they can seize opportunities that the rest of us may not actually think about, that could pave the way to success for them and for everybody else also. For every success, there's probably going to be a 100 failures, and it's really understanding that, realizing that, but I would rather have a 101,000 people do something so that there's a thousand successes and 100,000 failures, than have 1001 people do it where there's only one success, if my math add up. I told you I'm not very good at math."}],"markDefs":[],"style":"normal"},{"_key":"6a9dabf218b0","_type":"block","children":[{"_key":"fba67323202c0","_type":"span","marks":[],"text":"[chuckle]"}],"markDefs":[],"style":"normal"},{"_key":"3f936a8f42a0","_type":"block","children":[{"_key":"15617db01eaa0","_type":"span","marks":[],"text":"0:27:23.4 RS: Yeah, the one... Yeah, I think that adds up. Of course, the YouTube channel and the MOOCS, and a lot of the content that you produce is any in the interest... It's accessible anywhere. Someone who has internet access can learn from an expert, such as yourself. I do worry though, at what point is there a breakdown in terms of the hardware and the ability to actually design this technology? Does one need access to cloud computing and a work horse of a laptop to be able to play in this field?"}],"markDefs":[],"style":"normal"},{"_key":"105ff11b4334","_type":"block","children":[{"_key":"aa29087d189e0","_type":"span","marks":[],"text":"0:27:53.3 LM: To be able to get started and play in this field, absolutely no. To be able to go huge in this field, you do need access to high-end hardware like GPUs and TPUs and that kind of thing. So to split those two audiences for the Getting Started one, that's where we've been very carefully focused on easy high-level APIs that will run in Python, which is easy to install and use, that you can do on any laptop with the a CPU so that you can get up and running and kick the tires with these kind of things and to make that as quick and easy as possible for anybody to do. When you go beyond that though, and you start trying to train bigger models, not everybody has access to GPUs, not everybody has access to TPUs. So part of our strategy there was, we have this thing called Google Colab, and Google Colab is an in the browser notebook that runs with a Google Cloud back-end that can provide you free access to a GPU or a TPU. Obviously it's limited, but it's pretty generous. It's many hours of training that you can get for that, and all you need is a browser and a web connection to be able to do that, if you don't already have the hardware."}],"markDefs":[],"style":"normal"},{"_key":"f18886976d01","_type":"block","children":[{"_key":"8b89f7cf1e2f0","_type":"span","marks":[],"text":"0:29:00.3 LM: So that's the one first part of the offering. The another part of the offering though, is that when we start thinking about where do your models execute? Okay, so that many models are gonna be built to execute in data centers, the likes of Google or Amazon or Microsoft or on... But that's not the only area of opportunity, we can see that the area of opportunity on mobile handheld devices, embedded systems and all those kind of things is possibly even larger. And with the price of them dropping sharply, the hardware to build a phone is getting cheaper, the hardware to build embedded systems is getting cheaper. Then as long as we have an ecosystem of tools that will allow you to build for them with as low a dollar cost of entry as possible, as low an intellectual cost of entry as possible, those kind of things, that's when those markets can be seeded and those markets can grow. And like I said, I think we can all benefit. Let me share one example, 'cause there's a great project that... It was a couple of years ago, that was built by a bunch of high school and college students in India. And it's called Air Cognizer, I think that's the right phrase."}],"markDefs":[],"style":"normal"},{"_key":"2a1a76f87e3b","_type":"block","children":[{"_key":"ad89d67b8a1e0","_type":"span","marks":[],"text":"0:30:09.6 LM: And it's on the YouTube web... The TensorFlow YouTube website. And what they did was that they realized that in their city in India, there was extensive air pollution. And you know what it's like, we all probably are encountering and nowadays with fires nearby, I live in Washington, so every year we have to start looking at air quality because of forest fires. But what they realized was that, when you look at air quality and you see it on the news, or you see it on a website, that's the air quality at a sensor, which is being operated by somebody. Now that might be 20-30 miles from where you live, and the air quality where you live might be severely worse. Elderly parents that they had and grandparents were afraid to go out because they don't know the air quality and they could get sick. So these students got together and they realized if they get a sensor to measure the air quality, and they get a phone, a cheap Android phone with a camera on it, if they take a picture of the sky, they have data. If they measure the air quality on the sensor, they have a label, and if they go all over their city and they take lots of these pictures and lots of these sensors, you do that basic pattern matching to kind of build a model where you're saying, \"Well, when the sky looks like this, the pollution is like this\"."}],"markDefs":[],"style":"normal"},{"_key":"310f26b0bf6b","_type":"block","children":[{"_key":"a2b7b247b7780","_type":"span","marks":[],"text":"0:31:27.8 LM: And they turned that into an app, and now lots of folks in India can use that app where they can just take a photo of the sky and see a good prediction of the air quality near them, instead of looking at the news and seeing an air quality indicator that could be 20, 30, 40 miles away. And it's like little things like that, little innovations like that, because these were high school and college students, they don't have a lot of money, they're not forming a startup where they're hiring developers to do this kind of thing, the equipment for them to do that, was basic laptops that they had, the data? They generated the data themselves because they had the sensor and they had a cell phone where they could take a picture of the sky, they were able to build a model for this using the open source ecosystem, and they were able to deploy it for free to Android phones."}],"markDefs":[],"style":"normal"},{"_key":"1a1ac4eae0c7","_type":"block","children":[{"_key":"b7de2f29f0870","_type":"span","marks":[],"text":"0:32:12.5 LM: These kind of things, when I talk about really lowering that bar so we could raise the floor, but now it's like, \"Well, the rest of the world can benefit from what they learned\", because we now have the same problem in the West because of forest fires. And I could potentially go out and do the same thing to build an Air Cognizer for Washington State without needing to invest millions of dollars in a start-up to do so. So when you bust through that hype cycle and you understand how this works, then you can think like that, and that's what they did, they thought like that, and boom, they came up with this really cool solution."}],"markDefs":[],"style":"normal"},{"_key":"248603419bad","_type":"block","children":[{"_key":"cad5eb09fa920","_type":"span","marks":[],"text":"0:32:42.8 RS: This is the focus of your, about to be published, new book. Is that correct?"}],"markDefs":[],"style":"normal"},{"_key":"73077794fffa","_type":"block","children":[{"_key":"50140d2c295b0","_type":"span","marks":[],"text":"0:32:47.1 LM: Yep, so it's an AI and Machine Learning for On-Device Development is my upcoming book. I originally was gonna create this mega-book for O'Reilly called AI and Machine Learning for Coders. We realized this weighed too much for one book."}],"markDefs":[],"style":"normal"},{"_key":"063742ea0d42","_type":"block","children":[{"_key":"4ff13d8cbfc50","_type":"span","marks":[],"text":"[chuckle]"}],"markDefs":[],"style":"normal"},{"_key":"0828f610ed76","_type":"block","children":[{"_key":"6770864c034c0","_type":"span","marks":[],"text":"0:33:02.4 LM: So last year, I released the AI and Machine Learning for Coders, and now this year, it's kind of like the complimentary book/sequel, which is a AI and Machine Learning for On-Device Development. So it's really showing you how, as a mobile developer, you can start using models on Android, on iOS and a little sprinkling of doing it in a server with remote access or doing it on things like Raspberry Pi. It's packed with lots of examples of things like, you take a picture, here's how you can detect a face in the picture. Or here's how you can count the number of objects in the picture, like maybe you're building an app that's counting traffic, driving past your house. How do you count the number of cars? Those kind of examples... So I try to get very hands-on with them, of like, here's basically how this stuff works on your device. As of today, you don't train models on the device, you use models on the device. So the concept of my first book, AI and Machine Learning for Coders, or my first book in the series was really, \"Here's how you build the models\", and then the second book is, \"Okay, when you have models or there are off the shelf models available, here's how you use them, or here's how you can customize them to actually use them on your device\"."}],"markDefs":[],"style":"normal"},{"_key":"5dc06bbf5088","_type":"block","children":[{"_key":"d5c1acd601e30","_type":"span","marks":[],"text":"0:34:16.9 RS: Okay, so the model is not constructed locally? The model is accessed?"}],"markDefs":[],"style":"normal"},{"_key":"ee4e9241e698","_type":"block","children":[{"_key":"d0baecd49ba00","_type":"span","marks":[],"text":"0:34:20.9 LM: Yeah. As of today, trying to train a model on a mobile device, it's just going to be very hostile towards your battery because model training is very intensive. We are doing a lot of work on making that better, but as of today... Yeah, as a developer, you're better off training a model in the cloud with something like Colab, or on your developer workstation and then deploying it to your device."}],"markDefs":[],"style":"normal"},{"_key":"c2a221dc9cbd","_type":"block","children":[{"_key":"6da05a39a2040","_type":"span","marks":[],"text":"0:34:46.4 RS: Yes."}],"markDefs":[],"style":"normal"},{"_key":"4537d417c56e","_type":"block","children":[{"_key":"246492df4ca60","_type":"span","marks":[],"text":"0:34:47.3 LM: But that's changing. That is changing."}],"markDefs":[],"style":"normal"},{"_key":"876853926df0","_type":"block","children":[{"_key":"f8b0f4ac27ba0","_type":"span","marks":[],"text":"0:34:48.1 RS: Yeah. Well, fans of this podcast will remember our episode with Sama CEO, Wendy Gonzalez, who was speaking about this similar kind of problem of, \"How do we democratize access to AI?\" and I can envision an approach to that, which is just drop a 100 copies of your book and a 100 Android devices, just anywhere in the world and let a rip, right?"}],"markDefs":[],"style":"normal"},{"_key":"69440ecfcf11","_type":"block","children":[{"_key":"872ffcf798af0","_type":"span","marks":[],"text":"0:35:10.2 LM: Yeah, yeah, please do. I'd love to see the results."}],"markDefs":[],"style":"normal"},{"_key":"216db2b9db7f","_type":"block","children":[{"_key":"12cf77030aa30","_type":"span","marks":[],"text":"0:35:16.8 RS: Laurence has published all manner of content about the realities an opportunities of AI, both philosophical and technical. In the episode description, you'll find links to his MOOCs, books, and the TensorFlow YouTube channel where he frequently contributes. You can also find Laurence's resources on the new, How AI Happens, LinkedIn group. Here, we'll post all the research and resources mentioned by our guests and give you the opportunity to rub shoulders and ask follow-up questions with the experts you hear featured on the show. Just search How AI Happens on LinkedIn and say, hello. How AI Happens is brought to you by Sama. Sama provides accurate data for ambitious AI. Specializing in image, video and sensor data annotation and validation for Machine Learning algorithms in industries such as transportation, retail, e-commerce, media, MedTech, robotics and agriculture. For more information, head to sama.com."}],"markDefs":[],"style":"normal"}],"estimatedReadingTime":45,"featured_image":{"_type":"image","asset":{"_ref":"image-1502043edcf701cb4267cb2f6d7c6edf8e0e0cad-2500x1313-png","_type":"reference"}},"plaintextBody":"Many of the exciting advances in AI have resulted from well-funded companies and research departments, stocked with high-performance computers and every shiny toy the AI practitioner could want. But according to Laurence Moroney, Lead AI Advocate at Google, that’s not the only way to develop artificial intelligence.\n\n\n\nSo these students got together and they realized... if they take a picture of the sky, they have data. If they measure the air quality on the sensor, they have a label.\n\nLaurence joined our podcast, How AI Happens, to share examples of exciting advances in AI that are happening all over the world, many with no more than basic mobile devices. Laurence and his team have made it their mission to evangelize the opportunity of AI and work towards democratizing access to the technology’s development, a mission they accomplish via MooCs, YouTube, and a series of books on AI development. \n\nIn this episode, Laurence shares the nature of AI hype cycles, how AI practitioners can navigate them within their own organizations, and some of the amazing opportunities coming into play when access to AI \u0026 ML is made global. You can stream the full episode below, tune in via your favorite podcasting app, or read the whole transcript below.\n\n(audio embed)\n\nTranscript:\n\n0:00:00.0 Laurence Moroney: And then when they fed this back through an intention mechanism, they realized they didn't build a camouflage detector, they built a cloudy sky detector.\n\n0:00:12.2 Rob Stevenson: Welcome to 'How AI Happens', a podcast where experts explain their work at the cutting edge of artificial intelligence. You'll hear from AI researchers, data scientists and machine learning engineers, as they get technical about the most exciting developments in their field and the challenges they're facing along the way. I'm your host, Rob Stevenson, and we are about to learn how AI happens.\n\n0:00:42.0 RS: You don't have to be an AI expert to be skeptical about all the hype surrounding artificial intelligence and machine learning. Every company claims they have it, every sales deck mentions it, and worse, the media act as if the rise of the machines is happening sometime in late 2022. But amidst this hype cycle, those in the know understand the opportunity has never been greater. Enter Laurence Moroney. He's an industry veteran who has authored several books on AI development and even advises British Parliament on their AI approach. His mission in his role at Google is to evangelize the opportunity of AI and work towards democratizing access to the development of this technology.\n\n0:01:25.3 LM: I'm an AI lead at Google, so I lead the developer advocacy team, and our job is really to help inform and inspire the world around machine learning, artificial intelligence, deep learning and all that good stuff. So working with developers, working with communities, universities, all of those kind of folks to really help scale out the message and the opportunity that's there with AI.\n\n0:01:47.4 RS: Laurence joined the podcast to discuss the nature of AI hype cycles, how AI practitioners can navigate those cycles within their own organizations, and some of the amazing opportunities coming into play when access to AI and ML is made global.\n\n0:02:01.8 LM: As for my background, I was doing developer advocacy for a few years prior to Google, at places like Microsoft, a wonderful start-up in Israel, called Main Soft, and at Reuters, the news agency, kind of doing an internal advocacy role there, and then prior to that, the typical software engineer, all of those kind of things. Although my background at school was actually physics, my degree was in physics, but I came to the realization that nobody hires physicists, or very few people hire them, and I guess I wasn't good enough a physicist to be hired, so I ended up in this wonderful field instead.\n\n0:02:37.9 RS: It's interesting, you're the second individual I've spoken to, who got their start in physics and now have a career in AI. Is that a natural progression? What do you think is the link there?\n\n0:02:48.2 LM: I honestly... I don't think there is a natural progression, it's probably just a happy coincidence and maybe you're over-fitting in your audience. Sorry, AI joke there. For me, my path to AI actually came... It was really interesting that... 'cause when I first graduated college as a physicist, and it was in the UK, and it was in the middle of the worst recession that they had had since World War II. The current one, obviously, 'cause of COVID, is even worse. But back then, this was a pretty bad one, there was no kind of jobs or anything. And the government launched an initiative in 1992, the UK government, that they were gonna put together a cohort of 20 people to become AI specialists who could maybe be form the backbone of trying to help industry through AI and all of that kind of thing. And they needed people who were smart, but unemployed, and I at least fit one of those criteria, and I was unemployed, but we kinda did this battery of tests, it was like these kind of strange movies kind of thing, and I was accepted into the cohorts, which was really, really cool. And then I guess I got bitten by the AI bug then.\n\n0:03:53.7 LM: But in 1992, trying to do any kind of AI program was intensely difficult, it really didn't have any practical use. We were learning the languages like Prolog and LISP, and there was no industrial use for them, but there was some really fun academic stuff that you could do. But in the end, the program failed completely, but the potential was there, and I gotta give credit to the UK government, of figuring this out back in 1992. They were a little bit early, but it was really cool that they did it. It's funny that recently, in the last couple of years, I've been doing briefs to the UK governments, around AI, and I was like, \"Hey, do you know about that program?\" And of course, the MPs there, they're all long gone, the ones that did it. And the current ones were like, \"Did we really do that? That's awesome.\" I guess that's what got me bit by the bug and that led me down a career of programming and software engineering, to get me where I am today.\n\n0:04:45.9 RS: I'm interested to hear that you are spreading this message of the opportunity of AI, but then you also see all of these companies who are sort of saying they have AI or using AI in their messaging. Is there a gap of actual technology there? What is the difference between the reality of the technology and maybe the hype surrounding it?\n\n0:05:04.7 LM: Yeah, it's a great question. And by the fact that there's so many people doing this and waving around the AI magic pixie dust, hoping for customers or VC funding, that... If nothing else, that is a signal that this technology does have legs. The question is, does it get lost in the hype cycle or do we bust out of the hype cycle and start doing something really interesting? I always like to talk about, there's the... Gartner has this hype cycle curve, where you start with the peak of inflated expectations, and then you drop into something called the trough of disillusionment, and then once you're in the through of disillusionment, that's when you can really understand what the technology is and then you start climbing up through the plateau of productivity. And the kind of behavior that you're talking about just means that we're kind of on the wrong side at the moment, of this peak of inflated expectations. Part of what I'd like to describe my job as, is to do some quantum tunneling through that peak and end up in the trough of disillusionment. So I'm a professional disillusioner.\n\n0:06:02.9 LM: And then once you get into that and you understand what the technology actually is and what it does, then you can start being really useful with it. Obviously, you can look to the past to be able to predict the future. And in my career, there have been two massive tectonic shifts in computing. The first was really the widespread advent of the web and internet technology. The second was the smartphone. And if you think about, exactly the same thing happened in both those cases. I'll talk about the smartphone, which is the more recent one. So the hype cycle at the time was like, \"Throw away your desktop PC, throw away your laptop. You'll be able to do everything on your phone.\" And it's like, \"Forget about Office Suites, forget about programming environments, all of these kind of things. You're gonna get your phone, you're gonna plug it into a station on your desk and a big monitor will magically appear and it'll change how work is done.\" Well, that didn't happen. That to me, was a great example of the hype around the smartphone. But the smart phone still was a massive revolutionary technology that created a tectonic shift in the industry. I saw a stat, the largest creator of jobs in Western Europe during COVID, was the smartphone ecosystem. So not just people building smartphone applications, but people using them, and all of the stuff around that, like delivery services and all that type of stuff.\n\n0:07:23.8 LM: So we could see, that revolution started in 2007, and even now, 14 years later, the economy is benefiting greatly from it. The web revolution, the same thing, there was a whole ton of hype around the web, every shop in existence will go out of business, libraries will close. There was disruption and there were changes as a result of the web, but of course there was, I believe, an overall net gain. So when you start seeing these kind of things like when the hype first came in, but the people who were able to see through the hype and to be able to do something reasonable and productive when they fell into the trough of disillusionment, created whole new industries. Google came out as a result of the web, Amazon, Facebook, the Apple are the highest market cap company in the world right now, and that came as a result of the smartphone revolution. So there's so much that can happen when you can understand the actual limitations, start building to them and then rise up through that plateau of productivity as it's called in the Gartner Hype Cycle.\n\n0:08:28.1 LM: And that's really what I'm here to do, that's my role at Google, is to help people who are technically savvy to understand, \"Here's the possibility of things that you can do. Here's what you need to communicate within your business,\" and so when your product managers or when your CEO is wanting to wave that AI magic pixie dust, that kind of stuff, then it's the case, well, you can be the person who's got the expertise, who's able to say, \"I know this domain, and here's where AI can be used in this domain for real.\" And it might be nice to attract attention through marketing or through VC, but when you build a real product and you start building a real market around that, that's when the business can take off.\n\n0:09:09.7 RS: So if I'm an AI practitioner and I am contending with the hype around AI, or the example you gave of the CEO who's white boarding, \"Can we do this with AI?\" How can I level set expectations? There seems to be this little bit of education necessary, to make sure that people are steeped in reality when it comes to, \"What can this technology do? And what can you reasonably expect within your organization?\"\n\n0:09:34.5 LM: Yeah, I think effective communication is the number one tool, managing upwards like that is the number one tool. I've had a number of those conversations with folks who just thought that they can wave their arms and say, \"AI,\" and then find a programmer who could build the AI for them as they envisage it. But then to kinda just talk them through, \"Well, this is how it actually works, this is what it actually is. And if you wanna reach these goals, here's the kind of work that you would need to do, to be able to reach them.\" And often, it's setting lower goals and having a plan to be able to reach those lower goals and then use that as a plateau to go further and further and further. And I find in general, like CEO speak or CXO speak, they like that, instead of a yes person going, \"Yes, we can do whatever your vision is,\" that kind of thing, to actually be able to say, \"Well, here's a plan for how we can get to a very profitable future. It may not be the vision that you have, but it's concrete,\" and often, the folks in that level see themselves as the inspirational folks who get the plan moving in that direction by setting the goal and setting the long-term vision.\n\n0:10:45.8 LM: And when somebody can communicate up like that to say it's like, \"Well, we can't reach the exact nirvana that you're specifying, but we can build great products to do A, B, C and D, not all the way A through Z, and we can do it in this time frame,\" that, having that level of expertise to be able to speak to that comfortably and realistically, ends up being, I think, a great gift for everybody. If we go back to the conversation of what AI is and what AI isn't, is that I always like to draw this diagram that I say, \"Okay, here's traditional programming,\" and traditional programming, I draw it as a box, and that box is saying, \"You're putting rules in, you're putting data in and you're getting answers out.\" This is what programmers and the software department in your company have been doing since the dawn of software time, and the case is, what a programmer does is, they have to figure out how to express those rules in the programming language, so computers can do the work.\n\n0:11:36.2 LM: So for example, a very simple thing, like in financial services, there's a ratio called the price over earnings ratio, that's often a good one to determine the value of a company or one of the signals to determine the value of a company. And that's a very simple rule. Get the data of the price, get the data of the earnings, divide one by the other, and then you get an answer. There's obviously far more complex ones than that, but I like to use that one as a simple example. And you hire programmers because they know how to express those rules in a programming language and run them in an infrastructure. In the machine learning and AI world, I flip the axis around on that box. So instead of you trying to figure out the rules, you give the machine the answers and the data, and you have it figure out the rules. So for something like price over earnings, it's overkill, you don't need to do it. But what if there are patterns in your data that you don't see?\n\n0:12:26.5 LM: There are things about this company, and you can get a wealth of data around a company that you're doing an analysis on, and you can see that this company has done extremely well in the stock market, but you have no idea why, and this company has done extremely well, and you have no idea why, and then these bunch have done badly and you've no idea why. So then you have the answers, they've done well, they've done badly. You have the data, and the idea behind machine learning and AI is then, you can build a system that can do that pattern matching of the answers to the data and figure out what the rules are, to be able to do that.\n\n0:13:01.1 LM: So for you to do that effectively, you need good data scientists. It's not just, you get a shovel and you throw the data into the machine and something magic happens. You have your data scientists to try and make this as efficient as possible by picking the columns in the database or maybe doing feature crosses on those columns, where multiply this one by this one, that kind of thing. And the same way as your coders today, they're not just typing on a keyboard and stuff magically appears, they are figuring out the rules, they're figuring how to scale them. And that's really where the magic of good data science department applies, and so you've got skilled people who know the domain data, who know how to build models, so that the data is being used efficiently, so you can train a model in a couple of hours instead of a couple of decades, and that kind of thing. So it's like, that's where those folks, beyond trendy, really, really can show massive value for the company. And I'd say the same analogy, if you can get a programmer to build an effective program that runs your business in a day or a week, as opposed to an ineffective programmer who takes years to do the same task.\n\n0:14:07.6 LM: The same kind of thing can be applied with data scientists, that they can figure out which parts of the data to shovel, which parts not to shovel, they can figure out how to label those answers and all of those kind of things, so that the machine learning engineer can do their job effectively.\n\n0:14:21.7 LM: The way I generally like to define AI itself is, when you make a machine that responds the same way that an intelligent being would respond. So computer vision is a good example of that, is that if I show you a picture of a cat... If I show you a picture of my pet, you would say, \"That is a dog.\" Showing a computer a picture of my pets, prior to AI machine learning, deep learning, it would see a whole bunch of pixels and it has no parsing of the content, other than white pixels, blue pixels, those kind of things. When you start using machine learning and deep learning to then kind of train a computer to understand the difference between a cat and a dog, and then I show it this picture of my pets, and the computer will say, \"That's a dog.\" Now, the computer is responding in the same way as an intelligent being would respond, and that to me, is what artificial intelligence is all about. So you play it a sound, and instead of it saying, \"Here's a number of audio levels,\" it's actually able to determine your speech and to determine what you're saying, the same way as an intelligent being would. That to me, is artificial intelligence.\n\n0:15:31.6 LM: There are lots of ways that you can get there. Machine learning, deep learning are probably the most efficient way for things like computer vision, for audio processing, for tax processing and those types of things. So if we think about it and what it is... In terms of what it is and what it's not, it's not this magic thing that you can just say, \"We're gonna... Like in a Dilbert cartoon, we're gonna say, \"Let's put machine learning and artificial intelligence into our product and we get an upgrade.\" It doesn't really work like that.\n\n0:15:58.7 RS: The training is in the interest of an inference. When your technology can make an inference, an accurate inference, it has mimicked human cognition, right?\n\n0:16:06.5 LM: Yeah, exactly. And the nice thing is then, it can even go beyond human cognition, and let me give an example of this, that blows my mind. And so we worked on a project for diabetic retinopathy, at Google, where diabetic retinopathy is the world's leading cause of blindness. And the thing about it is that, it's easy to diagnose and it's easy to cure with early diagnosis. India has the world's second largest population, but it has a shortage of over 100 thousand qualified ophthalmologists. So we worked with doctors and hospitals in India to gather lots and lots of retina scans, to see... We'd label these retina scans... Data plus answers. We'd label these, based on those five different buckets, no diabetic retinopathy, all the way up to severe, and trained a machine learning model on this, to be able to be an artificial intelligence to respond the way an ophthalmologist would, and it ended up, like the publications that we did in various journals, showed that it was at least equivalent to a qualified ophthalmologist and often better. And so, that's the first mind-blowing part.\n\n0:17:13.5 LM: But then the second mind-blowing part, and the one that really hooked my interest in this was then a scientist within Google was looking at the data and realized, we don't just have labels of the diagnosis, we also have labels of the person's birth gender, or the person's age, or the person's blood pressure.\n\n0:17:33.6 LM: Now, an ophthalmologist can look at the scan of an eye and see blood clots and determine do they have diabetic retinopathy or not, but an ophthalmologist can't look at that scan and pick their age, or pick their gender. And so what if you have all of this data, you have your answers, you have your data, what if we could feed this into a model and do it? And it ended up, they trained a model that was 98% accurate in picking the assigned gender at birth, which is as good as, if not better than the average human, but obviously much better than a human looking at a retina, that kind of thing. It would be 50-50, it would be a coin flip. But it was 90% accurate, and it was also able to predict their age, with a mean average error of about three years.\n\n0:18:19.1 LM: And a few times in the past, I've told this story to an audience and I'd asked the audience to guess my age, and on average, the audience was... The mean average error from the audience was way more than that, and they're looking at me, they're looking at my gray hair, they're looking at my mannerisms, they're not looking at my retina, and they're still getting it even more wrong than this was... Again, looking at the retina. So we talk about human cognition and that kind of stuff, but in some ways, doing this kind of pattern recognition, we can go beyond human cognition, with examples like that one. If you have the data and if you have the labels that it's possible now for a machine to be able to do the matching of that data to that label and spot patterns that you as a human, wouldn't previously spot, and then there's massive, untold opportunities in that. So again, if we get down into that trust of disillusionment, and part of that is, I'm saying Machine Learning is fancy pattern matching.\n\n[chuckle]\n\n0:19:13.8 LM: And that kind of thing. There's nothing magical about it. And then when you understand that and you say, \"Well, I have this wealth of data in my business, can I find new business opportunities with this?\" And the answer to that, then is potentially, yes. In the same way as that scientist at Google was able to build a system to be able to predict somebody's age from a retina scan, which nobody knows how you can look at a retina and determine an age. From the model that they built, so you can now do an audit of that, and there's something called attention mechanisms, so you can see where the computer is paying attention to, to be able to derive what it is in a retina that let's you pick somebody's age. But it's like those are the kind of things that now, that the brute-force aspect of sheer compute power, doing that kind of pattern matching allows you to come up with these new scenarios that will rise you up through that plateau of productivity.\n\n\n\n0:20:07.3 RS: Yes, so you said it was an attention mechanism? And this allows you to clue in on, this is the variables that it was taking into account to result in this insight?\n\n\n\n0:20:18.1 LM: Yeah. Exactly, exactly. I teach it in one of my Coursera courses. I do advanced computer vision. And there's one really fun example that we go through in that one, it's not the retina one, that one is a little bit too complex, but there's a very famous machine learning exercise, which is pictures of cats and dogs that I was talking about earlier on, and how you train a computer to be able to recognize the difference between a cat and a dog. And you build a machine learning model in the course that can quite accurately tell the difference between a cat and a dog. But then you also do the attention mechanism stuff on that. And it turns out the primary difference that in this case, the computer was looking at, to pick the difference between a cat and a dog was the eyes. Sometimes you think, \"Oh the cat has pointy ears, the dog has floppy ears, for the most part\" or \"Their noses look differently\", but for the most part, when this model was actually working to pick the difference, it was like those were the features that it had zeroed in on and so then I was able to learn from that and go, \"Aha, so now when I build a model, maybe I should focus on the eyes to be more efficient\", that type of thing.\n\n0:21:16.7 RS: Yes, it strikes me as a crucial mechanism in removing harmful biases, for example, from a black box AI, from being able to look under the hood and say, \"Okay, this is what it was looking at to get this insight\". That can help remove a lot of this fear and a lot of these potentially, harmful biases or incorrect assumptions that technology would make.\n\n0:21:41.9 LM: Yeah, yeah, exactly. And there's a technique, it's also called... There's a thing that you can build, called a class activation map, and the idea with the class activation map is, you're seeing what the computer was paying attention to. A funny story about them, the US Army, realized that maybe computer vision could be used to see things and images that humans couldn't see. And say take for example, on the battlefield, what about being able to see a camouflaged tank? That like a human could look at it, camouflage is designed to fool the human eye, but what if you could have a machine be able to detect like a camouflage camouflaged tank? So they did an experiment where they got a bunch of data scientists and a bunch of machine learning engineers and they gave them a tank, and they said, \"Hey, you go out into the woods and one day take a whole bunch of pictures of this tank un-camouflaged\", and then the following day, they got the camouflage nets, and they put the camouflage nets on the tank and take a whole bunch of pictures of this tank camouflaged. And so build a model off of this one to see if you can pick a camouflage tank or a non-camouflage one, and they did what all good data scientists do, they had a training set of data, they had a test set of data, they had a validation set.\n\n0:22:54.3 LM: They built their model, they ran it and it was like 99% plus accurate. And they were like, \"Oh my gosh, we have built something that can really, really change the course of the battlefield\". They presented that to the Army, the Army loved it, and then they took it out and tested it and it failed completely.\n\n0:23:10.8 RS: Oh no. [chuckle]\n\n0:23:12.5 LM: And the reason why it failed completely was that, they took the pictures of the un-camouflaged tank one day, and they took the pictures of the camouflaged tank on another day. And on the day that they took the camouflaged tank, the sky was cloudy, and on the other day they had a blue sky, and then when they fed this back through an intention mechanism, they realized they didn't build a camouflage detector. They built a cloudy sky detector. [chuckle] So with the black box element of this kind of thing, it's easy to think that these are hard to debug and that kind of stuff, but they're not necessarily that difficult to debug if you understand how they're architected, and if I gave the elevator pitch for how you to do this, when you train an AI system or a machine learning system, you're flowing data one way and doing back prop the other way, but when you wanna do these attention mechanisms, those kind of things, it's just the way of flowing data in the other direction and effectively de-compiling it. If you're going through convolutions, you're de-convoluting it and that kind of stuff, and you can get a pretty good estimate for how the computer is looking at your data.\n\n\n\n0:24:12.1 RS: What is the difference between a classification map and an attention mechanism?\n\n\n\n0:24:15.6 LM: A class activation map is a...\n\n\n\n0:24:17.1 RS: Yeah. Thank you.\n\n\n\n0:24:18.3 LM: So it's a case of when you build a Convolutional Neural Network in particular, you're learning filters that can isolate features in a map, and a class activation map is where you just figure out where those features are on, you light it up on a diagram with a heat map or something like that. And that is a type of attention mechanism. There are also other ways of you being able to pick out attention within a machine learning model or something like that. Class activation maps are a very common one that are used in Computer Vision. Anything that you do, Convolutional Neural Networks, to be able to identify features, there are... Sometimes also use used Convolutions for sequence maps, so if you wanna predict weather in the future or something like that, you may use a one-dimensional convolution on that, and you can potentially have a class activation map there where it spots like, \"Hey, when you got a spike followed by a dip\", in this kind of thing, then that's usually followed by something else. But typically, it would be in an image-based one, it's where it's most commonly used.\n\n0:25:17.6 RS: I like how you mentioned the examples of the smartphone and understanding Hype Cycles, I'm curious if there are any lessons you think we can learn from the way that, that sort of technology was deployed and iterated upon that we can correct or do better with... As AI is sort of spread to the world.\n\n0:25:35.7 LM: The first part is letting people realize that they are in a hype cycle, we've been in hype cycles before. The people who were successful, were the ones... Or initially successful, at least, were the ones who saw through that, and this is what they did to see through it. Exposure to the platform, exposure to the technology, trying out new and exciting and different things, there's a whole graveyard of failed apps on Android and iOS, which laid the framework and the pathway for those apps that were successful. So really being those kind of early adopters, having that, try what you can, learn, iterate, continue. That's what's led to success, and I think that's the same kind of thing that can lead to success in the AI space.\n\n0:26:19.2 LM: One of the advantages of the AI space, is that the amount of investment that you have to make to be successful is a lot less than the amount of investment you might have previously had to make to become the big mobile app developer or to become the big website, and as a result, you don't necessarily have to be housed in the traditional areas on centers of excellence and success. So if we can try to democratize AI as much as possible by making it as available to as many people as possible so that they can seize opportunities that the rest of us may not actually think about, that could pave the way to success for them and for everybody else also. For every success, there's probably going to be a 100 failures, and it's really understanding that, realizing that, but I would rather have a 101,000 people do something so that there's a thousand successes and 100,000 failures, than have 1001 people do it where there's only one success, if my math add up. I told you I'm not very good at math.\n\n[chuckle]\n\n0:27:23.4 RS: Yeah, the one... Yeah, I think that adds up. Of course, the YouTube channel and the MOOCS, and a lot of the content that you produce is any in the interest... It's accessible anywhere. Someone who has internet access can learn from an expert, such as yourself. I do worry though, at what point is there a breakdown in terms of the hardware and the ability to actually design this technology? Does one need access to cloud computing and a work horse of a laptop to be able to play in this field?\n\n0:27:53.3 LM: To be able to get started and play in this field, absolutely no. To be able to go huge in this field, you do need access to high-end hardware like GPUs and TPUs and that kind of thing. So to split those two audiences for the Getting Started one, that's where we've been very carefully focused on easy high-level APIs that will run in Python, which is easy to install and use, that you can do on any laptop with the a CPU so that you can get up and running and kick the tires with these kind of things and to make that as quick and easy as possible for anybody to do. When you go beyond that though, and you start trying to train bigger models, not everybody has access to GPUs, not everybody has access to TPUs. So part of our strategy there was, we have this thing called Google Colab, and Google Colab is an in the browser notebook that runs with a Google Cloud back-end that can provide you free access to a GPU or a TPU. Obviously it's limited, but it's pretty generous. It's many hours of training that you can get for that, and all you need is a browser and a web connection to be able to do that, if you don't already have the hardware.\n\n0:29:00.3 LM: So that's the one first part of the offering. The another part of the offering though, is that when we start thinking about where do your models execute? Okay, so that many models are gonna be built to execute in data centers, the likes of Google or Amazon or Microsoft or on... But that's not the only area of opportunity, we can see that the area of opportunity on mobile handheld devices, embedded systems and all those kind of things is possibly even larger. And with the price of them dropping sharply, the hardware to build a phone is getting cheaper, the hardware to build embedded systems is getting cheaper. Then as long as we have an ecosystem of tools that will allow you to build for them with as low a dollar cost of entry as possible, as low an intellectual cost of entry as possible, those kind of things, that's when those markets can be seeded and those markets can grow. And like I said, I think we can all benefit. Let me share one example, 'cause there's a great project that... It was a couple of years ago, that was built by a bunch of high school and college students in India. And it's called Air Cognizer, I think that's the right phrase.\n\n0:30:09.6 LM: And it's on the YouTube web... The TensorFlow YouTube website. And what they did was that they realized that in their city in India, there was extensive air pollution. And you know what it's like, we all probably are encountering and nowadays with fires nearby, I live in Washington, so every year we have to start looking at air quality because of forest fires. But what they realized was that, when you look at air quality and you see it on the news, or you see it on a website, that's the air quality at a sensor, which is being operated by somebody. Now that might be 20-30 miles from where you live, and the air quality where you live might be severely worse. Elderly parents that they had and grandparents were afraid to go out because they don't know the air quality and they could get sick. So these students got together and they realized if they get a sensor to measure the air quality, and they get a phone, a cheap Android phone with a camera on it, if they take a picture of the sky, they have data. If they measure the air quality on the sensor, they have a label, and if they go all over their city and they take lots of these pictures and lots of these sensors, you do that basic pattern matching to kind of build a model where you're saying, \"Well, when the sky looks like this, the pollution is like this\".\n\n0:31:27.8 LM: And they turned that into an app, and now lots of folks in India can use that app where they can just take a photo of the sky and see a good prediction of the air quality near them, instead of looking at the news and seeing an air quality indicator that could be 20, 30, 40 miles away. And it's like little things like that, little innovations like that, because these were high school and college students, they don't have a lot of money, they're not forming a startup where they're hiring developers to do this kind of thing, the equipment for them to do that, was basic laptops that they had, the data? They generated the data themselves because they had the sensor and they had a cell phone where they could take a picture of the sky, they were able to build a model for this using the open source ecosystem, and they were able to deploy it for free to Android phones.\n\n0:32:12.5 LM: These kind of things, when I talk about really lowering that bar so we could raise the floor, but now it's like, \"Well, the rest of the world can benefit from what they learned\", because we now have the same problem in the West because of forest fires. And I could potentially go out and do the same thing to build an Air Cognizer for Washington State without needing to invest millions of dollars in a start-up to do so. So when you bust through that hype cycle and you understand how this works, then you can think like that, and that's what they did, they thought like that, and boom, they came up with this really cool solution.\n\n0:32:42.8 RS: This is the focus of your, about to be published, new book. Is that correct?\n\n0:32:47.1 LM: Yep, so it's an AI and Machine Learning for On-Device Development is my upcoming book. I originally was gonna create this mega-book for O'Reilly called AI and Machine Learning for Coders. We realized this weighed too much for one book.\n\n[chuckle]\n\n0:33:02.4 LM: So last year, I released the AI and Machine Learning for Coders, and now this year, it's kind of like the complimentary book/sequel, which is a AI and Machine Learning for On-Device Development. So it's really showing you how, as a mobile developer, you can start using models on Android, on iOS and a little sprinkling of doing it in a server with remote access or doing it on things like Raspberry Pi. It's packed with lots of examples of things like, you take a picture, here's how you can detect a face in the picture. Or here's how you can count the number of objects in the picture, like maybe you're building an app that's counting traffic, driving past your house. How do you count the number of cars? Those kind of examples... So I try to get very hands-on with them, of like, here's basically how this stuff works on your device. As of today, you don't train models on the device, you use models on the device. So the concept of my first book, AI and Machine Learning for Coders, or my first book in the series was really, \"Here's how you build the models\", and then the second book is, \"Okay, when you have models or there are off the shelf models available, here's how you use them, or here's how you can customize them to actually use them on your device\".\n\n0:34:16.9 RS: Okay, so the model is not constructed locally? The model is accessed?\n\n0:34:20.9 LM: Yeah. As of today, trying to train a model on a mobile device, it's just going to be very hostile towards your battery because model training is very intensive. We are doing a lot of work on making that better, but as of today... Yeah, as a developer, you're better off training a model in the cloud with something like Colab, or on your developer workstation and then deploying it to your device.\n\n0:34:46.4 RS: Yes.\n\n0:34:47.3 LM: But that's changing. That is changing.\n\n0:34:48.1 RS: Yeah. Well, fans of this podcast will remember our episode with Sama CEO, Wendy Gonzalez, who was speaking about this similar kind of problem of, \"How do we democratize access to AI?\" and I can envision an approach to that, which is just drop a 100 copies of your book and a 100 Android devices, just anywhere in the world and let a rip, right?\n\n0:35:10.2 LM: Yeah, yeah, please do. I'd love to see the results.\n\n0:35:16.8 RS: Laurence has published all manner of content about the realities an opportunities of AI, both philosophical and technical. In the episode description, you'll find links to his MOOCs, books, and the TensorFlow YouTube channel where he frequently contributes. You can also find Laurence's resources on the new, How AI Happens, LinkedIn group. Here, we'll post all the research and resources mentioned by our guests and give you the opportunity to rub shoulders and ask follow-up questions with the experts you hear featured on the show. Just search How AI Happens on LinkedIn and say, hello. How AI Happens is brought to you by Sama. Sama provides accurate data for ambitious AI. Specializing in image, video and sensor data annotation and validation for Machine Learning algorithms in industries such as transportation, retail, e-commerce, media, MedTech, robotics and agriculture. For more information, head to sama.com.","relatedPosts":[{"_id":"97fe94a6-283f-49a2-9311-96738e00e5c4","featured_image":{"_type":"image","asset":{"_ref":"image-ae9f62c210539de6ed2b60b71efa4be6b90021c6-1920x960-png","_type":"reference"}},"slug":{"_type":"slug","current":"volumental-shoe-sizing-app"},"tags":[{"label":"Case Studies","value":"Case Studies"}],"title":"Accurate Data Labeling Powers the Volumental Shoe Recommendation App — Helping Retailers Convert Mobile Customers"},{"_id":"6aa16e9a-75c4-44f5-8dec-6f1f06fb709e","featured_image":{"_type":"image","asset":{"_ref":"image-0434b713b7dcba1cdf98eff0eb50d7cb3d5fb008-1500x908-jpg","_type":"reference"}},"slug":{"_type":"slug","current":"fast-company-next-best-things-tech-2021"},"tags":[{"label":"Company News","value":"Company News"},{"label":"Awards","value":"Awards"}],"title":"Orbisk’s Sama-Powered Food Waste Solution Named to Fast Company’s First-Ever List of the Next Big Things in Tech"},{"_id":"728400d2-d453-42f7-b20c-47f753bc4583","featured_image":{"_type":"image","asset":{"_ref":"image-1502043edcf701cb4267cb2f6d7c6edf8e0e0cad-2500x1313-png","_type":"reference"}},"slug":{"_type":"slug","current":"podcast-episode-facebook-manohar-paluri"},"tags":[{"label":"Podcast","value":"Podcast"}],"title":"New Podcast Episode: Facebook's Manohar Paluri Makes Machines See"}],"slug":{"_type":"slug","current":"/podcast-google-global-ai-development"},"tags":[{"_key":"saTGs8ZP","label":"Ethical AI","value":"Ethical AI"},{"_key":"jr0XK73o","label":"Podcast","value":"Podcast"}],"title":"New Podcast Episode: Making AI Development Global with Google's Laurence Moroney"}}},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"/podcast-google-global-ai-development"},"buildId":"YkvXBy-diZpsGMy3AZGNl","isFallback":false,"dynamicIds":[4941,425,3551],"gsp":true,"appGip":true,"scriptLoader":[]}</script></body></html>