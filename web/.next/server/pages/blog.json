{"pageProps":{"config":{"footerNav":{"items":[{"_key":"f255606f8f25","_type":"navDropdownMenu","items":[{"_key":"76389ad94cbb","_type":"navItem","title":"Autonomous Transportation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"training-data-for-autonomous-driving"}}}},{"_key":"5f64a8d6a69d","_type":"navItem","title":"E-Commerce","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"training-data-for-ecommerce"}}}},{"_key":"f10e54ae04d0","_type":"navItem","title":"AR/VR","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"training-data-for-ar-vr"}}}},{"_key":"fd729b522a77","_type":"navItem","title":"Data Quality","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"data-quality"}}}}],"title":"Guides","url":null},{"_key":"681ef7d8763a","_type":"navDropdownMenu","items":[{"_key":"6238a422b667","_type":"navItem","title":"Our Story","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-story"}}}},{"_key":"258985d6d46b","_type":"navItem","title":"Our Team","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-team"}}}},{"_key":"e0a76077324a","_type":"navItem","title":"Our Mission","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"mission-vision-values"}}}},{"_key":"239e49661b0d","_type":"navItem","title":"Careers","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"careers"}}}},{"_key":"e005a740cd80","_type":"navItem","title":"Contact","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"company-contact"}}}}],"title":"Company","url":null}]},"logo":{"asset":{"_createdAt":"2021-10-29T18:38:04Z","_id":"image-e20f8cc53e5f74df10ae9a822edb7ec2c4d00f02-2380x636-svg","_rev":"yuZxWYwFNB6KJB4TM9NtaY","_type":"sanity.imageAsset","_updatedAt":"2021-10-29T18:38:04Z","assetId":"e20f8cc53e5f74df10ae9a822edb7ec2c4d00f02","extension":"svg","metadata":{"_type":"sanity.imageMetadata","dimensions":{"_type":"sanity.imageDimensions","aspectRatio":3.742138364779874,"height":636,"width":2380},"hasAlpha":true,"isOpaque":false,"lqip":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAYAAABFA8wzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAr0lEQVQYlU3QyUoDQBAE0HeIEjeixAVyESRI3BNFJSZxAU/+/wdJQSEehu6Zqa6uKnjBGz7xgTuc4gAj7LWe4LD9cc8Y+9jBUed84QGrEt/gEleYY9Ylr3jGU/tV77fFLirId0nWBYYgoACi+r3D6YPN0vwFm4VxmNlgfkK4qcLUZdVMcdHB+75FzWPfzzCpxXNcFxuOP2uxnhNLASaX5LjbnJJf6jYG2PpXh812/AvSEQ+GGZqgYgAAAABJRU5ErkJggg==","palette":{"_type":"sanity.imagePalette","darkMuted":{"_type":"sanity.imagePaletteSwatch","background":"#040404","foreground":"#fff","population":100.29,"title":"#fff"},"darkVibrant":{"_type":"sanity.imagePaletteSwatch","background":"#424242","foreground":"#fff","population":0,"title":"#fff"},"dominant":{"_type":"sanity.imagePaletteSwatch","background":"#040404","foreground":"#fff","population":100.29,"title":"#fff"},"lightMuted":{"_type":"sanity.imagePaletteSwatch","background":"#4c4c4c","foreground":"#fff","population":0,"title":"#fff"},"lightVibrant":{"_type":"sanity.imagePaletteSwatch","background":"#bcbcbc","foreground":"#000","population":0,"title":"#fff"},"muted":{"_type":"sanity.imagePaletteSwatch","background":"#4c4c4c","foreground":"#fff","population":0,"title":"#fff"},"vibrant":{"_type":"sanity.imagePaletteSwatch","background":"#7f7f7f","foreground":"#fff","population":0,"title":"#fff"}}},"mimeType":"image/svg+xml","originalFilename":"image.svg","path":"images/76e3r62u/production/e20f8cc53e5f74df10ae9a822edb7ec2c4d00f02-2380x636.svg","sha1hash":"ae6a56857a230101a883a9b93974923879775bc9","size":2009,"uploadId":"mtOtmqAQnCEIG5cEqXZ1YAOCuqHJ4X3g","url":"https://cdn.sanity.io/images/76e3r62u/production/e20f8cc53e5f74df10ae9a822edb7ec2c4d00f02-2380x636.svg"}},"mainNav":{"items":[{"_key":"58c18e9aa9ea","_type":"navDropdownMenu","items":[{"_key":"b5b5b8bee78b","_type":"navCat","items":[{"_key":"0e80156a2f1a","_type":"navItem","title":"How it Works","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"how-it-works"}}}},{"_key":"40bacee029b4","_type":"navItem","title":"Video Annotation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"video-annotation"}}}},{"_key":"32650ef07503","_type":"navItem","title":"Image Annotation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"image-annotation"}}}},{"_key":"fe9137cd0167","_type":"navItem","title":"3D & LiDAR Annotation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"3d-lidar"}}}},{"_key":"d9a1316d400a","_type":"navItem","title":"Natural Language Processing","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"natural-language-processing"}}}},{"_key":"ac12c7c5d70a","_type":"navItem","title":"Data Curation (Beta)","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"data-curation"}}}}],"title":"Platform","url":null},{"_key":"37ff4fa913bd","_type":"navCat","items":[{"_key":"6026b1a9314e","_type":"navItem","title":"Semantic Segmentation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"semantic-segmentation"}}}},{"_key":"f4611b19b406","_type":"navItem","title":"Polygons","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"polygons"}}}},{"_key":"5155d874d6c8","_type":"navItem","title":"Bounding Boxes","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"bounding-boxes"}}}},{"_key":"9ef3c1e21e74","_type":"navItem","title":"Key Points","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"key-points"}}}},{"_key":"314d4c00d351","_type":"navItem","title":"Cuboids","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"cuboids"}}}},{"_key":"8e17a6388d74","_type":"navItem","title":"Lines & Arrows","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"lines-and-arrows"}}}}],"title":"Shapes","url":null}],"title":"Platform","url":null},{"_key":"112867ca4d03","_type":"navDropdownMenu","items":[{"_key":"22699c7e06cb","_type":"navItem","items":null,"title":"Transportation & Navigation","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"transportation-navigation"}}}},{"_key":"122ae5928d6d","_type":"navItem","items":null,"title":"Retail & E-Commerce","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"retail-ecommerce"}}}},{"_key":"7bb234b69fb0","_type":"navItem","items":null,"title":"Consumer & Media","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"consumer-media"}}}},{"_key":"33e6a886b39d","_type":"navItem","items":null,"title":"Biotech & Medtech","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"biotech-medtech"}}}},{"_key":"d095b2619c4e","_type":"navItem","items":null,"title":"Robotics & Manufacturing","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"robotics-and-manufacturing"}}}},{"_key":"2c4b82a94d79","_type":"navItem","items":null,"title":"Food & Agriculture","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"training-data-food-agriculture"}}}}],"title":"Industries","url":null},{"_key":"c47e8763a906","_type":"navDropdownMenu","items":[{"_key":"1d563df30b3f","_type":"navItem","items":null,"title":"Quality","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"quality-training-data"}}}},{"_key":"041725f35d96","_type":"navItem","items":null,"title":"Security","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"security-and-trust"}}}},{"_key":"fd64ede25798","_type":"navItem","items":null,"title":"Ethical AI","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-impact"}}}},{"_key":"398dcbb1c95d","_type":"navItem","items":null,"title":"Compare","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"compare"}}}},{"_key":"93bdfdd87879","_type":"navItem","items":null,"title":"Partners","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"partners"}}}}],"title":"Why Sama","url":null},{"_key":"1d38bf63df54","_type":"navDropdownMenu","items":[{"_key":"be81659b38a5","_type":"navItem","items":null,"title":"API Documentation","url":{"_type":"link","externalUrl":"https://docs.sama.com/reference/overview","internalLink":null}},{"_key":"2cec80e94962","_type":"navItem","items":null,"title":"Blog","url":{"_type":"link","internalLink":null,"internalLink_custom":"/blog"}},{"_key":"09e284fcb1d3","_type":"navItem","items":null,"title":"Events","url":{"_type":"link","internalLink":null,"internalLink_custom":"/events"}}],"title":"Resources","url":null},{"_key":"dbee93713c19","_type":"navDropdownMenu","items":[{"_key":"12d594a568bf","_type":"navItem","items":null,"title":"Our Story","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-story"}}}},{"_key":"ce36540a102d","_type":"navItem","items":null,"title":"Our Team","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"our-team"}}}},{"_key":"34fc328e8022","_type":"navItem","items":null,"title":"Careers","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"careers"}}}},{"_key":"c1fe2961020a","_type":"navItem","items":null,"title":"Contact","url":{"_type":"link","internalLink":{"slug":{"_type":"slug","current":"company-contact"}}}},{"_key":"ebd81873e538","_type":"navItem","items":null,"title":"Press","url":{"_type":"link","internalLink":null,"internalLink_custom":"/press"}}],"title":"Company","url":null}],"nav_cta":{"_type":"button","link":{"_type":"link","internalLink":{"_ref":"136788cb-06a6-4f27-b75b-07faf403bfa6","_type":"reference"}},"title":"Request a Demo","type":"secondary"}}},"topPost":{"_createdAt":"2021-12-07T00:18:48Z","author":{"_id":"e8a1f3c6-0b07-4638-93d5-61a0924f32e3","avatar":{"_type":"image","asset":{"_ref":"image-2f8efc599a377bd580d0ae12f022a15e7e1acacd-632x676-webp","_type":"reference"}},"bio":"Amanda is the Content Marketing Manager at Sama, where each day she gets to learn about AI and how it’s transforming industry. She’s passionate about technology but periodically tries to get away from her computer to explore more analog things like collage and quilting.","name":"Amanda Durepos","slug":{"_type":"slug","current":"amanda-durepos"}},"config":{"description":"Learn how Volumental partnered with Sama to accurately label the datasets that fuel the computer vision technology for their mobile foot scanning app.","openGraphImage":null,"title":"Accurate Data Labeling Powers the Volumental Shoe Recommendation App — Helping Retailers Convert Mobile Customers"},"estimatedReadingTime":7,"featured_image":{"_type":"image","asset":{"_ref":"image-ae9f62c210539de6ed2b60b71efa4be6b90021c6-1920x960-png","_type":"reference"}},"plaintextBody":"Volumental produces shoe recommendations for millions of shoppers by leveraging a combination of 3D foot scans, retail purchase data, and AI. Their team partnered with Sama to label the datasets that fuel the computer vision technology for their mobile foot scanning app — one piece of Volumental’s technology suite which empowers retailers and brands to create frictionless and more personalized experiences for their customers, both in-store and online.\n\nOrdering shoes online can feel like a gamble. How many of us have anticipated the arrival of a fresh pair of sneakers, only to have to promptly return them due to poor fit? According to one study, about 52% of us have experienced that disappointment.\n\nShoe size labels can be a poor indicator of actual fit, both across categories of footwear and even within the same brand. And with an estimated $428 billion in merchandise returned to retailers in 2020, there exists a huge opportunity for retailers and brands to do some damage control.\n\nFor Sweden-based Volumental, the answer isn’t to solve for consistency or standardization within the shoe manufacturing process, but rather to leverage AI to deliver more accurate fit recommendations: an industry segment they are dubbing FitTech™.\n\n\n\nAI can help deliver more delightful, personalized retail experiences\n\n\nFor many years, Volumental has been outfitting shoe retailers with in-store scanners which capture 3D scans of customers’ feet within seconds. These scans are cross-referenced with their extensive database of retail purchase data to deliver product recommendations to shoppers, based on accurate foot measurements and the purchase behavior of consumers with similar feet.\n\nThis technology empowers shoppers to make good buying decisions, but it also supplies retailers with data-driven insights to help them provide more personalized recommendations to consumers both in-store and online.\n\nArmed with millions of foot scans and a database of purchase behavior from customers of nearly 100 of the world’s top retailers and brands, Volumental then set out to tackle the challenge plaguing e-commerce stores and shoe-wearers everywhere: online returns due to poor fit.\n\n\n\n(Image source: Volumental website.)\n\nThe Volumental mobile app delivers the same benefits to consumers, but this time, from the comfort of their homes. The user experience is seamless: take a few photos of your feet from key angles and receive accurate foot measurements along with data-backed recommendations for shoes that are sure to fit like a glove.\n\nData labeling challenges for high-precision foot scanning\n\n\nThe Volumental mobile app user experience may be straightforward, but the challenge of developing this technology was not. To deliver a seamless experience in the app, Volumental had to solve a range of technical problems.\n\nWhile the LiDAR capabilities that come equipped in modern-day smartphones work well to make many AR experiences more accurate and realistic, they are not useful for foot scanning. Existing AR frameworks on the market did not provide the level of accuracy required for Volumental’s mobile foot scanner, so they set out to build their own proprietary models.\n\n\n\nThese images of Volumental employees’ feet show the difference between foot scans reconstructed with sensors native to modern smartphones (left) vs the level of precision required to train their own proprietary models: pixel-perfect masks (right). (Source.)\n\n\nTo obtain the high-accuracy segmented images they needed to power their mobile scanning, Volumental began the search for a data labeling partner. They knew that the dataset had to adhere to an extremely high standard of quality if their mobile solution was to deliver the seamless experience their users were accustomed to in-store.\n\nMikael Andersson, Sr Product Owner at Volumental explained why this requirement was imperative:\n\n“For our mobile app, we needed extremely precise segmented data because we knew that every missed pixel would easily add up to millimeters of lost accuracy.” \n\nIn addition to a high standard of label quality, the data labeling project would also require annotators to know how to handle edge cases such as shadows, low-contrast light, and occlusions. These exceptions needed to be handled with consistency if the training data was to make Volumental’s algorithms behave predictably. For these edge cases, and to ensure that their solution would be able to scale without compromising quality, Volumental needed tight feedback loops to keep their models high-performing. \n\nTo meet all these requirements, Volumental partnered with Sama to deliver high-precision segmented labels for their datasets. Mikael explains:\n\n“Having worked with different cloud providers where the staff doing the actual work was always very hidden from us, we appreciated the transparency Sama gave us. They were communicative and very easy to work with from data collection to project management.”\n\nDelivering a delightful and uncompromisingly accurate experience to their users was important to Volumental, but so was social sustainability. As CMO Brent Hollowell explained, building a mass-market experience that is representative of the world must include diverse and representative datasets:\n\n“At the core of our interest in social sustainability are inclusivity and cultural diversity. Diversity of data is the strength of our AI-powered Fit Engine and it's also what helps us succeed as a company.”\n\nPartnering with Sama assured Volumental that the diversity of their datasets would be accurately represented in their models: to deliver hyper-personalized experiences to delight their users across the globe.\n\n\n\nBetter labels lead to better business outcomes\n\n\nIn part thanks to accurately labeled data, Volumental is creating more delightful omnichannel shopping experiences for consumers. Accurate 3D foot scans are just one piece of the puzzle: combined with their extensive database of purchase behavior and proprietary ML algorithms, Volumental can deliver hyper-personalized recommendations to consumers.\n\nThese recommendations don’t only provide better shopping experiences for users, they remove friction from the buying process and result in fewer online returns. The end result? Happy, loyal customers and ultimately, more revenue for retailers and brands — all thanks to AI-powered fit recommendations.","slug":{"_type":"slug","current":"volumental-shoe-sizing-app"},"tags":[{"label":"Case Studies","value":"Case Studies"}],"title":"Accurate Data Labeling Powers the Volumental Shoe Recommendation App — Helping Retailers Convert Mobile Customers"},"firstLoad":[{"_createdAt":"2021-12-07T00:12:33Z","author":{"_id":"0777f190-31e5-4a96-8066-90408db3cbc2","avatar":{"_type":"image","asset":{"_ref":"image-b1d5a2763e0b0ebd8c70e731c1e0f37a76c995f7-450x450-jpg","_type":"reference"}},"bio":"Suzin Wold is the Chief Marketing Officer at Sama, where she is helping companies deploy innovative and impactful AI technology. Suzin has 20 years’ experience delivering strategic direction and quantifiable results for early-stage startups and Fortune 100 organizations such as Bazaarvoice, Qlik, Rackspace, PayPal, and P&G. Outside of the office, Suzin volunteers for causes close to her heart with her two children.","name":"Suzin Wold","slug":{"_type":"slug","current":"suzin-wold"}},"config":{"description":"Sama has been recognized in Fast Company’s list of the Next Big Things in Tech for our work with our partners at Orbisk.","openGraphImage":null,"title":"Orbisk’s Sama-Powered Food Waste Solution Named to Fast Company’s First-Ever List of the Next Big Things in Tech"},"estimatedReadingTime":3,"featured_image":{"_type":"image","asset":{"_ref":"image-0434b713b7dcba1cdf98eff0eb50d7cb3d5fb008-1500x908-jpg","_type":"reference"}},"plaintextBody":"Our team at Sama is committed to building the technology solutions required to address our society’s pressing needs. From our social-impact business model and training programs that help individuals lift themselves out of poverty to partnerships with the organizations creating change across industries, we’ve always believed in accurate AI’s ability to change our world for the better.\n\n\n\nThat’s why we’re honored to announce today that we’ve been recognized in Fast Company’s first-ever list of the Next Big Things in Tech for our work with our partners at Orbisk.\n\n\n\nHighlighting the new technological breakthroughs that promise to help define the future of the industries they serve, Next Big Things In Tech finds the products, services, features, research, and other technology efforts having a positive impact on consumers, businesses, or society at large in the next five years.\n\n“The climate crisis is growing increasingly dire each day. Right now, between 8-10% of all greenhouse gas emissions are the direct result of food waste,” said Wendy Gonzalez, CEO at Sama. “As we work to find ways to be more environmentally conscious, we were inspired by the team at Orbisk’s vision for the future of food service. Together, we’re incredibly proud of the solution we’ve built and its impact in minimizing waste production.”\n\nEach year, 931 million tonnes of food end up in landfills, and of that, nearly 362 million tonnes come from the foodservice and retail industries. With Sama’s high-quality training data powering its algorithm, Orbisk’s fully automated food waste monitor allows hotels, restaurants, and cafés to reduce food waste by up to 70%. \n\nOrbisk’s solution works by scanning plates of food to detect and record what items are being thrown away automatically and their quantities. With this data, businesses can make smarter choices that help save money while reducing food waste. To ensure accuracy, Sama successfully labeled hundreds of thousands of images of food, rapidly iterating to reach consistent attribute tagging. This allows Orbisk to improve accuracy and build a robust product capable of accurately recognizing food of all kinds in all steps of the cooking process.\n\nTo date, our partnership has enabled businesses to reduce an average of 8,000lbs of food waste per year. In total, prototyping projects alone have saved over 220,400lbs to date, and we’re aiming to reach over 220,000,000lbs saved annually by 2025.\n\n“Fast Company is thrilled to highlight cutting-edge technologies that are solving real-world problems in unexpected ways. From climate change and public health crises to machine learning and security, these technologies will certainly have a profound impact on the future, and we’re honored to bring attention to them today,” says Stephanie Mehta, editor-in-chief of Fast Company.\n\nTogether, we look forward to helping reduce the rate of climate warming by mitigating food waste.\n\nLearn more about our partnership and its success here, or check out the full list of Fast Company's Next Big Things in Tech here.","slug":{"_type":"slug","current":"fast-company-next-best-things-tech-2021"},"tags":[{"label":"Company News","value":"Company News"},{"label":"Awards","value":"Awards"}],"title":"Orbisk’s Sama-Powered Food Waste Solution Named to Fast Company’s First-Ever List of the Next Big Things in Tech"},{"_createdAt":"2021-12-06T23:42:49Z","author":{"_id":"70f24746-bdb3-4801-adfd-17508d02ae50","avatar":{"_type":"image","asset":{"_ref":"image-9a5184335ade812b332047f70963b6e72a885c67-1194x1284-webp","_type":"reference"}},"bio":"Rob hosts & produces Sama's podcast, How AI Happens. How AI Happens is a podcast featuring experts and practitioners explaining their work at the cutting edge of Artificial Intelligence. Tune in to hear AI Researchers, Data Scientists, ML Engineers, and the leaders of today’s most exciting AI companies explain the newest and most challenging facets of their field.","name":"Rob Stevenson","slug":{"_type":"slug","current":"rob-stevenson"}},"config":{"description":"Facebook Director in AI Manohar Paluri joins the Sama Podcast, How AI Happens, to discuss the state of computer vision and egocentric perception.","openGraphImage":{"_type":"image","asset":{"_ref":"image-1502043edcf701cb4267cb2f6d7c6edf8e0e0cad-2500x1313-png","_type":"reference"}},"title":"New Podcast Episode: Facebook's Manohar Paluri Makes Machines See"},"estimatedReadingTime":2,"featured_image":{"_type":"image","asset":{"_ref":"image-1502043edcf701cb4267cb2f6d7c6edf8e0e0cad-2500x1313-png","_type":"reference"}},"plaintextBody":"Manohar Paluri has spent the bulk of his career developing methods to make machines see. Now, in his role as Director, Artificial Intelligence at Facebook (now Meta), computer vision is one building block in the massive undertaking of developing egocentric perception: making sense of data collected from a first-person perspective via wearable devices.\n\nMano joined our podcast, How AI Happens, to discuss the current state of computer vision, the challenges inherent in developing egocentric perception, and how Facebook is weighing the issues of transparency and privacy as personal data becomes, well, more personal.\n\nChief among considerations for Mano’s team is the shift from third-person sensor perception — that is, holding out a smartphone at arm’s length — to the first-person perspective granted to sensors in wearable tech. While it may not seem obvious, the difference in the data collected is tremendous. First-person perspective allows for better intention prediction with gaze recognition and hand-object interaction. However, it also has its own set of challenges, such as the user not bothering to hold their head as steady as they might hold a smartphone.\n\nMano explains how his team is tackling these issues, the ethical considerations at play, and the importance of not making sacrifices to transparency in the interest of accuracy. To hear Mano explain this and much more, you can stream the full episode below, or anywhere you get your podcasts.","slug":{"_type":"slug","current":"podcast-episode-facebook-manohar-paluri"},"tags":[{"label":"Podcast","value":"Podcast"}],"title":"New Podcast Episode: Facebook's Manohar Paluri Makes Machines See"},{"_createdAt":"2021-12-06T23:23:23Z","author":{"_id":"53157027-f755-45c1-9fe3-65d4d9db4cc0","avatar":{"_type":"image","asset":{"_ref":"image-98673ad34672168b493ce7aba4eb1e874fdb41c3-300x300-png","_type":"reference"}},"bio":"As the VP of Corporate Development and Strategy at Sama, Alex Shee is building an AI business ecosystem around Sama's cutting-edge AI platform. In his role, Alex leads key partnerships, GTM strategy, and management of the Montreal Sama office. He was also recently selected as one of the top 250 upcoming leaders in Canada by the Governor General of Canada (the equivalent of Presidential Award), one of the top 4 business development and sales leaders in tech by Floodgates in their Annual Anchor List and 2021 \"Power Player\" by the Peak.","name":"Alex Shee","slug":{"_type":"slug","current":"alex-shee"}},"config":{"description":"Sama is thrilled to partner with research center Mila, to help further the mission of creating innovative technologies to drive the AI industry forward. ","openGraphImage":{"_type":"image","asset":{"_ref":"image-f80b5e83a9927bafc61285d9e7a16b07070f53c1-1200x630-png","_type":"reference"}},"title":"Sama Partners with Mila to Solve Key Problems in AI Development"},"estimatedReadingTime":3,"featured_image":{"_type":"image","asset":{"_ref":"image-f80b5e83a9927bafc61285d9e7a16b07070f53c1-1200x630-png","_type":"reference"}},"plaintextBody":"As AI continues to deliver value in virtually every industry, companies seeing success from AI are standing on the shoulders of giants. For decades, research institutes have been driving innovation with significant contributions in the field of machine learning. These are the contributions that paved the way for the business applications we see all around us today.\n\n\n\nMila was founded by Turing Award Winner Yoshua Bengio back in 1993, with the mission to serve as a global pole for scientific advances that inspire innovation and the development of AI for the benefit of all. Since 2017, it has partnered with Université de Montréal and McGill University, closely linked with Polytechnique Montréal and HEC Montréal, to become the world’s largest academic research center in machine learning. \n\nToday, Mila brings together 750 researchers specializing in machine learning to collaborate with a wide variety of local, national, and international organizations to develop AI-driven projects, platforms, and partnerships to accelerate economic and social innovation. Sama is proud to be a part of this ecosystem:\n\n“As one of the top AI labs in the world, Mila is an incredible force for AI innovation. We are proud to work alongside Mila’s team of 750 researchers, professors, scientists, and students to develop the cutting-edge solutions leaders need to drive the AI industry forward, while leveraging bias-free and effective tech to positively impact the world around us.”\n- Wendy Gonzalez, CEO of Sama\n\nWith support from Mila, Sama co-hosted the first-ever workshop on Interactive Labeling and Data Augmentation for ICCV – one of the most prestigious AI conferences in the world – alongside Sasha Luccioni from Mila, Professor Jean-François Lalonde, and Professor Christian Gagné. Moreover, several Mila students who had the opportunity to intern at Sama through the partnership, have gone on to join our team full time. \n\n“The renewal of our partnership with Sama is a testament to their unwavering commitment to AI innovation and development as well as shared values of AI for good. We are happy to see Sama expanding its Montreal-based team and we look forward to continuing to work together to develop impactful solutions that will power tomorrow’s world.”\n- Yoshua Bengio, Founder and Scientific Director of Mila\n\nMoving forward, Sama and Mila will continue to work together to address AI and machine learning development challenges. In addition to co-authoring research with Mila professors and doctoral students, Sama will collaborate on Mila’s AI for Humanity projects, giving the team access to our high-quality training data platform to drive the development of AI for good.\n\nIn addition to partnering with Mila, Sama is continuing to invest in Montreal as a hub for AI innovation. Our AI R&D center is located a block away from Mila’s offices, and we plan to significantly expand our Montreal-based team to over 400.\n\n(P.S.: Sama is hiring!)\n\n\n\nThank you to Mila for working with us and continuing to believe in the potential of AI for good. We can’t wait to see what the future holds.\n\nRead more about the partnership here.","slug":{"_type":"slug","current":"sama-mila-partnership"},"tags":[{"label":"Company News","value":"Company News"}],"title":"Sama Partners with Mila to Solve Key Problems in AI Development"},{"_createdAt":"2021-11-10T15:20:55Z","author":{"_id":"e8a1f3c6-0b07-4638-93d5-61a0924f32e3","avatar":{"_type":"image","asset":{"_ref":"image-2f8efc599a377bd580d0ae12f022a15e7e1acacd-632x676-webp","_type":"reference"}},"bio":"Amanda is the Content Marketing Manager at Sama, where each day she gets to learn about AI and how it’s transforming industry. She’s passionate about technology but periodically tries to get away from her computer to explore more analog things like collage and quilting.","name":"Amanda Durepos","slug":{"_type":"slug","current":"amanda-durepos"}},"config":{"description":"Last week, Sama secured Series B, cementing the viability of purpose-driven companies—and hopefully inspiring others to pursue purpose and profitability. ","openGraphImage":{"_type":"image","asset":{"_ref":"image-e7a31b38bf862680df4a21015cebc9ab8232c733-5472x3648-jpg","_type":"reference"}},"title":"Getting to Series B: How Sama is Proving Impact is a Strategy for Business Success"},"estimatedReadingTime":9,"featured_image":{"_type":"image","asset":{"_ref":"image-e7a31b38bf862680df4a21015cebc9ab8232c733-5472x3648-jpg","_type":"reference"}},"plaintextBody":"Last week, Sama secured $70M in Series B funding, the second round of equity financing for the company. This marks the transition from solidifying product-market fit to truly taking the business and impact to scale.\n\nOn the road to Series B, Sama has received many recognitions for its innovative technology and impact sourcing model, including inclusion on the Forbes AI 50 and Fast Company’s World Changing Ideas lists.\n\nThat said, getting to this milestone has not been straightforward. The team had to overcome the “valley of death” and bust many myths along the way. One by one. A few of them are highlighted below, cementing the viability of purpose-driven companies and hopefully inspiring others to bust myths on their path to purpose and profitability.\n\nMyth #1: Impact requires a trade-off between purpose and profit\n\nAlthough impact investing has become more mainstream over the past decade, the notion that there is a trade-off between impact and financial return is still very much alive — despite academic evidence pointing to the opposite. While purpose-driven companies may integrate impact in their business models in different ways, Sama’s Series B raise solidifies the fact that there is no trade-off between purpose and profit as you grow, when impact is inherent to your value proposition and product. \n\nThe company partners with big corporations—Google, NVIDIA, Walmart—to provide them with quality data to train their machine learning models. Sama provides high-quality annotated text, images, and videos for a range of use-cases, powering robot-assisted surgery, autonomous vehicles, personalized online shopping experiences, and more. Sama hires over 90% of its workforce from low-income backgrounds and marginalized populations in Kenya and Uganda, training them and granting them employment in the digital economy. What’s more, Sama is an anti-ghost work company. Each of its employees is hired ethically and receives fair compensation and benefits. \n\nFor over 10 years, Sama has partnered with leading global brands. Their stellar commercial performance has been achieved as they continue to scale opportunities for underserved individuals through the digital economy. Sama was one of the first AI companies to become B-Corp certified and has helped over 56,000 people lift themselves out of poverty. Its training and employment program was recently validated by an MIT-led Randomized Controlled Trial, confirming the effectiveness of its impact sourcing model by demonstrating that individuals that received both training and inclusion in Sama’s hiring pool exhibited lower unemployment rates and higher average monthly earnings.\n\n\"Sama’s openness to evaluate the impact of their programs with the rigor of a randomized control trial was refreshing and shows that they’re a leader in the movement toward ethical practices within the AI industry.\"\n-David Atkin, Professor of Economics, MIT\n\nMyth #2: Diversity is a pipeline problem\n\nWe have all seen the data in one shape or form: white men get the lion’s share of investor funding. Despite the movements calling for diversity, women-led startups account for just 2.2% (https://pitchbook.com/news/articles/the-vc-female-founders-dashboard) of the $150 billion invested in companies by VCs annually. Many have argued that the lack of diversity is caused by a pipeline problem, that there simply are not enough qualified investment opportunities – especially as it regards tech businesses. With the Series B raise, Sama paves the way for busting the myth once and for all. \n\nSama is a female-founded and led tech company that is deploying an impact sourcing model creating opportunities for marginalized communities, with over half of Sama agents intentionally being women. Founded by late Laila Janah and now led by CEO Wendy Gonzalez, the company has achieved responsible hyper-growth, and consequently, for the second year, a spot on the Inc. 5000 list as one of America’s fastest-growing private companies. The data speaks for itself.\n\nSama’s Series B raise represents the largest round for a female-led AI infrastructure in history. The round is led by CDPQ’s Equity253 fund that targets companies that leverage diversity and inclusion as a vector of development. The fund is put in motion because studies clearly validate that diversity in companies fosters better decision-making and has a positive impact on innovation, risk management, productivity, and financial performance. \n\n\"At the BESTSELLER FOUNDATION the rationale for investing in diversity is also clear – not only for profit and for purpose, but also to ensure structural change through the positive ripple effects that transcends generations. Sama embodies such rationale by improving employment and income for those with the greatest barriers to work and changing the narrative for their dependents\"\n- Anne Cathrine Garde, Investment Manager and Head of Scaleups.\n\nMyth #3: Impact does not fit the venture capital model\n\nSama was started as a non-profit organization because no one believed it could ever be a business. When late-founder Laila Janah pitched venture capitalists on Sandy Hill Road, the impact sourcing model was disregarded as it did not fit the typical parameters of hyper-growth and capital efficiency. On the opposite side of the spectrum, grant givers did not believe that impact sourcing could meet the basic needs of the marginalized communities. Sama proved both groups wrong. The company was ahead of its time, but luckily the landscape has changed a lot since then, and with the Series B raise, Sama is showcasing that impact is fit for staged financing.\n\n\n\nSince 2015, with Wendy Gonzalez on board, the company has focused on building a repeatable and scalable business model. From 2016 and onwards, Sama sustained itself on earned revenues and became a profitable nonprofit. With the BESTSELLER FOUNDATION investment in 2017, the Kenyan subsidiary was transformed from a non-profit to a for-profit company.\n\nJannek Hagen, Managing Director was a part of the team driving the investment decision:\n\n\"We invested in Sama Kenya back in 2017 as the first investor. Since then, we have witnessed how the team has transformed from a not-for-profit to a full-fledged, for-profit AI technology company\".\n\nThe investment set the precedent for Sama at group level to be transformed into a for-profit to attract further financing, talent, and expertise the following year. In 2019, Sama completed their USD 14.8M Series A funding with venture capital Ridge Ventures leading the round supported by Social Impact Ventures, Bluecrest Limited Capital, Salesforce Ventures, and BESTSELLER FOUNDATION.\n\nToday, Sama has taken the next step in its journey with the Series B raise that will take its purpose and profitability to new scales. In 2021, the landscape of impact investing looks different with the proliferation of many asset classes that are embracing an impact lens, covering the whole investment lifecycle. The time for launching an impact business is ripe and a big recognition goes to founders like Leila Janah, who ahead of her time proved the viability of purpose-driven businesses.\n\nLet us bust more myths together, one by one!\n\nHow are you busting the myths of impact? In a Sub-Saharan African context, where Sama and the BESTSELLER FOUNDATION have a strong presence, the journey towards impact equilibrium is twofold. Let us jointly normalize the concept of purpose-driven businesses while highlighting and measuring the impact that is happening on the ground. Our goal is to continue to ensure that impact is not diluted or misrepresented but used as a competitive advantage.\n\n**This post was jointly authored by Anne Cathrine Garde, BESTSELLER FOUNDATION and Amanda Durepos, Sama.**\n\n---\n\nAbout BESTSELLER FOUNDATION: We support entrepreneurs and invest in businesses that work for supporting the wellbeing of our natural world, for creating better jobs and opportunity, for sustainable growth. Our work is made possible through the support of BESTSELLER, an international, family-owned fashion group. Right now, our main priority is to help tackle one of the biggest challenges of our time - how to reduce waste, how to reuse and recycle valuable resources. And how to find economically viable opportunity in doing so. These efforts are currently focused on providing early-stage capital for (aspiring) circular economy ventures in Sub-Saharan Africa. For more information, visit www.bestseller.org.","slug":{"_type":"slug","current":"impact-business"},"tags":[{"_key":"K6VnIonn","label":"Company News","value":"Company News"},{"_key":"Y81NfQzJ","label":"Impact","value":"Impact"}],"title":"Getting to Series B: How Sama is Proving Impact is a Strategy for Business Success"},{"_createdAt":"2021-11-04T14:08:29Z","author":{"_id":"a009d418-aa96-47ac-a73a-fd2cd52c79d9","avatar":{"_type":"image","asset":{"_ref":"image-e0d717f753ba4876a6b0dbf9f125cf6c3d27e545-500x500-webp","_type":"reference"}},"bio":"Wendy Gonzalez is an executive passionate about building high-performing, high-functioning teams that develop and scale innovative, impactful technology. With two decades of managerial and technology leadership experience for companies including EY, Capgemini, Cycle30 (acquired by Arrow Electronics) and General Communications Inc, Gonzalez is currently the CEO of Sama, the provider of accurate data for ambitious AI, used by leading technology companies such as Walmart, Google, Nvidia and Getty. Before taking on her role as CEO, Gonzalez spent 5 years at Sama as COO, and is an active Board Member of the Leila Janah Foundation.","name":"Wendy Gonzalez","slug":{"_type":"slug","current":"wendy-gonzalez"}},"config":{"description":"Sama has raised $70M Series B funding to build the first end-to-end AI platform that enables teams to manage the complete AI lifecycle.","openGraphImage":{"_type":"image","asset":{"_ref":"image-5129846575d1f7d8aa08a3784a1ff9eced8ba307-1000x500-png","_type":"reference"}},"title":"Sama Raises $70M Series B to Build a More Accurate, More Ethical, End-to-End AI Development Pipeline"},"estimatedReadingTime":4,"featured_image":{"_type":"image","asset":{"_ref":"image-5129846575d1f7d8aa08a3784a1ff9eced8ba307-1000x500-png","_type":"reference"}},"plaintextBody":"Sama has raised $70M of Series B funding to build the first end-to-end AI platform that enables teams to manage the complete AI lifecycle from start to finish. We’re partnering with some of the world’s top venture capital firms: our round is led by Caisse de dépôt et placement du Québec (CDPQ), a global investment group, with participation from First Ascent Ventures and Vistara Growth, in addition to all existing investors. Read more here.\n\n\n\n\nAt Sama, we’re shaping a future of AI that’s more accurate, fair, and ethical. Since Day 1, we’ve been committed to building technology that has a positive impact — across industries, but also across the globe.\n\nThis is no small task, and we’ve been busy since announcing our Series A funding in 2019. \n\nWe have opened offices in Kampala, Uganda, and Montreal, and Samasource became Sama. We were honored to win the 2020 AI Breakthrough Award for Best Image Processing Solution and this year were included in lists such as Forbes AI 50, Inc. 5000 Fastest-Growing Private Companies, 2021 AITechAward in Machine Learning Platforms category, and Fast Company’s World Changing Ideas.\n\n\n\n\nSama became one of the first AI companies to receive B Corp Certification and was recognized on the Best for the World™ 2021 list for BLabs Workers category. Our training and employment programs continue to help individuals lift themselves out of poverty — 56,000 individuals to date — with our 3-year Randomized Control Trial by MIT validating our long-term impact on employment rates and earnings.\n\n\n\n\nUp to now, we’ve annotated over 1B image points on our platform (an average of 1M tasks completed per month) for industry-leading companies by the likes of Google, Walmart, and NVIDIA. And we did all this while achieving up to 99.9% data accuracy for our clients, versus an industry average of 94%.\n\nWhat’s next?\n\n\nWorking with these exceptional clients for over a decade has highlighted an enormous area of opportunity, both for the future of Sama and for the AI industry as a whole. Enterprise AI teams have adopted a growing number of niche tools to support their end-to-end AI development cycle, and a lot of time (and accuracy) is lost building the infrastructure and pipeline required to integrate it all.\n\nAt Sama, we believe there’s an opportunity to bridge this gap, and to do so responsibly.\n\nToday, I’m thrilled to share that we’ve raised $70M of Series B funding to build the first end-to-end AI platform that enables teams to manage the complete AI lifecycle from start to finish. To achieve this, we’re partnering with some of the world’s top venture capital firms: our round is led by CDPQ with participation from First Ascent Ventures and Vistara Capital Partners, in addition to all existing investors.\n\nWith this funding and the support of our investors and community, we’re more committed than ever to building AI that delivers a positive impact: both for our clients who rely on us for high-quality data for their models, and for the lives of the professionals at the core of ethical AI supply chains.\n\nI want to thank all our investors for their trust in our mission, and for their commitment to changing the world for good. Thank you to our clients for entrusting us with delivering the high-quality data you need to fuel innovation. And an immense thanks to the Sama team and community for years of hard work, heart, and dedication.\n\nThank you — each and every one of you — for being part of this journey with us. We wouldn’t be where we are today without you. Let’s continue to shape a future of AI that’s more accurate and fair, together.\n\n\n\nWendy","slug":{"_type":"slug","current":"series-b"},"tags":[{"_key":"oEH9XOvc","label":"Company News","value":"Company News"}],"title":"Sama Raises $70M Series B to Build a More Accurate, More Ethical, End-to-End AI Development Pipeline"},{"_createdAt":"2021-10-25T18:45:56Z","author":{"_id":"70f24746-bdb3-4801-adfd-17508d02ae50","avatar":{"_type":"image","asset":{"_ref":"image-9a5184335ade812b332047f70963b6e72a885c67-1194x1284-webp","_type":"reference"}},"bio":"Rob hosts & produces Sama's podcast, How AI Happens. How AI Happens is a podcast featuring experts and practitioners explaining their work at the cutting edge of Artificial Intelligence. Tune in to hear AI Researchers, Data Scientists, ML Engineers, and the leaders of today’s most exciting AI companies explain the newest and most challenging facets of their field.","name":"Rob Stevenson","slug":{"_type":"slug","current":"rob-stevenson"}},"config":{"description":"Embodied Chief Technology Officer Stefan Scherer explains how conversational AI, few-shot learning, and lean robotic design brings Moxie the Robot to life.","openGraphImage":null,"title":"New Podcast Episode: Moxie the Conversational AI Robot Teaches Children Kindness"},"estimatedReadingTime":2,"featured_image":{"_type":"image","asset":{"_ref":"image-1502043edcf701cb4267cb2f6d7c6edf8e0e0cad-2500x1313-png","_type":"reference"}},"plaintextBody":"When you were a child, do you remember learning what it means to be kind?\n\nWhat about reading sadness in someone’s face, understanding the anger you felt, or respecting personal space?\n\nIf you don’t remember learning about any of these human moments, then Moxie, a conversational AI robot built by Embodied, is the android friend you never knew your childhood self needed.\n\nMoxie is designed to teach children social and emotional maturity, both through human-to-robot conversation as well as various missions that send the child out into the world to learn about kindness and friendship.\n\nTo learn more about what makes Moxie tick, we hosted Stefan Scherer, Chief Technology Officer at Embodied, on the latest episode of our How AI Happens podcast. Stefan explains the language processing happening within Moxie, and how the team was able to generate reliable conversational ability through lean few-shot learning.\n\nMoxie’s ability to shift between dynamic responsive conversation and scripted programmatic content raises fascinating questions about conversational AI: exactly how much responsiveness is required to create the feeling of a 1:1 conversation? And how can technologists draw a circle around a concept such as “kindness” in such a way that enables it to be shared between a child and an AI?\n\nStefan explains all this and more in the full episode. And, of course, we hear from Moxie, too.","slug":{"_type":"slug","current":"/moxie-the-robot-teaches-children-kindness-conversational-ai-child-development"},"tags":[{"label":"Podcast","value":"Podcast"}],"title":"New Podcast Episode: Moxie the Conversational AI Robot Teaches Children Kindness"},{"_createdAt":"2021-10-13T13:21:47Z","author":{"_id":"e8a1f3c6-0b07-4638-93d5-61a0924f32e3","avatar":{"_type":"image","asset":{"_ref":"image-2f8efc599a377bd580d0ae12f022a15e7e1acacd-632x676-webp","_type":"reference"}},"bio":"Amanda is the Content Marketing Manager at Sama, where each day she gets to learn about AI and how it’s transforming industry. She’s passionate about technology but periodically tries to get away from her computer to explore more analog things like collage and quilting.","name":"Amanda Durepos","slug":{"_type":"slug","current":"amanda-durepos"}},"config":{"description":"Find out how accurately labeled data is helping PolyPerception provide material recovery facilities with better visibility into their waste streams.","openGraphImage":null,"title":"How More Accurate Data Labeling is Helping PolyPerception Advocate for Responsible Waste Management"},"estimatedReadingTime":8,"featured_image":{"_type":"image","asset":{"_ref":"image-5b774da87e817474525a389529a9ea674aa54a11-4167x2084-png","_type":"reference"}},"plaintextBody":"PolyPerception provides an AI-powered waste management platform to plastics and material recovery facilities. Their technology tracks each individual piece of waste at an object level. This gives the facilities visibility into their waste streams so they can operate more efficiently and responsibly. The team has partnered with Sama to help fuel this technology, to further their mission of empowering stakeholders across waste management—from recyclers to municipalities to legislators—to make more sustainable decisions about waste and its impact on the environment.\n\nThe challenge of visibility in the waste management industry\n\n\nAs the volume of discarded waste continues to grow globally each year, so has the pressure on our landfills, resources, and environment. With waste disposal technology, infrastructure, and regulators struggling to catch up, one significant barrier blocks the way: visibility.\n\nOn average, 8 tonnes of waste passes through a waste sorting facility every hour. If this sounds like an almost inconceivable amount of waste, that’s because it is. For the operators of sorting centers, understanding and documenting the waste passing through each day remains a major challenge, forcing the waste management industry to operate with a lot of blind spots. \n\nTo circumvent this and better understand the makeup of the waste passing through, many facilities implement a sampling process, but sample sizes are typically small. Though 8 tonnes of waste passes through a facility every hour, sampling is often only done once a week. Even representative sample sets can be skewed by the subjectivity of human bias, making consistency a challenge.\n\nThese factors lead to datasets that don’t often show the full picture, forcing waste management facilities to largely operate on human intuition; a less-than-ideal approach to the decision-making required to meet federal regulations and to cut operational costs.\n\nChanging packaging trends and regulations\n\n\nThe sheer volume of waste passing through a facility is not the only obstacle for sorting center operators. In the world of waste management, tons of other parameters are constantly changing, transforming the efficiency and economics of the process.\n\nFor starters, brands often change their packaging in ways that impact how it’s sorted and where that packaging finally ends up. For example, Heinz is currently using a multi-layer PET bottle with a non-recyclable barrier, but this is soon slated to change in Europe. These changes often happen suddenly and without warning, giving facilities little time to react to make sure these bottles now end up in the appropriate output stream — and therefore at the right recycling facility.\n\nPackaging also varies from region to region. If a facility onboards a new source of waste, they may not understand regional differences, and their machines may not be optimized to sort materials accordingly. Slight margins of error are amplified when you consider the number of sorting steps and the sheer volumes processed.\n\nKeeping up with shifting packaging trends is only compounded by regulations that are also constantly in flux, and differ from one country to the next. All these variables from the outside require sorting facilities to constantly optimize their processes and plan strategically, but this is hard without quantifiable data.\n\n\nAccurate data labeling plays a crucial role\n\n\nThis is where PolyPerception comes in: to give operators in facilities continuous visibility into their waste flow systems by adding cameras to monitor the end-to-end process. This means tracking each piece of waste at an object level. Traceability and transparency allow these facilities to operate more efficiently, bringing them better commercial terms and preparing them to tackle new legislation and packaging trends.\n\nIn order to deliver actionable insights and quantitative data to their clients, PolyPerception set out to build a robust multi-object tracking model, but quickly found that the accurate labeling of data would play a key role.\n\nCrucially, they needed a labeling solution that could accurately label waste objects that travel quickly on conveyor belts in facilities with less-than-ideal lighting conditions. But they also needed a partner who could effectively annotate millions of waste objects while accounting for a wide range of packaging types, materials, processing speeds, and processing conditions.\n\nRafael Hautekiet, CEO of PolyPerception, was delighted by how feedback loops with Sama’s managed workforce of annotators resulted in better quality data for their model – annotations with an average Quality Score of 99%:\n\n“The team quickly learned to distinguish between waste objects, which differ greatly from region to region. Communication channels remained open for feedback, and we had a continuous open discussion about how the efforts were progressing.”\n\nThis line of open communication was important to PolyPerception when they were evaluating different data labeling partners. They wanted to feel like annotators were an extension of their own team, both to maintain visibility into the labeling process and to ensure that the many nuances of their labeling needs were being met.\n\nWhat more reliable, quantifiable data can do for waste management\n\n\nFor PolyPerception, accurate data in waste management has cascading effects for society – a rising tide to lift all boats. With more reliable data:\n\nRecyclers can better understand the composition of their input waste streams, allowing them to reach higher recycling rates, meet federal and state regulations while also cutting costs. \n\nMunicipalities and government agencies can confidently establish data-backed regulations that will have positive lasting impacts.\n\nConsumers can be better informed of how their actions have a direct and measurable impact on the world around us.\n\nThe economic, social, and environmental benefits of the above are too numerous to list, but they are at the core of PolyPerception’s longer-term vision: of empowering stakeholders across waste management to make more impactful decisions, to move the world toward a circular future.\n\nTo PolyPerception COO Parshva Mehta, accurately labeled data plays a small but important part in this ambitious undertaking. This is why it was important for PolyPerception to do data labeling a different way: to work with a provider whose values aligned with theirs, and with their mission to make the world a better place. In Parshva’s words:\n\n“There’s a possibility to make an impact on legislation and on the environment, but not without accurately labeled data. We appreciate that Sama started out by disrupting the status quo and by having a strong social mission. We really resonate with this.”\n\n\n","slug":{"_type":"slug","current":"/polyperception-case-study"},"tags":[{"_key":"qRJxxe50","label":"Case Studies","value":"Case Studies"}],"title":"How More Accurate Data Labeling is Helping PolyPerception Advocate for Responsible Waste Management"},{"_createdAt":"2021-08-17T19:01:34Z","author":{"_id":"26fb3cc4-608d-40e1-bb4d-955bceda232a","avatar":{"_type":"image","asset":{"_ref":"image-e0fe681e594567792ac79048513fe955cc770f54-518x518-svg","_type":"reference"}},"bio":"From self-driving cars to smart hardware, Sama fuels AI. Founded over a decade ago, we’re experts in image, video and sensor data annotation and validation for machine learning algorithms in industries including automotive, navigation, AR/VR, biotech, agriculture, manufacturing, and e-commerce. Our staff are driven by a mission to expand opportunity for low-income people through the digital economy, and our social business model has helped over 50,000 people lift themselves out of poverty.","name":"Sama Team","slug":{"_type":"slug","current":"sama-team"}},"config":{"description":"We’re honored to have made the Inc. 5000 List of America’s Fastest-Growing Private Companies… for the second year in a row.","openGraphImage":null,"title":"Sama Made the Inc. 5000 List (For the Second Year in a Row!)"},"estimatedReadingTime":2,"featured_image":{"_type":"image","asset":{"_ref":"image-0434b713b7dcba1cdf98eff0eb50d7cb3d5fb008-1500x908-jpg","_type":"reference"}},"plaintextBody":"We have some exciting news to share:\n\nWe’re honored to have made the Inc. 5000 List of America’s Fastest-Growing Private Companies… for the second year in a row!\n\nCompanies on the 2021 Inc. 5000 were ranked according to percentage revenue growth from 2017 to 2020 – a badge we’re especially proud to wear considering the challenges that 2020 brought businesses everywhere.\n\nNot only have the companies on the 2021 Inc. 5000 been very competitive within their markets, but this year’s list also proved especially resilient and flexible given 2020’s unprecedented challenges. Among the 5,000, the average median three-year growth rate soared to 543 percent, and median revenue reached $11.1 million. Together, these companies have added more than 610,000 jobs over the past three years.\n\nAs Scott Omelianuk, editor-in-chief of Inc. put it:\n\n“Building one of the fastest-growing companies in America in any year is a remarkable achievement. Building one in the crisis we’ve lived through is just plain amazing. This kind of accomplishment comes with hard work, smart pivots, great leadership, and the help of a whole lot of people.”\n\nOur CEO Wendy Gonzalez also shared some words about the recognition:\n\n“Last year was incredibly challenging for everyone and this recognition is a testament to our ability to not only endure through tremendous adversity as a team but come out stronger. I am incredibly proud of the work we’ve continued to accomplish, including the impact we’ve had as an industry leader in AI and our commitment to the ethical supply chain.”\n\nWe're thrilled to share the news, and even more excited about continuing our journey in 2021 and beyond with renewed ambitions.\n\nComplete results of the Inc. 5000, including company profiles and an interactive database that can be sorted by industry, region, and other criteria, can be found here.","slug":{"_type":"slug","current":"inc-5000-2021"},"tags":[{"_key":"i2eTixTT","label":"Company News","value":"Company News"}],"title":"Sama Made the Inc. 5000 List (For the Second Year in a Row!)"},{"_createdAt":"2021-08-10T18:08:48Z","author":{"_id":"e8a1f3c6-0b07-4638-93d5-61a0924f32e3","avatar":{"_type":"image","asset":{"_ref":"image-2f8efc599a377bd580d0ae12f022a15e7e1acacd-632x676-webp","_type":"reference"}},"bio":"Amanda is the Content Marketing Manager at Sama, where each day she gets to learn about AI and how it’s transforming industry. She’s passionate about technology but periodically tries to get away from her computer to explore more analog things like collage and quilting.","name":"Amanda Durepos","slug":{"_type":"slug","current":"amanda-durepos"}},"config":{"description":"Laurence Moroney, Lead AI Advocate at Google, joined our podcast to talk about how his team is democratizing access to AI's development.","openGraphImage":null,"title":"New Podcast Episode: Making AI Development Global with Google's Laurence Moroney"},"estimatedReadingTime":45,"featured_image":{"_type":"image","asset":{"_ref":"image-1502043edcf701cb4267cb2f6d7c6edf8e0e0cad-2500x1313-png","_type":"reference"}},"plaintextBody":"Many of the exciting advances in AI have resulted from well-funded companies and research departments, stocked with high-performance computers and every shiny toy the AI practitioner could want. But according to Laurence Moroney, Lead AI Advocate at Google, that’s not the only way to develop artificial intelligence.\n\n\n\nSo these students got together and they realized... if they take a picture of the sky, they have data. If they measure the air quality on the sensor, they have a label.\n\nLaurence joined our podcast, How AI Happens, to share examples of exciting advances in AI that are happening all over the world, many with no more than basic mobile devices. Laurence and his team have made it their mission to evangelize the opportunity of AI and work towards democratizing access to the technology’s development, a mission they accomplish via MooCs, YouTube, and a series of books on AI development. \n\nIn this episode, Laurence shares the nature of AI hype cycles, how AI practitioners can navigate them within their own organizations, and some of the amazing opportunities coming into play when access to AI & ML is made global. You can stream the full episode below, tune in via your favorite podcasting app, or read the whole transcript below.\n\n(audio embed)\n\nTranscript:\n\n0:00:00.0 Laurence Moroney: And then when they fed this back through an intention mechanism, they realized they didn't build a camouflage detector, they built a cloudy sky detector.\n\n0:00:12.2 Rob Stevenson: Welcome to 'How AI Happens', a podcast where experts explain their work at the cutting edge of artificial intelligence. You'll hear from AI researchers, data scientists and machine learning engineers, as they get technical about the most exciting developments in their field and the challenges they're facing along the way. I'm your host, Rob Stevenson, and we are about to learn how AI happens.\n\n0:00:42.0 RS: You don't have to be an AI expert to be skeptical about all the hype surrounding artificial intelligence and machine learning. Every company claims they have it, every sales deck mentions it, and worse, the media act as if the rise of the machines is happening sometime in late 2022. But amidst this hype cycle, those in the know understand the opportunity has never been greater. Enter Laurence Moroney. He's an industry veteran who has authored several books on AI development and even advises British Parliament on their AI approach. His mission in his role at Google is to evangelize the opportunity of AI and work towards democratizing access to the development of this technology.\n\n0:01:25.3 LM: I'm an AI lead at Google, so I lead the developer advocacy team, and our job is really to help inform and inspire the world around machine learning, artificial intelligence, deep learning and all that good stuff. So working with developers, working with communities, universities, all of those kind of folks to really help scale out the message and the opportunity that's there with AI.\n\n0:01:47.4 RS: Laurence joined the podcast to discuss the nature of AI hype cycles, how AI practitioners can navigate those cycles within their own organizations, and some of the amazing opportunities coming into play when access to AI and ML is made global.\n\n0:02:01.8 LM: As for my background, I was doing developer advocacy for a few years prior to Google, at places like Microsoft, a wonderful start-up in Israel, called Main Soft, and at Reuters, the news agency, kind of doing an internal advocacy role there, and then prior to that, the typical software engineer, all of those kind of things. Although my background at school was actually physics, my degree was in physics, but I came to the realization that nobody hires physicists, or very few people hire them, and I guess I wasn't good enough a physicist to be hired, so I ended up in this wonderful field instead.\n\n0:02:37.9 RS: It's interesting, you're the second individual I've spoken to, who got their start in physics and now have a career in AI. Is that a natural progression? What do you think is the link there?\n\n0:02:48.2 LM: I honestly... I don't think there is a natural progression, it's probably just a happy coincidence and maybe you're over-fitting in your audience. Sorry, AI joke there. For me, my path to AI actually came... It was really interesting that... 'cause when I first graduated college as a physicist, and it was in the UK, and it was in the middle of the worst recession that they had had since World War II. The current one, obviously, 'cause of COVID, is even worse. But back then, this was a pretty bad one, there was no kind of jobs or anything. And the government launched an initiative in 1992, the UK government, that they were gonna put together a cohort of 20 people to become AI specialists who could maybe be form the backbone of trying to help industry through AI and all of that kind of thing. And they needed people who were smart, but unemployed, and I at least fit one of those criteria, and I was unemployed, but we kinda did this battery of tests, it was like these kind of strange movies kind of thing, and I was accepted into the cohorts, which was really, really cool. And then I guess I got bitten by the AI bug then.\n\n0:03:53.7 LM: But in 1992, trying to do any kind of AI program was intensely difficult, it really didn't have any practical use. We were learning the languages like Prolog and LISP, and there was no industrial use for them, but there was some really fun academic stuff that you could do. But in the end, the program failed completely, but the potential was there, and I gotta give credit to the UK government, of figuring this out back in 1992. They were a little bit early, but it was really cool that they did it. It's funny that recently, in the last couple of years, I've been doing briefs to the UK governments, around AI, and I was like, \"Hey, do you know about that program?\" And of course, the MPs there, they're all long gone, the ones that did it. And the current ones were like, \"Did we really do that? That's awesome.\" I guess that's what got me bit by the bug and that led me down a career of programming and software engineering, to get me where I am today.\n\n0:04:45.9 RS: I'm interested to hear that you are spreading this message of the opportunity of AI, but then you also see all of these companies who are sort of saying they have AI or using AI in their messaging. Is there a gap of actual technology there? What is the difference between the reality of the technology and maybe the hype surrounding it?\n\n0:05:04.7 LM: Yeah, it's a great question. And by the fact that there's so many people doing this and waving around the AI magic pixie dust, hoping for customers or VC funding, that... If nothing else, that is a signal that this technology does have legs. The question is, does it get lost in the hype cycle or do we bust out of the hype cycle and start doing something really interesting? I always like to talk about, there's the... Gartner has this hype cycle curve, where you start with the peak of inflated expectations, and then you drop into something called the trough of disillusionment, and then once you're in the through of disillusionment, that's when you can really understand what the technology is and then you start climbing up through the plateau of productivity. And the kind of behavior that you're talking about just means that we're kind of on the wrong side at the moment, of this peak of inflated expectations. Part of what I'd like to describe my job as, is to do some quantum tunneling through that peak and end up in the trough of disillusionment. So I'm a professional disillusioner.\n\n0:06:02.9 LM: And then once you get into that and you understand what the technology actually is and what it does, then you can start being really useful with it. Obviously, you can look to the past to be able to predict the future. And in my career, there have been two massive tectonic shifts in computing. The first was really the widespread advent of the web and internet technology. The second was the smartphone. And if you think about, exactly the same thing happened in both those cases. I'll talk about the smartphone, which is the more recent one. So the hype cycle at the time was like, \"Throw away your desktop PC, throw away your laptop. You'll be able to do everything on your phone.\" And it's like, \"Forget about Office Suites, forget about programming environments, all of these kind of things. You're gonna get your phone, you're gonna plug it into a station on your desk and a big monitor will magically appear and it'll change how work is done.\" Well, that didn't happen. That to me, was a great example of the hype around the smartphone. But the smart phone still was a massive revolutionary technology that created a tectonic shift in the industry. I saw a stat, the largest creator of jobs in Western Europe during COVID, was the smartphone ecosystem. So not just people building smartphone applications, but people using them, and all of the stuff around that, like delivery services and all that type of stuff.\n\n0:07:23.8 LM: So we could see, that revolution started in 2007, and even now, 14 years later, the economy is benefiting greatly from it. The web revolution, the same thing, there was a whole ton of hype around the web, every shop in existence will go out of business, libraries will close. There was disruption and there were changes as a result of the web, but of course there was, I believe, an overall net gain. So when you start seeing these kind of things like when the hype first came in, but the people who were able to see through the hype and to be able to do something reasonable and productive when they fell into the trough of disillusionment, created whole new industries. Google came out as a result of the web, Amazon, Facebook, the Apple are the highest market cap company in the world right now, and that came as a result of the smartphone revolution. So there's so much that can happen when you can understand the actual limitations, start building to them and then rise up through that plateau of productivity as it's called in the Gartner Hype Cycle.\n\n0:08:28.1 LM: And that's really what I'm here to do, that's my role at Google, is to help people who are technically savvy to understand, \"Here's the possibility of things that you can do. Here's what you need to communicate within your business,\" and so when your product managers or when your CEO is wanting to wave that AI magic pixie dust, that kind of stuff, then it's the case, well, you can be the person who's got the expertise, who's able to say, \"I know this domain, and here's where AI can be used in this domain for real.\" And it might be nice to attract attention through marketing or through VC, but when you build a real product and you start building a real market around that, that's when the business can take off.\n\n0:09:09.7 RS: So if I'm an AI practitioner and I am contending with the hype around AI, or the example you gave of the CEO who's white boarding, \"Can we do this with AI?\" How can I level set expectations? There seems to be this little bit of education necessary, to make sure that people are steeped in reality when it comes to, \"What can this technology do? And what can you reasonably expect within your organization?\"\n\n0:09:34.5 LM: Yeah, I think effective communication is the number one tool, managing upwards like that is the number one tool. I've had a number of those conversations with folks who just thought that they can wave their arms and say, \"AI,\" and then find a programmer who could build the AI for them as they envisage it. But then to kinda just talk them through, \"Well, this is how it actually works, this is what it actually is. And if you wanna reach these goals, here's the kind of work that you would need to do, to be able to reach them.\" And often, it's setting lower goals and having a plan to be able to reach those lower goals and then use that as a plateau to go further and further and further. And I find in general, like CEO speak or CXO speak, they like that, instead of a yes person going, \"Yes, we can do whatever your vision is,\" that kind of thing, to actually be able to say, \"Well, here's a plan for how we can get to a very profitable future. It may not be the vision that you have, but it's concrete,\" and often, the folks in that level see themselves as the inspirational folks who get the plan moving in that direction by setting the goal and setting the long-term vision.\n\n0:10:45.8 LM: And when somebody can communicate up like that to say it's like, \"Well, we can't reach the exact nirvana that you're specifying, but we can build great products to do A, B, C and D, not all the way A through Z, and we can do it in this time frame,\" that, having that level of expertise to be able to speak to that comfortably and realistically, ends up being, I think, a great gift for everybody. If we go back to the conversation of what AI is and what AI isn't, is that I always like to draw this diagram that I say, \"Okay, here's traditional programming,\" and traditional programming, I draw it as a box, and that box is saying, \"You're putting rules in, you're putting data in and you're getting answers out.\" This is what programmers and the software department in your company have been doing since the dawn of software time, and the case is, what a programmer does is, they have to figure out how to express those rules in the programming language, so computers can do the work.\n\n0:11:36.2 LM: So for example, a very simple thing, like in financial services, there's a ratio called the price over earnings ratio, that's often a good one to determine the value of a company or one of the signals to determine the value of a company. And that's a very simple rule. Get the data of the price, get the data of the earnings, divide one by the other, and then you get an answer. There's obviously far more complex ones than that, but I like to use that one as a simple example. And you hire programmers because they know how to express those rules in a programming language and run them in an infrastructure. In the machine learning and AI world, I flip the axis around on that box. So instead of you trying to figure out the rules, you give the machine the answers and the data, and you have it figure out the rules. So for something like price over earnings, it's overkill, you don't need to do it. But what if there are patterns in your data that you don't see?\n\n0:12:26.5 LM: There are things about this company, and you can get a wealth of data around a company that you're doing an analysis on, and you can see that this company has done extremely well in the stock market, but you have no idea why, and this company has done extremely well, and you have no idea why, and then these bunch have done badly and you've no idea why. So then you have the answers, they've done well, they've done badly. You have the data, and the idea behind machine learning and AI is then, you can build a system that can do that pattern matching of the answers to the data and figure out what the rules are, to be able to do that.\n\n0:13:01.1 LM: So for you to do that effectively, you need good data scientists. It's not just, you get a shovel and you throw the data into the machine and something magic happens. You have your data scientists to try and make this as efficient as possible by picking the columns in the database or maybe doing feature crosses on those columns, where multiply this one by this one, that kind of thing. And the same way as your coders today, they're not just typing on a keyboard and stuff magically appears, they are figuring out the rules, they're figuring how to scale them. And that's really where the magic of good data science department applies, and so you've got skilled people who know the domain data, who know how to build models, so that the data is being used efficiently, so you can train a model in a couple of hours instead of a couple of decades, and that kind of thing. So it's like, that's where those folks, beyond trendy, really, really can show massive value for the company. And I'd say the same analogy, if you can get a programmer to build an effective program that runs your business in a day or a week, as opposed to an ineffective programmer who takes years to do the same task.\n\n0:14:07.6 LM: The same kind of thing can be applied with data scientists, that they can figure out which parts of the data to shovel, which parts not to shovel, they can figure out how to label those answers and all of those kind of things, so that the machine learning engineer can do their job effectively.\n\n0:14:21.7 LM: The way I generally like to define AI itself is, when you make a machine that responds the same way that an intelligent being would respond. So computer vision is a good example of that, is that if I show you a picture of a cat... If I show you a picture of my pet, you would say, \"That is a dog.\" Showing a computer a picture of my pets, prior to AI machine learning, deep learning, it would see a whole bunch of pixels and it has no parsing of the content, other than white pixels, blue pixels, those kind of things. When you start using machine learning and deep learning to then kind of train a computer to understand the difference between a cat and a dog, and then I show it this picture of my pets, and the computer will say, \"That's a dog.\" Now, the computer is responding in the same way as an intelligent being would respond, and that to me, is what artificial intelligence is all about. So you play it a sound, and instead of it saying, \"Here's a number of audio levels,\" it's actually able to determine your speech and to determine what you're saying, the same way as an intelligent being would. That to me, is artificial intelligence.\n\n0:15:31.6 LM: There are lots of ways that you can get there. Machine learning, deep learning are probably the most efficient way for things like computer vision, for audio processing, for tax processing and those types of things. So if we think about it and what it is... In terms of what it is and what it's not, it's not this magic thing that you can just say, \"We're gonna... Like in a Dilbert cartoon, we're gonna say, \"Let's put machine learning and artificial intelligence into our product and we get an upgrade.\" It doesn't really work like that.\n\n0:15:58.7 RS: The training is in the interest of an inference. When your technology can make an inference, an accurate inference, it has mimicked human cognition, right?\n\n0:16:06.5 LM: Yeah, exactly. And the nice thing is then, it can even go beyond human cognition, and let me give an example of this, that blows my mind. And so we worked on a project for diabetic retinopathy, at Google, where diabetic retinopathy is the world's leading cause of blindness. And the thing about it is that, it's easy to diagnose and it's easy to cure with early diagnosis. India has the world's second largest population, but it has a shortage of over 100 thousand qualified ophthalmologists. So we worked with doctors and hospitals in India to gather lots and lots of retina scans, to see... We'd label these retina scans... Data plus answers. We'd label these, based on those five different buckets, no diabetic retinopathy, all the way up to severe, and trained a machine learning model on this, to be able to be an artificial intelligence to respond the way an ophthalmologist would, and it ended up, like the publications that we did in various journals, showed that it was at least equivalent to a qualified ophthalmologist and often better. And so, that's the first mind-blowing part.\n\n0:17:13.5 LM: But then the second mind-blowing part, and the one that really hooked my interest in this was then a scientist within Google was looking at the data and realized, we don't just have labels of the diagnosis, we also have labels of the person's birth gender, or the person's age, or the person's blood pressure.\n\n0:17:33.6 LM: Now, an ophthalmologist can look at the scan of an eye and see blood clots and determine do they have diabetic retinopathy or not, but an ophthalmologist can't look at that scan and pick their age, or pick their gender. And so what if you have all of this data, you have your answers, you have your data, what if we could feed this into a model and do it? And it ended up, they trained a model that was 98% accurate in picking the assigned gender at birth, which is as good as, if not better than the average human, but obviously much better than a human looking at a retina, that kind of thing. It would be 50-50, it would be a coin flip. But it was 90% accurate, and it was also able to predict their age, with a mean average error of about three years.\n\n0:18:19.1 LM: And a few times in the past, I've told this story to an audience and I'd asked the audience to guess my age, and on average, the audience was... The mean average error from the audience was way more than that, and they're looking at me, they're looking at my gray hair, they're looking at my mannerisms, they're not looking at my retina, and they're still getting it even more wrong than this was... Again, looking at the retina. So we talk about human cognition and that kind of stuff, but in some ways, doing this kind of pattern recognition, we can go beyond human cognition, with examples like that one. If you have the data and if you have the labels that it's possible now for a machine to be able to do the matching of that data to that label and spot patterns that you as a human, wouldn't previously spot, and then there's massive, untold opportunities in that. So again, if we get down into that trust of disillusionment, and part of that is, I'm saying Machine Learning is fancy pattern matching.\n\n[chuckle]\n\n0:19:13.8 LM: And that kind of thing. There's nothing magical about it. And then when you understand that and you say, \"Well, I have this wealth of data in my business, can I find new business opportunities with this?\" And the answer to that, then is potentially, yes. In the same way as that scientist at Google was able to build a system to be able to predict somebody's age from a retina scan, which nobody knows how you can look at a retina and determine an age. From the model that they built, so you can now do an audit of that, and there's something called attention mechanisms, so you can see where the computer is paying attention to, to be able to derive what it is in a retina that let's you pick somebody's age. But it's like those are the kind of things that now, that the brute-force aspect of sheer compute power, doing that kind of pattern matching allows you to come up with these new scenarios that will rise you up through that plateau of productivity.\n\n\n\n0:20:07.3 RS: Yes, so you said it was an attention mechanism? And this allows you to clue in on, this is the variables that it was taking into account to result in this insight?\n\n\n\n0:20:18.1 LM: Yeah. Exactly, exactly. I teach it in one of my Coursera courses. I do advanced computer vision. And there's one really fun example that we go through in that one, it's not the retina one, that one is a little bit too complex, but there's a very famous machine learning exercise, which is pictures of cats and dogs that I was talking about earlier on, and how you train a computer to be able to recognize the difference between a cat and a dog. And you build a machine learning model in the course that can quite accurately tell the difference between a cat and a dog. But then you also do the attention mechanism stuff on that. And it turns out the primary difference that in this case, the computer was looking at, to pick the difference between a cat and a dog was the eyes. Sometimes you think, \"Oh the cat has pointy ears, the dog has floppy ears, for the most part\" or \"Their noses look differently\", but for the most part, when this model was actually working to pick the difference, it was like those were the features that it had zeroed in on and so then I was able to learn from that and go, \"Aha, so now when I build a model, maybe I should focus on the eyes to be more efficient\", that type of thing.\n\n0:21:16.7 RS: Yes, it strikes me as a crucial mechanism in removing harmful biases, for example, from a black box AI, from being able to look under the hood and say, \"Okay, this is what it was looking at to get this insight\". That can help remove a lot of this fear and a lot of these potentially, harmful biases or incorrect assumptions that technology would make.\n\n0:21:41.9 LM: Yeah, yeah, exactly. And there's a technique, it's also called... There's a thing that you can build, called a class activation map, and the idea with the class activation map is, you're seeing what the computer was paying attention to. A funny story about them, the US Army, realized that maybe computer vision could be used to see things and images that humans couldn't see. And say take for example, on the battlefield, what about being able to see a camouflaged tank? That like a human could look at it, camouflage is designed to fool the human eye, but what if you could have a machine be able to detect like a camouflage camouflaged tank? So they did an experiment where they got a bunch of data scientists and a bunch of machine learning engineers and they gave them a tank, and they said, \"Hey, you go out into the woods and one day take a whole bunch of pictures of this tank un-camouflaged\", and then the following day, they got the camouflage nets, and they put the camouflage nets on the tank and take a whole bunch of pictures of this tank camouflaged. And so build a model off of this one to see if you can pick a camouflage tank or a non-camouflage one, and they did what all good data scientists do, they had a training set of data, they had a test set of data, they had a validation set.\n\n0:22:54.3 LM: They built their model, they ran it and it was like 99% plus accurate. And they were like, \"Oh my gosh, we have built something that can really, really change the course of the battlefield\". They presented that to the Army, the Army loved it, and then they took it out and tested it and it failed completely.\n\n0:23:10.8 RS: Oh no. [chuckle]\n\n0:23:12.5 LM: And the reason why it failed completely was that, they took the pictures of the un-camouflaged tank one day, and they took the pictures of the camouflaged tank on another day. And on the day that they took the camouflaged tank, the sky was cloudy, and on the other day they had a blue sky, and then when they fed this back through an intention mechanism, they realized they didn't build a camouflage detector. They built a cloudy sky detector. [chuckle] So with the black box element of this kind of thing, it's easy to think that these are hard to debug and that kind of stuff, but they're not necessarily that difficult to debug if you understand how they're architected, and if I gave the elevator pitch for how you to do this, when you train an AI system or a machine learning system, you're flowing data one way and doing back prop the other way, but when you wanna do these attention mechanisms, those kind of things, it's just the way of flowing data in the other direction and effectively de-compiling it. If you're going through convolutions, you're de-convoluting it and that kind of stuff, and you can get a pretty good estimate for how the computer is looking at your data.\n\n\n\n0:24:12.1 RS: What is the difference between a classification map and an attention mechanism?\n\n\n\n0:24:15.6 LM: A class activation map is a...\n\n\n\n0:24:17.1 RS: Yeah. Thank you.\n\n\n\n0:24:18.3 LM: So it's a case of when you build a Convolutional Neural Network in particular, you're learning filters that can isolate features in a map, and a class activation map is where you just figure out where those features are on, you light it up on a diagram with a heat map or something like that. And that is a type of attention mechanism. There are also other ways of you being able to pick out attention within a machine learning model or something like that. Class activation maps are a very common one that are used in Computer Vision. Anything that you do, Convolutional Neural Networks, to be able to identify features, there are... Sometimes also use used Convolutions for sequence maps, so if you wanna predict weather in the future or something like that, you may use a one-dimensional convolution on that, and you can potentially have a class activation map there where it spots like, \"Hey, when you got a spike followed by a dip\", in this kind of thing, then that's usually followed by something else. But typically, it would be in an image-based one, it's where it's most commonly used.\n\n0:25:17.6 RS: I like how you mentioned the examples of the smartphone and understanding Hype Cycles, I'm curious if there are any lessons you think we can learn from the way that, that sort of technology was deployed and iterated upon that we can correct or do better with... As AI is sort of spread to the world.\n\n0:25:35.7 LM: The first part is letting people realize that they are in a hype cycle, we've been in hype cycles before. The people who were successful, were the ones... Or initially successful, at least, were the ones who saw through that, and this is what they did to see through it. Exposure to the platform, exposure to the technology, trying out new and exciting and different things, there's a whole graveyard of failed apps on Android and iOS, which laid the framework and the pathway for those apps that were successful. So really being those kind of early adopters, having that, try what you can, learn, iterate, continue. That's what's led to success, and I think that's the same kind of thing that can lead to success in the AI space.\n\n0:26:19.2 LM: One of the advantages of the AI space, is that the amount of investment that you have to make to be successful is a lot less than the amount of investment you might have previously had to make to become the big mobile app developer or to become the big website, and as a result, you don't necessarily have to be housed in the traditional areas on centers of excellence and success. So if we can try to democratize AI as much as possible by making it as available to as many people as possible so that they can seize opportunities that the rest of us may not actually think about, that could pave the way to success for them and for everybody else also. For every success, there's probably going to be a 100 failures, and it's really understanding that, realizing that, but I would rather have a 101,000 people do something so that there's a thousand successes and 100,000 failures, than have 1001 people do it where there's only one success, if my math add up. I told you I'm not very good at math.\n\n[chuckle]\n\n0:27:23.4 RS: Yeah, the one... Yeah, I think that adds up. Of course, the YouTube channel and the MOOCS, and a lot of the content that you produce is any in the interest... It's accessible anywhere. Someone who has internet access can learn from an expert, such as yourself. I do worry though, at what point is there a breakdown in terms of the hardware and the ability to actually design this technology? Does one need access to cloud computing and a work horse of a laptop to be able to play in this field?\n\n0:27:53.3 LM: To be able to get started and play in this field, absolutely no. To be able to go huge in this field, you do need access to high-end hardware like GPUs and TPUs and that kind of thing. So to split those two audiences for the Getting Started one, that's where we've been very carefully focused on easy high-level APIs that will run in Python, which is easy to install and use, that you can do on any laptop with the a CPU so that you can get up and running and kick the tires with these kind of things and to make that as quick and easy as possible for anybody to do. When you go beyond that though, and you start trying to train bigger models, not everybody has access to GPUs, not everybody has access to TPUs. So part of our strategy there was, we have this thing called Google Colab, and Google Colab is an in the browser notebook that runs with a Google Cloud back-end that can provide you free access to a GPU or a TPU. Obviously it's limited, but it's pretty generous. It's many hours of training that you can get for that, and all you need is a browser and a web connection to be able to do that, if you don't already have the hardware.\n\n0:29:00.3 LM: So that's the one first part of the offering. The another part of the offering though, is that when we start thinking about where do your models execute? Okay, so that many models are gonna be built to execute in data centers, the likes of Google or Amazon or Microsoft or on... But that's not the only area of opportunity, we can see that the area of opportunity on mobile handheld devices, embedded systems and all those kind of things is possibly even larger. And with the price of them dropping sharply, the hardware to build a phone is getting cheaper, the hardware to build embedded systems is getting cheaper. Then as long as we have an ecosystem of tools that will allow you to build for them with as low a dollar cost of entry as possible, as low an intellectual cost of entry as possible, those kind of things, that's when those markets can be seeded and those markets can grow. And like I said, I think we can all benefit. Let me share one example, 'cause there's a great project that... It was a couple of years ago, that was built by a bunch of high school and college students in India. And it's called Air Cognizer, I think that's the right phrase.\n\n0:30:09.6 LM: And it's on the YouTube web... The TensorFlow YouTube website. And what they did was that they realized that in their city in India, there was extensive air pollution. And you know what it's like, we all probably are encountering and nowadays with fires nearby, I live in Washington, so every year we have to start looking at air quality because of forest fires. But what they realized was that, when you look at air quality and you see it on the news, or you see it on a website, that's the air quality at a sensor, which is being operated by somebody. Now that might be 20-30 miles from where you live, and the air quality where you live might be severely worse. Elderly parents that they had and grandparents were afraid to go out because they don't know the air quality and they could get sick. So these students got together and they realized if they get a sensor to measure the air quality, and they get a phone, a cheap Android phone with a camera on it, if they take a picture of the sky, they have data. If they measure the air quality on the sensor, they have a label, and if they go all over their city and they take lots of these pictures and lots of these sensors, you do that basic pattern matching to kind of build a model where you're saying, \"Well, when the sky looks like this, the pollution is like this\".\n\n0:31:27.8 LM: And they turned that into an app, and now lots of folks in India can use that app where they can just take a photo of the sky and see a good prediction of the air quality near them, instead of looking at the news and seeing an air quality indicator that could be 20, 30, 40 miles away. And it's like little things like that, little innovations like that, because these were high school and college students, they don't have a lot of money, they're not forming a startup where they're hiring developers to do this kind of thing, the equipment for them to do that, was basic laptops that they had, the data? They generated the data themselves because they had the sensor and they had a cell phone where they could take a picture of the sky, they were able to build a model for this using the open source ecosystem, and they were able to deploy it for free to Android phones.\n\n0:32:12.5 LM: These kind of things, when I talk about really lowering that bar so we could raise the floor, but now it's like, \"Well, the rest of the world can benefit from what they learned\", because we now have the same problem in the West because of forest fires. And I could potentially go out and do the same thing to build an Air Cognizer for Washington State without needing to invest millions of dollars in a start-up to do so. So when you bust through that hype cycle and you understand how this works, then you can think like that, and that's what they did, they thought like that, and boom, they came up with this really cool solution.\n\n0:32:42.8 RS: This is the focus of your, about to be published, new book. Is that correct?\n\n0:32:47.1 LM: Yep, so it's an AI and Machine Learning for On-Device Development is my upcoming book. I originally was gonna create this mega-book for O'Reilly called AI and Machine Learning for Coders. We realized this weighed too much for one book.\n\n[chuckle]\n\n0:33:02.4 LM: So last year, I released the AI and Machine Learning for Coders, and now this year, it's kind of like the complimentary book/sequel, which is a AI and Machine Learning for On-Device Development. So it's really showing you how, as a mobile developer, you can start using models on Android, on iOS and a little sprinkling of doing it in a server with remote access or doing it on things like Raspberry Pi. It's packed with lots of examples of things like, you take a picture, here's how you can detect a face in the picture. Or here's how you can count the number of objects in the picture, like maybe you're building an app that's counting traffic, driving past your house. How do you count the number of cars? Those kind of examples... So I try to get very hands-on with them, of like, here's basically how this stuff works on your device. As of today, you don't train models on the device, you use models on the device. So the concept of my first book, AI and Machine Learning for Coders, or my first book in the series was really, \"Here's how you build the models\", and then the second book is, \"Okay, when you have models or there are off the shelf models available, here's how you use them, or here's how you can customize them to actually use them on your device\".\n\n0:34:16.9 RS: Okay, so the model is not constructed locally? The model is accessed?\n\n0:34:20.9 LM: Yeah. As of today, trying to train a model on a mobile device, it's just going to be very hostile towards your battery because model training is very intensive. We are doing a lot of work on making that better, but as of today... Yeah, as a developer, you're better off training a model in the cloud with something like Colab, or on your developer workstation and then deploying it to your device.\n\n0:34:46.4 RS: Yes.\n\n0:34:47.3 LM: But that's changing. That is changing.\n\n0:34:48.1 RS: Yeah. Well, fans of this podcast will remember our episode with Sama CEO, Wendy Gonzalez, who was speaking about this similar kind of problem of, \"How do we democratize access to AI?\" and I can envision an approach to that, which is just drop a 100 copies of your book and a 100 Android devices, just anywhere in the world and let a rip, right?\n\n0:35:10.2 LM: Yeah, yeah, please do. I'd love to see the results.\n\n0:35:16.8 RS: Laurence has published all manner of content about the realities an opportunities of AI, both philosophical and technical. In the episode description, you'll find links to his MOOCs, books, and the TensorFlow YouTube channel where he frequently contributes. You can also find Laurence's resources on the new, How AI Happens, LinkedIn group. Here, we'll post all the research and resources mentioned by our guests and give you the opportunity to rub shoulders and ask follow-up questions with the experts you hear featured on the show. Just search How AI Happens on LinkedIn and say, hello. How AI Happens is brought to you by Sama. Sama provides accurate data for ambitious AI. Specializing in image, video and sensor data annotation and validation for Machine Learning algorithms in industries such as transportation, retail, e-commerce, media, MedTech, robotics and agriculture. For more information, head to sama.com.","slug":{"_type":"slug","current":"/podcast-google-global-ai-development"},"tags":[{"_key":"saTGs8ZP","label":"Ethical AI","value":"Ethical AI"},{"_key":"jr0XK73o","label":"Podcast","value":"Podcast"}],"title":"New Podcast Episode: Making AI Development Global with Google's Laurence Moroney"},{"_createdAt":"2021-07-29T17:14:55Z","author":{"_id":"10ead718-57e1-41a8-b846-da3c81cc323a","avatar":{"_type":"image","asset":{"_ref":"image-a4c79da81bb1e23ce10fba84ea2cba5efe67a2a5-200x200-webp","_type":"reference"}},"bio":"Currently a Director of Product Management at Sama, Saul is passionate about the intersection of technology and social impact. He manages Sama’s data labelling products to ensure high quality training data efficiently and reliably reaches our customers. Experienced in both product and professional services, Saul is a proven leader who takes a data driven approach to expanding Sama’s capabilities and features. When not at work, you can usually find Saul enjoying the outdoors and spending time with his family.","name":"Saul Miller","slug":{"_type":"slug","current":"saul-miller"}},"config":{"description":"ML Assisted Annotation can help you generate high-quality pre-labeled and human-assisted annotations, for predictably higher quality data in half the time.","openGraphImage":null,"title":"ML Assisted Annotation Powered by MicroModels"},"estimatedReadingTime":7,"featured_image":{"_type":"image","asset":{"_ref":"image-65b7fac1b60586a0a7b9ff75006684e2c2467f1e-1800x900-png","_type":"reference"}},"plaintextBody":"Your machine learning model is only as good as the data it’s trained on. And with 80% of AI project time being spent training the large volume of data necessary to train a model, efficiency improvements early on in the process are sure to have compounding effects.\n\nAt Sama, we have a dedicated Machine Learning team working at the forefront of AI research to identify optimization opportunities just like this, so we can develop advanced annotation tools to smooth the path to production for our clients. One of the papers the team presented at last year’s CVPR—Human-Centric Efficiency Improvements in Image Annotation for Autonomous Driving—shared an approach to speeding up polygonal instance segmentation using ML.\n\nToday, this technology has been incorporated into our platform to make our clients’ labeling process more efficient.\n\nWe call it ML Assisted Annotation powered by our MICROMODEL technology, and it’s already helping clients predictably get higher quality training data in half the time.\n\nRead on for an overview of ML Assisted Annotation powered by MICROMODEL technology how it can help you develop models that are more scalable, robust and accurate – and can be brought into production more quickly.\n\nWhat is ML Assisted Annotation powered by MICROMODEL technology?\n\n\nML Assisted Annotation (MAA) powered by MICROMODEL technology is an architecture that allows Sama to expedite the labeling process by drawing from a library of models trained on specific use cases. MAA can be used to generate high-quality pre-labeled annotations, which annotators validate to help them continuously improve over time.\n\nThis powerful combination of skilled annotators and an AI-powered platform allows us to deliver a high standard of label quality to our customers every time, along with efficiency improvements and quicker time to market.\n\nHow it works\n\nIn order to understand how MAA works, we first need to discuss the DEXTR model. DEXTR, or “Deep Extreme Cut,” is a publicly available object segmentation model for images and videos. \n\n\n\nWe’ve outlined the DEXTR model and our approach in detail in this post.\n\n\n\nMany ML methods like DEXTR have been suggested to speed up the process of instance segmentation, but these are not typically tested in a high-scale production environment, nor are ML outputs easily edited by human annotators. This makes it difficult to confidently reach the label quality standards required to run a model in production.\n\nMAA combines the well-known DEXTR approach with a raster-to-polygon algorithm to make results easily editable by a human in the loop. We’ve found that this approach—which pairs skilled annotators with ML-powered automation—significantly increases labeling efficiency and quality.\n\nLet’s see what that looks like in practice, using an example from the Autonomous Vehicle industry.\n\nMachine-Assisted Polygon Annotation\n\n\n\nWhen an annotator logs into the Sama annotation platform, they are presented with this workspace. In this example, the workspace is customized to allow the annotator to draw instance segmentation polygons around each of these vehicles:\n\n\n\nYou’ll notice that there are several vehicles in this image. In a manual context, it could take a human several hours to deliver high-quality annotations of every single vehicle:\n\nWhat the manual annotation process would look like (sped up significantly): several clicks are required to draw a polygon around each of the vehicles.\n\n\n\nThis process is significantly accelerated with Machine-Assisted Polygon Annotation.\n\nThe model allows the annotator to use a crosshair tool to identify only four extreme points: left, right, top and bottom boundaries. These four clicks are the only inputs needed to create a heat map that is then sent to the inference server, returning an accurate prediction of a raster mask.\n\n\n\nWith Machine-Assisted Polygon Annotation, annotators only need to perform four clicks to produce an accurate raster mask prediction.\n\n\n\nMachine-Assisted Polygon Editing\n\n\n\nA polygon prediction can then be further refined by an annotator by switching into editing mode. This enables annotators to label precisely and ensure that high-quality requirements are met without compromise.\n\n\n\nIn this example, the raster mask prediction is edited by the annotator to ensure precise and high-quality labels.\n\n\n\nThis mode also enables annotators to use more than four extreme points in order to produce even more accurate predictions. A fifth user input point can easily be added, with the model immediately incorporating the new input to update its prediction.\n\nIf an ML model struggles to identify specific shapes, annotators can add a few more inference points to help result in a more accurate prediction, and then refine that prediction manually to ensure high-quality labels.\n\nResults from ML Assisted Annotation powered by MICROMODEL technology\n\n\nOur clients are already seeing impressive results from MAA powered by MICROMODEL technology:\n\nPredictably producing 94-98% IOU (Intersection over Union) accuracy\nBecause our models are pre-trained on specific use cases for better performance out of the gate, our clients are seeing a quicker time to accuracy.\n\n2-4x more efficient annotation process\nYou can clearly see above that using MAA over a more manual polygon labeling approach results in significant time savings. But it’s also an iterative process with a human annotator in the loop; modifications to the predictions get fed back into the training data pipeline to retrain the model, enabling it to perform better predictions over time.\n\n\nQuicker time to market\nThe end result for our clients is faster iterations and a quicker time to market. A more efficient annotation process results in more data returned quickly, and ultimately a significantly shorter path to production.\n\nWhat’s more: increasing the efficiency of this labor-intensive manual data annotation process reduces the barrier to entry for more ML teams... and not just those with large R&D budgets. Technology like this can also help democratize data labeling by driving down cost, so we can see even more deserving companies leverage AI to drive value for their business.\n\nSmall teams who are getting started with labeling may not have yet defined what type of annotations they need, or how much data they need to be successful. MAA can help them iterate more quickly, developing models in short increments rather than in large, cumbersome workstreams. The end result is a quicker time to value, and ultimately, to market — for organizations of all shapes and sizes.\n\nLearn more about ML Assisted Annotation powered by MICROMODEL technology by watching our recent webinar here, or reading more about it here.","slug":{"_type":"slug","current":"ml-assisted-annotation-micromodels"},"tags":[{"_key":"giPx682h","label":"Machine Learning","value":"Machine Learning"},{"_key":"JOgmW0AV","label":"Data Annotation","value":"Data Annotation"},{"_key":"45fExC0n","label":"Autonomous Transportation","value":"Autonomous Transportation"}],"title":"ML Assisted Annotation Powered by MicroModels"},{"_createdAt":"2021-07-15T18:31:35Z","author":{"_id":"37c7e793-6028-467d-9b68-f43d8c0e1812","avatar":{"_type":"image","asset":{"_ref":"image-0bedc789dac36f338b424f6e94cdc5966aeff856-360x360-webp","_type":"reference"}},"bio":"Kristen Itani Koue is passionate about using tech as a force for good. As Sama's Senior Impact Manager, Kristen leads efforts to measure and expand the impact of Sama's ethical supply chain and sustainability initiatives. Kristen is most happy when pushing companies to do what is best for all their stakeholders, running around after her two young children, or climbing up or snowboarding down mountains.","name":"Kristen Itani Koue","slug":{"_type":"slug","current":"kristen-itani-koue"}},"config":{"description":"This whitepaper by Partnership on AI examines the working conditions of data enrichment professionals, and what can be done to improve them.","openGraphImage":null,"title":"New White Paper by Partnership on AI: Responsible Sourcing of Data Enrichment Services"},"estimatedReadingTime":4,"featured_image":{"_type":"image","asset":{"_ref":"image-fdeacb17e65c946761066de369acc4bdf1353a73-3334x1668-png","_type":"reference"}},"plaintextBody":"When an organization sets out to build and deploy an AI model, a number of decisions have to be made. Decisions around building a robust data pipeline are among the most fundamental.\n\n\n\nChoosing the right data partner will obviously impact how well a model performs. If we look a bit deeper, we also find that this choice has a real impact on the well-being of the whole data supply chain workforce. Sometimes collectively referred to as data enrichment professionals, all workers involved in the data supply chain—from labelers to quality analysts—are affected by an organization’s data procurement decisions. \n\nThe complexity of the data procurement process combined with a lack of standards around equitable data supply chains has several downstream implications for these essential but largely unseen workers. Despite their foundational role, working conditions for data enrichment professions can be precarious: they can face wage uncertainty, low pay and limited career growth opportunities.\n\nYour data enrichment choices have a direct impact on workers’ well-being\n\nThere is, however, an opportunity to make a difference. The decisions organizations make while procuring data labeling services can have a meaningful impact on the working conditions of data enrichment professionals.\n\nPartnership on AI (PAI) is a multistakeholder organization that brings together academics, researchers, civil society organizations, companies building and using AI technology, and other groups working to better understand AI's lasting impacts. Their latest white paper Responsible Sourcing of Data Enrichment Services examines the working conditions of data enrichment professionals, and seeks to:\n\nCritically evaluate the impact of the industry’s current practices on workers;\n\nExplore practices the industry can adopt to improve worker well-being; and\n\nAdvance the discourse around the future of data enrichment work and the indispensable role it plays in AI development.\n\nThe paper gives AI practitioners and decision makers visibility into the impact of their decisions in procuring data enrichment services – from selecting providers, to running pilots, to conducting quality assurance and more.\n\nRead the full white paper: Responsible Sourcing of Data Enrichment Services\n\nSince data labeling is a key part of this equation, it was important for Sama to partner with PAI: to both share our lessons learned from several years of striving for more ethical supply chains, and to continue to learn from industry peers about responsible AI.\n\nIn fall of 2020, Sama participated in the five-week series of Responsible Sourcing workshops held by PAI, the output of which was a set of strategic recommendations for this white paper. The workshops brought together more than 30 professionals from different areas of the data enrichment ecosystem including representatives from data enrichment providers, researchers and product managers at AI companies, and leaders of civil society and labor organizations. \n\nTo fully understand the impact of AI on society, one must examine the bias and shortcomings of models, but also the means by which they are created.\n\nWhile more work and research is needed, Responsible Sourcing of Data Enrichment Services shares actionable insight that practitioners can use as a starting point to raise important conversations with internal stakeholders. Our hope is that these conversations will be a step in the right direction: toward giving data enrichment professionals better recognition for the critical role they play in building AI. \n\nRead the full white paper: Responsible Sourcing of Data Enrichment Services\n\n\n","slug":{"_type":"slug","current":"partnership-on-ai-whitepaper"},"tags":[{"_key":"pwpeoY5O","label":"Ethical AI","value":"Ethical AI"},{"_key":"Sf3M02mD","label":"Impact","value":"Impact"}],"title":"New White Paper by Partnership on AI: Responsible Sourcing of Data Enrichment Services"},{"_createdAt":"2021-06-24T16:00:00Z","author":{"_id":"e8a1f3c6-0b07-4638-93d5-61a0924f32e3","avatar":{"_type":"image","asset":{"_ref":"image-2f8efc599a377bd580d0ae12f022a15e7e1acacd-632x676-webp","_type":"reference"}},"bio":"Amanda is the Content Marketing Manager at Sama, where each day she gets to learn about AI and how it’s transforming industry. She’s passionate about technology but periodically tries to get away from her computer to explore more analog things like collage and quilting.","name":"Amanda Durepos","slug":{"_type":"slug","current":"amanda-durepos"}},"config":{"description":"Project Guideline by Google partnered with Sama to help people who are blind run without a guide, using only a smartphone, headphones, and a yellow guideline.","openGraphImage":null,"title":"How Sama's Accurate AI is Helping Blind Runners Run Independently"},"estimatedReadingTime":5,"featured_image":{"_type":"image","asset":{"_ref":"image-080a7046afcb7bb25b5af2d55d55883944f1c5eb-3334x1668-png","_type":"reference"}},"plaintextBody":"Project Guideline is an early-stage research project by Google that explores how on-device machine learning can help people with reduced vision to walk and run for exercise independently. The team has partnered with Sama to help fuel their experimental technology; allowing people who are blind and low vision to use a mobile phone, headphones, and a yellow guideline painted on the ground run without a guide.\n\n\n\nOverview\n\n\n\nIt started with a pointed question during a Google hackathon in the fall of 2019. Thomas Panek, an avid runner and CEO of Guiding Eyes for the Blind, posed the question to a group of designers and engineers:\n\n“Would it be possible to help a blind runner navigate, independently?”\n\nPanek, who is blind himself, has completed more than twenty marathons, including five Boston Marathons. While he’s had guide dogs and volunteer human guides to run with him throughout the years, he’s always had to follow—even though his legs and lungs had the capacity to go faster.\n\nIt quickly took off from there. By end of day, the team had a working prototype. Less than a year later, Panek was able to run independently for the first time in more than two decades.\n\nRead the full case study here. \n\n\n\nThe Challenge\n\n\n\nThe machine learning algorithm developed by Google requires only a line painted on a pedestrian path. Runners wear a regular Android phone in a harness around the waist and count on the camera to feed imagery to the algorithm, which identifies the painted line. The algorithm is tasked with detecting whether the line is to the runner’s left, right, or center, so audio signals can be sent to the runner to guide them to stay on track.\n\nFor humans, it’s fairly straightforward to recognize a line and follow it. For a machine learning model, it isn’t that easy. Imagine the running motion: as you start moving your feet you step from left to right, introducing a shake that can make the guideline blurry. Moving outdoors to Panek’s preferred running location, you introduce even more variables. The model must be able to handle a wide range of weather and lighting conditions, or objects like fallen leaves blocking the guideline.\n\n\n\nThe Solution\n\n\n\nSama’s expert annotators draw precise polygons around the single solid yellow lines and a single center line in the images. To do this, the Sama team underwent an intensive training process and continues to meet with Google’s engineers each week to check in on quality, discuss edge cases, and receive new instructions. Thus, with enough examples to learn from, the algorithm is trained to distinguish the pixels in the yellow line from everything else.\n\nBut quality AI starts with quality data. And quality data has to be diverse. The Project Guideline data needed to encompass every imaginable scenario that a runner might encounter. In Panek’s case, we quickly noticed that we had to include the runner’s hand blocking the guideline. This was solved by having our annotators infer the position of the line behind the hand—a great example of something that is easy for a human to do but rather difficult for a computer. By continuously adding these variations to the dataset, the model is getting smarter over time. \n\nFueling the cutting-edge technology that helps a blind man run without assistance truly is the stuff that dreams are made of. Sama’s annotators, the experts giving artificial intelligence its intelligence, love being a part of Project Guideline. Bridget Nattabi, who has worked on this project since its kickoff in July 2020, shares her thoughts:\n\n“Working on this project has allowed me to grow and master polygon annotation with high efficiency and accuracy. I also feel honored to be part of a team that is creating a life-changing navigation experience for the blind. It’s heartwarming to consider that what I do gives people a chance to navigate the world without a guide just like any sighted individual would.”\n\nA word from Project Guideline\n\n“Sama was a force multiplier for us and a key success factor for our project. They delivered high-quality annotated data on time, listened to our feedback, and were very flexible in accommodating our requests.”\n-Xuan Yang, Computer Vision Researcher at Google\n\nRead the full case study here. \n","slug":{"_type":"slug","current":"google-project-guideline"},"tags":[{"_key":"3slAcWy7","label":"Case Studies","value":"Case Studies"}],"title":"How Sama's Accurate AI is Helping Blind Runners Run Independently"}],"featuredPosts":[{"_id":"27487c06-2421-4d39-8930-6c49a04ffa49","featured_image":{"_type":"image","asset":{"_ref":"image-19ef3f125b8ee47727e9f94dc3aff7ed08a4d78c-720x360-png","_type":"reference"}},"slug":{"_type":"slug","current":"devops-tools-for-cloud-native-engineering"},"tags":[{"_key":"8AQmCtzZ","label":"Sama Engineering","value":"Sama Engineering"},{"_key":"Gl5fCrPJ","label":"Featured","value":"Featured"}],"title":"Factotum: Containerizing DevOps Tools for Cloud Native Engineering and CI/CD"},{"_id":"085b9054-a1d9-447e-a430-d2df9be23647","featured_image":{"_type":"image","asset":{"_ref":"image-04641081798c41caebebefa44685828d80b7434f-1200x675-png","_type":"reference"}},"slug":{"_type":"slug","current":"part-1-automating-model-training-on-the-cloud"},"tags":[{"_key":"OdrqBpR4","label":"Sama Engineering","value":"Sama Engineering"},{"_key":"Yw0P8Jjj","label":"Training Data","value":"Training Data"},{"_key":"08tVZdgm","label":"MLOps","value":"MLOps"},{"_key":"eMmu9s8R","label":"Featured","value":"Featured"}],"title":"The Sama MLOps Pipeline: Automating Model Training on the Cloud"},{"_id":"d57f4906-bd8a-4f84-8d9d-8bea5e8d7797","featured_image":{"_type":"image","asset":{"_ref":"image-6abd2f846119ba50a8325787f99ec3aeec68ffff-1076x605-png","_type":"reference"}},"slug":{"_type":"slug","current":"fast-vector-annotation"},"tags":[{"_key":"fJGSmFCx","label":"Vector Annotation","value":"Vector Annotation"},{"_key":"21OOfbwx","label":"Polygons","value":"Polygons"},{"_key":"SPABaoXN","label":"Sama Engineering","value":"Sama Engineering"},{"_key":"O5nmmFbm","label":"Featured","value":"Featured"}],"title":"Fast Vector Annotation with Machine Learning Assisted Annotation"}],"morePosts":[{"_createdAt":"2021-06-22T15:12:25Z","author":{"_id":"f972de8a-10c1-45e3-97c9-ac490eaceabe","avatar":{"_type":"image","asset":{"_ref":"image-4aa17073cfd70d2e8f7d8ed85325c14cb1519577-692x691-jpg","_type":"reference"}},"bio":"Loic has over 20 years of industry experience in the Cloud services and AI industry. At Sama he works as the VP of Research & Development. His experience includes Fortune 500 Companies such as Salesforce.com, Unity Technologies, and AT&T where he led the development of large scale AI, data analytics, and cloud solutions. Loic received his MS in computer science from UTBM, France.","name":"Loic Juillard","slug":{"_type":"slug","current":"loic-juillard"}},"config":{"description":"Sama's third annual Innovation Week is coming to a close, and once more, our teams have given us plenty to be excited about.","openGraphImage":{"_type":"image","asset":{"_ref":"image-c1343597ce10d9d908608f0be0204d0a0d9a09b2-1200x600-png","_type":"reference"}},"title":"Innovation Week: How Sama Builds a Culture of Experimentation"},"estimatedReadingTime":3,"featured_image":{"_type":"image","asset":{"_ref":"image-c1343597ce10d9d908608f0be0204d0a0d9a09b2-1200x600-png","_type":"reference"}},"plaintextBody":"At Sama, we are committed to building a platform that helps organizations bring their models to production more quickly. But succeeding in a field as nascent as AI requires more than just bright minds and an ambitious roadmap.\n\n\n\nA key ingredient to success – and one that is often overlooked – is a mindset of experimentation; a culture that encourages teams to solve issues in new and more efficient ways. Early on, we found that our teams thrive in this kind of environment, which is why this week, we’re wrapping up our third Innovation Week. \n\nThe concept is simple: for one week, anyone can work on a project they feel passionate about. During the week, you have free rein to work on whatever you please in whichever way you choose. There are no meetings and no interruptions. You are free to try new things, invent and learn. You can be part of a team or single-handedly run with your ideas.\n\nThis year, some exciting highlights include:\n\nA more efficient approach to video tracking and segmentation\n\nNew Smart Polygon tool that is able to greatly increase annotation efficiency\n\nEnhancing our platform through the introduction of a Sama CLI and data pre-processing capabilities\n\nThe atmosphere is incredible. The week starts with a kickoff, where everyone can present the problem they are trying to solve and how they are planning to solve it. The closing ceremony is called the “Grand Reveal,” where each individual or group demos what they worked on. It sometimes yields incredible presentations... other times, it doesn't.\n\nFreedom breeds creativity. These events have brought some of the most core and innovative components of our platform. Last year, over 50% of all Innovation Week projects were incorporated into our roadmap and implemented within the following two quarters. A perfect example of this is our MicroModel technology, which was initially borne from one of these projects. We now use this technology for Machine Assisted Annotation for deployments in the automotive and e-commerce industries.\n\nNot only does the event enhance our product, it also attracts talent. This year, we doubled our R&D team and are continuing to grow.\n\nInnovation Week gives our R&D team the space to do what they do best: observe, experiment and discover.\n\nInnovation Week is coming to a close, and once more, our teams have given us plenty to be excited about. As always, many of the projects are slated to appear on our platform. In particular, we saw lots of work around our new 3D LiDAR annotation automation and data processing… stay tuned for that.\n\nAt Sama, Innovation Week is designed to encourage experimentation by allowing teams to shift the focus from our immediate customer’s needs to a broader, more bold approach to Machine Learning. If that sounds fun to you, consider checking out the open roles on our R&D team here.","slug":{"_type":"slug","current":"innovation-week-2021"},"tags":[{"_key":"DWf2I8xz","label":"Machine Learning","value":"Machine Learning"},{"_key":"TUfn4bAi","label":"Product","value":"Product"},{"_key":"imL766wL","label":"AI Practitioners","value":"AI Practitioners"}],"title":"Innovation Week: How Sama Builds a Culture of Experimentation"},{"_createdAt":"2021-06-17T19:32:29Z","author":{"_id":"e8a1f3c6-0b07-4638-93d5-61a0924f32e3","avatar":{"_type":"image","asset":{"_ref":"image-2f8efc599a377bd580d0ae12f022a15e7e1acacd-632x676-webp","_type":"reference"}},"bio":"Amanda is the Content Marketing Manager at Sama, where each day she gets to learn about AI and how it’s transforming industry. She’s passionate about technology but periodically tries to get away from her computer to explore more analog things like collage and quilting.","name":"Amanda Durepos","slug":{"_type":"slug","current":"amanda-durepos"}},"config":{"description":"Sama CEO Wendy Gonzalez joins our podcast, How AI Happens, to discuss why providing work is a more impactful approach to ending poverty than providing aid.","openGraphImage":{"_type":"image","asset":{"_ref":"image-1502043edcf701cb4267cb2f6d7c6edf8e0e0cad-2500x1313-png","_type":"reference"}},"title":"New Podcast Episode: Sama CEO Wendy Gonzalez on Upskilling Talent from Developing Nations"},"estimatedReadingTime":21,"featured_image":{"_type":"image","asset":{"_ref":"image-1502043edcf701cb4267cb2f6d7c6edf8e0e0cad-2500x1313-png","_type":"reference"}},"plaintextBody":"AI starts with data. Clean, curated, labeled, ready-to-plug-into-your-models data. But it’s not always so easy to get your hands on a dataset that you can use to quickly and efficiently push your models into production. That’s why the individuals who focus on data labeling are so important, and why Sama is making huge efforts to cultivate the next generation of AI specialists.\n\n\nRather than sourcing from the world’s top universities or boot camps, Sama has spent several years delivering a course entitled Artificial Intelligence 101 to individuals in Kibera, the largest slum in Africa. This course teaches students the basics of AI work, simultaneously training AI talent and taking aim at systemic poverty.\n\nTo discuss the results of these efforts, Sama’s CEO Wendy Gonzalez joined our podcast, How AI Happens. Wendy explains:\n\n🖥️ Why providing work is a more impactful approach to ending poverty than providing aid;\n\n🎓 How Sama’s program has measurably improved women’s income and employment rate by 60%;\n\n✏️ How data labeling skills provide talent with access to employment in AI and beyond.\n\n\n\nStream the full episode below, and if you’d like to see the nuts and bolts of how Sama’s mission has affected the community, be sure to check out MIT’s recent RCT study measuring the impact of AI education on student employability and income.\n\n\n(audio embed)\n\n\n\nAnd don’t forget to subscribe to How AI Happens on your favorite podcast streaming platform!\n\n\n\nTranscript:\n\n\n0:00:00.0 Wendy Gonzalez: Talent is distributed equally, but opportunity is not. And the best way to solve poverty, which is basically the root cause for every major social ill in the world, is by giving work, not giving aid.\n\n0:00:16.8 Rob Stevenson: Welcome to How AI Happens, a podcast where experts explain their work at the cutting edge of artificial intelligence. You'll hear from AI researchers, data scientists, and machine learning engineers as they get technical about the most exciting developments in their field and the challenges they're facing along the way. I'm your host, Rob Stevenson, and we are about to learn how AI happens.\n\n0:00:48.1 Rob: Today on How AI Happens, we're going to talk about the next generation of AI specialists. While this might bring to mind the image of a starry-eyed Stanford PhD or a youthful self-taught prodigy, I'm thinking of a different source of talent, because over the last several years, Sama has been delivering a training program entitled Artificial Intelligence 101 to eager individuals in Kibera, the largest slum in Africa, just outside Nairobi, Kenya. To learn more about how an AI company can train technical talent while simultaneously taking aim at systemic poverty, I sat down with Wendy Gonzalez, CEO of Sama.\n\n0:01:29.5 Wendy: I have, I'm a little embarrassed to say, over 25 years of experience [chuckle] in enterprise technology and SaaS and AI. I started my career in management consulting, really helping large companies figure out how to leverage technology. I switched over to the enterprise side, working to really implement disruptive technologies. And then I co-founded an Internet of Things startup about a decade back to build a SaaS platform, because again, IoT was a way to really disrupt the industry, and then I switched over to AI. So I joined Sama in 2015, and Sama is the leading trainee data as a service platform. We work with the Global 2000 to really help enable their mission-critical AI applications.\n\n0:02:13.1 Wendy: I was really compelled to join Sama because I believe deeply in Sama's mission, and really, our philosophy that Sama was founded on is that talent is distributed equally, but opportunity is not. And the best way to solve poverty, which is basically the root cause for every major social ill in the world is by giving work, not giving aid. Over a trillion dollars' worth of aid has been donated to sub-Saharan Africa since the 1960s, yet, GDP hasn't changed. While it seems like the right thing to do, the best thing that we can do to really solve the problem of poverty is by providing financial independence, and that's through giving work. And so, Sama's mission of purposely hiring people in underserved communities to give work was something that really spoke to me, because as a child of immigrants and marrying my husband who was the first person in his entire family through all generations to go to school, the power of work is transformative in terms of lifting up your community and lifting up the people in your family.\n\n0:03:11.4 Wendy: So that mission spoke very, very deeply to me. Sama had a really unique and audacious view on this, which is, it's not just about kind of paying living wages and providing employment and benefits; it's about purposely hiring people who've got the greatest barriers to employment. And so, Sama's model is to hire, in underserved communities, 50% women, 50% youth who have household incomes of less than $2 a day, which is the World Bank standard for poverty. And so I was fascinated with this idea of taking purposeful action and change to hire people and not just sort of provide wages, but really provide a transformative career path to hopefully break the poverty cycle permanently.\n\n0:03:52.1 Rob: This notion of giving work rather than aid has taken the form of Sama's Digital Basics Program, that's the AI 101 course I mentioned earlier. As Wendy explains, this training is the first step in removing the barriers to access between eager, underserved workers and well, work.\n\n0:04:12.8 Wendy: One of the challenges is not just about, \"Hey, I'm in this situation, I didn't graduate from a fancy school or college,\" it's also by just having access to the network to get jobs. So I say barriers to employment, it's not just kind of education and where I live, but it's like, \"Do I know the right people, how do we even get connected to a job?\" So the Sama Digital Basics Program really started by working with community partners in underserved communities, I'll give you an example in Nairobi, to where we work with partners like the Human Needs project that has a facility that is embedded in the Kibera slum, which is the largest slum sub-Saharan Africa. So, it was an idea to bring digital skills training into communities, so that, again, to provide and reduce that barrier to access.\n\n0:04:57.7 Wendy: And so what the Digital Basics Program does is it provides everything from basic skills like mounting and keyboards, but also the basics of AI. So what is artificial intelligence, what role does training data play in empowering artificial intelligence applications, and it's really the initial training that is necessary for somebody to come and join the Sama program.\n\n0:05:20.2 Rob: It should be pointed out here that the goal of the Digital Basics Program isn't merely to create a farm team of future Sami employees, though many of them do wind up working there; rather, the skills that go along with data labeling end up providing individuals with a much wider breadth of opportunity.\n\n0:05:38.4 Wendy: It's not just about building training for the purpose of, \"Okay, now you can do data labeling,\" what we found, if they're doing this program 'cause we were actually launched in 2008, is that the skills necessary to do labeling and tagging are critical thinking skills that actually apply to many different jobs on a go-forward basis. Our intention was always not just hiring people into Sama and you'll be with Sama for the rest of your lives; it was really about building the skills that allow our workers to go on to higher-paying jobs, return to university. That's the entire idea of when I say permanently breaking the poverty cycle, is to build the foundation so that people can move on to higher-paying jobs.\n\n0:06:16.1 Wendy: So while we have a pathway, of course, to move up within Sama, the other objective of this is to build a core set of technical skills. So the training typically occurs within community or at our offices, and then of the people who are trained, some go on and move on to other jobs, many come and apply at Sama. After doing this level of training, we would hire people in as employees, so we're different, we are not freelancing, we are not crowdsourcing. A part of our mission is to provide living wages, benefits, and professional development that'll allow people to further their careers. And so they get hired into Sama, and typically, they will do data labeling as an entry point. And so data labeling, just to take us back a little bit in terms of artificial intelligence, is that...\n\n0:07:03.7 Wendy: You think about it this way, AI is as intelligent as the trainee data it's built on, because machine learning is all about recognizing patterns, then using deep learning techniques for the application to make decisions. Put another way, before a car can drive itself, like a self-driving car, it needs to be able to detect roads, pedestrians, vehicles, and traffic signs, and training data is basically structuring the data so that a computer vision application can identify, what is a car, what's a drivable space, what's a road sign, et cetera. And while that sounds like it's relatively simple, it's actually incredibly, incredibly complex. Some of these data labeling activities include data labeling in 3D. I don't know if you've ever seen radar or light or images, it's very, very complex. And then beyond that, it's not just about detecting and after being that information correctly; it's about the precision of it. And so, tagging a car is not just tagging a car, sometimes you need to include the side-view mirrors, maybe you need to include the shadow under the car, maybe you do need to include what's behind the car, maybe you don't.\n\n0:08:05.3 Wendy: So there's actually quite a bit of complexity, and so, in terms of the types of work and the skills that are being built, you have to tie it back to a taxonomy, there could be business rules. So, a part of what's being developed as critical thinking skills as well.\n\n0:08:22.9 Rob: As I mentioned before, this program has been underway for years, so, this podcast episode isn't meant to be an audio press release. The reason I wanted to bring Wendy on to discuss the program is because of a recent study measuring the effects of these efforts, a six-year randomized control trial conducted by MIT and Innovations for Poverty Action, a research and policy nonprofit promoting effective solutions to global poverty. Wendy explained some findings from the report, and whether those findings were in line with initial goals.\n\n0:08:55.4 Wendy: The thing that we are really trying to understand or MIT was trying to understand is this purposeful hiring model that this part of Sama's mission, that's core to the way that we operate, is that intervention of purposely hiring somebody from an underserved community, does that actually improve their employability and their income rates in the long term? Does it actually break the poverty cycle that I was talking about before, or would these people just would have succeeded anyways?\n\n0:09:18.5 Wendy: So when we talk about really, how do you measure that, it's called a counterfactual study, which, when friends ask, \"Well, what do you mean? What is an RCT? Why did you do this study\", it's kind of like, the FDA does it for drug approvals, right? Somebody takes a placebo, somebody takes the medicine, and then you find out at the end, well, did the medicine really work? And so that's really what we're trying to do here. Did this purposeful intervention of hiring, did it make a difference in somebody's employability and growth and income?\n\n0:09:46.0 Wendy: The study wasn't just a matter of, \"Hey, let's take some surveys.\" It's actually even something in the works for six years. So we plan for a year, a year and a half, to identify folks and create a very detailed study, three years of actually surveying people on a regular basis. So, fun fact, over 2000-plus hours of surveying time [chuckle] and interviews and calls. But at the end of the day, the idea was to say, \"Did the intervention work? Is there a meaningful and material difference, and do we have all over the data over time to prove it?\" I believe all of our internal tracking that yes, we were, so it was amazing to get that ratified, that, yes, indeed, over the long term, this purposeful hiring model made a huge difference in terms of income and employment levels. But in particular for women, that was the thing that was really exciting to learn, and that was a little bit surprising, is that Sama's model has been to create a purposeful higher model of 50% women and 50% youth.\n\n0:10:48.0 Wendy: And we focused there from a mission perspective, because what I think has been well-researched and understood is that when women are lifted up in the economy and when women are lifted up in income, they contribute back to their communities, more kids go to school, there's a real network effect of investing in women. And so that was part of our purposeful hiring model, to where we have a criteria in hiring at least 50% women, which is a little bit unique, and again, purposeful. And what we found is that after this three-year time frame, there was a 60% improvement in employability and income rates for women who went through the Sama intervention versus who did not. And that was really exciting. Really, really exciting to see that that basically means that our hypothesis that women have barriers to entry and employment is indeed true, but that the purposeful hiring model at the beginning of their careers actually makes a difference in them not only having greater income but continuing to stay employed.\n\n0:11:46.5 Rob: When you look at the impact these studies showed with women specifically, was that surprising or just delighting?\n\n0:11:54.7 Wendy: It was delighting. We did a lot of community surveys before launching this program, because let's not just assume we know what people need, that's the entire point of financial independence, let's hear from them what is needed, and what we found is that, in particular, it was just really challenging for women to get into the right networks, to get jobs. And so, this was the model between that and knowing that the impact that women can have when they are lifted up, but I think what was surprising is not just the income levels, but I think what surprised me was the employment levels. I mean, 60% is significant. So, yeah, I was delighted, [chuckle] to answer your question.\n\n0:12:34.3 Rob: Of course, the ability to do a job and the ability to get a job are vastly different skills. This was reflected in the report, as researchers found subjects who did not receive employment placement assistance had a much harder time finding work, even if they had the same technical training as others. So, does that mean mere up-skilling is not enough?\n\n0:12:57.2 Wendy: I think what that speaks to is that while training is incredibly important, that action, the purposeful hiring, is really kind of what moves the needle. I'm all for providing the training, and I think what we found is that what we're trying to do is, in addition to the core skills training, is gonna be, how do we help people match themselves to jobs, and there's some pretty incredible organizations out there who are specializing in this area, so we don't assume we've gotta figure it all out. [chuckle] We are working with partners to help us on things like the skills matching. But the key thing, you have to make those purposeful choices, so, oftentimes, I talk to our customers about the ethical AI supply chain, or really how you use impact criteria as part of how you make your buying decisions. And I think that's something that's incredibly important, because I know we're going to be a proof point and move tens of thousands and over time, hundreds of thousands, of people out of poverty, but imagine the world's biggest corporations are spending trillions of dollars in procurement. Imagine what they can do if they make those same purposeful hiring decisions. We can leave millions and tens of millions of people out of poverty.\n\n0:14:08.6 Wendy: We're doing this at Sama, but I would love for every company in the world to take the same approach, and if you're not in a position to make these purposeful hiring decisions, well, work with suppliers, use social impact criteria as part of how you make your buying decisions. So the more we can get this out there, that, \"Hey, the model works,\" makes a meaningful difference, it also has tremendous business benefits as well. What happens for us, we have incredible retention, and that has created more value in our AI platform. So there are many, many different reasons to take this approach, and from a social mission standpoint, we can build incredible technology, create incredible value from our products, and we can change lives at the same time.\n\n0:14:51.5 Rob: What do you foresee in terms of additional education beyond data labeling? When you look at further development for their up-skilling, do you foresee that being an offering over time?\n\n0:15:00.8 Wendy: Oh, yeah, absolutely. I love that you mentioned that. I hate to sound buzz wordy, if you will, but I mean, data is the new code. The skills that are being built here aren't just for, \"Okay, I can label\"; it's really about building not just those critical thinking skills, but the way that we move our workforce up the value chain is that they are building analytical skills. So gone are the days where our workforce would come in and be like, \"Oh, is there a dog in this picture?\" or something like that. They're doing way more sophisticated work, doing everything from training machine learning models and driving very sophisticated training data sets, to evaluating and quality sharing training data sets that have been produced by automation, all the way to identifying what's missing, do we have a representative and complete data set? So it's really about moving from labeling and taxonomies and workflows to analytics and beyond. So, yeah, there's a lot of exciting work ahead, and beyond the analytics and management, yes, data science, that is the next frontier.\n\n0:16:08.7 Rob: If data science is the next frontier, then any company seriously deploying it has an awesome responsibility, not just to make a great product, but to utilize this technological position to up-skill the next generation of talent, and do so in such a way that ensures representative, more diverse, more creative future for our industry.\n\n0:16:31.6 Wendy: Next time on How AI Happens:\n\n0:16:38.5 Speaker 3: There's a pretty substantial rules-based expert system that sits on top of this to help manage some of the downsides of the inherent biases we have in the data.\n\n0:16:53.0 Wendy: How AI happens is brought to you by Sama. Sama provides accurate data for ambitious AI, specializing in image, video, and sensor data annotation and validation for machine learning algorithms in industries such as transportation, retail, e-commerce, media, med tech, robotics, and agriculture. For more information, head to sama.com.","slug":{"_type":"slug","current":"podcast-episode-wendy-gonzales"},"tags":[{"_key":"lSFpOak0","label":"Impact","value":"Impact"},{"_key":"hJS7rXT4","label":"Podcast","value":"Podcast"}],"title":"New Podcast Episode: Sama CEO Wendy Gonzalez on Upskilling Talent from Developing Nations"},{"_createdAt":"2021-06-08T14:17:40Z","author":{"_id":"10ead718-57e1-41a8-b846-da3c81cc323a","avatar":{"_type":"image","asset":{"_ref":"image-a4c79da81bb1e23ce10fba84ea2cba5efe67a2a5-200x200-webp","_type":"reference"}},"bio":"Currently a Director of Product Management at Sama, Saul is passionate about the intersection of technology and social impact. He manages Sama’s data labelling products to ensure high quality training data efficiently and reliably reaches our customers. Experienced in both product and professional services, Saul is a proven leader who takes a data driven approach to expanding Sama’s capabilities and features. When not at work, you can usually find Saul enjoying the outdoors and spending time with his family.","name":"Saul Miller","slug":{"_type":"slug","current":"saul-miller"}},"config":{"description":"After a decade of successful text annotation projects, we’re launching our ML-powered Natural Language Processing Annotation Tool.","openGraphImage":null,"title":"Quickly Bring Your NLP Models into Production with AI-Powered Annotation"},"estimatedReadingTime":3,"featured_image":{"_type":"image","asset":{"_ref":"image-cb41c540ba989cd0258ef2f70cf6ce1bc99f2793-3334x1668-png","_type":"reference"}},"plaintextBody":"TLDR; After a decade of successful text annotation projects, we’re launching our ML-powered NLP Annotation Tool.\n\n\n\nIf you work in AI, you know just how hard Natural Language Processing (NLP) problems can be to solve. Though the study of NLP dates back to the 1950s, AI practitioners and researchers are still grappling with the many ambiguities and complexities of language.\n\nHumans intuitively know that words can have different meanings depending on context, and that they can acquire new meanings over time. But capturing all these nuances and incorporating them into an ML model is about as difficult as it sounds.\n\nFor every additional variable that must be accounted for in a model, there is an equal number of opportunities for NLP models to fail. Even a small margin of error can have huge consequences. A lack of varied perspectives or proper inputs can corrupt a data set, create bias, and have serious downstream consequences.\n\nThe only way to navigate this ambiguity is with large, high-quality data sets annotated by a diverse set of labelers.\n\nQuickly bring high-performing NLP models into production\n\nTraditional approaches to labeling Natural Language Processing data – especially using crowdsourced and self-service labeling platforms – often slow the path to production. Inexperienced labelers and the lack of a continuous feedback loop can result in poor quality data sets and time-consuming iteration cycles.\n\nWith Sama, you can get started quickly with self-service and scale over time, or work with our directly managed workforce of annotators trained on your specific needs and best practices for your industry. This bespoke approach enables us to deliver high-performing data sets for your projects, so you can analyze and draw insight from unstructured data for a multitude of NLP use cases – from product review analysis, to document summarization and understanding, to misinformation detection and much more.\n\n>> Learn more about how Sama can help make training data for NLP your competitive advantage\n\n\nOur ML-assisted labeling platform uses active learning to quickly share high precision predictions, automating away simple labels and freeing annotators to create more and higher quality labels. Built-in QA and human in the loop capabilities allow edge cases to be raised early in the process for quicker iteration cycles.\n\nThis powerful combination of skilled annotators and an AI-powered platform allows us to deliver a high standard of label quality to our customers every time, along with efficiency improvements and quicker time to market.\n\nLaunch your Natural Language Processing projects more quickly and efficiently\n\nThe field of Natural Language Processing has made significant progress in the last few years – but there’s plenty of distance still to go.\n\nWherever you want to go next with NLP, let Sama get you there faster.\n\n>> Learn more about how Sama can help make training data for NLP your competitive advantage","slug":{"_type":"slug","current":"natural-language-processing-annotation"},"tags":[{"_key":"WOb8dgoC","label":"NLP","value":"NLP"}],"title":"Quickly Bring Your NLP Models into Production with AI-Powered Annotation"},{"_createdAt":"2021-05-27T16:50:20Z","author":{"_id":"e8a1f3c6-0b07-4638-93d5-61a0924f32e3","avatar":{"_type":"image","asset":{"_ref":"image-2f8efc599a377bd580d0ae12f022a15e7e1acacd-632x676-webp","_type":"reference"}},"bio":"Amanda is the Content Marketing Manager at Sama, where each day she gets to learn about AI and how it’s transforming industry. She’s passionate about technology but periodically tries to get away from her computer to explore more analog things like collage and quilting.","name":"Amanda Durepos","slug":{"_type":"slug","current":"amanda-durepos"}},"config":{"description":"How AI Happens is a podcast by Sama featuring experts and practitioners explaining their work at the cutting edge of AI/ML.","openGraphImage":null,"title":"How AI Happens: A Podcast by AI Practitioners for AI Practitioners"},"estimatedReadingTime":2,"featured_image":{"_type":"image","asset":{"_ref":"image-1502043edcf701cb4267cb2f6d7c6edf8e0e0cad-2500x1313-png","_type":"reference"}},"plaintextBody":"How AI Happens is a podcast featuring experts and practitioners explaining their work at the cutting edge of AI/ML. Tune in to hear AI Researchers, Data Scientists, ML Engineers, and the leaders of today’s most exciting AI companies explain the newest and most challenging facets of their field.\n\n\n\nEvery day, most of us will touch AI in some way — whether at work, at home, or strapped to our wrists and in the palm of our hands. Applications of ML have seamlessly found their way into our lives and our businesses, thanks to a select few who have set out to reimagine how we work in virtually every industry.\n\nMany may understand how AI impacts their daily lives, but few know how to effectively build it.\n\nIn Sama’s new podcast, How AI Happens, we sit down with AI Researchers, Data Scientists, ML Engineers and the leaders of today’s most exciting AI companies to discuss the newest and most challenging facets of their field. \n\nFor our inaugural episode, we sat down with Adnan Khaleel, an HPC and AI expert from Dell. Adnan explains how Dell’s HPC customers are scaling out their AI implementations, how they balance speed vs. accuracy, and explores the parallelization of a radiology algorithm built to detect anomalous cells.\n\nListen and subscribe to How AI Happens on Apple Podcasts, Spotify, Amazon, Google Podcasts, or Overcast.\n\nHappy listening!","slug":{"_type":"slug","current":"how-ai-happens-podcast"},"tags":[{"_key":"TpMM6FVr","label":"Machine Learning","value":"Machine Learning"},{"_key":"sR9wjqUS","label":"AI Practitioners","value":"AI Practitioners"},{"_key":"5AlBk2XP","label":"Podcast","value":"Podcast"}],"title":"How AI Happens: A Podcast by AI Practitioners for AI Practitioners"},{"_createdAt":"2021-05-18T15:19:55Z","author":{"_id":"a009d418-aa96-47ac-a73a-fd2cd52c79d9","avatar":{"_type":"image","asset":{"_ref":"image-e0d717f753ba4876a6b0dbf9f125cf6c3d27e545-500x500-webp","_type":"reference"}},"bio":"Wendy Gonzalez is an executive passionate about building high-performing, high-functioning teams that develop and scale innovative, impactful technology. With two decades of managerial and technology leadership experience for companies including EY, Capgemini, Cycle30 (acquired by Arrow Electronics) and General Communications Inc, Gonzalez is currently the CEO of Sama, the provider of accurate data for ambitious AI, used by leading technology companies such as Walmart, Google, Nvidia and Getty. Before taking on her role as CEO, Gonzalez spent 5 years at Sama as COO, and is an active Board Member of the Leila Janah Foundation.","name":"Wendy Gonzalez","slug":{"_type":"slug","current":"wendy-gonzalez"}},"config":{"description":"This week, researchers at MIT released a white paper evaluating Sama's impact through a three-year Randomized Controlled Trial study. Here are their findings.","openGraphImage":null,"title":"RCT Results from MIT: Evaluating the Impact of SamaÃƒÂ¢Ã¢â€šÂ¬Ã¢â€žÂ¢s Training and Job Programs"},"estimatedReadingTime":3,"featured_image":{"_type":"image","asset":{"_ref":"image-b5f0cb379e97750335d17d53062508bf6115d4e7-3334x1668-png","_type":"reference"}},"plaintextBody":"I am excited to announce that this week, researchers at the Massachusetts Institute of Technology (MIT) released a white paper evaluating our impact through a 3-year Randomized Controlled Trial (RCT) study. On the heels of this achievement, I am reminded of Leila Janah, my dear friend and the late founder of Sama.\n\n\n\nLeila’s dream was to conduct an RCT, often referred to as the “gold standard” in research. An RCT is an independent study, in which a third party validates the impact of your social model. We had long known we were creating impact through our own data collection, however, in 2016, we had reached a point where we wanted to have it validated.\n\nThis led to a joint effort with researchers at MIT, and with Innovations for Poverty Action (IPA), to launch a study from 2017 to 2020 to evaluate the effectiveness of our training and employment programs in creating sustainable pathways out of poverty in Nairobi, Kenya. It studied three groups of individuals from similar socioeconomic backgrounds that were randomly assigned to receive training through Sama (Group 1), or receive training and the opportunity for employment at Sama (Group 2), or receive neither training nor the opportunity for employment (Control Group).\n\n(See IPA’s project summary for an easily digestible explanation of the impact evaluation.)\n\nOver the course of the three-year study, individuals reported their employment status, earnings, and the industry they worked in. They also shared insights about their current and future outlook on aspects ranging from community engagement to health to life satisfaction. The main finding of the study is that individuals who were trained by and had the chance to work at Sama (Group 2) were more likely to experience better outcomes than other groups. By the end of the study, average earnings for individuals in Group 2 were almost 40% higher than those in the Control Group, and unemployment rates were 10% lower. Training and the opportunity to work at Sama had an even greater impact on women. Average earnings for women in Group 2 were 60% higher than women in the Control Group.\n\nThe findings reinforce what our internal research has long shown: that our impact hiring model has a positive and meaningful effect on long-term employment rates and earnings. To have MIT validate our model proves that business can be a force for social good. And while it takes conviction to run a purposeful hiring model, we are driving an ethical supply chain that meaningfully improves employment and income outcomes for those with the greatest barriers to work.\n\nIt is my hope that these findings will contribute to larger sustainable development discussions across the public and private sector and in particular will drive corporations who spent trillions each year on their supply chain to utilize impact criteria as part of their decision-making process. Think of the impact we can drive then.\n\nRead the Paper: Evaluating Sama’s Training and Job Programs in Nairobi, Kenya\n\n\n\nAuthors:\nDavid Atkin (MIT) \nAntoinette Schoar (MIT Sloan) \nKiara Wahnschafft (MIT)\n\nRead More Key Stats from the RCT","slug":{"_type":"slug","current":"rct-results-mit"},"tags":[{"_key":"X2bQOmTh","label":"Impact","value":"Impact"}],"title":"RCT Results from MIT: Evaluating the Impact of SamaÃƒÂ¢Ã¢â€šÂ¬Ã¢â€žÂ¢s Training and Job Programs"},{"_createdAt":"2021-05-10T15:00:00Z","author":{"_id":"e8a1f3c6-0b07-4638-93d5-61a0924f32e3","avatar":{"_type":"image","asset":{"_ref":"image-2f8efc599a377bd580d0ae12f022a15e7e1acacd-632x676-webp","_type":"reference"}},"bio":"Amanda is the Content Marketing Manager at Sama, where each day she gets to learn about AI and how it’s transforming industry. She’s passionate about technology but periodically tries to get away from her computer to explore more analog things like collage and quilting.","name":"Amanda Durepos","slug":{"_type":"slug","current":"amanda-durepos"}},"config":{"description":"Tribe Dynamics helps customers get better ROI from influencer programs. Find out how partnering with Sama helped Tribe better serve clients and expand into new markets.","openGraphImage":null,"title":"How Sama Powers Tribe Dynamics to Measure Your Influencer Marketing Efforts"},"estimatedReadingTime":6,"featured_image":{"_type":"image","asset":{"_ref":"image-df166412c7473ff8223b8e439246245a9dc8ce2d-3334x1668-png","_type":"reference"}},"plaintextBody":"Tribe Dynamics launched in 2012 to help countless leading global brands operationalize, scale, and measure their internal influencer programs—all in a single influencer marketing software platform. Since 2017, the Sama team has powered this technology, training Tribe’s machine learning algorithm and increasing reporting capabilities by 350% to date, helping to build robust influencer communities for a fast-growing, global portfolio of brands.\n\nWhile influencer marketing isn’t a new concept, it has become wildly popular in the past few years. It’s a type of marketing that uses endorsements and product mentions from influencers—tastemakers who have a dedicated social following and are viewed as experts within their niche. Influencer marketing works because of the high amount of trust that influencers have built up with their following. Recommendations from influencers also serve as a form of social proof to a brand’s potential customers.\n\nBut how do you measure who talks about you and how you compare against competitors?\n\nThis is where Tribe Dynamics comes in. The universe of what they track consists of two parts. First, a growing database of over 2,500 brands, including social handles and colloquial ways of discussing the different brands. You can imagine brands missing out on key conversations if they fail to capture slang or abbreviations like #ABH, referring to the popular cosmetics company Anastasia Beverly Hills. The second part involves the influencers who live in their ambassador relationship management system. Here, the profiles and online activities of 200,000 influencers are stored and sorted by the various industries and interests. When combining this list of brands with the group of influencers, Tribe delivers a powerful collection of social posts mentioning your brand—one that truly identifies your most passionate influencer community. \n\n\n\nThe Challenge\n\n\n\nTribe Dynamics’ direct users are marketing teams tasked with measuring the ROI of their influencer program. They want to track their share of the conversation versus their market share benchmark to assess how well they’re doing against competitors and identify their most effective influencers. In short, they need Tribe Dynamics to help them cut through the noise and make data-driven decisions.\n\n\n\nHere’s an example; if a post is talking about Benefit Cosmetics and the company is tagged as such, it’s typically an easy find. However, it becomes more complicated when the algorithm needs to detect the difference between “I love this blush from Benefit” and “The benefit of using blush,” where one is a brand mention and the other a tutorial.\n\nMarketing teams also need to be able to judge the quality of an influencer’s performance and avoid spending budget on fraudulent influencers. Tribe Dynamics allows them to see who their top drivers are for Earned Media Value (EMV), a proprietary metric that measures the value of third-party digital content created about a brand, and surface the right influencers. After all, the hardest working influencers may be people they don’t even know about yet.\n\nTribe Dynamics’ machine learning algorithm catches 95% of the mentions for some brands and 60% for others, and the team relies on Sama as part of their ecosystem to deliver full accuracy.\n\n\n\nDownload the full case study here. \n\n\nThe Solution\n\n\n\nSama’s expert annotators assume the tasks of locating, extracting, and tagging key brand mentions in the posts generated by Tribe Dynamics. This human-in-the-loop intervention consistently reaches a quality SLA of >99%, enabling the algorithm to become more intelligent over time.\n\nSama handles 60-70% of the monthly vetting tasks: identifying brand mentions and common language ways of talking about a brand that the algorithm isn’t yet trained on.\n\nThis continuous vetting also helps overcome model drift. In the fast-moving world of social media, training a machine learning model is not a single, finite stage in the process. Even after it’s deployed in a production environment, this steady stream of new training data—and continuous vetting—ensures the model’s predictive accuracy over time.\n\nIts success shows in the numbers:\n\nThe volume of data Tribe Dynamics is able to provide their clients has grown almost 4x—from 700 brands in 2018 to 2,600 brands this year.\n\nSama has been key to this growth.\n\n\n\nA Word from Tribe Dynamics\n\n\n\nAs almost all of the expansion involves vetting, Sama has been a valuable resource in Tribe’s international expansion.\n\n“We’ve launched in over a dozen markets in two to three years. That, without support, would’ve crushed our internal teams. Sama was able to take on additional workload quickly and efficiently. It has been a notable piece of our successful global business,” says Clare Bruzek, VP of Operations.\n\nSama has become part of the architecture of the company. When Tribe Dynamics decides to expand into different markets, Sama is integral in the scoping of these new opportunities. “It’s the only sustainable vetting option for our international expansion. We now provide international data on 1,250 brands to 94 clients across 12 global markets, making up 30% of our revenue.”\n\nBruzek shares:\n\n“Working with Sama has made a demonstrable impact in our ability not only to service our current clients better, but also to expand our services to new types of clients and new markets. We have only been able to meet client needs in that way because of what Sama has been able to achieve.”\n\nDownload the full case study here. ","slug":{"_type":"slug","current":"tribe-dynamics-case-study"},"tags":[{"_key":"a68HDnn3","label":"Case Studies","value":"Case Studies"}],"title":"How Sama Powers Tribe Dynamics to Measure Your Influencer Marketing Efforts"},{"_createdAt":"2021-05-05T16:24:03Z","author":{"_id":"26fb3cc4-608d-40e1-bb4d-955bceda232a","avatar":{"_type":"image","asset":{"_ref":"image-e0fe681e594567792ac79048513fe955cc770f54-518x518-svg","_type":"reference"}},"bio":"From self-driving cars to smart hardware, Sama fuels AI. Founded over a decade ago, we’re experts in image, video and sensor data annotation and validation for machine learning algorithms in industries including automotive, navigation, AR/VR, biotech, agriculture, manufacturing, and e-commerce. Our staff are driven by a mission to expand opportunity for low-income people through the digital economy, and our social business model has helped over 50,000 people lift themselves out of poverty.","name":"Sama Team","slug":{"_type":"slug","current":"sama-team"}},"config":{"description":"We’re proud to announce our honorable mention in Fast Company’s 2021 World Changing Ideas Awards for AI and Data alongside leaders such as CNN and Immunai.","openGraphImage":null,"title":"Honorable Mention in Fast CompanyÃƒÂ¢Ã¢â€šÂ¬Ã¢â€žÂ¢s 2021 World-Changing Ideas Awards"},"estimatedReadingTime":3,"featured_image":{"_type":"image","asset":{"_ref":"image-6cb6375fa1b8e381f1db8152440adfb093b0b60f-1650x1275-png","_type":"reference"}},"plaintextBody":"At Sama, we’ve understood the potential that AI and data have to reshape our world since day one. Already used to power essential services like surgery, vaccination development and transportation, AI is becoming more accessible every day. That’s why we’re committed to helping the world’s most ambitious AI teams develop the diverse and accurate data sets they need to ensure their algorithms succeed.\n\n\n\nToday, on the heels of our recent inclusion in the 2021 Forbes AI 50 list, we’re proud to announce our honorable mention in Fast Company’s 2021 World Changing Ideas Awards for the AI and Data category alongside leaders such as CNN, Immunai and Zoox. This is Sama’s second consecutive World Changing Ideas win, following our finalist recognition as a result of our animal conservation and anti-poaching work with Vulcan in 2020. \n\n\n\n“There is no question our society and planet are facing deeply troubling times. So, it’s important to recognize organizations that are using their ingenuity, impact, design, scalability, and passion to solve these problems,” says Stephanie Mehta, editor-in-chief of Fast Company. “Our journalists, under the leadership of senior editor Morgan Clendaniel, have discovered some of the most groundbreaking projects that have launched since the start of 2020.”\n\n\n\nThis year’s recognition highlights our AI Bias Detection solution, which was created to detect and combat systemic bias in artificial intelligence. In addition to causing inefficiencies, bias can result in dangerous algorithm outcomes across hiring, safety and criminal justice. Understanding that AI will be critical to societal change moving forward, our AI Bias Detection solution offers advanced analytics and reporting capabilities to spot and correct bias before it’s implemented.\n\n\n\n“It’s an honor to be recognized in Fast Company’s World Changing Ideas this year alongside so many incredible organizations,” says Wendy Gonzalez, CEO of Sama. “At Sama, we’re dedicated to using AI and training data for good and will continue to leverage our expertise to create the most effective, safe and equitable future of technology possible.”\n\n\n\nNow in its fifth year, the World Changing Ideas Awards honor the businesses, policies, projects, and concepts that are actively engaged and deeply committed to pursuing innovation when it comes to solving health and climate crises, social injustice, or economic inequality. This year, a panel of eminent Fast Company editors and reporters selected winners and finalists from a pool of more than 4,000 entries across transportation, education, food, politics, technology, and more.\n\n\nTo learn more about our recognition and to see the complete list of Fast Company’s World Changing Ideas honorees, click here.","slug":{"_type":"slug","current":"honorable-mention-in-fast-companys-2021-world-changing-ideas-awards"},"tags":[{"_key":"WOaBRJBK","label":"Company News","value":"Company News"},{"_key":"JY3FKCos","label":"Ethical AI","value":"Ethical AI"},{"_key":"JhqG8b1a","label":"Awards","value":"Awards"}],"title":"Honorable Mention in Fast CompanyÃƒÂ¢Ã¢â€šÂ¬Ã¢â€žÂ¢s 2021 World-Changing Ideas Awards"},{"_createdAt":"2021-05-03T21:44:34Z","author":{"_id":"26fb3cc4-608d-40e1-bb4d-955bceda232a","avatar":{"_type":"image","asset":{"_ref":"image-e0fe681e594567792ac79048513fe955cc770f54-518x518-svg","_type":"reference"}},"bio":"From self-driving cars to smart hardware, Sama fuels AI. Founded over a decade ago, we’re experts in image, video and sensor data annotation and validation for machine learning algorithms in industries including automotive, navigation, AR/VR, biotech, agriculture, manufacturing, and e-commerce. Our staff are driven by a mission to expand opportunity for low-income people through the digital economy, and our social business model has helped over 50,000 people lift themselves out of poverty.","name":"Sama Team","slug":{"_type":"slug","current":"sama-team"}},"config":{"description":"Thanks to our industry-spanning work we are honored to announce our inclusion in the 2021 Forbes AI 50 list alongside other leading AI companies.","openGraphImage":null,"title":"Sama Recognized in the 2021 Forbes AI 50 List"},"estimatedReadingTime":2,"featured_image":{"_type":"image","asset":{"_ref":"image-23697fb2984860fddca93d9a96e1ab91aa7bfb9c-2000x1125-png","_type":"reference"}},"plaintextBody":"It goes without saying that this past year has had its challenges. Through it all, our team at Sama has remained committed to providing leading companies with the highest quality training data to get predictably higher accuracy in half the time. That’s because we know that AI is the key to the future of technology, and without diverse and accurate data sets, the technology will ultimately fail.\n\nThanks to our industry-spanning work with partners such as Walmart, Google and NVIDIA, we are honored to announce our inclusion in the 2021 Forbes AI 50 list alongside leading companies including Duolingo, Samsara and Narrativ. In its third year, the Forbes AI 50 highlights the most promising North American businesses using AI in ways that are fundamental to their operations.\n\nBy combining our expert-human-in-the-loop team with cutting-edge technology, we’ve put in the time and effort to perfect our machine learning-assisted annotation and achieve SLAs well above the industry standard this past year. With new innovations like our AI Bias Detection solution and milestones, including our B Corp Certification, we’ve continued to prioritize our double bottom line, measuring our success not only in terms of revenue but also impact.\n\n\"I’m incredibly proud of what our team has accomplished over the past year both in terms of our success providing high-quality data to industry leaders and maintaining our commitment to social impact,” says Wendy Gonzalez, CEO of Sama. “As AI becomes increasingly essential to operations across industries, we’re excited to have a hand in the future of effective, non-biased AI, and are grateful to be recognized as one of the leading companies in the space.\"\n\nThis recognition from Forbes reflects our continued success in leveraging AI for good. Through partnerships with customers to help hotels and restaurants achieve zero food waste, power anti-poaching and animal conservation efforts, enable safe and effective robot-assisted surgery and more, we’re consistently harnessing best-in-class technology to address the most pressing challenges in our society today. \n\nTo learn more about our achievements and to see the complete list of Forbes AI 50 winners, visit Forbes' article here.","slug":{"_type":"slug","current":"sama-recognized-in-the-2021-forbes-ai-50-list"},"tags":[{"_key":"RgPudZ6F","label":"Company News","value":"Company News"},{"_key":"kLwgMkEb","label":"Awards","value":"Awards"}],"title":"Sama Recognized in the 2021 Forbes AI 50 List"},{"_createdAt":"2021-04-16T00:13:26Z","author":{"_id":"88e43c38-2712-41d4-9df3-8656c163c4db","avatar":{"_type":"image","asset":{"_ref":"image-af1346669e45d7264a36f051c18aea76061725bb-1895x1894-webp","_type":"reference"}},"bio":"Kyra is passionate about world-changing tech and sustainability, and happiest when these come together (looking at you, Sama). Stereotypical Dutch, she enjoys urban cycling and eating stroopwafels.","name":"Kyra Harrington","slug":{"_type":"slug","current":"kyra-harrington"}},"config":{"description":"We asked experts working in the field about their thoughts on the role of humans in Machine Learning, and humans and the future of ML.","openGraphImage":null,"title":"Experts Explain: How to Think About Human-Centered Machine Learning"},"estimatedReadingTime":6,"featured_image":{"_type":"image","asset":{"_ref":"image-a780ec1434b6c9c7513e0346be3e51fea3b5961b-1800x1013-png","_type":"reference"}},"plaintextBody":"If, as many assume, AI is to take over many organizational roles from humans, it would have to develop considerably from its current standing. MIT has defined ‘human-centered AI’ as “the design, development, and deployment of systems that learn from and collaborate with humans in a deep, meaningful way”. Therefore, to become less ‘human-centered’, you would need an AI landscape in which smart algorithms do all the heavy lifting. We asked experts working in the field about their thoughts on the role of humans in Machine Learning, and humans and the future of ML.\n\nRemo, Senior Software Engineer at Apple, states: “ML as a part of software engineering is by definition human-centric. It is human-centric because it substitutes the work of humans. For example in the recommendation of music, the identification of spam, or in object recognition. ML is human-centric because it is often (or almost always) trained on human generated or at least labeled data. And it is human-centric because ML models are built and designed on top of people's inductive biases about the world. At the same time it is not human (or human centric) because it does not reason or think. It spots patterns but does not \"connect the dots.\" \n\nIndu Khatri, the Machine Learning Lead at financial giant HSBC echoed the point above: “I would break down ML problems into three parts. The first one being identifying the problem to which ML needs to be applied and defining a broad architecture about how ML models will solve the problem. The second stage is developing the ML models and the third stage is taking actions based on ML models, getting the feedback from your environment and improving the models further. Out of these three stages, I believe Stage one will always need some kind of human intervention. With the advent of AutoML the amount of human intervention is decreasing everyday. Finally, for decreasing the amount of human intervention in Stage three we would need to improve the sample efficiency of Reinforcement Learning so that our Models can map predictions to actions in a feasible way.”\n\nConversely, Staff ML / NLP Research Scientist at Stanford and former Senior Research Scientist at Uber AI, Piero Molino, suggested that moving away from a human-centric model would be a mistake. “I believe there are several friction points that can be automated, like the data/model interface, the model search, evaluation and monitoring, Ops in general. But what I would rather wish is for ML to become more human-centric in the sense that it should put more humans at the center of its strategy rather than increased efficiency, and that is achieved with more humans in the loop evaluation and data generation processes, more robustness and more fairness evaluations.”\n\nData Scientist at Gartner, Lavi Nigam, thinks we’re already fairly close to an AutoML model, which as the name suggests, would mean far less human-interaction needed. So much so, that we could only be a few years away from this coming to fruition. “When more and more intrinsic pieces of data science workflows are automated mathematically and programmatically. We already see AutoML models that can figure out the best model for your data with any constraint defined. As the AutoML advances, we will eventually see that human interference in model building will greatly reduce and result in more optimized models. Deployment automation and Model Tracking (both part of MLOps) are other areas of focus where human involvement will drastically reduce in the coming years.”\n\nShuo Zhang, Senior Machine Learning Engineer, Bose Corporation, agreed that we’re fairly close to an ML model which requires little human interaction. “There are many current techniques that make ML algorithms less dependent on human supervision by leveraging the intrinsic structures of large amounts of data, such as self supervision and unsupervised techniques.”\n\nTwo other experts we asked agreed that ML as a concept requires human intervention. Removing this wouldn’t be beneficial and could actually be the opposite. Jason Gauci, a Software Engineering Manager at Facebook stated that “ML should work hand-in-hand with people, not replace them or automate the things that they do without oversight.” This was somewhat echoed by Sean Xie, Director of AI at Pfizer: “Current technologies are still focused on solving narrowly defined and specific problems. There’s a long way to go to be less human-centric.”\n\nIf we were to move toward an AutoML/less human-centric model, how could it be done? Yaman Kumar, PhD Computer Science at the University of Buffalo suggested that you would need to “join forces with the philosophy, metaphysics and ethics department and see the field adopting human-centric vision right, left and centre. As long as both AI and philosophy departments are cutoff and work in their own silos, things will go on as-is. Recent times have shown green shoots where more and more people from philosophy backgrounds are entering the field and guiding key areas such as fairness in ML.”","slug":{"_type":"slug","current":"how-to-think-about-human-centered-machine-learning"},"tags":[{"_key":"pOB3rwcB","label":"Machine Learning","value":"Machine Learning"},{"_key":"v412ROa8","label":"Expert Advice","value":"Expert Advice"}],"title":"Experts Explain: How to Think About Human-Centered Machine Learning"},{"_createdAt":"2021-04-08T19:39:10Z","author":{"_id":"88e43c38-2712-41d4-9df3-8656c163c4db","avatar":{"_type":"image","asset":{"_ref":"image-af1346669e45d7264a36f051c18aea76061725bb-1895x1894-webp","_type":"reference"}},"bio":"Kyra is passionate about world-changing tech and sustainability, and happiest when these come together (looking at you, Sama). Stereotypical Dutch, she enjoys urban cycling and eating stroopwafels.","name":"Kyra Harrington","slug":{"_type":"slug","current":"kyra-harrington"}},"config":{"description":"How do you define training data quality and measure it? How do you improve it? We go into defining, measuring, and reviewing your training data quality.","openGraphImage":null,"title":"How to Define and Measure Your Training Data Quality"},"estimatedReadingTime":8,"featured_image":{"_type":"image","asset":{"_ref":"image-d6c18c74368eef76cb0a2effb3afd42265b0f90f-1800x1013-png","_type":"reference"}},"plaintextBody":"Data quality plays a crucial role in Machine Learning (ML) models’ performance and directly leads to your projects succeeding, failing, or going off-budget. “Garbage In Garbage Out” is a phrase commonly used in the machine learning community, which means that the training data quality ultimately determines the model’s quality.\n\nOur experience working with companies using ML has shown that the best models are based on comprehensive datasets, complete with a range of detailed labels. Unfortunately, many decision-makers still underestimate the time and resources needed to create, manage, and annotate datasets. Indeed, creating quality datasets is often one of the most expensive and time-consuming elements of building a machine learning application.\n\nBut how do you define data quality and measure it? Furthermore, how do you improve it? The answers depend on the type of problem you’re solving.\n\n\nDefining Training Data Quality in Annotation\n\nIn data annotation, we often speak of “accuracy” and “consistency”. Accuracy in data labeling measures how close the labeling is to ground-truth or how well the labeled features in the data are matching real-world conditions. Consistency refers to the degree of accuracy across the overall dataset. Are annotations consistently accurate across your datasets? Other characteristics of data quality may include completeness, integrity, reasonability, timeliness, uniqueness, validity, and accessibility.\n\nThe path to high-quality, scalable data quality always begins with a deep understanding of your project requirements, allowing you to develop well-defined annotation criteria against which to measure quality. Experienced AI-driven organizations often establish a quality rubric that describes what quality means in the context of a project. Sama’s approach is to anticipate the errors that we might see in a task and assign numerical penalty values before the annotation process starts.\n\nThe main benefit of this approach is to ensure that both your company and Sama’s team are on the same page about how quality is defined and measured. This allows our experts to create comprehensive and actionable instructions without room for interpretation and inconsistencies, saving a lot of time down the road.\n\nMeasuring Training Data Quality\n\nSeveral methods exist to help companies measure data quality. To define the correct annotation of given data, you want to start by creating annotation guidelines. On top of proposing a multi-level quality checks system, Sama’s experts have built unique know-how in efficiently designing annotation guidelines that enhance data quality.\n\nHere are some of the more common data quality measurement processes:\n\n\n1. Benchmarks or gold sets help measure how well a set of annotations from a group or individual matches the vetted benchmark established by knowledge experts or data scientists. Benchmarks tend to be the most affordable QA option since it involves the least amount of overlapping work. Benchmarks can provide a useful reference point as you continue to measure your output's quality during the project. They can also be used as test datasets to screen annotation candidates.\n\nAt Sama, Gold Tasks are used in two more ways: During training, to assess annotators and identify those ready to move into production, and once in production to generate an automated metric on quality. You can read more about Sama’s approach to gold tasks here.\n\n2. Consensus measures the percentage of agreement between multiple human or machine annotators. To calculate a consensus score, it is necessary to divide the sum of agreeing labels by the total number of labels per asset. The goal is to arrive at a consensus decision for each item. An auditor typically arbitrates any disagreement amongst the overlapped judgments. Consensus can be either performed by assigning a certain number of reviewers per data point or be automated.\n\n3. Cronbach's alpha test is an algorithm used to measure the average correlation or consistency of items in a dataset. Depending on the characteristics of research (for instance, its homogeneity), it may help quickly assess the labels’ overall reliability.\n\n4. Review is another method to measure data quality. This method is based on the review of label accuracy by a domain expert. The review is usually conducted by visually checking a limited number of labels, but some projects review all labels. Sama enables companies to easily review quality through a sampling portal: a dedicated portal providing full transparency and accountability on data quality. Your team can get full transparency on the batch’s quality and provide direct feedback to data trainers.\n\nDue to the iterative machine learning model testing and validation stages, we must keep in mind that data quality can change during a project. As you train your model or after making your solution live, you’ll probably find patterns in your inaccuracies or identify edge cases that will force you to adapt your dataset.\n\nReviewing Training Data Quality\n\nBecause no two AI projects are alike, you need to make sure that your quality assurance (QA) process is designed to meet the unique needs of your particular project. Here, both data accuracy and consistency are reviewed, separate steps that a data scientist or project manager may perform manually or in an automated way.\n\nTwo different types of QA processes:\n\nSama’s own QA managers review the tasks using both manual and automated techniques.\n\nClient’s QA process performed by a data scientist, most likely manual only.\n\nReviewing tasks is a pain point for most data science teams. We believe that your team should spend less time on these time-consuming and tedious tasks and spend more time on strategic work. As such, we created the Auto QA process. Auto QA creates an instant feedback loop to prevent logical fallacies, which helps annotators improve and get it right the first time.\n\nAutomated logic checks are triggered before a task is submitted on Sama’s platform by our annotators. Auto logic checks can identify several potential issues in your data— for instance, invalid answer combinations, repetitions, or size requirements. Leveraging Auto QA will help you prevent errors that may be impossible to detect by the manual QA review process. It reduces the time spent by manual QAs and allows annotators to focus on the more critical errors or edge cases.\n\nSama’s training data platform handles the entire annotation lifecycle and employs a quality feedback loop, enabling us to offer the highest quality SLA (>95%), even on the most complex workflows. Understanding the importance and prioritizing the quality of your training data will help in achieving success with your models. The first step in gaining good quality training data begins with finding the right processes and platforms to label your training data.","slug":{"_type":"slug","current":"define-and-measure-training-data-quality"},"tags":[{"_key":"aZTVAo0T","label":"Training Data","value":"Training Data"},{"_key":"Wr7YIM1K","label":"Data Quality","value":"Data Quality"}],"title":"How to Define and Measure Your Training Data Quality"},{"_createdAt":"2021-03-29T21:29:09Z","author":{"_id":"785c9b8f-1869-4ce3-9eaa-c53945aa9736","avatar":{"_type":"image","asset":{"_ref":"image-c187f0a84bc4d1a6870d3a7a8528f242920a33aa-309x343-webp","_type":"reference"}},"bio":"Aurelie Drouet leads Product Marketing at Sama. Hailing from France and with expertise in driving revenue growth for companies in the US and Latin America, Aurelie's expertise spans several countries. She previously led Strategic Partnerships at Dreem.","name":"Aurélie Drouet","slug":{"_type":"slug","current":"aurelie-drouet"}},"config":{"description":"87% of AI projects will never make it into production. Why? We asked ML experts.","openGraphImage":null,"title":"10 Experts on the Biggest Roadblocks to Bringing ML Models to Production"},"estimatedReadingTime":7,"featured_image":{"_type":"image","asset":{"_ref":"image-b5b41f578774ef4d9391188b97c960a4f9e43e2c-900x506-png","_type":"reference"}},"plaintextBody":"In its infancy, Machine Learning was hailed as a silver bullet, something that could solve your problems and automate tasks with high-quality output with less effort required than ever. It's been predicted that 87% of AI projects will never make it into production. Why? We asked ML experts what they believe to be the main reasons that ML projects fail.\n\n\n\nTL;DR:\n\nA disconnect between the science and real-world application of the ML solutions and business expectations.\n\nUnreasonable expectations from business hierarchies on both the outcome and cost of many ML projects .\n\nAiming to develop MLOps without due diligence and research into some of the challenges that could be faced along the way .\n\nTo make an ML project successful, we need to find the right problem, use the right data, and develop the right method. Many ML projects do not meet these three requirements.\n\nIt’s not easy for companies to find enough data to run useful and high quality ML models.\n\n\n\nLavi Nigam\nData Scientist, Gartner\n\n“The biggest reason for project failure is ML processes maturity. There are too many moving and distinct pieces in ML/DL workflows and they are not mostly tied intrinsically by a single tool/framework. Enterprises and open source projects are trying to bridge this gap and I feel in the next 3 years we will see good progress in this area. Open source end-to-end MLOps are very important since they will help with wider adoption just like Tensorflow did for deep learning. Another big issue which increases project failure is that currently data science is evolving and has not reached ‘enterprise ready consensus’ with regards to set practices for different domains.”\n\n\n\nSparkle R. \nAssociate Director Data Science, Johnson & Johnson\n\n“ML projects still fail because of the disconnect between the science and real-world application of the ML solutions and business expectations. We are now in a society that prefers to use the word ML to demonstrate prestige despite having no clear impact. While there are many other reasons that can contribute to a ML project’s failure, the major factors include: a lack of high-quality data, poorly designed research questions, overly optimistic business expectations and a disconnect between the developers, product owners, data scientist and the ML-based system end users.”\n\n\n\nRemo Storni\nSenior Software Engineer, Apple\n\n“The biggest reason for ML project failures are unreasonable expectations about what is possible and unreasonable optimism about the project. People have trouble expecting the unexpected. There are a number of ML projects that fail and often these are problems that ML can't easily solve properly right now like conversational AI. There is a much bigger number of problems where ML falls short of expectations or where the project hits unexpected data or engineering problems.”\n\n\n\nRavi Dalal \nSenior Computer Vision Engineer, Walmart\n\n“I think this happens because people don’t do enough prep work before starting the project. It doesn’t make sense to apply a deep learning model where a logistic regression can do the trick. So, HOMEWORK before starting the project is very critical for the success of any ML project”.\n\n\n\nPiero Molino\nStaff ML / NLP Research Scientist, Stanford University\n\n\"Because of the uncertainty baked in many parts of the machine learning development process. It is very difficult to assess beforehand if a machine learning project will succeed without analyzing the data, training initial models, evaluating them and then iterating. Product teams still don't know if there's enough signal in the data to begin with, how much data would they need, how expensive annotating it would be, and in many cases they don't have great ways to monitor and evaluate models. All these uncertainty sources, together with wrong expectations, may lead to failure of ML projects.\"\n\n\n\nManmeet Singh\nMachine Learning Lead, Apple\n\n“There are a variety of reasons ML projects fail. Sometimes ML projects are initiated without synergy on expectations, objectives, and success criteria of the project between the business and ML teams. There could be other reasons ranging from lack of expected data, expertise, limitations in the technology itself for certain domains. This is a long-term investment & hence clear strategy and leadership support are necessary for success.”\n\n\n\nJason Gauci\nSoftware Engineering Manager, Facebook\n\n“Many projects fail because people don't trade off the benefit of success with the consequence of failure. Imagine a smart garage door opener that could open your garage door in anticipation of your arrival. If it opens when you want, it saves a button press. But if it opens when you aren't around, someone can rob your house. Because of this extreme tradeoff, the model needs to be impossibly accurate because it's competing with a button press that is almost 100% accurate”\n\n\n\nZhiyong (Sean) Xie\nDirector, AI, Pfizer\n\n“Most people just tried to find nails with an existing hammer. To make an ML project successful, we need to find the right problem, use the right data, and develop the right method. Many ML projects do not meet these three requirements. There is also miscommunication between the ML scientists and domain experts. It is not easy to find enough data to train the model. New methods need to be developed based only on the problem and available data.”\n\n\n\nIndu Khatri \nMachine Learning Lead, HSBC\n\n“Most ML projects fail because of a lack of understanding among the Business Executives about how ML models apply to their business. This usually leads to ML teams not solving the right problem for the business and underwhelming results. I have heard about projects that are stuck in research because of unclear problem statements.”\n\n\n\nYaman Kumar\nPhD Computer Science, University of Buffalo\n\n“Projects failing in ML, in my opinion, is chiefly due to three reasons: under-specification, over-expectation and clean toy datasets. While most of our datasets are so clean that the models trained on them hardly work in the real conditions, the ones that do are marred by the hype surrounding AI and ML. Underspecification normally comes from a lack of maturity in the field.”","slug":{"_type":"slug","current":"10-experts-biggest-roadblocks-ml-production"},"tags":[{"_key":"fLUi1ttd","label":"Machine Learning","value":"Machine Learning"},{"_key":"1iCuMNwM","label":"Expert Advice","value":"Expert Advice"}],"title":"10 Experts on the Biggest Roadblocks to Bringing ML Models to Production"},{"_createdAt":"2021-03-23T19:00:21Z","author":{"_id":"4e2e7cef-d6eb-4bb7-bd39-375c6299677e","avatar":{"_type":"image","asset":{"_ref":"image-f1a274bcfdb5e70d814f1bab2b6bbd644728e9be-1480x1462-jpg","_type":"reference"}},"bio":"With a background in Computer Science, Abha leads the Customer Success Engineering team at Sama. The team is responsible for managing technical relationships with customers and prospects to understand their business needs, ideate upon them, and manage the implementation and communication of the solutions developed. ","name":"Abha Laddha","slug":{"_type":"slug","current":"abha-laddha"}},"config":{"description":"Sama is an expert in efficiently designing annotation guidelines that enhance data quality. Gold Tasks refer to tasks that have been annotated perfectly.","openGraphImage":null,"title":"Sama's Gold Tasks: ML Training Data with Gold-Standard Quality"},"estimatedReadingTime":4,"featured_image":{"_type":"image","asset":{"_ref":"image-2be5ee7e7ae0847f3bedec01bb88266c371e3eb9-4000x2250-jpg","_type":"reference"}},"plaintextBody":"Several methods exist to help companies define and measure data quality. To define the correct annotation of given data, you want to start by creating annotation guidelines. On top of proposing a multi-level quality checks system, Sama’s experts have built unique know-how in efficiently designing annotation guidelines that enhance data quality.\n\nCue Gold Tasks; referring to tasks that have been annotated “perfectly” or meet the “gold standard”. Such tasks are often used by the client to communicate their expectations around precision and quality used as examples during training. At Sama, we use Gold Tasks in two more ways: During training, to assess annotators and identify those who are ready to move into production and during production to generate an automated metric on quality.\n\nGold Assessments\n\nEvery project launch at Sama is accompanied with a period of training, where annotators focus on requirements for the specific workflow, familiarizing themselves with the taxonomy, accuracy levels needed, and edge cases. Gold tasks come in as they move from classroom training to practice tasks.\n\nA gold set is created that is representative of the overall complexity of the dataset, ensuring a healthy mix of the edge cases. annotators practice on this set of which we already have “gold” answers. As each task is submitted we are able to compare the annotator answers with the gold task, generating custom metrics and error tags. The metrics are determined by the type of workflow and tool used, for e.g. in a semantic segmentation workflow, we focus on IoU calculations per label and depending on the client rubric each label may be weighed differently.\n\nThese metrics are then used to create trends and analyze each annotator’s performance individually, and provide relevant feedback. We are able to analyze trends at an asset label (which type of images are more difficult than others?), annotator level (which annotator is struggling exactly where?), and the impact of time (was today better than yesterday?).\n\nGold assessments, therefore, help us accelerate training by providing customized feedback to each annotator early on and allowing us to track their improvement over time. This enables Sama to quickly identify doubts, find edge cases, and have high confidence that annotators are ready to move on to production. Lastly, this allows us to calibrate and train the manual QAs on the specifics of this particular workflow, ensuring that nothing is missed.\n\n\nGold Metrics\n\nSimilar to gold assessments, gold metrics compare an annotator’s tasks against a known, completed task. These tasks, however, are interspersed within the production queue with the annotators unaware that these are gold tasks. These tasks then act as tests for the annotators, generating similar metrics as mentioned above. This allows the team to report upon the annotator’s performance against the gold tasks that increase insight into quality and help to further tailor training and coaching.\n\nGold metrics are most useful for clients looking to automate the quality loop on their side. Given that their Sama project team consistently samples and approves only high quality tasks, it is a neat way for them to save time and capacity.\n\nBecause no two AI projects are alike, you need to make sure that your quality assurance (QA) process is designed to meet the unique needs of your particular project. Learn more on how to supercharge your data quality with Sama's Automated Quality Accelerators. ","slug":{"_type":"slug","current":"sama-gold-tasks"},"tags":[{"_key":"YSoeJ1Gj","label":"Product","value":"Product"},{"_key":"AHeszSpi","label":"Training Data","value":"Training Data"},{"_key":"9nTBOCjn","label":"Data Annotation","value":"Data Annotation"},{"_key":"ku9OMDnM","label":"Data Quality","value":"Data Quality"}],"title":"Sama's Gold Tasks: ML Training Data with Gold-Standard Quality"},{"_createdAt":"2021-03-17T03:58:33Z","author":{"_id":"40a70383-c941-405c-ae5b-f0aba421ee53","avatar":{"_type":"image","asset":{"_ref":"image-e0fe681e594567792ac79048513fe955cc770f54-518x518-svg","_type":"reference"}},"bio":"Rafael and Juan are both senior members of Sama R&D where they focus on Data Engineering and Data Science initiatives that help boost operational efficiency and achieve the highest quality.","name":"Rafael Alfaro & Juan Esquivel","slug":{"_type":"slug","current":"rafael-alfaro-and-juan-esquivel"}},"config":{"description":"In this series of three we’ll go into Experiment Driven Development and A/B Testing. EDD is fact-based development: based on evidence, not intuition.","openGraphImage":null,"title":"Part 3: A/B Testing with Python"},"estimatedReadingTime":6,"featured_image":{"_type":"image","asset":{"_ref":"image-bbf0e002b88fd9c3b2fcbd032f60f114bc93eed0-1980x990-png","_type":"reference"}},"plaintextBody":"We've previously explored the foundations of Experiment Driven Design and A/B Testing. Today we'll dig into A/B Testing with Python because analysis can be easily automated with existing open source python libraries. In this post we will explore their usage with an example. To orient the reader, we will state a few definitions to anchor the example:\n\nControl Group: current user interface.\nExperiment Group: rearranged point annotation button.\n\nH0: The mean of the annotation time for the control group is the same as the mean of the annotation time for the experiment group; there is no effect from rearranging the point annotation button.\n\nH1: The mean of the annotation time for the control group is different from the mean of the annotation time for the experiment group; there is an observable effect from rearranging the point annotation button.\n\nLet us assume that we ran an A/B Test feature experiment for two weeks. The UI modifications consisted of rearranging a button used in the process of drawing polygons around objects Let us assume these were recorded annotation times per image in minutes, for users of each variant (it can be represented as a python list):\n\nA. Control group (original arrangement):\n\nvariant_a = [150, 195, 120, 160, 97, 20, 100, 121, 250, 300, 80, 75, 100, 196, 147, 120, 100, 190, 57, 100, 157, 186, 91, 190, 210, 222, 192, 243, 99, 151]\n\n\n\nB. Experiment group (rearranged button):\n\nvariant_b = [120, 110, 96, 99, 87, 55, 43, 83, 200, 100, 125, 140, 75, 91, 141, 121, 250, 35, 94, 65, 85, 67, 93, 161, 35, 34, 111, 124, 85, 103]\n\n\n\n1. Run the t-test from the scipy.stats module of scipy (a mathematical, scientific and engineering library).\n\n\nimport scipy.stats as stats\n\nt, p = stats.ttest_ind(variant_a, variant_b, equal_var=False)\n\n\n\n2. Calculate the degrees of freedom according to Welch’s t-test definition which is the one implemented in stats.ttest_ind\n\n# For illustrative details see Wikipedia\n\n\ns1 = np.std(variant_a)\ns2 = np.std(variant_b)\nn1 = len(variant_a)\nn2 = len(variant_b)\n\ndf = np.floor(((((s1 ** 2) / n1) + ((s2 ** 2) / n2)) ** 2) /\n(((s1 ** 4) / ((n1 ** 2) * (n1 - 1))) + ((s2 ** 4) / ((n2 ** 2) * (n2 - 1)))))\n\n\n\n3. Now, using the same scipy.stats library, get the t-critical value for 95% or an alpha of 0.05 (1 - confidence level) from the t distribution’s ppf (percent point function) function and evaluate the t statistic from the previous step. If it falls in the range [-t-critical, t-critical] then H0 cannot be rejected, if it is outside, then we can reject H0 in favor of H1:\n\nalpha = 0.05\nt_critical_value = stats.t.ppf(1 - (alpha/2), df)\nnull_hypothesis = bool(t_critical_value >= t_value >= -t_critical_value)\n\n\n\n4. The confidence interval of variant_b (experiment) will help us visualize the difference between the two variants. If the mean of the control group doesn’t fall inside of this interval then the means of the two groups are significantly apart from each other, which suggests that the results are statistically significant.\n\ns = np.std(variant_b)\nx = np.mean(variant_b)\nn = len(variant_b)\nrho = (t_critical_value * s) / np.sqrt(n)\nconf_int = x - rho, x + rho\n\n\n\n\n\n5. Statistical power is the probability that the test correctly rejects the null hypothesis, in other words, the probability of a true positive result. This is only useful when the null hypothesis is rejected. A low value of power could be an indication that the sample size is not big enough yet to validate the results. To calculate the statistical power we use the class TTestIndPower from the module statsmodels.stats.power (https://www.statsmodels.org/stable/stats.html?highlight=power#module-statsmodels.stats.power) of the statsmodel (https://www.statsmodels.org/) library.\n\n\nfrom statsmodels.stats.power import TTestIndPower\n\n# Effect size based on Cohen’s d formula: https://en.wikipedia.org/wiki/Effect_size#Cohen's_d (https://en.wikipedia.org/wiki/Effect_size#Cohen's_d)\n\nx1 = np.mean(variant_a)\nx2 = np.mean(variant_b)\ns1 = np.std(variant_a)\ns2 = np.std(variant_b)\nn1 = len(variant_a)\nn2 = len(variant_b)\n\ns = np.sqrt((((n1 - 1) * (s1 ** 2)) + ((n2 - 1) * (s2 ** 2))) / (n1 + n2 - 2))\neffect = np.abs((x1 - x2) / s)\n\npower = TTestIndPower().power(effect, nobs1=n1, ratio=n2 / n1, df=(n1 + n2 - 2), alpha=alpha)\n\n\n\n6. Plot the sample distributions with confidence intervals as a visual aid using matplotlib library.\n\n\nimport matplotlib.pyplot as plt\n\n# Control\nfig, ax = plt.subplots(figsize=(12,6))\nxA = np.linspace(40, x1 + 3*s1, 100)\nyA = stats.norm(loc=x1, scale=s1).pdf(xA)\nax.plot(xA, yA, c='red', label='Variant A Distribution')\nax.axvline(x=x1, c='red', alpha=0.5, linestyle='--', label='Variant A')\n\n# Experimental\nxB = np.linspace(40, x2 + 3*s2, 100)\nyB = stats.norm(loc=x2, scale=s2).pdf(xB)\nax.plot(xB, yB, c='blue', label='Variant B Distribution')\nax.axvline(x=x2, c='blue', alpha=0.5, linestyle='--', label='Variant B')\n\n# Confidence interval\nax.axvline(conf_int[0], c='green', linestyle='--', alpha=0.5)\nax.axvline(conf_int[1], c='green', linestyle='--', alpha=0.5, label='Confidence Interval')\n\nplt.xlabel('Annotation Time')\nplt.ylabel('Percent of Tasks per Annotation Time')\nplt.title('Annotation Time Distributions')\nplt.legend()\nplt.show()\n\n\n\n","slug":{"_type":"slug","current":"experiment-driven-development-part-3"},"tags":[{"_key":"2iLUnerV","label":"Sama Engineering","value":"Sama Engineering"}],"title":"Part 3: A/B Testing with Python"},{"_createdAt":"2021-03-14T21:00:14Z","author":{"_id":"4e2e7cef-d6eb-4bb7-bd39-375c6299677e","avatar":{"_type":"image","asset":{"_ref":"image-f1a274bcfdb5e70d814f1bab2b6bbd644728e9be-1480x1462-jpg","_type":"reference"}},"bio":"With a background in Computer Science, Abha leads the Customer Success Engineering team at Sama. The team is responsible for managing technical relationships with customers and prospects to understand their business needs, ideate upon them, and manage the implementation and communication of the solutions developed. ","name":"Abha Laddha","slug":{"_type":"slug","current":"abha-laddha"}},"config":{"description":"Automated quality accelerators are technology innovations that are focused on reducing the amount of manual quality assurance time spent in QA processes.","openGraphImage":null,"title":"Supercharge Your Data Quality with Automated Quality Accelerators"},"estimatedReadingTime":4,"featured_image":{"_type":"image","asset":{"_ref":"image-0353ebdd4cd94e4e29f102019edc39fb91d77499-4485x2522-png","_type":"reference"}},"plaintextBody":"Let’s start at the beginning. What are automated quality accelerators and why should we care? Automated quality accelerators are technology innovations that are focused on reducing the amount of manual quality assurance time spent in QA processes. They may be used to expedite annotator education, generate automated measures of annotation quality, and prevent logical fallacies. Our accelerators are integrated into our Sama training data platform and can be customized for unique use cases and needs by our dedicated Customer Success Engineering team.\n\nWhile it’s key to have a human in the loop when creating and verifying training data, automating processes within the workflow improves efficiency while guaranteeing high quality, saving everyone time and money. Quality accelerators also focus the effort of Sama’s annotators towards the most challenging aspect of the task, minimizing the volume of manual rework they need to do, and catching mistakes early in the process —equipping them to do their job well. Ultimately, automated quality accelerators enable us to deliver super high-quality data for complex use cases in the most efficient manner.\n\n\n\nAutomated Quality Accelerators at Sama\n\nAutomated Logic Checks:\n\n\n\nAutomated Logic checks are triggered before a task is submitted on Sama by our annotators. Each task is assessed using a fixed set of rules to check for invalid combinations of labels within a shape, across all shapes, and dependencies with the metadata. These rules are flexible and customized to each workflow, focusing on all errors types that don’t need human judgement. If an error is found, the annotator needs to fix the task before it can be submitted. To help the annotator to fix the task and learn from their mistake, a message is displayed which contains shape specific error tags.\n\nAuto logic checks are optimized for different kinds of errors, including but not limited to:\n\nInvalid answer combinations: Combinations that the ontology prevents, for example more than two wheels being tagged on an item labeled “bicycle.”\n\nUniqueness or preventing repetitions: More than one object in an image being assigned the same unique identifier or the same label when the ontology prohibits that. For example, two noses in a single person keypoints workflow.\n\nSize requirements: Ensuring that size specifications are met. For example, guaranteeing consistent size in a 3D workflow where constant cuboid size is required or enforcing a minimum pixel rule\n\nRelational checks: Given attributes and sub-attributes, ensure that values selected aren’t contradictory. For example, a bicyclist polygon isn’t grouped/attached to a car bounding box\n\nThese checks are incredibly efficient for the following reasons:\n\nCreate an instant feedback loop to prevent logical fallacies, which helps annotators improve and get it right the first time\n\nPrevents errors that may be impossible to detect by a manual QA review processes\n\nReduces time spent by manual QAs and allow them to focus on the more critical errors or sample more tasks\n\nHelps annotators to adapt quickly to changing project instructions, ensuring that new instructions are being followed and are understood correctly\n\nLastly, it improves overall TPT and reduces the time from task creation to delivery\n\nUnder a strictly manual process, highly skilled quality assurance annotators would need to review and provide feedback manually. While the latter process is still a vital part of our human-in-the-loop data annotation, auto logic checks free up their expertise to focus on more subjective errors and edge cases.\n\nOur enterprise-level clients are successfully using Sama Quality Accelerators to realize extremely high data quality for their most complex use cases, improving overall model performance. Now is the time to supercharge your data quality.","slug":{"_type":"slug","current":"data-quality-with-auto-q-a"},"tags":[{"_key":"5AiNXS1h","label":"Product","value":"Product"},{"_key":"Izvu8Acj","label":"Training Data","value":"Training Data"},{"_key":"6O3wnuJC","label":"Data Quality","value":"Data Quality"}],"title":"Supercharge Your Data Quality with Automated Quality Accelerators"},{"_createdAt":"2021-03-08T21:41:38Z","author":{"_id":"40a70383-c941-405c-ae5b-f0aba421ee53","avatar":{"_type":"image","asset":{"_ref":"image-e0fe681e594567792ac79048513fe955cc770f54-518x518-svg","_type":"reference"}},"bio":"Rafael and Juan are both senior members of Sama R&D where they focus on Data Engineering and Data Science initiatives that help boost operational efficiency and achieve the highest quality.","name":"Rafael Alfaro & Juan Esquivel","slug":{"_type":"slug","current":"rafael-alfaro-and-juan-esquivel"}},"config":{"description":"In this series of three we’ll go into Experiment Driven Development and A/B Testing. EDD is fact-based development: based on evidence, not intuition.","openGraphImage":null,"title":"Part 2: A/B Testing"},"estimatedReadingTime":4,"featured_image":{"_type":"image","asset":{"_ref":"image-bbf0e002b88fd9c3b2fcbd032f60f114bc93eed0-1980x990-png","_type":"reference"}},"plaintextBody":"After last week's intro into Experiment Driven Development at Sama, we'll go further into A/B Testing today. A/B Testing is a randomized experiment method to compare how two populations behave in a controlled environment and determine whether the variation of some target metrics defined are significant or not, to determine that the experiment yields better results than the alternative.\n\nWe say that a baseline sample (variation A), which normally refers to some existing system, is compared against an experimental treatment (variation B). In software development, samples drawn from the two populations will be used to analyze the metrics associated with the usage of features. We generally want to make sure that any new feature has a positive impact: improved usability, lower duration to finish a process, etc. We should aim to have data to back up our claims that a feature has benefits, otherwise it would be fair to question why we want to deploy a new feature.\n\nOne way of evaluating an A/B experiment is through the use of a t-test which works well when we expect the distribution to be normal and it also allows us to not worry about the unknown standard deviation of our data. Note, however, that population distributions are not always expected to be normal, of course, and the t-test can be replaced by some other appropriate hypothesis test, depending on the distribution of the data, e.g. Kolmogovor-Smirnov. In our case, we want to determine if the means of the two data samples are significantly different from each other, with a given confidence level (90%, 95% and 99% are commonly used values).\n\nThe framework of the experiment revolves around the definition of a hypothesis for an A/B Test as follows:\n\nH0: The mean of the baseline metric is the same as the mean of the experiment metric; there is no effect from the treatment (variation) of the experiment, thus the two means belong to the same population.\nH1: The mean of the baseline metric is different from the mean of the experiment metric; there is an observable effect from the treatment (variation) of the experiment metric and the two means belong to different populations.\n\nWe then define the timeline for the feature/process experiment, run the experiment and collect the observations from the samples of the two variants. We should have a notion in terms of how long we want to run this to collect enough information (we will treat this as out of scope on this piece, however).\n\nIn order to perform the t-test evaluation, we need per sample sizes (N), means (X) and the standard deviations (s) to calculate the statistic t and the degrees of freedom (v). This is calculated as follows (using Welch’s t-test for independent variables with unequal variances and unequal sample sizes):\n\nOnce the statistic and degrees of freedom are calculated, along with an (1-confidence level), we can evaluate our hypothesis against the t-distribution table to determine whether or not the populations are different.\n\nIf our t statistic is less than the value from the table, given the degrees of freedom and the significance level, we can reject the null hypothesis as there is enough evidence to determine that sample means are from different populations. That would mean our new feature is really different from the control and we can release it, if the direction of the variation is in line with our objectives (e.g. lower means when we want to lower durations is good).\n\nThere are other more nuanced circumstances that we can address with a similar framework. For instance, we may want to test two variants of a new feature side by side. We may also want to use a slightly different statistical tool than a t-test, depending on what our interests are. What is important is the test-driven culture that should be fostered within organizations to have a data-drive approach to justify the release of new features.\n\nNext up: A/B Testing with Python.","slug":{"_type":"slug","current":"experiment-driven-development-part-2"},"tags":[{"_key":"FSfjH4D2","label":"Sama Engineering","value":"Sama Engineering"}],"title":"Part 2: A/B Testing"},{"_createdAt":"2021-03-02T05:05:17Z","author":{"_id":"40a70383-c941-405c-ae5b-f0aba421ee53","avatar":{"_type":"image","asset":{"_ref":"image-e0fe681e594567792ac79048513fe955cc770f54-518x518-svg","_type":"reference"}},"bio":"Rafael and Juan are both senior members of Sama R&D where they focus on Data Engineering and Data Science initiatives that help boost operational efficiency and achieve the highest quality.","name":"Rafael Alfaro & Juan Esquivel","slug":{"_type":"slug","current":"rafael-alfaro-and-juan-esquivel"}},"config":{"description":"In this series of three we’ll go into Experiment Driven Development. EDD is fact-based development: based on evidence, not intuition.","openGraphImage":null,"title":"Part 1: Experiment Driven Development"},"estimatedReadingTime":3,"featured_image":{"_type":"image","asset":{"_ref":"image-bbf0e002b88fd9c3b2fcbd032f60f114bc93eed0-1980x990-png","_type":"reference"}},"plaintextBody":"In this series of three we’ll go into Experiment Driven Development and A/B testing. The opposite of developing features based on anecdotes heard in stories from the CEO’s next-door neighbor, EDD seeks proof and is iterative. EDD can be defined as fact-based development: development based on evidence gathered from the field, not intuition.\n\nIn EDD every new feature or process implemented is validated through a formal experiment design process, which looks to test a hypothesis that describes the status quo of the feature. Example hypotheses could range from \"Making a button bigger does not impact clicks\" all the way to \"Making a web app responsive does not increase visitation\" compared. In statistical terms, the base statement is referred to as the null hypothesis (H0), the status quo, and then an alternative hypothesis(H1) is proposed. The null hypothesis will usually state that the change introduced by the experiment will not affect the current behavior while the alternative supports that there is in fact a change.\n\nThe alternative hypothesis is a prediction of what is expected to happen before running the experiment. It can be a bold statement, not an open question and it should have three parts:\n\nThe variable (if we add/change/remove...): the change that the experiment will measure against the current state of the feature/process.\n\nThe desired result (then we expected to see...): what we expect to see after the change is introduced, a qualitative difference between the current state and new state.\n\nThe rationale behind the prediction (because we have seen that...): prior knowledge that has led you to come up with the current hypothesis (from prior observation).\n\nFor example, one can define the pair of hypotheses for a new registration form in a website as:\n\nH0: Changing the registration form from multiple to single page will not impact the current user registration rate.\n\nH1: Changing the registration from multiple to single page will increase the current user registration rate by 5% because we have previously seen that there is a 5% abandon rate on the multi page form format.\n\n\n\nEDD is based on A/B Testing, which is a randomized experiment method to compare two variants of a single variable. In this case, a baseline metric is compared thanks to the definition control (status quo) and treatment (new feature) groups in order to determine if the variation has a significant impact or not. Ideally, most decisions to release a feature would be based on the results given by A/B Tests. At Sama, we want to find viable ideas or fail fast. Instead of developing a monolithic solution and pushing a release, we iterate through experiments, evaluating how features perform and, most importantly, if and how customers use them.\n\nNext up: A/B Testing and A/B Testing with Python.","slug":{"_type":"slug","current":"experiment-driven-development-part-1"},"tags":[{"_key":"sZmqu6EC","label":"Sama Engineering","value":"Sama Engineering"}],"title":"Part 1: Experiment Driven Development"},{"_createdAt":"2021-02-09T20:20:36Z","author":{"_id":"88e43c38-2712-41d4-9df3-8656c163c4db","avatar":{"_type":"image","asset":{"_ref":"image-af1346669e45d7264a36f051c18aea76061725bb-1895x1894-webp","_type":"reference"}},"bio":"Kyra is passionate about world-changing tech and sustainability, and happiest when these come together (looking at you, Sama). Stereotypical Dutch, she enjoys urban cycling and eating stroopwafels.","name":"Kyra Harrington","slug":{"_type":"slug","current":"kyra-harrington"}},"config":{"description":"We reached out to various ML experts, asking them the questions: Why is high-quality training data so important? Why do so many projects fail in ML?","openGraphImage":null,"title":"10 Experts Give Reasons Why High-Quality Training Data is so Important"},"estimatedReadingTime":6,"featured_image":{"_type":"image","asset":{"_ref":"image-f6c86749d02ef692a6d0252be265f98ef9d35890-900x507-png","_type":"reference"}},"plaintextBody":"In our guide on Data Quality we discussed the need for high-quality data for Machine Learning models. It is widely accepted that without ample amounts of high-quality training data, the application of AI and Machine Learning is impossible. This has also been seen in studies, including an IDC survey, in which only 30% of companies reported a 90% or higher success rate in their AI rollout, with reported failure rates of 10 to 49 percent. A key reason for this? Data! \n\nWe partnered with our friends from RE•WORK to reach out to various ML experts, specifically asking them the questions: Why is high-quality training data so important? Why do so many projects fail in ML?\n\n\nManmeet Singh\nMachine Learning Lead, Apple\n\n\"The core of any Machine Learning model is what input is being fed to it as the model generalizes based on these training examples. The criteria to choose a ML model is heavily dependent on the kind of input available. For the model to learn anything relevant, training data plays a key role. Imagine in a supervised setting, we are trying to do object recognition. If the labels themselves are messed up what would the model learn? Besides the quality, the quantity of training examples also plays a major role. Training data forms the basis of business decisions based on the offline KPIs being measured on their information. They are the building block for defining a roadmap to the product cycle.\"\n\n\nIndu Khatri\nMachine Learning Lead, HSBC\n\n\"There are two main reasons why quality training data is important. First one is that many problems are solved using Supervised Learning and training data forms the backbone for such applications. The second and more deeper reason is that with the advent of AutoML, democratization of ML skills, and open sourcing of cutting edge research and tools; they are no longer competitive advantages. The only way businesses can sustain a competitive advantage in AI applications is through differentiated training data.\"\n\n\nLavi Nigam\nData Scientist, Gartner\n\n\"In supervised learning, algorithms are dependent on training data to extract relevant patterns for future predictability, hence clean, unbiased and processed training data is crucially important. It’s like the “garbage in garbage out” rule for training any ML/DL models. Although, sometimes, we have lack of training data available and in such cases we have many new semi-supervised learning algorithms coming up. I see great future in such techniques as businesses all across the world don't work at Google/Facebook data scales mostly.\"\n\n\nZhiyong (Sean) Xie\nDirector, AI, Pfizer\n\n“‘Give me a lever long enough, and I shall move the world’. With deep learning methods, we may say ‘Give me data big enough and I can predict anything.’ Data is the foundation of Machine Learning, especially the deep learning method, with the machines learning everything from data. If you feed a machine biased data, it gives you biased predictions. Garbage in, garbage out.”\n\n\nShuo Zhang\nSenior ML Engineer, Bose Corporation\n\n“One point I'd like to stress is the domain knowledge and domain specificity in ML. People sometimes think of ML as a ubiquitous technology that can be universally applied to any domain. But in reality, blindly applying ML is dangerous, and you should always know your domain and your data in a very deep way.”\n\n\nPiero Molino\nNLP Research Scientist, Staff ML Team, Stanford\n\n\"How would you train models without it? More seriously, quality and size of data are important because we are trying to tackle difficult tasks and we haven't figured out yet methods that are very robust to noise or that can be trained from smaller amounts of data.\"\n\n\nSparkle R. \nAssociate Director Data Science, Johnson & Johnson\n\n\"While innovative ML tools and techniques are being developed at a rapid pace, ML practitioners can sometimes get drawn into the novelty of applying newer approaches without realizing that the fundamentals of science and lack of high-quality data make many of these algorithms impractical for some healthcare facing solutions. Additionally, in our haste to publish our findings, researchers often forget that these systems will be used by an end-user (patient and provider), and expert level performance in development does not guarantee real-world clinical utility, adoption and transferability across heterogeneous healthcare systems. So, it is equally important that the end user’s workflow is also considered to ensure that the lab to real world transition is successful.\"\n\n\nYaman Kumar\nPhD Computer Science, University of Buffalo\n\n\"Training data is so important since most of the people, books, blogs, videos start and end with supervised learning. We currently do not know how to work in unsupervised settings. As we move towards unsupervised settings, the requirement of training data as we know it will reduce. In that world, gathering training data would not be an arduous task as it is supposed to be now.\"\n\n\nKiana Alikhademi\nArtificial Intelligence & Computer Science, University of Florida\n\n\"Training data is the backbone of any machine learning system, without sufficient training data, it is impossible for a machine to learn patterns or solve problems. The importance of training data illustrates why inadequate, or low quality training data, could lead to Machine Learning systems’ failure. Training data ought to be representative of all different groups within the sample without inheriting any societal prejudices.\"\n\n\nJack Brzezinski\nChief AI Scientist at AI Systems & Strategy Lab\n\n\"I feel that the role of knowledge will be increasing. Structures, various knowledge representation types will be essential for the next wave of AI innovation. The lawmakers might soon require AI, ML models to be compliant with multiple statutes or regulations.\"","slug":{"_type":"slug","current":"experts-high-quality-training-data-importance"},"tags":[{"_key":"HWRhI8n2","label":"Training Data","value":"Training Data"},{"_key":"QPqXb7Bo","label":"Data Quality","value":"Data Quality"},{"_key":"deOuCKuN","label":"Expert Advice","value":"Expert Advice"}],"title":"10 Experts Give Reasons Why High-Quality Training Data is so Important"},{"_createdAt":"2021-02-01T20:53:26Z","author":{"_id":"e9e6679d-3ed9-4cd2-a5a5-cfbff31e1057","avatar":{"_type":"image","asset":{"_ref":"image-e33a218a0ab19114b971463e566b1d1cbdb2e6cd-512x512-webp","_type":"reference"}},"bio":"Mathieu is a Senior Software Engineer at Sama. He has been developing software for more than two decades, with a deep passion for DevOps, CI/CD, Infrastructure as Code, Kubernetes and everything Cloud Native. A joyful father of four, Mathieu loves working with people, learning from them, sharing his love of software engineering, coaching and bringing the best out of everyone, including a smile!","name":"Mathieu Frenette","slug":{"_type":"slug","current":"mathieu-frenette"}},"config":{"description":"Introducing Factotum: an MIT-licensed, open source, kubernetes-oriented, general purpose docker container for devs/devops and custom CI/CD pipelines.","openGraphImage":null,"title":"Factotum: Containerizing DevOps Tools for Cloud Native Engineering and CI/CD"},"estimatedReadingTime":4,"featured_image":{"_type":"image","asset":{"_ref":"image-19ef3f125b8ee47727e9f94dc3aff7ed08a4d78c-720x360-png","_type":"reference"}},"plaintextBody":"Our Cloud Journey\n\nLike most companies making the transition to the cloud today, one of the biggest challenges we face in empowering our engineering teams to adopt cloud-native technologies, such as Kubernetes and CI/CD, is the high barrier to entry of simply setting up their local machines with a unified set of tools and configs to interact with those cloud environments. As DevOps, we would ideally like all our colleagues to easily have access to the same tools and environments, and to even extend that to our CI/CD pipelines, which have no reason to run different versions of those tools from our development machines.\n\nContainers are a natural go-to for the job. However, while they're great at encapsulating many tools with specific versions and repeatable, predictable outcomes, containers are designed with remote services and jobs in mind, rather than day-to-day use as a local work environment.\n\nWhen you start to use containers as a daily working tool, you quickly stumble on many roadblocks. You need to master Docker CLI commands and flags to launch your container in various conditions, environment variables, volume mounts and port mappings. The syntax is different depending if you already started your container in the past, or if it's already running and you just want to open a few extra shells into it. What if you need to access multiple kubernetes clusters in parallel, each with its own container? And don't forget that if you modify any config files within your container, those will be discarded the next time you rebuild and launch a fresh copy of your image! Finally, if you want to share the same tools and configs with your colleagues and (gasp!) even your CI/CD pipeline, you're in for an extra ride!\n\nNaively patching up some Dockerfile with your desired tools is not the end of the road. For us, it was just the beginning.\n\n\nThe Process\n\nWe have long tinkered with the idea of packaging up a neat multi-purpose Docker container that would handle most use cases and make it seamless to setup and interact with different Kubernetes clusters. Starting with a few prototypes and then some inspiration from Cloud Posse's Geodesic container—which does a great job of streamlining the installation and launching of the container— our experiments finally evolved into a tool generic and mature enough to be shared with the community!\n\nOur goal has been to share such a tool with the DevOps community and, thanks to the folks at Sama, this vision has become a reality. Let me introduce you to an MIT-licensed, open source, kubernetes-oriented, general purpose docker container for devs/devops and custom CI/CD pipelines, that we affectionately called \"Factotum\" (from Latin, basically meaning an employee who does all kinds of work).\n\nCheck out the source on GitHub\n\nWhat to Know Before You Begin\n\nEven if you can try the vanilla build of Factotum as is from GitHub and Docker Hub, please understand that Factotum is really intended to be customized and made your own in order to leverage its full potential. If you settle to try it, it is worth forking the repo, customizing the Dockerfile and following the instructions in README.md. While that process of setting up your own customized build of Factotum can be rather involved, be assured that using, maintaining, upgrading and sharing it with your teammates afterwards is intended to be as straightforward as possible—it just takes that little initial effort! And, if you encounter any issues or can't figure how to set it up correctly, don't hesitate to file an issue in the GitHub repo and give us feedback.\n\nHappy factotum'ing.","slug":{"_type":"slug","current":"devops-tools-for-cloud-native-engineering"},"tags":[{"_key":"8AQmCtzZ","label":"Sama Engineering","value":"Sama Engineering"},{"_key":"Gl5fCrPJ","label":"Featured","value":"Featured"}],"title":"Factotum: Containerizing DevOps Tools for Cloud Native Engineering and CI/CD"},{"_createdAt":"2021-01-22T23:06:59Z","author":{"_id":"88e43c38-2712-41d4-9df3-8656c163c4db","avatar":{"_type":"image","asset":{"_ref":"image-af1346669e45d7264a36f051c18aea76061725bb-1895x1894-webp","_type":"reference"}},"bio":"Kyra is passionate about world-changing tech and sustainability, and happiest when these come together (looking at you, Sama). Stereotypical Dutch, she enjoys urban cycling and eating stroopwafels.","name":"Kyra Harrington","slug":{"_type":"slug","current":"kyra-harrington"}},"config":{"description":"2021 Predictions: We asked a range of ML experts about what they believe will be the next big thing in AI and Machine Learning.","openGraphImage":null,"title":"What's next? 17 Machine Learning Predictions for 2021"},"estimatedReadingTime":10,"featured_image":{"_type":"image","asset":{"_ref":"image-21b9dcfd77e3eb1e777b3d499c73c89ddf24d454-1200x675-png","_type":"reference"}},"plaintextBody":"Large developments in AI and Machine Learning are normally announced as part of a campaign or during important keynote presentations, but we thought we would try and get a sneak peak into 2021 developments in the field. We partnered with our friends from RE•WORK by asking a range of experts in Machine Learning what they believe will be the next big thing. \n\n\n\nTushar Chugh\n\nMachine Learning Software Engineer, Google\nTushar’s predictions for 2021 are very much based on the outcome of work already underway. The former General Motors trailblazer suggested that he was on the lookout for the following in 2021: 1. The “rapid” training, evaluation and productionization for the large sequence models (such as GPT-3, T5). 2. The research towards developing giant ML models that can cater to multi-model inputs from various tasks and that can generalize well to the new tasks.\n\n\n\nZhiyong (Sean) Xie\n\nDirector, AI, Pfizer\nWith over 17 years at Pfizer working in AI, Sean has overseen tasks ranging from quantification of MRIs to multivariate analysis of disease progress and most recently, a global effort in drug safety assessments. When asked what he thought might be on the horizon for this year, Sean suggested “We may train the machine to predict the Machine Learning in 2021.” This rather funny response, if true, could see a move toward the automation in ML we have discussed for some years.\n\n\n\nAlireza Rostamzadeh\n\nData Science & Machine Learning, Apple\nAlireza’s predictions for the year ahead were quite something, and we love the sound of this! “2021 will be the year when we start to see more tangible ML-driven products; from significant improvements in self-driving cars to a wave of new products based on augmented reality”.\n\n\n\nShuo Zhang \n\nSenior Machine Learning Engineer, Bose Corporation\nWorking across NLP, Deep Learning and now ML, Shuo has a range of experience. When asked, Shuo suggested that while the question in itself is extremely broad, “I'd say that less dependence on human supervision by leveraging the intrinsic structures of large data is a path ML research is heading toward.” A step closer to the infamous automation buzzword.\n\n\n\nJason Gauci\n\nSoftware Engineering Manager, Facebook\nJason’s experience has spanned creative positions at Apple, Google and now Facebook, where he is working on a scalable reinforcement learning platform. When we asked Jason what he thought we could see in ML this year, he suggested “I predict that decision making AI will surge in popularity. Imagine an AI system that can tune constants in your code, or one that monitors your diet and suggests food. We have done a lot in the realm of signal processing but decision making continues to be an area with a lot of engineering trial-and-error.”\n\n\n\nSadid Hasan\n\nSenior Director of AI, CVS\n“In 2021, researchers would continue to take a leap in developing complex AI applications related to natural language understanding and generation by leveraging the ongoing advancements in multi-modal (text, speech, image) data fusion-based algorithms and more efficient transformer architectures. In addition, powerful synthetic data generation and augmentation techniques would enhance effective training of machine learning models by alleviating the challenges related to accessing sufficient ground-truth data. We would also see further emphasis on AI model’s ethicality, generalizability, explainability, and reproducibility along with efficient model Ops for a beneficial and robust on-device deployment. Furthermore, with the ongoing proliferation of healthcare data, the AI community would continue to build novel machine learning-based healthcare applications leading to increased AI adoption for providing meaningful decision-making support to end-users.”\n\n\n\nLavi Nigam \n\nData Scientist, Gartner\n“As more and more companies are heading towards AI/ML Maturity and working with more production scale ML/DL deployments, their focus in 2021 will be more on MLOps where they need to work on key aspects of processes like - Model/Data Drift Analysis, Model Interpretability, Data Governance, Model Scaling & AutoML. This year we will finally see many maturity models and practices for ML/DL operations coming up from different vendors and companies which will be very crucial in the long run.”\n\n\n\nBeat Raphael Schaad\n\nSenior Data Scientist, Sky\nThe Senior Data Scientist at Sky when asked his predictions for 2021 stayed very much on the hot topic of COVID. “The goal for 2021 is that Data can support governments beyond counting Covid19 cases and death rates. Given the recent events ML will have to improve massively in inference and causality issues. Forecasting methods using AI do not deliver anything on our historic events scenarios mainly because of the lack of explainability of the generated features.”\n\n\n\n\nIndu Khatri\n\nMachine Learning Lead, HSBC\n2021 will be the Year of MLOps. Many cloud services such as GCP's AI Platform, AWS's Sagemaker have matured over the past years and are readily adaptable by ML teams. In 2021 and beyond Data Scientists would have to work collaboratively with DEs/MLEs to take their beautiful models from lab to production and realize business value.\n\n\n\nPiero Molino\n\nNLP Research Scientist, Staff ML Team, Stanford\nThe former Senior ML practitioner at UBER, currently makes up part of Professor Chris Ré's Hazy Research group on ML systems in California. Piero suggested that in industry he believes “models will start to come closer instead of being in separate silos like it happens today in most cases. In academia, I believe there will be more research focused on robustness and generalization.”\n\n\n\nKiana Alikhademi \n\nResearch Assistant, University of Florida\n“The year 2020 has significantly changed our lives in many ways. The way we work, communicate and learn has been impacted in many significant ways. Artificial Intelligence continues to be a key technology trend when it comes to the things that will change how we live, work, and play in the near future. I predict that artificial intelligence will be the main technology in the following areas: If any threat such as COVID were to occur, then that should be detected ahead of time. To help businesses prepare for situations like this pandemic, we must understand how users behave during such an emergency.”\n\n\n\nDivya Sivasankaran\n\nSenior Machine Learning Engineer, Autodesk\n\"Over the last year, we've seen a lot of local AI startups being sold/acquired. Many are struggling to bring AI products to market. I believe the pandemic merely sped up the inevitable. The silver lining to me here is that we've managed to cut down on the hype (noise) giving us time and resources to focus on impact with tangible applications (signal). That's why I think 2021 will be the year we will start to see AI/ML features in production for real - i.e., AI will successfully make the transition from being a spice to a core ingredient.\"\n\n\n\nRavi Dalal\n\nSenior Computer Vision Engineer, Walmart\n“I think 2020 has changed the world around us in many ways, and the retail sector is no exception. The pandemic has taught everyone new ways of shopping whether it's online, curbside pickup or concierge services for senior members. And AI/ML has played a major role in shaping all these solutions everywhere. Going in 2021, I feel rather than quantity of data, the market will shift towards the quality of data being captured. As more and more data points are getting captured to make better ML models; need of the hour is to make light weight models that can run on edge devices to filter and capture just the meaningful data. I call it -- \"AI/ML for Intelligent Data collection.”\n\n\n\nShaina Raza\n\nResearch Assistant, Ryerson University\nShaina, a former lecturer and now Research Assistant in ML gave one of the more exciting predictions on the list, which would mean large scale change and positive development in the field in the months to come. “Machine Learning is going to be easier, cheaper and beyond the limitations. The exponential power of the computing resources will be in the hands of laymen, and we see the revolution of the world much more earlier than expected.”\n\n\n\nYaman Kumar\n\nPhD Computer Science, University of Buffalo\nYaman’s research in ML revolves around Adversarial Networks, Interpretability, QA and Speech and is supported by Google doctoral Fellowship. Yaman simply suggested three compartments of ML which he believes will develop rapidly in 2021. “Unsupervised Learning, Explainability, and Fairness in ML.” Surprisingly, it was the only mention of unsupervised learning, which has seen to become somewhat of a buzzword at the backend of 2020.\n\n\n\nJack Brzezinski\n\nChief AI Scientist at AI Systems & Strategy Lab\nI feel that the role of knowledge will be increasing. Structures, various knowledge representation types will be essential for the next wave of AI innovation. The lawmakers might soon require AI, ML models to be compliant with multiple statutes or regulations.\n\n\n2021 is set to be uncertain in many ways. However, as with last year, hard work behind the scenes in AI and ML continues. The range of optimistic yet realistic predictions above, if accurate, could see 2021 as a year in which some of the largest steps in AI and Machine Learning advancement for some years take place.\n\nWhat do you think could be developed this year?","slug":{"_type":"slug","current":"17-machine-learning-predictions-for-2021"},"tags":[{"_key":"94W8kEob","label":"Machine Learning","value":"Machine Learning"},{"_key":"CKYpD6ea","label":"AI","value":"AI"},{"_key":"CzXbg3oJ","label":"Expert Advice","value":"Expert Advice"}],"title":"What's next? 17 Machine Learning Predictions for 2021"},{"_createdAt":"2021-01-19T17:04:40Z","author":{"_id":"7aaa2439-b7e5-45f9-8aee-1fbf3c9b5fb8","avatar":{"_type":"image","asset":{"_ref":"image-0a1ace27b14b286beed42f8a189b8d4c9f8d5e71-512x512-webp","_type":"reference"}},"bio":"Dimitri is a software developer specializing in computer vision. Currently a machine learning developer at Sama, Dimitri has developed machine learning based products for the entertainment and image processing industries. He holds a Masters degree in Electrical Engineering from McGill University, where he performed research on active object recognition. He is passionate about the use of technology in order to combat income inequality and climate change. Outside of work, he can be found playing beach volleyball or table tennis depending on the time of year.","name":"Dimitri Gallos","slug":{"_type":"slug","current":"dimitri-gallos"}},"config":{"description":"The Sama MLOps Pipeline: At Sama, we decided to build our own automated training pipeline in order to limit costs, and to avoid tying ourselves to a particular cloud provider.","openGraphImage":null,"title":"The Sama MLOps Pipeline: Automating Model Training on the Cloud"},"estimatedReadingTime":3,"featured_image":{"_type":"image","asset":{"_ref":"image-04641081798c41caebebefa44685828d80b7434f-1200x675-png","_type":"reference"}},"plaintextBody":"Training computer vision models are notoriously computationally intensive, often requiring multiple GPUs. It's therefore usually not performed locally. One of the challenges when it comes to launching training jobs on the cloud or private GPU clusters is dealing with all the required manual steps. For example, when using AWS, ML engineers need to spin-up an EC2 instance manually to launch a training job, and then manually decommission it once the training job is completed. \n\nAlthough commercial tools do exist to automate this process (for example, SageMaker or DataBricks), at Sama we decided to build our own automated training pipeline in order to limit costs, and to avoid tying ourselves to a particular cloud provider.\n\nOur pipeline allows our ML Engineers and Scientists to launch a training job on the cloud by simply pushing the code they developed locally to a predefined git branch. This is very simple to achieve using a modern CI/CD platform like Codefresh. A Codefresh “trigger” can be set to track commits to specific git branches of a repository. Once a commit is pushed to a target branch, a Codefresh pipeline is triggered. The pipeline is just a workflow defined in a yaml file that executes the following steps :\n\nClone the tracked git repository, as well as any other repos required (in our case we have a separate repo for all our ML related tools).\n\nBuild a Docker image with all the project specific dependencies.\n\nDeploy the training job on the GPU cluster.\n\nSend a slack message to a channel that tracks all the training jobs whenever the results are ready or if there is an error.\n\nThe specific implementation of step 3 above depends on the particular frameworks and libraries that are used to train the models and track their performance, as well as the cloud provider. In our team, we use Kubernetes to orchestrate the creation and decommission of the instances. We also use mlflow to manage the ML lifecycle, which has built-in Kubernetes deployment support. So for us, this step simply reduces to doing some cloud provider specific configuration and running an mlflow experiment with Kubernetes as the backend.\n\n\n\nSummary of the Sama automated training pipeline: from pushing the code to Github to running the training job on AWS.\n\n\n\nAside from the obvious time savings, the advantage of this setup is that it is fully configurable and can be made to work with any cloud provider, or even a private GPU cluster. As an added bonus, it enforces experiments to be separated in different git commits, which we find is good practice.","slug":{"_type":"slug","current":"part-1-automating-model-training-on-the-cloud"},"tags":[{"_key":"OdrqBpR4","label":"Sama Engineering","value":"Sama Engineering"},{"_key":"Yw0P8Jjj","label":"Training Data","value":"Training Data"},{"_key":"08tVZdgm","label":"MLOps","value":"MLOps"},{"_key":"eMmu9s8R","label":"Featured","value":"Featured"}],"title":"The Sama MLOps Pipeline: Automating Model Training on the Cloud"},{"_createdAt":"2021-01-15T20:16:49Z","author":{"_id":"a009d418-aa96-47ac-a73a-fd2cd52c79d9","avatar":{"_type":"image","asset":{"_ref":"image-e0d717f753ba4876a6b0dbf9f125cf6c3d27e545-500x500-webp","_type":"reference"}},"bio":"Wendy Gonzalez is an executive passionate about building high-performing, high-functioning teams that develop and scale innovative, impactful technology. With two decades of managerial and technology leadership experience for companies including EY, Capgemini, Cycle30 (acquired by Arrow Electronics) and General Communications Inc, Gonzalez is currently the CEO of Sama, the provider of accurate data for ambitious AI, used by leading technology companies such as Walmart, Google, Nvidia and Getty. Before taking on her role as CEO, Gonzalez spent 5 years at Sama as COO, and is an active Board Member of the Leila Janah Foundation.","name":"Wendy Gonzalez","slug":{"_type":"slug","current":"wendy-gonzalez"}},"config":{"description":"Samasource is now Sama. The same team that powers the world’s most ambitious AI, but with a new name that represents our vision moving forward.","openGraphImage":null,"title":"We Are Now Sama: Accurate Data For Ambitious AI"},"estimatedReadingTime":3,"featured_image":{"_type":"image","asset":{"_ref":"image-fbafe834a890fa166be72754be9610ccc9693cd2-2844x1600-png","_type":"reference"}},"plaintextBody":"As we welcome 2021, we’re ready to embrace new beginnings. Therefore, we’re proud to announce that we’re now Sama, the same team that powers the world’s most ambitious AI projects with high-quality and accurate data, but now with a new name that represents our vision moving forward.\n\nThis change comes at a time when our company is at an inflection point. Our technology has quickly become the preferred option by some of the most sophisticated companies in the world. I know Leila would be proud to see where our company is today and that we are finally sharing Sama, a name we’ve used internally for years, with the world.\n\nIf there’s one thing we can all agree on, it’s that 2020 was a tumultuous year. From a deadly pandemic to global protests and a national presidential election - its events are sure to impact our society for years and decades to come.\n\nAs many of you know, our founder, Leila Janah, passed away following a battle with epithelioid cancer. Since then, we’ve worked to fulfill her legacy through technological innovation, navigated the challenges of COVID-19, and stepped up to address the ongoing challenges of bias in artificial intelligence (AI).\n\nDespite its challenges, 2020 was a year of milestones and achievements for our team. From our recognition on the Inc. 5000 list as one of North America’s fastest-growing private companies to launching our Machine Learning Assisted Annotation, we look back on 2020 with an overall optimism for the future.\n\nSama reflects several business developments we’ve made over the past few years. Starting with our transition to a for-profit business model in 2018, we’ve been focused on scaling our business to continue to provide high-quality training data for ambitious AI for some of the world’s leading brands such as Google, NVIDIA, and Walmart.\n\nSince transitioning our business model, we’ve streamlined our approach to focus on accuracy, consistency, and simplicity, launching solutions like PII Data Anonymizer and Machine Learning Assisted Annotation. These solutions leverage automation in addition to human oversight, allowing efficient yet accurate data annotation and validation to take place. Moving forward, our focus is on further developing our tech as we expand our presence in industries such as retail, biotechnology, and media communications.\n\nWe are excited to share this milestone in our company’s history as we embark on our journey to becoming the world’s leading training data provider. Our new name, in conjunction with our doubled down approach to technology, will guide our company and our mission for years to come.\n\nWithout our community's help, we could not have gotten to where we are today, so thank you to all the Sama employees, investors, and partners for supporting us throughout this transitional journey.\n\nWe can’t wait for you to see what’s next.","slug":{"_type":"slug","current":"samasource-is-now-sama"},"tags":[{"_key":"GS7wrNs8","label":"Company News","value":"Company News"},{"_key":"BSu2iKoe","label":"Leila Janah","value":"Leila Janah"},{"_key":"YLf0JPMd","label":"Data Quality","value":"Data Quality"}],"title":"We Are Now Sama: Accurate Data For Ambitious AI"},{"_createdAt":"2020-12-21T18:21:43Z","author":{"_id":"785c9b8f-1869-4ce3-9eaa-c53945aa9736","avatar":{"_type":"image","asset":{"_ref":"image-c187f0a84bc4d1a6870d3a7a8528f242920a33aa-309x343-webp","_type":"reference"}},"bio":"Aurelie Drouet leads Product Marketing at Sama. Hailing from France and with expertise in driving revenue growth for companies in the US and Latin America, Aurelie's expertise spans several countries. She previously led Strategic Partnerships at Dreem.","name":"Aurélie Drouet","slug":{"_type":"slug","current":"aurelie-drouet"}},"config":{"description":"If you have a passing interest or are just looking for a refresher in all things Machine Learning, we have put together a list of 10 books.","openGraphImage":null,"title":"10 Must-Read Machine Learning Books"},"estimatedReadingTime":9,"featured_image":{"_type":"image","asset":{"_ref":"image-bc8699367ba2089c548213191c632bbbe6c784a9-1280x640-png","_type":"reference"}},"plaintextBody":"With the year coming to a close and not many other things to do than to stay put at home, this holiday season could be the perfect time to dive deeper into some books. If you have a passing interest or are just looking for a refresher in all things Machine Learning, we have put together a list of 10 books. Although published at varying points in the development of Deep Learning and Machine Learning, each book offers unique insights. It was near impossible to narrow the list to just ten, but we couldn’t look past those below.\n\n\n1. Grokking Deep Learning\nAndrew W Trask (2009)\n\nGrokking Deep Learning is suggested to be a perfect place to delve into the subset of Machine Learning, not only describing and explaining APIs and frameworks, but also talking the reader through how they can actually build algorithms from scratch. This hands-on style of writing will help you build an AI capable of beating you in a classic game of Atari and Neural Networks capable of understanding basic images. While this is not a beginners guide, experience with calculus is not required, merely a high school level of mathematical understanding.\n\n2. The Hundred-Page Machine Learning Book\nAndriy Burkov (2019)\n\nAn all you need to know guide to Machine Learning in just 100 pages, what more could you need? The Director of Data Science at Gartner, Andriy, suggests that you are a mere read of this book away from being ready to build complex AI systems, pass an interview or start your own business. Also available on Kindle, the 2019 release covers gradient descent, cluster analysis, dimensionality reduction and more. Is it for you? Andriy suggests that it is suitable for those both working in the field and those dipping their toe to find out more about the increasingly complex field of Machine Learning.\n\n\n3. Introduction to Machine Learning with Python: A Guide for Data Scientists\nSarah Guido & Andreas C. Mueller (2016)\n\nAlthough released in 2016, this 400 word bible for Machine Learning gives a great grounding in the basics of ML, providing a thorough and hands-on approach to Python use in ML. Learn not only what the most important concepts and algorithms are, but also when and how to use them. Imperative topics including machine learning workflow: data preprocessing and working with data are covered, as well as training algorithms, evaluating results, and implementing those algorithms into a production-level system\n\n\n4. Machine Learning For Absolute Beginners: A Plain English Introduction\nOliver Theobold (2017)\n\nA curveball, maybe, as we realize that those reading this list may have experience in the field, however, Machine Learning for Absolute Beginners walks through ML history and works in plain english with no coding experience necessary. What exactly will you be learning? The very basics including, decision trees, regression analysis, data reduction, k-means and more, giving you a great underlying understanding of the building blocks used in Machine Learning and how they can be used. Finally, some career advice with Oliver talking you through career options and how best to utilize the ML knowledge just picked up post-read.\n\n\n5. Mathematics for Machine Learning\nMarc Peter Deisenroth (2020)\n\nThis textbook puts the normally disparate course style of teaching in Mathematics to shame, combining together all of the fundamental mathematical tools needed to understand machine learning, including linear algebra, analytic geometry, matrix decompositions, vector calculus, optimization, probability and statistics. These concepts are then used to derive four central machine learning methods: linear regression, principal component analysis, Gaussian mixture models and support vector machines, giving a brilliant starting point for those entering the field and those looking for a refresher. Alongside the textual information, this book also includes examples and tests to ensure the reader's understanding.\n\n\n6. Pattern Recognition and Machine Learning\nChristopher M. Bishop (2007)\n\nChristopher Bishop’s Pattern Recognition and Machine Learning presents approximate inference algorithms that permit fast approximate answers in situations where exact answers are not feasible. The first of its kind on pattern recognition to present the Bayesian viewpoint, uses graphical models to describe probability distributions, which at the time, was not evident in any other ML text. Unlike some of the other inclusions on this list, familiarity with multivariate calculus and basic linear algebra is required, and some experience in the use of probabilities would be helpful though not essential.\n\n\n7. Probabilistic Graphical Models: Principles and Techniques\nDaphne Koller & Nir Friedman (2009)\n\nA general framework for constructing and using probabilistic models of complex systems that would enable a computer to use available information for making decisions. This book isn’t for beginners, nor for the faint of heart as it dives right into probabilistic graphical models in detail, including Bayesian and Markov Networks, inference, and learning from complete / incomplete data. If you want to get the most out of this book, there’s an option to attend Daphne Koller’s lectures on Probabilistic Graphical Models at Stanford University, on Coursera. Fun fact, Koller is actually one of the founders of Coursera, an online education platform.\n\n\n8. Machine Learning: A Bayesian and Optimization Perspective (Net Developers)\nSergios Theodoridis (2015)\n\nThe book builds carefully from the basic classical methods to the most recent trends of the time, including chapters on pattern recognition, statistical/adaptive signal processing, statistical/Bayesian learning, as well as short courses on sparse modeling, deep learning, and probabilistic graphical models. All of the major techniques you’ll need to know prior to working in the field are covered, including Mean/Least-Squares regression and filtering, Kalman filtering, stochastic approximation and online learning, Bayesian classification, decision trees, logistic regression and boosting methods. Alongside all of the theoretical text, this book includes case studies, code to be experimented with and more.\n\n\n9. Machine Learning: A Probabilistic Perspective\nKevin P. Murphy & Francis Bach (2012)\n\nKevin describes this text as a comprehensive introduction to machine learning methods that use probabilistic models and inference as a unifying approach. This overview text combines breadth and depth, offering necessary background material on such topics as probability, optimization, and linear algebra as well as discussion of recent developments in the field, including conditional random fields, L1 regularization, and deep learning. Rather than providing a cookbook of different heuristic methods, the book stresses a principled model-based approach, often using the language of graphical models to specify models in a concise and intuitive way. Alongside this, the software platforms used in examples are freely available online. Unlike some of the other texts in this list, Machine Learning: A Probabilistic Perspective is suitable for upper-level undergraduates, giving an ideal introduction to ML and Mathematical formulas.\n\n\n10. Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems\nAurelien Geron (2019)\n\nIn the last few years, breakthroughs in Deep Learning have boosted the entire field of machine learning. Now, even programmers who know close to nothing about this technology can use simple, efficient tools to implement programs capable of learning from data. Through minimal use of theory and maximum practical examples, this text helps you gain an intuitive understanding of the concepts and tools for building intelligent systems. You'll learn a range of techniques, starting with simple linear regression and progressing to deep neural networks. With regular examples throughout, it’s a great book to not only grasp how and why it all works, but to also test it yourself.","slug":{"_type":"slug","current":"10-must-read-machine-learning-books"},"tags":[{"_key":"R9BEAeeH","label":"Machine Learning","value":"Machine Learning"},{"_key":"OUl8Z7DG","label":"Best of","value":"Best of"}],"title":"10 Must-Read Machine Learning Books"},{"_createdAt":"2020-12-15T21:43:21Z","author":{"_id":"a3099d34-9595-4978-b517-e508196414c1","avatar":{"_type":"image","asset":{"_ref":"image-6643136d6c33f77b8e49366c166642ca5dafba8d-500x500-webp","_type":"reference"}},"bio":"Frédéric is a researcher and team leader with over 15 years of R&D experience in machine learning, AI, NLP, speech recognition, and computer vision. Currently Head of AI at Sama, he has worked on building ML-based products in multiple industries from Healthcare to Retail, in large companies and startups. He cares about the impact of technology, and outside of work, you can often see him on a bicycle or on skis.","name":"Frederic Ratle","slug":{"_type":"slug","current":"frederic-ratle"}},"config":{"description":"In this article we summarize an approach that we have developed to speed up polygonal instance segmentation using machine learning.","openGraphImage":null,"title":"Fast Vector Annotation with Machine Learning Assisted Annotation"},"estimatedReadingTime":8,"featured_image":{"_type":"image","asset":{"_ref":"image-6abd2f846119ba50a8325787f99ec3aeec68ffff-1076x605-png","_type":"reference"}},"plaintextBody":"At Sama, Vector Annotation of objects using polygons is a task that our expert annotators spend a great deal of time on. This is especially true for projects involving autonomous vehicles, where it is typical to apply instance segmentation to label scenes comprising hundreds of frames, each with multiple objects (vehicles, pedestrians, traffic signs, etc.) like you see in Figure 1.\n\nFigure 1. Example of Polygonal Annotation in Sama.\n\n\n\nIn this post, we summarize an approach that we have developed to speed up polygonal instance segmentation using machine learning. This approach was presented earlier this year at the CVPR Workshop on Scalability in Autonomous Driving, and the ICML Workshop on Human-in-the-Loop Learning.\n\nFew-Click Annotation\n\nBuilding instance segmentation Deep Learning (DL) models for autonomous vehicles requires a significant amount of labeled data. The use of Machine Learning (ML) for producing pre-annotations to be reviewed by human annotators, whether in an interactive setting or as a pre-processing procedure, is a very popular approach for scaling up labeling while controlling the costs.\n\nMultiple approaches have been suggested for machine-assisted instance segmentation. These typically consist of a DL-based segmentation of the object(s) integrated into a human-in-the-loop system. The human can interact with the system by correcting the model output, initializing the model with one or several clicks, or a combination of those steps. Examples of such systems include Polygon-RNN++ [1], DELSE [7], DEXTR [3], and CurveGCN [2]. Those systems all present good results, but some open questions remain:\n\nDo these methods perform well when a production-level accuracy is required, as when working for a customer project?\n\nDoes the choice of annotation tool influence the results? The gains to be made by using ML depend on how difficult it is for humans to draw polygons in the provided UI. Here we used our optimized drawing tool for polygons, which is part of our labeling platform.\n\nML integration is not usually approached from a human-centric perspective. Beyond the optimization of traditional metrics like IoU, what interactions are most desirable and how should we present the output of the model to annotators?\n\nOur method relies on combining the well-known DEXTR [3] approach with a raster-to-polygon algorithm, to make the result more easily editable. This is not unlike what other tools (such as CVAT) have implemented, though we have optimized this approach for our specific use cases using A/B testing.\n\nThe Model\n\nOur instance segmentation model is based on the well-known Deep Extreme Cut (DEXTR) approach [3], along with a raster-to-polygon conversion algorithm that yields high quality polygons whose vertices are sampled in a way that reproduces human drawing patterns. The model uses the few clicks provided by human annotators at inference time. The steps are described in Figure 2.\n\nFigure 2. An overview of the approach.\n\n\n\nRegarding the model itself, we adopted a custom version of the UNet [5] along with an EfficientNet backbone [6] (instead of the ResNet backbone used in the paper).\n\nIn our experience, for human annotators to produce good instance segmentation masks efficiently, a polygon annotation tool should be used. As such, we needed to convert the raster masks produced by our model to high quality polygons. To add to the challenge, humans tend to produce sparse polygons, adding vertices only when necessary. We therefore adopted a raster-to-polygon procedure that minimizes the number of output vertices.\n\nA/B Testing the Approach\n\nAt Sama, we use A/B testing as much as possible to systematically refine and improve our new features. To this end, we have developed a flexible testing infrastructure that can ingest and aggregate data from multiple internal processes and is made available to anyone within the organization.\n\nThis framework measures the statistical impact of proposed changes on our efficiency metrics (such as drawing time or shape adjustment time). The significance of observed differences on a given efficiency metric is evaluated using statistical tests.\n\nToy A/B Tests\n\nWe conducted an A/B test of the method using a synthetic automotive dataset called SYNTHIA-AL [8]. The dataset's images and corresponding annotations were generated from video streams at 25 frames per second (FPS). Figure 3 shows SYNTHIA image examples, along with their segmentation (done manually and with the Few-Click tool).\n\nFigure 3. SYNTHIA example images, along with their manual and semi-automated annotations.\n\n\n\nThe test, applied only to motor vehicles, reproduced realistic annotation guidelines, namely:\n\nThe drawn polygon needs to be within 2 pixels of the edge of the vehicle.\n\nAll vehicles down to 10 pixels (height or width) need to be annotated.\n\nFollowing this test, we found a nearly 3-fold reduction in annotation time. On the other hand, we also found that on some of the more complex shapes, annotators were spending quite some time manually adjusting the ML output. DEXTR's authors originally showed that the segmentation can be improved with additional clicks beyond the four initial ones. We therefore extended our few-click tool to allow online refinement of the polygons by considering modifications to their vertices as extra clicks. At train time we simulated the corrective clicks by considering the point of greatest deviation between predicted mask and ground truth as illustrated in Figure 4.\n\nProblem: DEXTR’s 4 extreme clicks are not always sufficient.\n\nObservation: DEXTR trained on 4 clicks benefits from additional clicks.\n\nSolution: Fine-tune DEXTR model with additional clicks for hard samples as established by IoU at train time.\n\nFigure 4. Integrating additional clicks in the training process.\n\n\n\nUsing this method, annotators are able to re-trigger the model inference with an additional click, instead of manually adjusting the output. We proceeded to a second toy A/B test, and results showed that we could obtain a theoretical efficiency gain of up to 3.5x on vehicles using the improved method.\n\nDownload our paper on Human-Centric Efficiency Improvements in Image Annotation for Autonomous Driving here and stay tuned to hear more about our latest advances!\n\n\n\nReferences\n\nAcuna, D., Ling, H., Kar, A., and Fidler, S. Efficient annotation of segmentation datasets with polygon-rnn++. In CVPR, 2018.\n\nLing, H., Gao, J., Kar, A., Chen, W., and Fidler, S. Fast interactive object annotation with curve-gcn. In CVPR, 2019.\n\nManinis, K.-K., Caelles, S., Pont-Tuset, J., and Van Gool, L. Deep extreme cut: From extreme points to object segmentation. In Computer Vision and Pattern Recognition (CVPR), 2018.\n\nPapadopoulos, D., Uijlings, J., Keller, F., and Ferrari, V. Extreme clicking for efficient object annotation. In ICCV, 2017.\n\nRonneberger, O., Fischer, P., and Brox, T. U-net: Convolutional networks for biomedical image segmentation. CoRR, abs/1505.04597, 2015. URL http://arxiv. org/abs/1505.04597.\n\nTan, M. and Le, Q. V. Efficientnet: Rethinking model scaling for convolutional neural networks. CoRR, abs/1905.11946, 2019. URL http://arxiv.org/ abs/1905.11946.\n\nWang, Z., Acuna, D., Ling, H., Kar, A., and Fidler, S. Object instance annotation with deep extreme level set evolution. In CVPR, 2019.\n\nZolfaghari Bengar, J., Gonzalez-Garcia, A., Villalonga, G., Raducanu, B., Aghdam, H. H., Mozerov, M., Lopez, A. M., and van de Weijer, J. Temporal coherence for active learning in videos. arXiv preprint arXiv:1908.11757, 2019.\n\nThis post was written by Frederic Ratle and Martine Bertrand.","slug":{"_type":"slug","current":"fast-vector-annotation"},"tags":[{"_key":"fJGSmFCx","label":"Vector Annotation","value":"Vector Annotation"},{"_key":"21OOfbwx","label":"Polygons","value":"Polygons"},{"_key":"SPABaoXN","label":"Sama Engineering","value":"Sama Engineering"},{"_key":"O5nmmFbm","label":"Featured","value":"Featured"}],"title":"Fast Vector Annotation with Machine Learning Assisted Annotation"},{"_createdAt":"2020-12-01T19:25:19Z","author":{"_id":"26fb3cc4-608d-40e1-bb4d-955bceda232a","avatar":{"_type":"image","asset":{"_ref":"image-e0fe681e594567792ac79048513fe955cc770f54-518x518-svg","_type":"reference"}},"bio":"From self-driving cars to smart hardware, Sama fuels AI. Founded over a decade ago, we’re experts in image, video and sensor data annotation and validation for machine learning algorithms in industries including automotive, navigation, AR/VR, biotech, agriculture, manufacturing, and e-commerce. Our staff are driven by a mission to expand opportunity for low-income people through the digital economy, and our social business model has helped over 50,000 people lift themselves out of poverty.","name":"Sama Team","slug":{"_type":"slug","current":"sama-team"}},"config":{"description":"Samasource is thrilled to announce that Wendy Gonzalez is our new Chief Executive Officer.","openGraphImage":null,"title":"Meet Our New CEO: Wendy Gonzalez"},"estimatedReadingTime":3,"featured_image":{"_type":"image","asset":{"_ref":"image-c30da58e631de99c9639604c9831763911b5860f-6240x3120-jpg","_type":"reference"}},"plaintextBody":"Today, the Sama Board of Directors, leadership team and employees are thrilled to announce that Wendy Gonzalez is our new Chief Executive Officer.\n\nHaving served as President and COO at Sama since 2018, Wendy stepped into the role of Interim CEO when our CEO and founder, Leila Janah, passed away in January of 2020 following a battle with epithelioid sarcoma.\n\nOver the past year, Wendy has successfully led the Sama team through the uncertainty of 2020 while achieving significant organizational milestones along the way. As a company, we’ve continued to develop our leading training data platform, including launching Machine Learning Assisted Annotation which has improved annotation efficiency by over 300% to regularly deliver quality SLAs between 96-99%.\n\nIn addition to recruiting an engineering workforce of more than 30% Ph.Ds., under Wendy’s leadership, Sama has achieved a three-year revenue growth of 134%, gaining recognition on the Inc. 5000 list as one of America's fastest-growing private companies.\n\nWendy has over two decades of managerial and technology leadership experience for companies including EY, Capgemini Consulting and Cycle30 (acquired by Arrow Electronics), and is an active Board Member of the Leila Janah Foundation. Wendy’s commitment to actualizing Leila's vision at Sama is unwavering.\n\n\"We have been determined to find the right person to carry forward Leila's vision and commitment to Sama, and that woman is Wendy,\" said Ben Metcalfe, Member of Sama's Board of Directors and Board Advisor at Ridge Ventures. \"Following a thorough recruitment process, we're certain that Wendy is the right person to lead Sama through this next stage.\"\n\nIn her new role, Wendy will drive the technology, innovation and growth that Leila began. As CEO, she becomes a part of a small group of female leaders within the male-dominated AI industry and will work not only to prioritize innovation but empower people around the world to be part of the growing AI economy.\n\nOver the years at Sama, Wendy has become a trusted mentor and thought leader. As a team, we look forward to being a part of her success.\n\nCongratulations, Wendy!\n\nRead more about the news in our press release here and follow Wendy on Twitter and LinkedIn to stay up-to-date on future company announcements.","slug":{"_type":"slug","current":"meet-our-new-ceo-wendy-gonzalez"},"tags":[{"_key":"PZYp5HYu","label":"Company News","value":"Company News"},{"_key":"Lx1s1Tlt","label":"Wendy Gonzalez","value":"Wendy Gonzalez"},{"_key":"BmcJBjt4","label":"Leila Janah","value":"Leila Janah"}],"title":"Meet Our New CEO: Wendy Gonzalez"},{"_createdAt":"2020-11-23T16:48:22Z","author":{"_id":"10ead718-57e1-41a8-b846-da3c81cc323a","avatar":{"_type":"image","asset":{"_ref":"image-a4c79da81bb1e23ce10fba84ea2cba5efe67a2a5-200x200-webp","_type":"reference"}},"bio":"Currently a Director of Product Management at Sama, Saul is passionate about the intersection of technology and social impact. He manages Sama’s data labelling products to ensure high quality training data efficiently and reliably reaches our customers. Experienced in both product and professional services, Saul is a proven leader who takes a data driven approach to expanding Sama’s capabilities and features. When not at work, you can usually find Saul enjoying the outdoors and spending time with his family.","name":"Saul Miller","slug":{"_type":"slug","current":"saul-miller"}},"config":{"description":"Announcing our support for custom keypoint shapes in SamaHub, our training data platform trusted by the world's leading AI teams, for vector image and video annotation.","openGraphImage":null,"title":"Custom Keypoint Shapes for Vector Image & Video Annotation"},"estimatedReadingTime":3,"featured_image":{"_type":"image","asset":{"_ref":"image-0ea3313b4d00bb103e8441964eeb3968dfee2947-1144x644-png","_type":"reference"}},"plaintextBody":"As a leader in high-quality training data, Sama supports clients across various use cases and applications. The ability to identify specific keypoint landmarks and track their relationship to one another is unlocking some of the most interesting developments in computer vision technology. This includes motion tracking like human pose identification for virtual fitness trainers or sports analytics. It also includes facial landmarks for emotion analysis, facial verification security, or driver alertness detection. It could also include hand gesture control for AR/VR or sign language transcription.\n\nWe are thrilled to announce our support for custom keypoint shapes in our training data platform trusted by the world's leading AI teams, for vector image and video annotation. While Sama has long supported other vector shapes like bounding boxes, polygons, and cuboids, these keypoint use cases require custom shapes that have a predefined number and order of points. Sama can now be configured to support skeletons, hands, eyelids or any other complex custom shape. Each keypoint can have its own label, color, and connection to other points. Multiple keypoint shapes are supported on the same annotation project.\n\n\nOptimizing for Quality and Efficiency\n\nThis new capability optimizes quality and efficiency in producing ground truth training data for our clients. Our expert annotators have a facilitated drawing experience where the shape builds itself as they annotate each point. The correct label for each point is inferred from the order that it is placed so no extra time is spent assigning labels to each point. We see quality improvement from visualizing the annotations as a cohesive connected shape instead of as free standing individual points. The custom keypoint shape also always has the same number and order of points—this means that no points could ever be omitted or mislabeled. In addition to the quality benefits, our A/B testing showed an 27% decrease in annotation time on a skeleton image annotation workflow over individual points.\n\nCompleted annotation data is returned to our clients in a structured delivery format that contains information about each point, its relative order in the array and its connection to other points.\n\nIf you're currently working on a computer vision algorithm that requires high quality keypoint annotations on images or videos, make sure to read more on our platform page or get in touch with an expert to discuss your training data needs.","slug":{"_type":"slug","current":"custom-keypoint-shapes"},"tags":[{"_key":"T7HkzkJx","label":"Product","value":"Product"},{"_key":"j9XlG6o5","label":"Keypoints","value":"Keypoints"},{"_key":"o2UoWoaC","label":"Video Annotation","value":"Video Annotation"},{"_key":"3GbpMBcq","label":"Vector Annotation","value":"Vector Annotation"}],"title":"Custom Keypoint Shapes for Vector Image & Video Annotation"},{"_createdAt":"2020-11-18T19:05:07Z","author":{"_id":"88e43c38-2712-41d4-9df3-8656c163c4db","avatar":{"_type":"image","asset":{"_ref":"image-af1346669e45d7264a36f051c18aea76061725bb-1895x1894-webp","_type":"reference"}},"bio":"Kyra is passionate about world-changing tech and sustainability, and happiest when these come together (looking at you, Sama). Stereotypical Dutch, she enjoys urban cycling and eating stroopwafels.","name":"Kyra Harrington","slug":{"_type":"slug","current":"kyra-harrington"}},"config":{"description":"12 Influential Women Working in Machine Learning, 2020.","openGraphImage":null,"title":"12 Women in Machine Learning to Watch"},"estimatedReadingTime":9,"featured_image":{"_type":"image","asset":{"_ref":"image-3651ed4b3fa5305116eb19a08c7ca1ac4b1ce130-900x506-png","_type":"reference"}},"plaintextBody":"Global spend on AI is predicted to be $98 Billion by 2023, up from 37.5 Billion in 2019. Maybe not unexpected for those witnessing it up close, but a whopping growth trajectory nonetheless. While machine learning models strive to mirror and predict real life as closely as possible, the people behind these models don't represent the real world. Despite this rapid forecasted growth, women still only make up a 12% of the ML workforce.\n\nAt Sama we believe in inclusive AI that benefits everyone, and believe highlighting role models is a key part in this work. With that in mind, we put together a celebratory list of some of the women we look up to and have spearheaded development in AI and Machine Learning in 2020. While it was near impossible to narrow down our list, we highly encourage you to connect with them and follow their incredible work going into 2021.\n\n\n\nFeryal Behbahani, Research Scientist, DeepMind\n\nFeryal obtained her BEng from Heron-Watt University in 2006, later going on to receive her MSc in Artificial Intelligence and Doctor of Philosophy in Machine Learning from Imperial College London. Post graduation, Feryal worked as a mentor at OpenAI and as a Research Scientist for Latent Logic (now Waymo). In 2019, Feryal started working as a Research Scientist at DeepMind, alongside volunteering at the Women in Machine Learning initiative as a director. Freyal’s work is currently focussed on Reinforcement Learning.\n\n\n\nMartine Bertrand, Lead AI, Sama\n\nThe desire to understand the universe led Martine to study physics at the University of Ottawa where she ultimately completed a Ph.D. in 2012. She then held Post-Doctoral Fellowships at the University of Carleton and her alma mater before undertaking a career as an industrial Research Scientist. She tackled challenges in computational chemistry at the Chemical Computing Group, natural language processing at Stradigi AI, and medical imaging at Imagia before joining Sama as Lead AI where she now steers ML R&D efforts and guides the development of the MLOps infrastructure.\n\n\n\nJenny Sy, Data Scientist, USA for UNHCR\n\nCurrently working as a Data Scientist at the UNHCR, an organization which protects refugees and empowers them with hope and opportunity, Jenny is focussed on building the organizations analytics database, developing key department metrics, conducting research and more. Jenny obtained her B.Sc from Ateneo de Manila University and her MBA in Business Administration from China Europe International Business School. Alongside working at UNHCR, Jenny also volunteers as a Treasurer for the Women in Machine Learning organization, supporting Women in STEM fields.\n\n\n\nJulia Kroll, Data & ML Engineer, Amazon\n\nJulia Kroll is a Data and ML Engineer at Amazon, currently advising engineers at enterprise companies on migrating to and innovating with the AWS cloud. Julia also works on implement performant, scalable, and secure solutions on AWS, specializing in big data, analytics, and machine learning applications. Julia has also worked as a Data Engineer at Alexa artificial intelligence, following her role as a software engineer at HubSpot.\n\n\n\nKallirroi Dogani, Machine Learning Engineer, Facebook\n\nEarlier this year, Facebook gained a brilliant Machine Learning engineer in Kallirroi Dogani. Having previously worked as a ML Scientist at ASOS and Data Scientist at Tractable and Workable. Kallirroi obtained her second MSC in Artificial Intelligence from the University of Leuven, having received her first a year earlier from the University of Athens in Advanced Information Systems.\n\n\n\nLucy Wang, Machine Learning Engineer, Twitter\n\nCurrently working as a Machine Learning Engineer at Twitter, Lucy is focussed on the use of Machine Learning in Healthcare. Lucy previously held positions of Staff and Senior Data Scientist as Buzzfeed having earlier graduated from Columbia Engineering with an M.S in Computer Science. Aside from ML, Lucy holds interests in Natural Language Processing and Deep Learning.\n\n\n\nTobi Bosede, Founder & CEO, Ilekun Health\n\nTobi obtained a BA in Mathematics from the University of Pennsylvania and MSE from John Hopkins University in Applied Mathematics and Statistics before beginning her career as a Software Engineer at JPMorgan Chase. In the years since, Tobi has held positions as a Data Scientist at Sprint, Researcher at John Hopkins University and Lead in ML at Capital One, all prior to becoming the founder of Ilekun Health, a smart technology company in the healthcare space. Ilekun Health is a technology company that gleans insight around provider quality, services offered, and price from a complex deluge of unstructured health data using artificial intelligence (AI)—currently raising initial pre-seed.\n\n\n\nTian Su, Director of Machine Learning, Walmart\n\nAs an experienced Data Scientist, Tian is currently working as Director of ML at Walmart. Having previously held positions of Senior Data Scientist & Head of AI/ML at 7-Eleven, Tian has been heavily focussed on personalization and delivery for customers in the CPG market. Dr Tian holds considerable experience and skill in Advanced Analytics, Data Mining, Statistical Modeling, Machine Learning, Databases and Artificial Intelligence. She also boasts a strong research background with a Ph.D. from Yale University and Master’s Degree focused on Computer Science from Georgia Institute of Technology.\n\n\n\nNicole Barberis, Machine Learning & Quantum ML, IBM\n\nNicole currently works as a Deep Learning and Quantum ML Developer for IBM in the US, aiding in the development of IBMs python solution. Nicole is a big believer in doing quantum machine learning (QML) research as she states this evolving field will eventually complement your modern suite of analytics solutions (machine learning, deep learning, etc.) Nicole worked at IBM for nine years as a Data Scientist and Information Security Analyst, before landing at her current position after two years at Bloomberg as a Data Scientist. Nicole received her MS in Applied Statistics from the University of Wyoming.\n\n\n\nSaeedeh Salimianrizi, Applied ML Scientist, Amazon\n\nHaving held several data science positions at companies including Verisk Analytics, Simarian and Farmers insurance, Saeedeh currently works as an Applied ML Scientist at Amazon in San Francisco. For the past two years, Saeedeh has been improving Amazon’s augmented reality pipeline acceptance rate using CNNs as well as building a CNN-based solution with 95% accuracy, eliminating the need for manual data annotation for shoe vendors. Saeedeh received her MSc in Systems Engineering from Boston University having also studied Industrial Engineering at the University of Tehran.\n\n\n\nQian (Wendy) Xiong, Machine Learning Engineer, Google\n\nAfter achieving a 3.95 GPA in her Statistics PhD, Qian stayed at the University of Colorado State for five years, first as a statistical consultant and latest a graduate teaching assistant. In 2018, Qian moved out of the educational setting altogether, starting as a Data Scientist/ML Engineer at the Expedia Group, working on conversational AI to provide intelligent and personalized automatic customer service. Having spent 18 months at Expedia, Qian moved to Google in April of this year. Qian is Proficient in Python (tensorflow/keras/pandas/scikit-learn/numpy), AWS, Linux, R and SQL. Hands-on Big Data experience with Spark.\n\n\n\nGalina Malovichko, PhD, Applied Machine Learning Scientist, Lyft\n\nGalina obtained her PhD from UC Davis in Condensed Matter and Material Physics, having previously received an MS in Physics from the Moscow Institute of Physics and Technology. Whilst studying, Galina worked as a PhD Student Researcher and Teaching Assistant, later moving to Lyft in 2018. Initially working as a Data Scientist analyzing new features for machine learning models, predicting Lyft rides ETA, Galina later moved on to be an Applied ML Scientist, a position she has held for the last two and a half years. In her current role, Galina has built an ML stack to predict travel times, built traffic detection models and more.","slug":{"_type":"slug","current":"12-women-in-machine-learning-to-watch"},"tags":[{"_key":"Fysfdyt0","label":"Machine Learning","value":"Machine Learning"},{"_key":"nnpdrksh","label":"Best of","value":"Best of"},{"_key":"2MmoF9VK","label":"Women in AI","value":"Women in AI"}],"title":"12 Women in Machine Learning to Watch"},{"_createdAt":"2020-11-16T23:15:17Z","author":{"_id":"f972de8a-10c1-45e3-97c9-ac490eaceabe","avatar":{"_type":"image","asset":{"_ref":"image-4aa17073cfd70d2e8f7d8ed85325c14cb1519577-692x691-jpg","_type":"reference"}},"bio":"Loic has over 20 years of industry experience in the Cloud services and AI industry. At Sama he works as the VP of Research & Development. His experience includes Fortune 500 Companies such as Salesforce.com, Unity Technologies, and AT&T where he led the development of large scale AI, data analytics, and cloud solutions. Loic received his MS in computer science from UTBM, France.","name":"Loic Juillard","slug":{"_type":"slug","current":"loic-juillard"}},"config":{"description":"Sama was a partner of the McGill Engineering Hackathon, the largest annual hackathon run by the McGill Electrical, Computer, and Software Engineering StudentÃƒÂ¢Ã¢â€šÂ¬Ã¢â€žÂ¢ Society.","openGraphImage":null,"title":"Code.Jam(2020)-McGill Hackathon: and the winner is A Virtual Fitting Room"},"estimatedReadingTime":3,"featured_image":{"_type":"image","asset":{"_ref":"image-8b71517603a306e0f80ea070e3d0d532f0039105-1024x512-png","_type":"reference"}},"plaintextBody":"For the second consecutive year, Sama was a Terabyte partner of the McGill Engineering Hackathon, the largest annual hackathon run by the McGill Electrical, Computer, and Software Engineering Student’ Society. This as part of our close partnership with McGill University and the broader Montreal Machine learning Technology community.\n\nIn this year defined by COVID-19, the CodeJam team opted for the very fitting “Digital by Default” theme. Staying on topic, we proposed our very own challenge with an “Online Retail and Shopping Smart App”, wherein students would get to interact with a custom fashion segmentation API trained on our iMaterialist open dataset.\n\nThe participation was incredible! Out of 27 teams, 9 tackled our challenge. The submissions were split into two categories:\n\nRecommendation Engine: “I have seen someone wear this, where can I find it?”\n\nThe Virtual Fitting Room: “How would this look on me”\n\nMost recommendation approaches involved extracting one or multiple pieces of clothing using the segmentation API and querying an image repository for similar items. The models were producing good recommendations when the piece of clothing was well defined. Results were less accurate when the quality of the source image segmentation was approximate. A number of factors such as the type of clothes, occlusion (hair, jewelry, etc.), and ambient picture attributes affect segmentation and produce an approximate product match.\n\n\n\nMy Wardrobe\n\nTeam “GradientBoys” took on the task of virtually showing clothes on a subject, a virtual fitting room of sort. They implemented a complex pipeline that involved segmenting the subject picture (person looking to try the clothes), extracting the style of clothing mask, and segmenting the article of clothing from the library. This was followed by clever usage of the OpenPose model for keypoint identification that allowed to extract a set of local and global distortions to modify the new piece of clothing to fit the subject. Completely taking the in-person shopping experience out of the equation, trying on clothes has never been this smart. Perhaps even more impressive considering it was built in less than 36 hours.\n\nAwesome work, team GradientBoys, and thank you McGill, and all of CodeJam Student Execs for organizing this amazing event. Looking forward to the years to come!","slug":{"_type":"slug","current":"codejam-2020-mcgill-hackathon"},"tags":[{"_key":"Fd3ZhNBx","label":"Sama Engineering","value":"Sama Engineering"},{"_key":"3M2wKXav","label":"Events","value":"Events"}],"title":"Code.Jam(2020)-McGill Hackathon: and the winner is A Virtual Fitting Room"},{"_createdAt":"2020-09-24T16:19:34Z","author":{"_id":"80db3356-b402-44cb-a717-2e0f9c9fa3e4","avatar":{"_type":"image","asset":{"_ref":"image-399295e959574e371fe2ba7bfd55ba4aee8a589d-320x320-jpg","_type":"reference"}},"bio":"Heather is passionate about bringing world-changing technologies to market and using supply chain purchasing power for good. She is a data-driven strategist experienced in developing and leading go-to-market, communications, and sustainability initiatives at start-ups and multi-national organizations. Heather is most happy when she’s growing companies that make a positive impact, enjoying the outdoors, and spending time with her family.","name":"Heather Gadonniex","slug":{"_type":"slug","current":"heather-gadonniex"}},"config":{"description":"We're humbled and honored to announce that, as of today, Sama is the first AI company to receive the prestigious B Corp certification.","openGraphImage":null,"title":"From Dreams to Reality: Our Journey to Becoming a Certified B Corporation"},"estimatedReadingTime":4,"featured_image":{"_type":"image","asset":{"_ref":"image-2277f59b40f900b74161027781351788ae996308-2132x1066-jpg","_type":"reference"}},"plaintextBody":"I’ll never forget the first time I met Leila Janah. She was interviewing me and spoke excitedly about the potential of Sama achieving B Corp certification, one of her main priorities for the company. In the next breath, she talked about dominating the training data industry and catapulting Sama to claim its much-earned spot in the AI landscape.\n\nThis introduction was just the first of many conversations we would later have on the importance of sustainability, impact, and responsible hyper-growth.\n\nI’m deeply humbled and honored to announce that, as of today, Sama is among the first AI companies to receive the prestigious B Corp certification. The achievement comes on the heels of completing our three-year Randomized Control Trial (RCT), which demonstrated the actualized impact of our hybrid model and continued commitment to fusing purpose and profit, both internally and externally.\n\n\n\n“This achievement is the result of years of hard work and dedication from our entire Sama community. By securing B Corp certification and completing our RCT, we’re not only carrying Leila’s passion and commitment to impact, but we’re making a tremendous stride within the AI industry,” says Wendy Gonzalez, CEO of Sama. “I’d like to extend immense thanks to everyone who played a part in making Leila’s dream a reality.”\n\n\n\nB Corp certification is a measurement certified by B Lab, a non-profit company that measures a company’s social and environmental performance. We received a score of 98.5, excelling in the ‘Workers' and 'Community Impact' criteria, and placing us well above the 80 points necessary to achieve B Corporation status. Of the 3,500+ Certified B Corporations, Sama is the first and only AI company recognized and joins companies such as WeTransfer, Patagonia, Hootsuite, and Ben & Jerry’s, all who use business as a force for good.\n\nThree years ago, Leila kicked off what would become a rigorous journey towards completing a full RCT. This in-depth trial, often referred to as the \"gold standard\" in research, evaluated our training and employment effectiveness towards our mission of creating a sustainable pathway out of poverty. It studied three groups of individuals from similar socioeconomic backgrounds that were randomly assigned to receive either training through Sama (Group 1), training and the opportunity for employment at Sama (Group 2), or neither training nor the opportunity for employment (Control Group).\n\nOne of the trial’s main findings is that individuals who are trained and employed by Sama make higher levels of employment and earnings (Group 2). This study and subsequent completion of the RCT further validated the training programs we’ve created at Sama, an impact model that has helped 50,000 people lift themselves out of poverty, increased wages by 4x, and provided over 11,000 hours of training. \n\nBecoming B Corp certified and completing an RCT in tandem is a direct example of how our team at Sama is leveraging AI to address critical societal issues. This year has proved that making a real impact and having a mission-driven business model is what truly matters in driving the bottom line. We believe that receiving B Corp certification should be the new metric companies strive for in today’s day and age. It’s not just about chasing after unicorn status anymore, it’s about creating a successful company while creating meaningful change. \n\nWe’ve accomplished our goals in large part as a result of our supportive community, but it doesn’t stop here. We’re looking forward to continuing our commitment to making a lasting impact on the world and improving the lives of as many as possible.\n\nDue to our hardworking team and our supportive investors, friends and family, we’ve been able to follow through on the vision and legacy created by our founder, Leila Janah.\n\nOn behalf of the entire Sama team, thanks for taking this journey with us.","slug":{"_type":"slug","current":"we-are-a-b-corp"},"tags":[{"_key":"hZTYAcKb","label":"Company News","value":"Company News"},{"_key":"DDJ2bEmS","label":"Ethical AI","value":"Ethical AI"},{"_key":"oKWZS5Lg","label":"Impact","value":"Impact"},{"_key":"AuzJCOHb","label":"Leila Janah","value":"Leila Janah"}],"title":"From Dreams to Reality: Our Journey to Becoming a Certified B Corporation"},{"_createdAt":"2020-09-04T15:25:34Z","author":{"_id":"88e43c38-2712-41d4-9df3-8656c163c4db","avatar":{"_type":"image","asset":{"_ref":"image-af1346669e45d7264a36f051c18aea76061725bb-1895x1894-webp","_type":"reference"}},"bio":"Kyra is passionate about world-changing tech and sustainability, and happiest when these come together (looking at you, Sama). Stereotypical Dutch, she enjoys urban cycling and eating stroopwafels.","name":"Kyra Harrington","slug":{"_type":"slug","current":"kyra-harrington"}},"config":{"description":"AI is often framed as something that’ll change our future, but many people aren’t aware of quite the extent to which AI currently used in society and everyday life. ","openGraphImage":null,"title":"5 Examples of AI You Didn't Know You Used"},"estimatedReadingTime":6,"featured_image":{"_type":"image","asset":{"_ref":"image-db6c1732497afdfb78c26af05cbd6a1641fe3258-2132x1066-png","_type":"reference"}},"plaintextBody":"AI is often framed as something that’ll change our future, but many people aren’t aware of quite the extent to which AI already used in society and everyday life. While it’s important to recognize that AI is still very much in its infancy in regard to large-scale change, there have been incremental advancements in recent years, which have somewhat gone under the radar for those not regularly perusing the latest AI news or working in said fields. To explore just how prevalent AI is in our everyday lives, we have collected five spaces in which AI is shaping consumer behavior and practices.\n\n1. Netflix\nThe entire catalogue of movies and shows at Netflix is ranked, customized and ordered for each individual user in a personalized manner using Machine Learning (yes, you can blame your roommate for messing up the algorithms and data). Through the use of Machine Learning, Netflix is able to forecast, and facilitate your next series binge with five key stages to their recommendation model: ranking & layout, similarities, evidence and search, model improvement and exploit learning. In short, Netflix uses customer engagement to find similarities and patterns in your watching data, alongside the categories you most often visit and even the artwork to which you’re drawn to. These hypotheses are then A/B tested for accuracy and developed to enhance user experience.\n\n2. Virtual Assistants\nOk, so this may seem like an obvious inclusion on this list, but many often don’t realize what it is that really helps to power Siri, Cortana and their industry colleagues. The seemingly simple command to action transaction is not as simple as it seems, with mere short sentences going through a variety of processes including recognition of wake words, speech processing, natural language understanding, text-to-speech and more. Many will remember that the initial virtual assistant offerings would often have many misspelled words, as well as an inability to understand the message and the obvious struggles with accents. However, projections for virtual assistants suggest that the already 20% voice search KPI on phones is set to increase, alongside adoption of VA into greater devices including cars and wearables. With the gradual implementation of VA into personal devices, it’s easy to overlook how far they have actually come!\n\n3. Online Shopping\nAI being used in e-commerce and online shopping is suggested to reach revenues of over $30 billion by 2025, which poses the question: how is it being implemented? Well, prediction of customer behavior is a crucial aspect of its success, auto-populating websites through algorithms made up of history, third party data, content data and other information to offer the necessary reference to the user. Alongside these examples, AI is also being used in the collection of data from consumers, listening to feedback, automation of review emails and product suggestions for retargeting. Alongside personalization and product recommendation, e-commerce retailers are now utilizing chatbots to provide 24/7 assistance, made possible through the development of self-learning capabilities and NLP. Interested in reading more? Check out our E-Commerce Guide.\n\n4. Education\nThere have been many early applications of AI in education, including, but not limited to grading, plagiarism detection, personalization and more. Recent developments in Machine Learning have seen companies like Gradescope using AI to develop assisted grouping techniques of handwritten answers from students. These groupings work on a points-based rubric allowing for accurate marking in seconds, which in-turn, can free up time for teachers and allows for greater lesson planning time, to name but a few benefits. Current AI algorithms are also being used to assist in the fight against plagiarism. Tools including Turnitin are using AI to locate copied sentences, structuring and other stylometrics alongside monitoring the creation and moderation dates of work. The future of AI in education, according to many, lies in the development of heavily tailored courses and classes for students with specific needs, which may not be as far off as you’d think with education startups receiving over 20 billion dollars worth of funding by the end of 2018.\n\n5. Ride Sharing\nRidesharing apps have been reported to use a variety of algorithms both for the benefit of the customers and organizations. It was only as recent as 2017 that Uber had admitted to adapting their pricing for rides based on customer data collected on socioeconomic factors of users. Seen as one of the first major adopters of AI, services like Uber have suggested that AI is central to almost every aspect of their business including fraud detection, risk assessment, safety processes, marketing spend and allocation, matching drivers and riders, route optimization and more. Ridesharing apps also use personal data in an anonymized and aggregated form to closely monitor which features of the service are used most. Through this, Uber and their competitors are able to analyze usage patterns and to determine where they should further focus developments.\n\nThese subtle implementations of AI across industries and in businesses may come as a surprise, but we have no doubt that over the next few years, AI adoption will not only become widespread, but increasingly publicized.","slug":{"_type":"slug","current":"ai-you-didnt-know-you-used"},"tags":[{"_key":"uZeu8hE2","label":"AI","value":"AI"},{"_key":"oYVzsLww","label":"Best of","value":"Best of"}],"title":"5 Examples of AI You Didn't Know You Used"},{"_createdAt":"2020-08-26T18:18:07Z","author":{"_id":"80db3356-b402-44cb-a717-2e0f9c9fa3e4","avatar":{"_type":"image","asset":{"_ref":"image-399295e959574e371fe2ba7bfd55ba4aee8a589d-320x320-jpg","_type":"reference"}},"bio":"Heather is passionate about bringing world-changing technologies to market and using supply chain purchasing power for good. She is a data-driven strategist experienced in developing and leading go-to-market, communications, and sustainability initiatives at start-ups and multi-national organizations. Heather is most happy when she’s growing companies that make a positive impact, enjoying the outdoors, and spending time with her family.","name":"Heather Gadonniex","slug":{"_type":"slug","current":"heather-gadonniex"}},"config":{"description":"Through our work with Vulcan, we have been awarded the winner of the 2020 AI Breakthrough Awards for the Best Image Processing Solution.","openGraphImage":null,"title":"Sama Wins 2020 Artificial Intelligence Breakthrough Award for Best Image Processing Solution"},"estimatedReadingTime":3,"featured_image":{"_type":"image","asset":{"_ref":"image-10bbf2e602804aa2ffe6104a315daa9713a53334-2000x1000-png","_type":"reference"}},"plaintextBody":"As the leading company providing high-quality training data and model validation software and solutions to more than 25% of the Fortune 50, we have always taken pride in our ability to ensure smart AI starts with quality data. Without high-quality, diverse and accurate data sets, AI just doesn’t work.\n\nToday, we are honored to announce that through our work with Vulcan, we have been awarded the winner of the 2020 AI Breakthrough Awards for the Best Image Processing Solution. \n\n“In one of the toughest years yet, our team has consistently prevailed and furthered our mission of providing high-quality data for some of the world’s largest tech companies,” says Wendy Gonzalez, Interim CEO of Sama. “It’s because of their persistence and dedication that we have the opportunity to celebrate this win among many others this year. We’re thankful for this recognition and are inspired to continue our work in driving AI forward.”\n\nIn 2019, the UN reported that nature is declining globally at rates unprecedented in human history. We are causing a devastating impact on global biodiversity, with nearly one million animal and plant species threatened by extinction. In an effort to mitigate this, our expert annotators applied our technology to advance AI algorithms, powering one of the leading wildlife conservation efforts with Vulcan, a project and investment company that uses data to make a positive impact on endangered species, climate change, ocean health, and more.\n\nThrough our work with Vulcan, we were able to address the current threat of wildlife trafficking while collecting data that will inform long-term strategies to protect endangered species and ensure stable and thriving generations. Through our technology, Vulcan has significantly improved its turnaround times to process training data, allowing algorithms to thrive without compromising on quality. To date, we have labeled nearly one million images for Vulcan, achieving above industry-standard quality SLA of 95% in support of their efforts. Together, we are combating large-scale poaching that contributes to extinction, while supporting a more sustainable ecosystem through image processing solutions.\n\nThe annual awards program honors AI excellence, innovation and success in a range of AI and machine learning related categories, including AI and Machine Learning Platforms, Smart Robotics, Business Intelligence and Analytics, Natural Language Processing, industry-specific AI applications and many more. This year they saw over 2,000 nominations globally.\n\nWe’re honored to have our work with Vulcan recognized by this prestigious program and are inspired to continue working towards our mission every day.\n\nCheck out the complete list of AI Breakthrough Award winners here: https://aibreakthroughawards.com/2020-winners/ ","slug":{"_type":"slug","current":"artificial-intelligence-breakthrough-award"},"tags":[{"_key":"Z4dKhKCG","label":"Company News","value":"Company News"},{"_key":"r9kvSdJK","label":"Ethical AI","value":"Ethical AI"},{"_key":"rU8MHfKu","label":"Awards","value":"Awards"},{"_key":"uy3WXjRk","label":"Use Cases","value":"Use Cases"},{"_key":"0Qr5y568","label":"Data Quality","value":"Data Quality"}],"title":"Sama Wins 2020 Artificial Intelligence Breakthrough Award for Best Image Processing Solution"},{"_createdAt":"2020-08-24T22:30:00Z","author":{"_id":"26fb3cc4-608d-40e1-bb4d-955bceda232a","avatar":{"_type":"image","asset":{"_ref":"image-e0fe681e594567792ac79048513fe955cc770f54-518x518-svg","_type":"reference"}},"bio":"From self-driving cars to smart hardware, Sama fuels AI. Founded over a decade ago, we’re experts in image, video and sensor data annotation and validation for machine learning algorithms in industries including automotive, navigation, AR/VR, biotech, agriculture, manufacturing, and e-commerce. Our staff are driven by a mission to expand opportunity for low-income people through the digital economy, and our social business model has helped over 50,000 people lift themselves out of poverty.","name":"Sama Team","slug":{"_type":"slug","current":"sama-team"}},"config":{"description":"Samasource Honored on Inc. Magazine’s Annual List of America’s Fastest-Growing Private Companies—the Inc. 5000","openGraphImage":null,"title":"We made the Inc. 5000 list!"},"estimatedReadingTime":2,"featured_image":{"_type":"image","asset":{"_ref":"image-0434b713b7dcba1cdf98eff0eb50d7cb3d5fb008-1500x908-jpg","_type":"reference"}},"plaintextBody":"What! We're honored and excited to share that we've made Inc. Magazine’s Annual List of America’s Fastest-Growing Private Companies, the most prestigious ranking of the nation’s fastest-growing private companies, coming in at No. 2952.\n\n“We’re honored to have been recognized by Inc. as one of the fastest-growing private companies in the US,” said Wendy Gonzalez, President and Interim CEO of Sama. “While this year has been challenging in many ways, it has been a year of growth for AI technologies and the high-quality data that powers them. This recognition is a testament to the hard work and dedication our team has demonstrated throughout the last decade. I’m proud of how far we’ve come and look forward to the advancements that lie ahead.”\n\nNot only have the companies on the 2020 Inc. 5000 been very competitive within their markets, but the list as a whole shows staggering growth compared with prior lists as well. The 2020 Inc. 5000 achieved an incredible three-year average growth of over 500 percent, and a median rate of 165 percent. The Inc. 5000’s aggregate revenue was $209 billion in 2019, accounting for over 1 million jobs over the past three years.\n\n“The companies on this year’s Inc. 5000 come from nearly every realm of business,” says Inc. editor-in-chief Scott Omelianuk. “From health and software to media and hospitality, the 2020 list proves that no matter the sector, incredible growth is based on the foundations of tenacity and opportunism.”\n\nWhat a great way to take stock of business and continue our journey together with renewed ambitions.\n\nComplete results of the Inc. 5000, including company profiles and an interactive database that can be sorted by industry, region, and other criteria, can be found here.","slug":{"_type":"slug","current":"we-made-the-inc.-5000-list"},"tags":[{"_key":"G24pVOQf","label":"Company News","value":"Company News"},{"_key":"96XHFEEw","label":"Awards","value":"Awards"}],"title":"We made the Inc. 5000 list!"},{"_createdAt":"2020-07-17T18:31:06Z","author":{"_id":"88e43c38-2712-41d4-9df3-8656c163c4db","avatar":{"_type":"image","asset":{"_ref":"image-af1346669e45d7264a36f051c18aea76061725bb-1895x1894-webp","_type":"reference"}},"bio":"Kyra is passionate about world-changing tech and sustainability, and happiest when these come together (looking at you, Sama). Stereotypical Dutch, she enjoys urban cycling and eating stroopwafels.","name":"Kyra Harrington","slug":{"_type":"slug","current":"kyra-harrington"}},"config":{"description":"From accidental Alexa purchasing to bias in recruitment, we have gathered 5 AI fails from the last few years.","openGraphImage":null,"title":"The Training Data Challenge: 5 AI Fails"},"estimatedReadingTime":4,"featured_image":{"_type":"image","asset":{"_ref":"image-9e345dfd7e3354b64d6ad3e61e5b723a0650a32c-1200x628-jpg","_type":"reference"}},"plaintextBody":"AI is often hailed as the ‘next big thing’ and an answer to all of our problems. We’re certainly betting on it: global spend on AI is predicted to be a whopping $98 Billion by 2023, up from 37.5 Billion in 2019. But we’re still in the early days when it comes to fulfilling the promise of AI and one of the reasons is training data—the annotated data a machine needs to learn to see or hear. Training data is essential to the development of any machine learning model. A global survey of Data Scientists, AI Experts and Stakeholders revealed that 8 out of 10 AI projects fail and 96% run into problems with data quality and labeling. \n\nEven applications now leading the scene have had their fair share of mishaps along the way. We’ve listed some examples of when AI might not have been performing at its best.\n\n\n\n1. The Somewhat Vulgar Virtual Assistant\n\nIt only took 24 hours for Tay, Microsoft's new conversational understanding chatbot, to start tweeting some extremely insensitive and offensive material online. The initial idea was to have Tay learn through ‘casual conversation’ with fellow Twitter users, which perhaps, at that time, was too far-fetched. While a majority of the 100k+ tweets were not considered to be eyebrow-raising, a selection of mimicking and extremely offensive posts saw Tay taken down after just one day. Unfortunately, the follow-up chatbot, ‘Zo’ resulted in the same fate, albeit after five months of live interaction.\n\n\n\n2. IBM Watson for Oncology\n\nMany see AI as the future of medicine, but it’s been suggested that IBMs Watson for Oncology initially over-promised and underdelivered with misdiagnosis, incorrect drug treatment offerings and unsafe judgement calls on patients. While there was and still is promise, the current ‘messy’ state of healthcare systems and mismatch between both the working and learning styles of doctors and machines became evident. Watson Oncology, however, continues to improve, with memory banks of every rare disease, increasing knowledge and a lack of cognitive bias potentially held by long serving medical professionals.\n\n\n\n3. Amazon AI Bias Recruitment\n\nNow scrapped, the once used AI recruiting tool from Amazon was found to be perpetuating the gender gap in tech jobs. The initial hope for a perfect filtration system for the top applications, was soon found to host significant bias towards hiring men due to being trained on resumes submitted in previous years—which were predominantly from male applicants. The use of historical data which facilitated existing bias has seen great advancements in regard to hiring diverse talent, but continues to have a long road ahead.\n\n\n\n4. Purchasing on Alexa\n\nResearch suggests that by 2023 over eight billion voice assistants will be present in consumers' lives. We predict many of these will be subject of, or susceptible to, some humorous moments while in development. We have seen doll houses ordered through ads on television (oops!), parrots casually chatting with Alexa, hacking issues, and all sorts. There is no doubt that the virtual assistant has further developed to a more accurate level since, but we’re excited for the future of viral YouTube videos to come.\n\n\n\n5. Insurance company uses social media data to issue rates, shows bias\n\nAdmiral Insurance, a popular company for first-time drivers, aimed to embed AI to analyse the Facebook data of those applying for insurance as they claimed there was a ‘proven link’ between personality and their driving style or ability. Facebook was quick to stop any advancements in this due to underlying ethical concerns, data privacy and potential bias of models.\n\nWhile AI carries a lot of promise, it also carries a lot of hype. When it comes to AI, your model is only as good as the data it’s trained on, because here applies: garbage in, garbage out.","slug":{"_type":"slug","current":"the-training-data-challenge-5-ai-fails"},"tags":[{"_key":"3firrVWY","label":"AI","value":"AI"},{"_key":"93GN7laV","label":"Best of","value":"Best of"},{"_key":"WeyhHs1O","label":"Data Quality","value":"Data Quality"}],"title":"The Training Data Challenge: 5 AI Fails"},{"_createdAt":"2020-06-29T19:47:48Z","author":{"_id":"1a59f036-e3fe-4f02-9a34-688ce45de143","avatar":{"_type":"image","asset":{"_ref":"image-7d8f236ba010dd4927d0c5a93368bdce1f712843-390x390-webp","_type":"reference"}},"bio":"Currently a Project Manager at Sama, Taylor Rouleau has a passion for ensuring ethical and sustainable practices in tech. After 5 years leading production teams for our customers, Taylor's expertise is applied internally in our Project Management Office. She heads up efforts to maintain our industry-leading data training processes with a special focus on Security & Compliance.","name":"Taylor Rouleau","slug":{"_type":"slug","current":"taylor-rouleau"}},"config":{"description":"We explain the various types of machine learning algorithms including supervised, unsupervised and reinforcement learning, as well as business use cases.","openGraphImage":null,"title":"What Are the Types of Machine Learning?"},"estimatedReadingTime":6,"featured_image":{"_type":"image","asset":{"_ref":"image-3faf334fa409d858100d8be69e4f3a1c87e85922-4096x2732-png","_type":"reference"}},"plaintextBody":"Many will recognize the term AI or Artificial Intelligence, understanding that this broad term applies to almost any technique which allows for computers to mimic human behavior. Machine Learning is a subset of AI which includes abstruse statistical techniques, supporting gradual task improvement through experience gained. These broad sets of algorithms are used to extract useful models from raw data which are in turn used for a variety of mining tasks & synthetic tasks. In this blog we aim to explain both the various types of machine learning algorithms including supervised, unsupervised and reinforcement learning, as well as highlighting its business use examples. Many of the terms used in the blog can be further understood through Google’s extensive ML glossary, found here.\n\n\n\n“Machine learning research is part of research on artificial intelligence, seeking to provide knowledge to computers through data, observations and interacting with the world. That acquired knowledge allows computers to correctly generalize to new settings”\n\n- Yoshua Bengio\n\n\n\nSupervised Learning - Definition, benefits & limitations\n\nRecognized as the most common type of Machine Learning, supervised learning algorithms are designed to learn through example, hence the term ‘supervised’. To achieve this, the algorithm uses provided input and output data. This provided data is labeled to provide a base for future data processing. Using this data, the goal is to produce an accurate mapping function which in-turn allows for prediction of the desired output. Supervised learning is then further compartmentalized into a range of algorithms, including, but not limited to decision trees, logistic regression & support vector machines. Of course, as with many facets of AI, supervised learning has both advantages and disadvantages. Firstly, supervised learning is a simple process to understand and is extremely useful in classification problems. That said, supervised learning is not ‘real-time’ data, meaning that there will be delays in results required. Alongside this, supervised learning requires substantial computation time for training and is considerably more complex in comparison to unsupervised learning due to the need for labeling all inputs.\n\nUnsupervised Learning - Definition, benefits & limitations\n\nUnsupervised learning refers to the process of giving an algorithm no labeled data and leaving it to structure its own output. Through this lack of labeling, models using unsupervised learning can suggest subtle trends that would otherwise be unfound, especially when using semi-supervised learning. Unsupervised Learning can be seen as extremely beneficial, as it then becomes possible to uncover previously unknown patterns in data. The downside? Unsupervised learning results make it hard to find meaning in the data due to the lack of answer labels and this also makes it harder to compare to supervised learning tasks. Applications of unsupervised learning include clustering, anomaly detection and association mining.\n\nBefore moving on to reinforcement learning, it is important to also address semi-supervised learning. Semi-supervised learning sits between the two aforementioned methods, using a mixture of both tagged and untagged data to fit models. This technique is best suited for a large amount of data with both tagged and untagged sections. An example of this? Amazon’s Alexa! Jeff Bezos has previously spoken very highly of semi-supervised learning, suggesting that the reduced amount of labeled data needed to achieve the same accuracy improvement by 40 times.\n\n\n\nReinforcement Learning - Definition, benefits & limitations\n\nA recent buzzword, reinforcement learning is a technique used to aid the development of 'learning' in an environment, through the process of trial and error. This in turn, uses 'feedback' to correct itself. Unlike the above, whereby feedback provided to the agent is a correct set of actions for performing a task, Reinforcement Learning uses reward and punishment as signals for positive and negative behavior, with the goal to find a suitable action model that would maximize the total cumulative reward of the agent. This feedback design acts as a motivational factor for the RL-agent, whereby an understanding of outcome pushes the agent to learn the method of maximizing accumulated rewards over time. Applications of reinforcement learning are often seen in robotics for industrial automation, for data processing and in the creation of training systems. This technique has many positives, including being seen to solve various complicated problems which cannot be solved with conventional techniques including robotic movement and video game completion, similar to human problem solving in regard to process and repeat and the lessening in the potential for repeat mistakes.\n\nA challenge that should be recognized when looking at RL is the time it takes to generate data. This seems to be commonplace in the majority of keynote discussions surrounding different algorithms and subsets of AI. Alongside this, it is suggested that RL assumes the world is Markovian, which it is not. The Markovian model describes a sequence of possible events in which the probability of each event depends only on the state attained in the previous event.\n\nMachine Learning, in its many forms, is seen as a staple in AI, with the potential to scale, a key factor in the growth of intelligent machines. A number of industries utilizing large swathes of data already recognize the potential of ML, as it’s regularly used in financial services, healthcare, government processes, transportation, and more. Using ML not only increases the potential effectiveness of the product, but can aid in a competitive advantage over those proceeding without.","slug":{"_type":"slug","current":"types-of-machine-learning"},"tags":[{"_key":"xTN3uVzu","label":"Machine Learning","value":"Machine Learning"}],"title":"What Are the Types of Machine Learning?"},{"_createdAt":"2020-06-19T20:12:52Z","author":{"_id":"a009d418-aa96-47ac-a73a-fd2cd52c79d9","avatar":{"_type":"image","asset":{"_ref":"image-e0d717f753ba4876a6b0dbf9f125cf6c3d27e545-500x500-webp","_type":"reference"}},"bio":"Wendy Gonzalez is an executive passionate about building high-performing, high-functioning teams that develop and scale innovative, impactful technology. With two decades of managerial and technology leadership experience for companies including EY, Capgemini, Cycle30 (acquired by Arrow Electronics) and General Communications Inc, Gonzalez is currently the CEO of Sama, the provider of accurate data for ambitious AI, used by leading technology companies such as Walmart, Google, Nvidia and Getty. Before taking on her role as CEO, Gonzalez spent 5 years at Sama as COO, and is an active Board Member of the Leila Janah Foundation.","name":"Wendy Gonzalez","slug":{"_type":"slug","current":"wendy-gonzalez"}},"config":{"description":"We’ve decided to take action both inside our organization and in partnership with local organizations to drive toward a more equitable society.","openGraphImage":null,"title":"Underscoring Our Commitment to Racial Justice and Equality"},"estimatedReadingTime":6,"featured_image":{"_type":"image","asset":{"_ref":"image-86e8e4063cb04eb424755f0cce2de16c50442a1c-2135x1068-png","_type":"reference"}},"plaintextBody":"Like many people, I have been deeply saddened, frustrated, and outraged by the violence against Black people in the United States. This systemic challenge we face requires not only immediate action. It requires a change in the way we think, see, and operate.\n\nTrue change happens with purposeful action and in the decisions we make every day. It takes investment for the long term, even when there is pressure to perform in the short term. As I’ve been telling my teams as we organize to contribute the fight for justice for Black people, “We are in a marathon, not a sprint.”\n\nI also firmly believe that change starts locally. It starts with us as individuals and within our communities.\n\nLastly, change needs to be measurable - not just this quarter or next, but on an ongoing basis. We need to hold ourselves accountable to ensure we’re making positive progress toward a more just, equitable society. Since our founding in 2008, we have treated our impact metrics with the same level of fidelity and reporting as we have our financials. We will apply the same rigor of measure to the Black Lives Matter engagement strategy and actions I’m committing to today.\n\nFollowing our company values, we’ve decided to take action both inside our organization and in partnership with local organizations to drive toward a more equitable society where Black people in America realize the same level of humanity as others.\n\nI’m committing to four core initiatives to support racial inclusion.\n\nFinancial Support: Earlier this week, we launched a corporate matching program to raise donations for three local organizations. Sama seeded this program with funds and is matching each employee donation 2:1. The three local organizations include:\n\nCode2040, a San Francisco based nonprofit activating, connecting, and mobilizing the largest racial equity community in tech to dismantle the structural barriers that prevent Black and Latinx technologists from fully participating in the tech industry.\n\nAI4ALL, an Oakland based non-profit lead by a Sama alum, opens doors to artificial intelligence for underrepresented talent through education and mentorship.\n\nColor Of Change, an Oakland based organization, is the nation’s largest online justice organization. They design campaigns powerful enough to end practices that hold Black people back, and champion solutions that move us all forward.\n\nHoodstock, a Montreal based organization, generates spaces for dialogue and mobilizing initiatives to eliminate systemic inequalities and develop supportive, inclusive, secure and dynamic communities.\n\nDiversity and Inclusion: While we have rigorous programs in place to address gender diversity and inclusion, and enjoy a cross-cultural mix of people within our organization, we found that our North American diversity representation could be improved. To achieve this goal, we’re committing to expand our gender diversity and inclusion program to specifically include inclusion metrics for Black and other people of color.\n\nInternal Education: We are committed to hosting internal education and engagement sessions covering topics such as institutional racism, racial bias in AI, diversity hiring best practices, and the importance of voting. We also started an internal forum for our teams to openly exchange ideas for action and provide additional support to each other.\n\nPartnerships: We are engaging with partners within the AI community committed to better understanding and taking action against AI Bias. We’re also engaging with organizations that support upskilling, mentoring, and recruitment to drive economic mobility and inclusion for Black Americans in the tech industry.\n\nMy hope is that everyone in our broader technology community will drive the change needed to make the United States a more equitable and inclusive country. We must stand together and bring humanity to our industry, and to our country.\n\n(In case you missed it, below is our original statement. )\n\nThe murder of George Floyd has reignited an international movement for equality and justice. It sparked a powder keg of emotions that have left many feeling frustrated, helpless, angry, outraged, and sad. We here at Sama stand by one of our core company values -- Humanity. Humanity for the countless number of Black lives who have been victims of police brutality. Humanity for every person that tries to survive daily in a system that routinely oppresses them. Humanity for those who so often do not receive it, all because of the color of their skin.\n\nThe world of tech so often speaks of creating a new, better world -- but we cannot do that if we do not stand for the rights of everyone. Humanity and compassion are necessary. In order to avoid bias in ourselves and the technology we produce, we must consider how daily actions, words, and thoughts contribute to a racist and prejudiced world.\n\nTo quote our late founder Leila Janah, “Don’t underestimate the ripple effect of what you do. These kinds of small actions undertaken in coordination by large numbers of people have toppled empires.” We stand in solidarity with those driving positive change. Here is a list of resources we found helpful.","slug":{"_type":"slug","current":"our-commitment-to-racial-justice-and-equality"},"tags":[{"_key":"ceQUdDQq","label":"Company News","value":"Company News"},{"_key":"Ac6EgzO1","label":"Ethical AI","value":"Ethical AI"},{"_key":"s1l8UVKZ","label":"Leila Janah","value":"Leila Janah"}],"title":"Underscoring Our Commitment to Racial Justice and Equality"},{"_createdAt":"2020-06-10T16:27:24Z","author":{"_id":"80db3356-b402-44cb-a717-2e0f9c9fa3e4","avatar":{"_type":"image","asset":{"_ref":"image-399295e959574e371fe2ba7bfd55ba4aee8a589d-320x320-jpg","_type":"reference"}},"bio":"Heather is passionate about bringing world-changing technologies to market and using supply chain purchasing power for good. She is a data-driven strategist experienced in developing and leading go-to-market, communications, and sustainability initiatives at start-ups and multi-national organizations. Heather is most happy when she’s growing companies that make a positive impact, enjoying the outdoors, and spending time with her family.","name":"Heather Gadonniex","slug":{"_type":"slug","current":"heather-gadonniex"}},"config":{"description":"Maximizing Training Data in AI Securely","openGraphImage":null,"title":"Data Protection and Privacy for Training Data"},"estimatedReadingTime":5,"featured_image":{"_type":"image","asset":{"_ref":"image-7fa93d0a7942fc64939bb9f56f4aa294b7dbd8ad-1280x400-png","_type":"reference"}},"plaintextBody":"TL;DR:\n\nThe need for data to meet privacy & security requirements by law can often reduce the amount of training data available\n\nThe growth of popularity in AI has been mirrored by a growing number of concerns surrounding privacy, security and ethical use of data\n\nPII includes any information which could point toward identification, including, but not limited to social media information, IP addresses and more\n\nSama gives the ability for AI companies to scale training data at a faster pace without compromising quality, privacy or security\n\nWith the steady rise in both popularity and progress in Artificial Intelligence (AI) over recent years, many have been quick to address potential privacy and security concerns, with buzzwords like ‘ethics’ and ‘responsibility’ never too far from discussion. While the initial public perception of AI was “will automation steal my job”, steady progress has seen facets of AI and Machine Learning technology present in our living rooms, cars, phones and more, mostly without people knowing. That said, an important question has emerged: What level of trust can—and should—we place in these AI systems?\n\nIn an age of increasingly complex governmental data privacy requirements, it can be hard to understand not only the level of personal data that’s available, but also how this is protected, both in law (GDPR, Information Privacy law etc.), but also through the development of solution provider products.\n\nPersonally identifiable information (PII) is to be considered any information which could identify a specific individual. Of course, the wide definition of PII can create challenges, especially when searching for AI training data as it can cover anything from IP addresses, imagery, behavioral data, social media information, and more.\n\nWhy do we need such swathes of data? Well, a simple input/output equation suggests that more data equates to the ability for increased training and training environments. This, in turn, leads to models that are often increasingly accurate due to both the level of training and the various training scenarios it has been placed inside [1]. At this stage, it is also important to recognize the differentiation between both structured & unstructured data as well as supervised & unsupervised learning. You can read more on this here.\n\nTo surmise, the main challenges faced by those in need of large data training sets include, but are not limited to, the following:\n\nInability to utilize all owned data due to GDPR and CCPA privacy restrictions\n\nLack of anonymized video training data available for use\n\nPreviously used techniques, including pixelation of imagery reducing model performance for video analysis\n\nRequired manual human intervention\n\nRecent developments on our platform aim to address the above through the use of Vector Annotation, Semantic Segmentation, Lidar/3D Annotation, and Dynamic Labelling. These developments when coupled with ISO-certified data centers, vulnerability testing of systems, data storage encryption & GDPR compliance, not only ensure the highest level of internal security, but also the most dynamic and innovative data utilization service available.\n\nMany applications have previously struggled to keep personally identifying information safe across a variety of data sources, especially when street-level images, cars, retail places, and similar are discussed, however, Sama uses deep learning pre-annotation technology to anonymize data without the need for a human intervention! The process for this includes:\n\nData is run through our anonymizer technology service before any labeling occurs\n\nThis service automatically detects faces and license plates to obscure and does so until unrecognizable\n\nThis AI-generated content creates training data that looks like real-time data when people and vehicles are the primary objects of interest for the algorithm\n\nThe above, through the lack of human intervention further accentuates the privacy of PII data\n\nThis service then allows for increased test data at a faster pace, without compromising security, allowing you to scale your AI whilst also not compromising the trust of stakeholders\n\nWant to learn more? Check out our Anonymization webinar here.","slug":{"_type":"slug","current":"data-protection-and-privacy-for-training-data"},"tags":[{"_key":"j3OupYSm","label":"Security & Trust","value":"Security & Trust"},{"_key":"pW5yVuE3","label":"Training Data","value":"Training Data"},{"_key":"KuCG26mD","label":"Anonymization","value":"Anonymization"}],"title":"Data Protection and Privacy for Training Data"},{"_createdAt":"2020-05-12T16:08:52Z","author":{"_id":"a009d418-aa96-47ac-a73a-fd2cd52c79d9","avatar":{"_type":"image","asset":{"_ref":"image-e0d717f753ba4876a6b0dbf9f125cf6c3d27e545-500x500-webp","_type":"reference"}},"bio":"Wendy Gonzalez is an executive passionate about building high-performing, high-functioning teams that develop and scale innovative, impactful technology. With two decades of managerial and technology leadership experience for companies including EY, Capgemini, Cycle30 (acquired by Arrow Electronics) and General Communications Inc, Gonzalez is currently the CEO of Sama, the provider of accurate data for ambitious AI, used by leading technology companies such as Walmart, Google, Nvidia and Getty. Before taking on her role as CEO, Gonzalez spent 5 years at Sama as COO, and is an active Board Member of the Leila Janah Foundation.","name":"Wendy Gonzalez","slug":{"_type":"slug","current":"wendy-gonzalez"}},"config":{"description":"We’re excited to introduce Chloe, an automated public chatbot service to support in the fight against the coronavirus.","openGraphImage":null,"title":"Introducing Chloe: A ChatBot to Help You Get Accurate Health Information During COVID-19"},"estimatedReadingTime":3,"featured_image":{"_type":"image","asset":{"_ref":"image-08a4bf963b3d04e0e0017d67bf2b972531285856-2000x1000-jpg","_type":"reference"}},"plaintextBody":"For over a decade, we have developed mission-critical data for AI applications. As we continue to look for ways to improve the lives of many each day, we’re excited to introduce Chloe, an automated public chatbot service to support in the fight against the coronavirus. We’ve partnered with several leaders in artificial intelligence development including Dialogue Technologies, MILA, Nu Echo, along with support from Google, John Hopkins University and Dataperformers, to enhance this service.\n\nSince the start of the coronavirus pandemic, information has constantly been evolving. Most of us don’t have the time or mental capacity to check the news or medical reports on an hourly or daily basis. It’s not because we don’t want to be informed, but it's become nearly impossible to keep up, especially on top of everything we’re dealing with at home and at work.\n\nIt’s affecting the healthcare workers who are at the forefront of this fight and it’s also affecting individuals mental well being and causing anxiety to surge. That’s why we’ve decided to offer our services to help support an online system that will do it for you. Through Chloe, people can get the most up-to-date information instantly.\n\n“COVID-19 is impacting everyone at an alarming rate, that’s why we’re excited to work with such an astonishing group of professionals to help power such a vital service. Our team is honored to have been able to help make this happen.” - Wendy Gonzalez, CEO, Sama\n\nThe Chloe chatbot is available today and supports Canadians by becoming the first phase of getting care - both for your physical and mental wellbeing. Providing current and verified information about COVID-19 with clear answers to specific questions on the subject is the first step. At the end of the assessment, it will provide you resources that correlate with your medical inquiry. But we know that having a clear sense of mind doesn’t stop there. If the assessment indicates that you have a likelihood of having been exposed to the virus, Chloe will answer questions about the testing phase and monitor people in self-isolation to keep track of their condition.\n\nChloe is powered through natural language processing technology (NLP). Our team at Sama makes Chloe smarter by helping her understand the human language. We have real people behind the chatbot, annotating every data asset to help ensure that citizens are getting the most accurate information available in real-time.\n\nWe believe that it’s our obligation to use our industry-leading annotation solutions to help as many people as possible navigate these trying times. Our goal is to provide a safe service with truthful, current and accurate information for everyone. We hope that you’ll sign up and take advantage of this free service. Let’s work together to help alleviate our first responders and support our healthcare system.\n\nWe’re excited to help bring Chloe to market and are eager to contribute what we can in this fight against COVID-19.\n\nTo access Chloe, please visit covid19.dialogue.co.","slug":{"_type":"slug","current":"chatbot-during-covid-19"},"tags":[{"_key":"k5wnuMl8","label":"Company News","value":"Company News"},{"_key":"KjXPtdNx","label":"AI","value":"AI"},{"_key":"A3zPSdd2","label":"Training Data","value":"Training Data"},{"_key":"z3km6Gbw","label":"Use Cases","value":"Use Cases"},{"_key":"oNwQIM12","label":"Data Quality","value":"Data Quality"}],"title":"Introducing Chloe: A ChatBot to Help You Get Accurate Health Information During COVID-19"},{"_createdAt":"2020-04-28T17:30:19Z","author":{"_id":"80db3356-b402-44cb-a717-2e0f9c9fa3e4","avatar":{"_type":"image","asset":{"_ref":"image-399295e959574e371fe2ba7bfd55ba4aee8a589d-320x320-jpg","_type":"reference"}},"bio":"Heather is passionate about bringing world-changing technologies to market and using supply chain purchasing power for good. She is a data-driven strategist experienced in developing and leading go-to-market, communications, and sustainability initiatives at start-ups and multi-national organizations. Heather is most happy when she’s growing companies that make a positive impact, enjoying the outdoors, and spending time with her family.","name":"Heather Gadonniex","slug":{"_type":"slug","current":"heather-gadonniex"}},"config":{"description":"Fast Company has recognized Samasource as a finalist in the AI and Data category as part of their 2020 World Changing Ideas Awards.","openGraphImage":null,"title":"Fast Company Names SamaÃƒâ€šÃ‚Â a 2020 World Changing Ideas Finalist in AI and Data"},"estimatedReadingTime":3,"featured_image":{"_type":"image","asset":{"_ref":"image-3bb8e0adeda260278b213dc40d2819a792dfe6f8-3534x1767-png","_type":"reference"}},"plaintextBody":"Since our founding in 2008, we’ve been driven by the idea that through technology, we can make the world a better place. Ever since, our team has continuously broken barriers as we became the trusted, high-quality training data and validation provider for 25% of the Fortune 50 companies.\n\nThanks to our team’s dedication to providing high quality training data and trustworthy technology, we’re honored that Fast Company has recognized us as a finalist in the AI and Data category as part of their 2020 World Changing Ideas Awards.\n\n“This recognition is a testament to our commitment to using technology to fuel positive impacts on our world,” says Wendy Gonzalez, President and Interim CEO of Sama. “We’re humbled to have received this recognition from Fast Company. This award further validates our industry-leading software technology and our team’s efforts to ensure only the highest quality standards.”\n\nFast Company recognized us as a finalist for our work with Vulcan, a project and investment company using data to make a positive impact on endangered species, climate change, ocean health, and more. Image recognition technology plays an important role in wildlife conservation and through our work together, we created an AI solution that was able to record and monitor African wildlife and threats of poaching, human-wildlife conflict and loss of habitat. Through that technology, we were able to combat large-scale poaching that contributes to extinction to support a more sustainable ecosystem. To date, we’ve labeled nearly one million images for Vulcan, achieving above industry-standard quality in support of their efforts.\n\n“There seems no better time to recognize organizations that are using their ingenuity, resources, and, in some cases, their scale to tackle society’s biggest problems,” says Stephanie Mehta, editor-in-chief of Fast Company. “Our journalists, under the leadership of senior editor Morgan Clendaniel, have uncovered some of the smartest and most inspiring projects of the year.”\n\nThe World Changing Ideas Awards is one of Fast Company’s major annual awards programs and is focused on social good, seeking to elevate finished products and brave concepts that make the world better. A panel of judges from across sectors choose winners, finalists, and honorable mentions from a pool of 3,000 this year and based their decisions on feasibility and the potential for impact. With a goal of awarding ingenuity and fostering innovation, Fast Company draws attention to ideas with great potential and helps them expand their reach to inspire more people to start working on solving the problems that affect us all.\n\nWe’re thankful to everyone who has made an impact and provided guidance to Sama - our teams, investors, customers and community - this award acknowledges us all.\n\nHead this way to check out the complete list of companies featured in Fast Company’s World Changing Ideas. ","slug":{"_type":"slug","current":"world-changing-ideas-finalist"},"tags":[{"_key":"ZsUzaThh","label":"Company News","value":"Company News"},{"_key":"V1MkPdiw","label":"Ethical AI","value":"Ethical AI"},{"_key":"zh1YPgpW","label":"AI","value":"AI"},{"_key":"3r8B4ITq","label":"Awards","value":"Awards"}],"title":"Fast Company Names Sama a 2020 World Changing Ideas Finalist in AI and Data"},{"_createdAt":"2020-04-23T21:37:48Z","author":{"_id":"26fb3cc4-608d-40e1-bb4d-955bceda232a","avatar":{"_type":"image","asset":{"_ref":"image-e0fe681e594567792ac79048513fe955cc770f54-518x518-svg","_type":"reference"}},"bio":"From self-driving cars to smart hardware, Sama fuels AI. Founded over a decade ago, we’re experts in image, video and sensor data annotation and validation for machine learning algorithms in industries including automotive, navigation, AR/VR, biotech, agriculture, manufacturing, and e-commerce. Our staff are driven by a mission to expand opportunity for low-income people through the digital economy, and our social business model has helped over 50,000 people lift themselves out of poverty.","name":"Sama Team","slug":{"_type":"slug","current":"sama-team"}},"config":{"description":"The traffic light problem for autonomous vehicles is critical for all vehicle safety, and unlike human-drivers, AVs rely solely on computer vision systems to navigate the world around us.","openGraphImage":null,"title":"The Traffic Light Problem for Autonomous Vehicles"},"estimatedReadingTime":5,"featured_image":{"_type":"image","asset":{"_ref":"image-04a6a4a0b08c6631b9ea6592f4d5e29e4ca09ba5-4496x3000-jpg","_type":"reference"}},"plaintextBody":"Solving the traffic light problem for autonomous vehicles is critical for all vehicle safety, not just autonomous vehicles. And unlike human-driven cars, AVs rely solely on their computer vision system and the data used to train them to navigate the world around us.\n\nCurrently, the best self-driving assistance systems incorrectly perceive something in their environment once every tens of thousands of hours. If that object is a traffic light, and the car gets it wrong, passengers, pedestrians, cyclists, etc., are all at risk. Here’s a look at the traffic light problem for autonomous cars from three perspectives. \n\n\n\n1. Traffic lights tell road users when to stop and go, but they only work when everyone follows the rules.\n\nTraffic lights are an engineered system, timed around traffic patterns. There are rules in place that tell cars when to stop and go, but the inherent human behavior of drivers, pedestrians and cyclists sometimes means these rules are loosely interpreted.\n\nThere are no physical barriers forcing road users to abide by traffic signals. They work because drivers follow the rules. AVs must also get the rules right, and that means countless hours of real-world exposure to the unspoken rules (or lack thereof) of the road.\n\nThe quality and accuracy of the data received from sensor packages must be precise, leaving no room for interpretation or inconsistencies. Also, license plates, faces or other personal identifying information (PII) may need to be anonymized to protect the privacy of people who might appear in the raw footage. \n\nEnsuring AVs learn the right rules requires unbiased, appropriately labeled and high-quality training data based on a range of driving scenarios.\n\n\n\n2. Traffic lights challenge both the vision system and the team developing the algorithms.\n\nBecause traffic lights are not a distance detection problem, AVs cannot use lidar or radar to navigate traffic signals. They must rely solely on their computer vision system to understand when to stop and go.\n\nThis can be difficult for both the vision system as well as the team developing the algorithm because the visibility of traffic lights may vary based on weather conditions like bright sunlight, rain, snow or fog. Similarly, not all intersections have traffic lights, so if the AV doesn’t detect one, that could be correct.\n\nThe treatment of out of service traffic signals can also vary. One city might use a plastic bag to indicate an out-of-service light while another city, or even county, might use masking tape or some other method to cover broken traffic signals.\n\nContext clues like head nods or hand signals help human drivers manage low visibility or the lack of a traffic light, but since AVs cannot register this supplemental visual information, machine learning and computer vision engineers must train the AV on such scenarios as they arise.\n\n3. Stock datasets aren’t enough to help AVs navigate traffic lights safely.\n\nThe volume and diversity of data required for autonomous vehicles is vast, and stock datasets cannot cover all use cases.\n\nDuncan Curtis, Sama VP of Product shares approximately 1,000 to 10,000 images are needed to deploy a solution onto a vehicle, and in order to launch a product publicly, approximately 10,000 to 100,000 images are needed per ADAS feature. That’s a lot of data, and the amount of data needed to account for edge cases like traffic lights in unique road conditions is unknown.\n\nSince AVs often need data from a specific camera or sensor package (because that’s what the car will use in production), generic stock data isn’t enough to help AVs navigate traffic lights safely. In addition to this, models need to be refreshed with ongoing training data as road rules, and the world around us changes.\n\nOur team of data labeling experts annotate over 4M tasks per month, and for AV use cases, we’ve achieved 99.5 percent quality SLAs with more than 100 tags per image. We’ve also successfully achieved full productivity within our labeling teams in as little as two to five days.\n\nIf you need ground truth data for your ML model, connect with our team for a virtual consultation and demo of our industry-leading data annotation platform.","slug":{"_type":"slug","current":"the-traffic-light-problem-for-autonomous-vehicles"},"tags":[{"_key":"ivLPY6Ly","label":"AI","value":"AI"},{"_key":"Liw4Inz5","label":"Training Data","value":"Training Data"},{"_key":"3LVFK315","label":"Data Annotation","value":"Data Annotation"},{"_key":"YhUSiZyI","label":"Data Quality","value":"Data Quality"},{"_key":"72HsQzsx","label":"Autonomous Transportation","value":"Autonomous Transportation"}],"title":"The Traffic Light Problem for Autonomous Vehicles"},{"_createdAt":"2020-04-22T23:33:05Z","author":{"_id":"80db3356-b402-44cb-a717-2e0f9c9fa3e4","avatar":{"_type":"image","asset":{"_ref":"image-399295e959574e371fe2ba7bfd55ba4aee8a589d-320x320-jpg","_type":"reference"}},"bio":"Heather is passionate about bringing world-changing technologies to market and using supply chain purchasing power for good. She is a data-driven strategist experienced in developing and leading go-to-market, communications, and sustainability initiatives at start-ups and multi-national organizations. Heather is most happy when she’s growing companies that make a positive impact, enjoying the outdoors, and spending time with her family.","name":"Heather Gadonniex","slug":{"_type":"slug","current":"heather-gadonniex"}},"config":{"description":"Creating lasting social impact, understanding our carbon footprint and being environmentally sustainable are just few of our goals for sustainability and impact.","openGraphImage":null,"title":"Celebrating 50 Years of Earth Day: Honoring Leila Janah's Legacy"},"estimatedReadingTime":3,"featured_image":{"_type":"image","asset":{"_ref":"image-01151de9b1aeaf0afe4d22613bf6b5537354c561-1386x808-png","_type":"reference"}},"plaintextBody":"I woke up this morning thinking about Leila’s fierce commitment to sustainability.\n\nThe two of us spent quite a lot of time visioning how our team could expand Sama’s Give Work platform to incorporate environmental sustainability, and how the organization could play an even bigger role in creating a more equitable, just world.\n\n\n\nPHOTO: Leila Janah, Founder,Sama\n\n\n\nFrom nixing the use of water bottles at all of our offices to launching the Give Work Challenge, a full-scale business competition that rewards entrepreneurs for social and environmental innovation, Leila had a lot of ideas to weave triple bottom line principles (being financially profitable, creating lasting social impact, and being environmentally sustainable) into our business model. In addition to spearheading our impact model, she sparked a deep love of nature in the visitors to our East African offices by increasing their exposure to African nature and wildlife. One of her favorite topics to muse about over the past few years was how to calculate the positive climate impacts of hiring and empowering women in East Africa.\n\nOn this 50th anniversary of Earth Day, I want to take the time to remember Leila’s legacy by giving you a glimpse into a few of the sustainability activities we are working on here at Sama. Mid last year, we officially launched our sustainability program. Our first goals were to understand our carbon footprint (GHGe per GHG Protocol Corporate Standard, Scope 1 and 2), develop an environmentally preferable purchasing program for ongoing consumables, and create biophilic office environments that brought nature inside.\n\nPHOTO: Sama East Africa delivery center\n\n\n\nUltimately, Leila wanted to pursue B Corporation certification. She always wanted to lead by example, to show the world how business could be both profitable and a force for good.\n\nWhat better way to do this than provide the ultimate success story and demonstrate that a technology company can be committed to both providing the leading training data platform and to using business as a force for good?\n\n“One of the things I’m proudest of at Sama is our collaboration with conservation groups including the Nature Conservancy to use AI to track endangered species, combat poaching, and protect wilderness. Not only that, but we do it by employing women (more than 50% of our workforce!) from low-income backgrounds, which itself is a way to fight climate change.” - Leila Janah\n\n\n\nI’m thrilled that Sama is actively engaged with B Lab and is in the final stages of audit verification for our B Corporation certification. I couldn’t be prouder of our Nairobi based Sustainability Analyst, Robert Wahome, for ensuring we have all of the data in place needed to drive this initiative forward, including our first ever Carbon Footprint. In my heart, I know Leila is proud too.","slug":{"_type":"slug","current":"celebrating-50-years-of-earth-day-honoring-leila-janahs-legacy"},"tags":[{"_key":"OFjdWc6T","label":"Ethical AI","value":"Ethical AI"},{"_key":"OtSjlWNo","label":"Impact","value":"Impact"},{"_key":"fWAUAQ8u","label":"Leila Janah","value":"Leila Janah"}],"title":"Celebrating 50 Years of Earth Day: Honoring Leila Janah's Legacy"},{"_createdAt":"2020-04-02T20:30:00Z","author":{"_id":"6dd25391-26af-42ff-a2a2-f0778ce1b002","avatar":{"_type":"image","asset":{"_ref":"image-4e1c47984bb16cb0370855b6272663d6744216d3-450x450-jpg","_type":"reference"}},"bio":"Currently a Senior Product Manager at Sama, Audrey guides cross-functional teams to create thoughtful product solutions. She has guided teams of designers and engineers at HUGE Inc. and NBCUniversal, and monitored user analytics at the Wall Street Journal. With a BA in history from Harvard, an MA in anthropology from Columbia and an MBA from UNC Chapel Hill KFBS, Audrey is passionate a using technology and data analytics facilitate social impact and environmental solutions through technology.","name":"Audrey Boguchwal","slug":{"_type":"slug","current":"audrey-boguchwal"}},"config":{"description":"SamaHub's video and 3D object tracking with frame level labeling assists companies in quickly building models that better reflect real-world behavior.","openGraphImage":null,"title":"Object Tracking with Frame Level-Labeling"},"estimatedReadingTime":3,"featured_image":{"_type":"image","asset":{"_ref":"image-7eb4854393afff7be19269b7e8414936e411403f-5506x3671-jpg","_type":"reference"}},"plaintextBody":"We live in an ever-changing world, where AI-enabled technology has become a new normal for society. To assist top organizations in their efforts to build smarter computer vision algorithms, we’ve rolled out a new release for video and 3D object-tracking in our leading data annotation platform.\n\nThere are a number of applications that use computer vision to track how the world, and the objects in it, change overtime. For a self-driving car to navigate safely, it needs to track other moving objects on the road and make predictions about their future movement, so it can plan its driving path.\n\nAR and VR applications like video games need to track the motion of individual people to create a seamless digital experience. These vision applications have something in common: they all seek to understand the change in position, behavior and characteristics of unique objects over time.\n\nObject tracking annotation offers object tracking capabilities for complex scenarios, including path planning, traffic light status, sentiment analysis, etc.\n\nThis frame-level labeling technology allows unique objects to be dynamically tracked across a video or a sequence of 3D point cloud data from a Lidar sensor. Change in position and pose are captured with annotation shapes like cuboids, polygons and bounding boxes.\n\nSama supports custom label taxonomies for both the main object class (person, car, etc.) and dynamic labeling for other object characteristics that change over time, such as visibility percentage of an object or a specific set of characteristics like emotions. Sama’s built-in automated interpolation between video frames helps ensure efficient, high quality labeled training data for a variety of object tracking use cases.\n\nFor over 10 years, Sama has delivered turnkey, high-quality training data and validation to train the world's leading AI technologies. Video and 3D object tracking are no exception, and this update for video object tracking annotation in 2D RGB video and 3D Lidar data will continue to assist organizations in quickly building models that better reflect real-world behavior.\n\nSama has deep expertise working with training data for object tracking use cases across a variety of industries including autonomous vehicles, AR/VR, retail and e-commerce, communications, media and entertainment, to name just a few.\n\nDownload our solution brief to learn more about our secure training data annotation platform, or contact our team here.","slug":{"_type":"slug","current":"object-tracking-in-samahub-with-frame-level-labeling"},"tags":[{"_key":"OjIX5QKU","label":"Product","value":"Product"},{"_key":"2ZGxEWq0","label":"Video Annotation","value":"Video Annotation"},{"_key":"iBmdS1VE","label":"Training Data","value":"Training Data"},{"_key":"uZYhm6jx","label":"Data Annotation","value":"Data Annotation"}],"title":"Object Tracking with Frame Level-Labeling"},{"_createdAt":"2020-03-26T16:49:42Z","author":{"_id":"6dd25391-26af-42ff-a2a2-f0778ce1b002","avatar":{"_type":"image","asset":{"_ref":"image-4e1c47984bb16cb0370855b6272663d6744216d3-450x450-jpg","_type":"reference"}},"bio":"Currently a Senior Product Manager at Sama, Audrey guides cross-functional teams to create thoughtful product solutions. She has guided teams of designers and engineers at HUGE Inc. and NBCUniversal, and monitored user analytics at the Wall Street Journal. With a BA in history from Harvard, an MA in anthropology from Columbia and an MBA from UNC Chapel Hill KFBS, Audrey is passionate a using technology and data analytics facilitate social impact and environmental solutions through technology.","name":"Audrey Boguchwal","slug":{"_type":"slug","current":"audrey-boguchwal"}},"config":{"description":"Samasource is excited to launch the PII Data Anonymizer for video training data. This technology enables obscuring of sensitive information in training data.","openGraphImage":null,"title":"Keep it Secret, Keep it Safe: Announcing the PII Data Anonymizer"},"estimatedReadingTime":3,"featured_image":{"_type":"image","asset":{"_ref":"image-70afee37d4e99e8fac42e758c436c2f61d991a7d-1904x797-jpg","_type":"reference"}},"plaintextBody":"Sama is excited to launch the PII Data Anonymizer as part of our platform for video training data. This technology enables obscuring of sensitive, personally identifying information (PII) in training data.\n\nIn light of new laws like GDPR and CCPA, it’s important for companies building AI and ML technologies to carefully manage data with PII information. Obscuring PII helps Sama and our customers work to protect privacy.\n\nSama’s PII Data Anonymizer helps make more data available to train AI by keeping personally identifying information safe across a variety of data sources: People in camera images from retail spaces and public places, street-level images of people and license plates captured by vehicles, smart city applications on public transit and more.\n\nApplications for anonymization range from autonomous transportation, detailed customer demographics, customer data like clothing and emotion, people counters, and security.\n\nThis deep learning pre-annotation technology allows Sama to obscure faces and vehicle license plates that appear in data without the need for any human intervention. That means that private information remains private and is never seen by another person.\n\n\n\nWhen Sama receives customer data, it can be run through our anonymizer technology service before any labeling occurs. The service would automatically detect faces and license plates and obscure them, as well as blur faces and license plates so they are not recognizable.\n\nAlternatively, it can replace faces and license plates with realistic computer-generated avatars. This AI-generated content creates training data that looks like real-time data when people and vehicles are the primary objects of interest for the algorithm.\n\nUnlike manual blurring, Sama’s PII Data Anonymizer is run without a human examining the data, which contributes to the privacy of PII data. It is built on deep learning and is run within our technology platform, ensuring that customer data never leaves Sama’s secure cloud environment.\n\nFrom pilots to multi-year projects, Sama securely trains and validates computer vision and NLP models. We work on a range of use cases ranging from e-commerce to autonomous transportation, manufacturing, navigation, retail, AR/VR, and biotech. If your goal is to quickly build smarter AI, contact our team to discuss your training data needs.","slug":{"_type":"slug","current":"keep-it-secret-keep-it-safe-announcing-the-pii-data-anonymizer"},"tags":[{"_key":"4C8kDRnD","label":"Product","value":"Product"},{"_key":"sCm7cDGc","label":"Security & Trust","value":"Security & Trust"},{"_key":"w6zwqXk4","label":"Anonymization","value":"Anonymization"}],"title":"Keep it Secret, Keep it Safe: Announcing the PII Data Anonymizer"},{"_createdAt":"2020-03-08T19:00:00Z","author":{"_id":"80db3356-b402-44cb-a717-2e0f9c9fa3e4","avatar":{"_type":"image","asset":{"_ref":"image-399295e959574e371fe2ba7bfd55ba4aee8a589d-320x320-jpg","_type":"reference"}},"bio":"Heather is passionate about bringing world-changing technologies to market and using supply chain purchasing power for good. She is a data-driven strategist experienced in developing and leading go-to-market, communications, and sustainability initiatives at start-ups and multi-national organizations. Heather is most happy when she’s growing companies that make a positive impact, enjoying the outdoors, and spending time with her family.","name":"Heather Gadonniex","slug":{"_type":"slug","current":"heather-gadonniex"}},"config":{"description":"Sama's commitment to an ethical AI supply chain enables us to close the gender pay gap, by paying a living wage to all of our employees.","openGraphImage":null,"title":"How Sama is Closing the Gender Pay Gap for Women in the AI Supply Chain"},"estimatedReadingTime":3,"featured_image":{"_type":"image","asset":{"_ref":"image-8556bc7f46d3029f92f018877f7fe103dd60b86f-2048x1365-jpg","_type":"reference"}},"plaintextBody":"For centuries, women have made history as innovators, inventors and trailblazers. I’m grateful that everyday I get to witness history in the making as part of a female-led tech company that provides industry leading, high quality training data technology and solutions that are underpinned by an ethical AI supply chain.\n\nIt’s this commitment to an ethical supply chain that enables us to close the gender pay gap by paying a living wage to all of our employees.\n\nThe AI supply chain is the combination of the human workforce and advanced technology solutions that help bring machine learning based systems to market. To operationalize AI, everything from data labeling to model development needs to be in sync, and as it is with any supply chain, ethics and sustainability come into play. \n\nBehind every Al, there’s a person deciding what data is needed and the best model to use. There’s also someone guiding AI strategy, developing the tech to support AI pipelines, and so on.\n\nData annotation is a key part of making machine learning possible, and conversations around ethical AI supply chains are vital to have now if we want to ensure the labeling industry is a positive force.\n\nAccording to our baseline impact survey data, prior to joining Sama, female workers in our global delivery centers earned 70 cents for every dollar earned by men, despite having comparable educational backgrounds.\n\nWe found that gender discrimination—especially in the technology sector—and the challenge of being a primary family caretaker make it difficult for many women to get into and stay in the formal employment sector in Kenya and Uganda.\n\nWomen are highly driven and eager to align their education with real-world opportunities, yet a recent report from the World Economic Forum found that if progress continues at its current rate, it would take roughly 95 years for sub-Saharan Africa to achieve gender parity.\n\nThis number is astonishing, but there is a path forward, and it involves equipping younger generations with the skills needed to succeed in the growing digital economy.\n\nAt Sama, our workers receive digital literacy training, as well as specialized training on artificial intelligence and our advanced training data platform. Also, in addition to connecting women and youth to dignified digital work, workers gain access to life and professional skills development opportunities, to further advance their careers.\n\nWhen women succeed, everyone benefits, and closing the gender gap at work is key to achieving at least five of the sustainable development goals set by the UN. In the last decade, Sama has positively impacted over 50,000 lives, and we’re proud to have achieved gender parity in our global work centers, by ensuring our workers earn equal pay for equal work. \n\nIf you’re interested in learning more about our impact, read our story here, or work with us on training data and model validation, to start making a positive global impact one bounding box at a time.","slug":{"_type":"slug","current":"how-samasource-is-closing-the-gender-pay-gap-for-women-in-the-ai-supply-chain"},"tags":[{"_key":"daz4fDnC","label":"Ethical AI","value":"Ethical AI"},{"_key":"wLYQCPhS","label":"Women in AI","value":"Women in AI"},{"_key":"EiPsNBnG","label":"Impact","value":"Impact"}],"title":"How Sama is Closing the Gender Pay Gap for Women in the AI Supply Chain"},{"_createdAt":"2020-02-28T21:00:00Z","author":{"_id":"b4d4d096-8187-41fa-a386-87ce949c9915","avatar":{"_type":"image","asset":{"_ref":"image-45005425be54d2d450b1aa53f7d9435477531eb3-1664x1758-jpg","_type":"reference"}},"bio":"Liliosa is the Impact and Marketing Manager at Sama.","name":"Liliosa Mbirimi Muturi","slug":{"_type":"slug","current":"liliosa-mbirimi-muturi"}},"config":{"description":"As AI adoption expands, untapped communities are finding work at the cutting edge of AI. Here are 4 ways AI makes a positive impact on communities in East Africa.","openGraphImage":null,"title":"4 Ways AI Makes a Positive Impact on Communities in East Africa"},"estimatedReadingTime":6,"featured_image":{"_type":"image","asset":{"_ref":"image-7e68dc7b894694d301fe5feff694b3df88f8beda-2048x1365-jpg","_type":"reference"}},"plaintextBody":"In a small town in Northern Uganda, Ocem turns on his lights at 6am to get ready for work. It’s his second year working at Sama, and before becoming an AI trainer, he was a student at the local university, moonlighting as a farmer.\n\nWorking in AI was not a path Ocem imagined until he was recruited to work at Sama. In fact, like many students, his greatest uncertainty was whether he could put his degree to good use at all, post graduation.\n\nOcem’s story is like many other young professionals in East Africa, but as AI adoption explodes, these talented, untapped communities are finding work they never thought possible, at the cutting edge of AI.\n\nHere are four ways AI makes a positive impact on communities in East Africa.\n\nGainful Employment\n\nA report by the World Bank shared that 60 percent of the unemployed in Africa are youth, who after graduating from University will take on average, one year to find employment in their field of study. \n\nI believe this is due to the lack of formal career opportunities within the region, making it difficult for the employment industry to support the volume of college graduates entering the workforce.\n\nAs a result, talented graduates find work in menial jobs that often don’t provide a sustainable income, but Sama and other tech companies are working to fix that.\n\nThe explosion of AI has birthed the demand for high-quality, ground truth data for artificial intelligence, and with training, recent graduates like Ocem can find meaningful work in the growing digital economy.\n\nDriven by a mission to expand opportunity for low-income people, Sama's social impact business model has helped over 50,000 people move themselves out of poverty through digital work.\n\nWorkers in our East Africa centers are paid a living wage and competitive benefits. They also receive ongoing digital skills training and have access to professional development opportunities that further help increase the purchasing power of their communities, potentially ending a long cycle of poverty.\n\nSkills and Knowledge\n\nAs more tech companies expand operations to Africa, and more people start gaining on-the-job experience working in machine learning and AI, the positive impact AI makes on communities in East Africa will only expand.\n\nI’ve personally witnessed how energized the youth in East Africa are about the intricacies of enriching data for AI. For many, this budding tech boom has motivated them to enroll in courses centered around data sciences and AI.\n\nAlso, the Deep Learning Indaba, an annual meeting for AI enthusiasts in Africa has brought together a growing number of youths for week long discussions, debates and research on machine learning and AI.\n\nWith a reliable IT infrastructure, paired with increased trust in the skill level of youth workers in the region, East Africa has the potential to become a major hub for AI training data.\n\nAt Sama, our AI training classes fill up weekly, and this level of investment in skills development for young professionals is what’s needed to continue developing the talent pool. \n\nDiversity and Inclusion\n\nUnesco reported that 30% of the tech-workforce in sub-Saharan Africa are women, and despite the challenges of gender discrimination in the technology sector, the percentage of female workers is steadily growing. \n\nWomen in Africa have often been set apart from the tech industry because culturally, they were considered primary caretakers, expected to focus on their family, not their career. Now, the vast opportunities in AI are helping to change that.\n\nWe actively recruit women and youth to work in our East Africa centers, providing in-depth technical training, so underserved communities can pursue a career in AI. From scholarship programs to nursing rooms, we’ve also made it a priority to establish an office culture conducive to the success of women workers.\n\nOur baseline survey data found that women earned 70 cents for every dollar earned by men, before joining Sama. By ensuring we achieve gender parity in pay, while simultaneously paying a living wage, our workers can support themselves and their families sustainably.\n\nData Privacy and Protection\n\nAs more populations in Africa adopt mobile technology and digital apps, their exposure to AI-enabled technologies that collect data to improve experiences will only increase. These interactions can be as simple as product recommendations from an online store, or interactions with an automated messenger bot.\n\nGiven the rapid advancement of AI and the Internet of Things (IoT) , the Kenyan government recently passed a data protection law which complies with the European Union’s General Data Protection Regulation (GDPR). \n\nSimilar to GDPR, this legislation outlines restrictions on data handling and sharing, in an effort to regulate the processing of personal data and information in the country.\n\nThis commitment to increased digital security will no doubt have a positive impact on the citizens of Kenya, and in many ways, it sets the standard for data privacy and protection across the continent.\n\nMcKinsey Global Institute predicts that AI has the potential to deliver an additional economic output of $13 trillion by 2030. This economic growth, alongside the digital transformation of sub-Saharan Africa will have enormous positive impact on communities in East Africa.\n\nIf you’re interested in learning more about how Sama connects people to dignified digital work, you can read about our social business model here.","slug":{"_type":"slug","current":"4-ways-ai-makes-a-positive-impact-on-communities-in-east-africa"},"tags":[{"_key":"AEPEpJXp","label":"Ethical AI","value":"Ethical AI"},{"_key":"tc6Hsfbm","label":"AI","value":"AI"},{"_key":"VmY4sBKG","label":"Impact","value":"Impact"},{"_key":"iLYfly0n","label":"Data Annotation","value":"Data Annotation"}],"title":"4 Ways AI Makes a Positive Impact on Communities in East Africa"},{"_createdAt":"2020-02-04T22:15:39Z","author":{"_id":"6dd25391-26af-42ff-a2a2-f0778ce1b002","avatar":{"_type":"image","asset":{"_ref":"image-4e1c47984bb16cb0370855b6272663d6744216d3-450x450-jpg","_type":"reference"}},"bio":"Currently a Senior Product Manager at Sama, Audrey guides cross-functional teams to create thoughtful product solutions. She has guided teams of designers and engineers at HUGE Inc. and NBCUniversal, and monitored user analytics at the Wall Street Journal. With a BA in history from Harvard, an MA in anthropology from Columbia and an MBA from UNC Chapel Hill KFBS, Audrey is passionate a using technology and data analytics facilitate social impact and environmental solutions through technology.","name":"Audrey Boguchwal","slug":{"_type":"slug","current":"audrey-boguchwal"}},"config":{"description":"During the REWORK Deep Learning Summit, Sama shared how top organizations obtain secure, high-quality training data, fighting AI bias in the process.","openGraphImage":null,"title":"Fighting AI Bias by Obtaining High-Quality Training Data"},"estimatedReadingTime":4,"featured_image":{"_type":"image","asset":{"_ref":"image-df3e88916d772584990f79eaa76fbbf00fb8c830-3872x2592-jpg","_type":"reference"}},"plaintextBody":"I recently presented a talk at the ReWork Deep Learning Summit titled, “Fighting AI Bias: How to Obtain Secure, High-Quality Training Data,\" but I think it’s equally important this knowledge is also shared outside of the summit.\n\nBias can make its way into your model at any stage of the training data lifecycle, potentially compromising the accuracy and performance of your algorithms. And as more organizations develop their own AI and ML programs, the necessity of superior quality data is even more pertinent.\n\nImpact of Biased Data in Computer Vision\n\nAI bias can creep in at any stage of the training data lifecycle, and bias presents itself most commonly in three categories: dataset bias, training bias and algorithmic bias.\n\nDataset bias is as you might expect—the data does not provide enough information for the model to learn the problem, or it’s unrepresentative of reality in some way. Training bias is the result of poor quality or inconsistent data labeling, and lastly, algorithmic bias occurs when the algorithm itself makes poor predictions or produces poor results.\n\nModels trained on biased data not only produce inaccurate algorithms, they also present ethical, legal and safety problems. And in some cases, biased data in computer vision can perpetuate historical, negative stereotypes across race and gender.\n\nLeft unchecked, algorithms trained on biased data greatly impact the lives of people using the very technologies meant to enhance their everyday experiences.\n\n\n\nCountering Bias in Training Data\n\nCountering bias in training data starts by having an effective training data strategy.\n\nLast year at Embedded Vision Summit, I presented a talk on practical training data strategies to avoid bias, sharing four ways to mitigate unwanted bias in training data. \n\nI want to echo my thoughts here that an effective training data strategy makes for a strong defense against AI bias. Fighting bias in training data means determining your data needs, developing training rules to cover known uses cases, and diversifying data to cover edge cases.\n\nAs your model learns, countering bias means evolving rules and sourcing more data when needed—all while keeping apprised of legal and ethical sourcing considerations.\n\nObtaining Superior Quality Datasets\n\nTop organizations understand that if they want smarter models, they need ethically sourced, quality data (https://www.samasource.com/quality-scale). Your quality requirements might vary, depending on your model, but the fact remains that diverse, high-quality data helps counter AI bias.\n\nFor over a decade, hundreds of organizations, including 25% of the Fortune 50 have relied on Samasource to deliver secure, high-quality training data and model validation for machine learning.\n\nWe’ve helped organizations like Walmart improve their retail item coverage, and others like Vulcan Inc., improve turnaround time to process training datasets. We’ve even partnered with organizations like Cornell Tech to produce an open-source dataset of our own. \n\nHere are a few things to keep in mind when sourcing superior quality datasets:\n\nBe aware of local privacy and property laws as you collect data.\n\nEnsure you have legal user consent for data capture.\n\nStay informed of the security protocols of facilities processing your training data.\n\nWhen possible, stay informed of the working conditions of the workers labeling your data, and support that pay living wages and benefits.\n\nFrom pilots to multi-year projects, Samasource securely trains and validates computer vision and NLP models. We work on a range of use cases ranging from e-commerce to autonomous transportation, manufacturing, navigation, retail, AR/VR, and biotech, and if your goal is to build smarter AI, contact our team to discuss your training data needs. ","slug":{"_type":"slug","current":"fighting-ai-bias-by-obtaining-high-quality-training-data"},"tags":[{"_key":"JOSMV7ei","label":"Events","value":"Events"},{"_key":"X1b43vej","label":"Training Data","value":"Training Data"},{"_key":"zoYY0bth","label":"Data Quality","value":"Data Quality"},{"_key":"8v2jDpFA","label":"AI Bias","value":"AI Bias"}],"title":"Fighting AI Bias by Obtaining High-Quality Training Data"},{"_createdAt":"2019-12-20T02:00:00Z","author":{"_id":"97dc2368-fffb-4c41-82aa-5a9cbe2ec670","avatar":{"_type":"image","asset":{"_ref":"image-af58425525bb33d8cffdc1f1b10f02bf1e4faf57-1916x2028-jpg","_type":"reference"}},"bio":"Sharon is the Content Marketing Manager at Sama where she's responsible for telling the story behind the company's impact sourcing mission and human-powered training data solutions. Sharon holds a MS in Integrated Marketing Communications and is passionate about helping social enterprises transform abstract concepts into results-driven marketing.","name":"Sharon L. Hadden","slug":{"_type":"slug","current":"sharon-l-hadden"}},"config":{"description":"In this interview, we chat with Head of AI at Samasource about AI trends to expect in 2020, as well as frequently asked questions about AI and machine learning.","openGraphImage":null,"title":"8 Answers to Your Questions About AI and Machine Learning"},"estimatedReadingTime":null,"featured_image":{"_type":"image","asset":{"_ref":"image-ade4117797bfbff2e90f48d6ad558ab992aca273-3423x2283-jpg","_type":"reference"}},"plaintextBody":null,"slug":null,"tags":[{"_key":"Y7bAcGrE","label":"Machine Learning","value":"Machine Learning"},{"_key":"qhgHNaG5","label":"AI","value":"AI"},{"_key":"0PqR2xB7","label":"Best of","value":"Best of"},{"_key":"NoohHt2W","label":"Sama Engineering","value":"Sama Engineering"}],"title":"8 Answers to Your Questions About AI and Machine Learning"},{"_createdAt":"2019-12-02T19:00:00Z","author":{"_id":"1a59f036-e3fe-4f02-9a34-688ce45de143","avatar":{"_type":"image","asset":{"_ref":"image-7d8f236ba010dd4927d0c5a93368bdce1f712843-390x390-webp","_type":"reference"}},"bio":"Currently a Project Manager at Sama, Taylor Rouleau has a passion for ensuring ethical and sustainable practices in tech. After 5 years leading production teams for our customers, Taylor's expertise is applied internally in our Project Management Office. She heads up efforts to maintain our industry-leading data training processes with a special focus on Security & Compliance.","name":"Taylor Rouleau","slug":{"_type":"slug","current":"taylor-rouleau"}},"config":{"description":"Samasource was proud to sponsor CodeJam 2019, an annual hackathon at McGill University, from November 15 - 17, 2019.","openGraphImage":null,"title":"Highlights from McGill CodeJam 2019"},"estimatedReadingTime":null,"featured_image":{"_type":"image","asset":{"_ref":"image-980fdc38382a1cc5d9c462b19141b595b5d9ea31-974x460-png","_type":"reference"}},"plaintextBody":null,"slug":null,"tags":[{"_key":"FYGgyErZ","label":"Sama Engineering","value":"Sama Engineering"},{"_key":"bymHQxr3","label":"Events","value":"Events"}],"title":"Highlights from McGill CodeJam 2019"},{"_createdAt":"2019-11-25T19:00:00Z","author":{"_id":"97dc2368-fffb-4c41-82aa-5a9cbe2ec670","avatar":{"_type":"image","asset":{"_ref":"image-af58425525bb33d8cffdc1f1b10f02bf1e4faf57-1916x2028-jpg","_type":"reference"}},"bio":"Sharon is the Content Marketing Manager at Sama where she's responsible for telling the story behind the company's impact sourcing mission and human-powered training data solutions. Sharon holds a MS in Integrated Marketing Communications and is passionate about helping social enterprises transform abstract concepts into results-driven marketing.","name":"Sharon L. Hadden","slug":{"_type":"slug","current":"sharon-l-hadden"}},"config":{"description":"In this interview, we chat with Taylor Rouleau, Project Manager at Sama on how Walmart Labs used AI to improve their retail item coverage.","openGraphImage":null,"title":"How Walmart Labs Used AI to Improve Retail Item Coverage"},"estimatedReadingTime":null,"featured_image":{"_type":"image","asset":{"_ref":"image-0dda25b386d198579da4a9acc6e67c0ec1dfb06f-1000x667-jpg","_type":"reference"}},"plaintextBody":null,"slug":null,"tags":[{"_key":"pujip4Jo","label":"Case Studies","value":"Case Studies"}],"title":"How Walmart Labs Used AI to Improve Retail Item Coverage"},{"_createdAt":"2019-11-19T19:00:00Z","author":{"_id":"a009d418-aa96-47ac-a73a-fd2cd52c79d9","avatar":{"_type":"image","asset":{"_ref":"image-e0d717f753ba4876a6b0dbf9f125cf6c3d27e545-500x500-webp","_type":"reference"}},"bio":"Wendy Gonzalez is an executive passionate about building high-performing, high-functioning teams that develop and scale innovative, impactful technology. With two decades of managerial and technology leadership experience for companies including EY, Capgemini, Cycle30 (acquired by Arrow Electronics) and General Communications Inc, Gonzalez is currently the CEO of Sama, the provider of accurate data for ambitious AI, used by leading technology companies such as Walmart, Google, Nvidia and Getty. Before taking on her role as CEO, Gonzalez spent 5 years at Sama as COO, and is an active Board Member of the Leila Janah Foundation.","name":"Wendy Gonzalez","slug":{"_type":"slug","current":"wendy-gonzalez"}},"config":{"description":"When we work with companies that want to use AI in e-commerce, we notice a few common barriers in AI adoption. Here are 4 reasons e-commerce needs AI to stay ahead.","openGraphImage":null,"title":"4 Compelling Reasons to Use AI in E-commerce"},"estimatedReadingTime":null,"featured_image":{"_type":"image","asset":{"_ref":"image-9cbf25ce2c598676fd52d23ab3fee8700b305c4a-500x333-jpg","_type":"reference"}},"plaintextBody":null,"slug":null,"tags":[{"_key":"DCGPNa4P","label":"AI","value":"AI"},{"_key":"KwAtlFPO","label":"Best of","value":"Best of"},{"_key":"1uBvx190","label":"Use Cases","value":"Use Cases"},{"_key":"Cryu3t8R","label":"E-Commerce","value":"E-Commerce"}],"title":"4 Compelling Reasons to Use AI in E-commerce"},{"_createdAt":"2019-11-08T19:30:00Z","author":{"_id":"26fb3cc4-608d-40e1-bb4d-955bceda232a","avatar":{"_type":"image","asset":{"_ref":"image-e0fe681e594567792ac79048513fe955cc770f54-518x518-svg","_type":"reference"}},"bio":"From self-driving cars to smart hardware, Sama fuels AI. Founded over a decade ago, we’re experts in image, video and sensor data annotation and validation for machine learning algorithms in industries including automotive, navigation, AR/VR, biotech, agriculture, manufacturing, and e-commerce. Our staff are driven by a mission to expand opportunity for low-income people through the digital economy, and our social business model has helped over 50,000 people lift themselves out of poverty.","name":"Sama Team","slug":{"_type":"slug","current":"sama-team"}},"config":{"description":"ICCV 2019 provided a welcoming platform for the distribution and discussion of scholarly and technical work in computer vision.","openGraphImage":null,"title":"3 Takeaways from ICCV 2019"},"estimatedReadingTime":null,"featured_image":{"_type":"image","asset":{"_ref":"image-c66363bf6c32d33afe6180066409aa883cde1821-1500x1000-jpg","_type":"reference"}},"plaintextBody":null,"slug":null,"tags":[{"_key":"y8AlUYn8","label":"Best of","value":"Best of"},{"_key":"67uTPs7c","label":"Events","value":"Events"}],"title":"3 Takeaways from ICCV 2019"},{"_createdAt":"2019-10-31T19:30:00Z","author":{"_id":"97dc2368-fffb-4c41-82aa-5a9cbe2ec670","avatar":{"_type":"image","asset":{"_ref":"image-af58425525bb33d8cffdc1f1b10f02bf1e4faf57-1916x2028-jpg","_type":"reference"}},"bio":"Sharon is the Content Marketing Manager at Sama where she's responsible for telling the story behind the company's impact sourcing mission and human-powered training data solutions. Sharon holds a MS in Integrated Marketing Communications and is passionate about helping social enterprises transform abstract concepts into results-driven marketing.","name":"Sharon L. Hadden","slug":{"_type":"slug","current":"sharon-l-hadden"}},"config":{"description":"Here's what Nike's use of AR in e-commerce means for the retail industry.","openGraphImage":null,"title":"What Nike's Use of AR in E-commerce Means for the Retail Industry"},"estimatedReadingTime":null,"featured_image":{"_type":"image","asset":{"_ref":"image-7ae53a5241d19127bbf145b4e4827d4d3c611117-1000x667-jpg","_type":"reference"}},"plaintextBody":null,"slug":null,"tags":[{"_key":"CRJq9YCS","label":"AI","value":"AI"},{"_key":"r7tObS22","label":"E-Commerce","value":"E-Commerce"},{"_key":"ERoPGwf6","label":"Retail","value":"Retail"},{"_key":"6vQAFdFK","label":"AR/VR","value":"AR/VR"}],"title":"What Nike's Use of AR in E-commerce Means for the Retail Industry"},{"_createdAt":"2019-10-24T22:00:00Z","author":{"_id":"97dc2368-fffb-4c41-82aa-5a9cbe2ec670","avatar":{"_type":"image","asset":{"_ref":"image-af58425525bb33d8cffdc1f1b10f02bf1e4faf57-1916x2028-jpg","_type":"reference"}},"bio":"Sharon is the Content Marketing Manager at Sama where she's responsible for telling the story behind the company's impact sourcing mission and human-powered training data solutions. Sharon holds a MS in Integrated Marketing Communications and is passionate about helping social enterprises transform abstract concepts into results-driven marketing.","name":"Sharon L. Hadden","slug":{"_type":"slug","current":"sharon-l-hadden"}},"config":{"description":"This list of computer vision insights shares how artificial intelligence is learning to understand and relate to the intensely visual world around us.","openGraphImage":null,"title":"Computer Vision Insights From Around the Web"},"estimatedReadingTime":null,"featured_image":{"_type":"image","asset":{"_ref":"image-31c1da1bdf3c6cd218e26d4f06a30f002ec18a8e-2000x1333-jpg","_type":"reference"}},"plaintextBody":null,"slug":null,"tags":[{"_key":"gRBnMPo9","label":"Machine Learning","value":"Machine Learning"},{"_key":"rxlxYiKX","label":"AI","value":"AI"},{"_key":"kT5jCNe2","label":"Best of","value":"Best of"},{"_key":"3o90fgFc","label":"Computer Vision","value":"Computer Vision"}],"title":"Computer Vision Insights From Around the Web"},{"_createdAt":"2019-09-26T23:30:00Z","author":{"_id":"26fb3cc4-608d-40e1-bb4d-955bceda232a","avatar":{"_type":"image","asset":{"_ref":"image-e0fe681e594567792ac79048513fe955cc770f54-518x518-svg","_type":"reference"}},"bio":"From self-driving cars to smart hardware, Sama fuels AI. Founded over a decade ago, we’re experts in image, video and sensor data annotation and validation for machine learning algorithms in industries including automotive, navigation, AR/VR, biotech, agriculture, manufacturing, and e-commerce. Our staff are driven by a mission to expand opportunity for low-income people through the digital economy, and our social business model has helped over 50,000 people lift themselves out of poverty.","name":"Sama Team","slug":{"_type":"slug","current":"sama-team"}},"config":{"description":"Here are a few things to consider, to strengthen your data security practices.","openGraphImage":null,"title":"4 Things That Make a Difference in Data Security"},"estimatedReadingTime":null,"featured_image":{"_type":"image","asset":{"_ref":"image-ea7e9958cf6957b59e16e49dcf1ec785eadbecff-5760x3840-jpg","_type":"reference"}},"plaintextBody":null,"slug":null,"tags":[{"_key":"PJHsWYQd","label":"AI","value":"AI"},{"_key":"n0lW8qhB","label":"Security & Trust","value":"Security & Trust"},{"_key":"hDx5GOGL","label":"Training Data","value":"Training Data"}],"title":"4 Things That Make a Difference in Data Security"},{"_createdAt":"2019-08-27T16:55:52Z","author":{"_id":"97dc2368-fffb-4c41-82aa-5a9cbe2ec670","avatar":{"_type":"image","asset":{"_ref":"image-af58425525bb33d8cffdc1f1b10f02bf1e4faf57-1916x2028-jpg","_type":"reference"}},"bio":"Sharon is the Content Marketing Manager at Sama where she's responsible for telling the story behind the company's impact sourcing mission and human-powered training data solutions. Sharon holds a MS in Integrated Marketing Communications and is passionate about helping social enterprises transform abstract concepts into results-driven marketing.","name":"Sharon L. Hadden","slug":{"_type":"slug","current":"sharon-l-hadden"}},"config":{"description":"Here are 6 TED talks on AI Ethics anyone working in artificial intelligence should watch.","openGraphImage":null,"title":"6 TED Talks to Watch on AI Ethics"},"estimatedReadingTime":null,"featured_image":{"_type":"image","asset":{"_ref":"image-732eda1d26d7e742d29a6898b03b98578f328aaf-1920x1280-jpg","_type":"reference"}},"plaintextBody":null,"slug":null,"tags":[{"_key":"W3DkGS5h","label":"Ethical AI","value":"Ethical AI"},{"_key":"ltDe5GIk","label":"Best of","value":"Best of"},{"_key":"TKGFOsI9","label":"Training Data","value":"Training Data"},{"_key":"L9htGs5b","label":"AI Bias","value":"AI Bias"}],"title":"6 TED Talks to Watch on AI Ethics"},{"_createdAt":"2019-08-20T21:30:00Z","author":{"_id":"97dc2368-fffb-4c41-82aa-5a9cbe2ec670","avatar":{"_type":"image","asset":{"_ref":"image-af58425525bb33d8cffdc1f1b10f02bf1e4faf57-1916x2028-jpg","_type":"reference"}},"bio":"Sharon is the Content Marketing Manager at Sama where she's responsible for telling the story behind the company's impact sourcing mission and human-powered training data solutions. Sharon holds a MS in Integrated Marketing Communications and is passionate about helping social enterprises transform abstract concepts into results-driven marketing.","name":"Sharon L. Hadden","slug":{"_type":"slug","current":"sharon-l-hadden"}},"config":{"description":"Data isnÃƒÂ¢Ã¢â€šÂ¬Ã¢â€žÂ¢t the only thing holding back artificial intelligence. Read more about some of the challenges and trends in AI.","openGraphImage":null,"title":"What's Holding Back Artificial Intelligence?"},"estimatedReadingTime":null,"featured_image":{"_type":"image","asset":{"_ref":"image-f0d61bc7762955f6affe83c5358b216c9fdc77e3-4836x3372-jpg","_type":"reference"}},"plaintextBody":null,"slug":null,"tags":[{"_key":"opg67GGB","label":"Machine Learning","value":"Machine Learning"},{"_key":"zbe0rrVL","label":"AI","value":"AI"},{"_key":"dV7VmzZT","label":"Best of","value":"Best of"}],"title":"What's Holding Back Artificial Intelligence?"},{"_createdAt":"2019-07-11T22:00:00Z","author":{"_id":"6dd25391-26af-42ff-a2a2-f0778ce1b002","avatar":{"_type":"image","asset":{"_ref":"image-4e1c47984bb16cb0370855b6272663d6744216d3-450x450-jpg","_type":"reference"}},"bio":"Currently a Senior Product Manager at Sama, Audrey guides cross-functional teams to create thoughtful product solutions. She has guided teams of designers and engineers at HUGE Inc. and NBCUniversal, and monitored user analytics at the Wall Street Journal. With a BA in history from Harvard, an MA in anthropology from Columbia and an MBA from UNC Chapel Hill KFBS, Audrey is passionate a using technology and data analytics facilitate social impact and environmental solutions through technology.","name":"Audrey Boguchwal","slug":{"_type":"slug","current":"audrey-boguchwal"}},"config":{"description":"Samasource's revamped toolset for 2D image vector segmentation is ideal for computer vision projects using vector shapes to structure training data.","openGraphImage":null,"title":"Revamped 2D Vector Segmentation"},"estimatedReadingTime":null,"featured_image":{"_type":"image","asset":{"_ref":"image-31269a4f01b8e495d1ec30a473f063a4957254c6-5760x3840-jpg","_type":"reference"}},"plaintextBody":null,"slug":null,"tags":[{"_key":"oc26gThR","label":"Product","value":"Product"},{"_key":"8Uhzi08N","label":"Vector Annotation","value":"Vector Annotation"},{"_key":"W46d0x8z","label":"Training Data","value":"Training Data"},{"_key":"NwhOkizM","label":"Data Annotation","value":"Data Annotation"},{"_key":"46Go0q8m","label":"Data Quality","value":"Data Quality"}],"title":"Revamped 2D Vector Segmentation"},{"_createdAt":"2019-07-01T21:45:00Z","author":{"_id":"80db3356-b402-44cb-a717-2e0f9c9fa3e4","avatar":{"_type":"image","asset":{"_ref":"image-399295e959574e371fe2ba7bfd55ba4aee8a589d-320x320-jpg","_type":"reference"}},"bio":"Heather is passionate about bringing world-changing technologies to market and using supply chain purchasing power for good. She is a data-driven strategist experienced in developing and leading go-to-market, communications, and sustainability initiatives at start-ups and multi-national organizations. Heather is most happy when she’s growing companies that make a positive impact, enjoying the outdoors, and spending time with her family.","name":"Heather Gadonniex","slug":{"_type":"slug","current":"heather-gadonniex"}},"config":{"description":"Most media coverage discuss bias, fairness, and ethical use of AI, but the humanitarian aspect of the AI supply chain is often overlooked.","openGraphImage":null,"title":"The Ethical AI Supply Chain: Protecting the Soul of AI"},"estimatedReadingTime":null,"featured_image":{"_type":"image","asset":{"_ref":"image-9da8ed5f9e247d160615efa55bcb38366df86d5a-3000x3000-jpg","_type":"reference"}},"plaintextBody":null,"slug":null,"tags":[{"_key":"5qTQ6zwl","label":"Ethical AI","value":"Ethical AI"},{"_key":"iRBewe3m","label":"AI","value":"AI"},{"_key":"29LDhGI9","label":"Impact","value":"Impact"},{"_key":"TkUkSBfs","label":"Leila Janah","value":"Leila Janah"}],"title":"The Ethical AI Supply Chain: Protecting the Soul of AI"},{"_createdAt":"2019-06-28T21:59:52Z","author":{"_id":"80db3356-b402-44cb-a717-2e0f9c9fa3e4","avatar":{"_type":"image","asset":{"_ref":"image-399295e959574e371fe2ba7bfd55ba4aee8a589d-320x320-jpg","_type":"reference"}},"bio":"Heather is passionate about bringing world-changing technologies to market and using supply chain purchasing power for good. She is a data-driven strategist experienced in developing and leading go-to-market, communications, and sustainability initiatives at start-ups and multi-national organizations. Heather is most happy when she’s growing companies that make a positive impact, enjoying the outdoors, and spending time with her family.","name":"Heather Gadonniex","slug":{"_type":"slug","current":"heather-gadonniex"}},"config":{"description":"From facial recognition to AR/VR, computer vision is changing the way we interact with the world around us. Here are some highlights from CVPR 2019.","openGraphImage":null,"title":"Highlights from CVPR 2019"},"estimatedReadingTime":null,"featured_image":{"_type":"image","asset":{"_ref":"image-d37fc7fdfe75a66d5f87a4ab2829f5f7c4030be8-4032x3024-jpg","_type":"reference"}},"plaintextBody":null,"slug":null,"tags":[{"_key":"9fySqjzW","label":"AI","value":"AI"},{"_key":"8IsWZFwF","label":"Events","value":"Events"},{"_key":"AlpYkFWc","label":"Computer Vision","value":"Computer Vision"}],"title":"Highlights from CVPR 2019"},{"_createdAt":"2019-06-18T17:23:05Z","author":{"_id":"97dc2368-fffb-4c41-82aa-5a9cbe2ec670","avatar":{"_type":"image","asset":{"_ref":"image-af58425525bb33d8cffdc1f1b10f02bf1e4faf57-1916x2028-jpg","_type":"reference"}},"bio":"Sharon is the Content Marketing Manager at Sama where she's responsible for telling the story behind the company's impact sourcing mission and human-powered training data solutions. Sharon holds a MS in Integrated Marketing Communications and is passionate about helping social enterprises transform abstract concepts into results-driven marketing.","name":"Sharon L. Hadden","slug":{"_type":"slug","current":"sharon-l-hadden"}},"config":{"description":"We've collected 6 computer vision infographics on everything from visual search to the history of computer vision from around the web.","openGraphImage":null,"title":"From Around the Web: 6 Computer Vision Infographics"},"estimatedReadingTime":null,"featured_image":{"_type":"image","asset":{"_ref":"image-6590ae389c492e7971eb49032f9d91cf34325811-2247x1500-jpg","_type":"reference"}},"plaintextBody":null,"slug":null,"tags":[{"_key":"bM4ZQ3e6","label":"Best of","value":"Best of"},{"_key":"lg4g7ftM","label":"Computer Vision","value":"Computer Vision"},{"_key":"8tkHMZla","label":"Infographic","value":"Infographic"}],"title":"From Around the Web: 6 Computer Vision Infographics"},{"_createdAt":"2019-06-12T20:00:00Z","author":{"_id":"97dc2368-fffb-4c41-82aa-5a9cbe2ec670","avatar":{"_type":"image","asset":{"_ref":"image-af58425525bb33d8cffdc1f1b10f02bf1e4faf57-1916x2028-jpg","_type":"reference"}},"bio":"Sharon is the Content Marketing Manager at Sama where she's responsible for telling the story behind the company's impact sourcing mission and human-powered training data solutions. Sharon holds a MS in Integrated Marketing Communications and is passionate about helping social enterprises transform abstract concepts into results-driven marketing.","name":"Sharon L. Hadden","slug":{"_type":"slug","current":"sharon-l-hadden"}},"config":{"description":"Here are 7 organizations attending CVPR 2019 who are leading the way in computer vision, plus 3 noteworthy companies from around the web.","openGraphImage":null,"title":"10 Organizations Leading the Way in Computer Vision"},"estimatedReadingTime":null,"featured_image":{"_type":"image","asset":{"_ref":"image-a49d2248810c7d2141277314bfa9b78a95c2a9a3-2250x1500-jpg","_type":"reference"}},"plaintextBody":null,"slug":null,"tags":[{"_key":"pm9yH2PJ","label":"Best of","value":"Best of"},{"_key":"YwMfUUBk","label":"Data Annotation","value":"Data Annotation"},{"_key":"NsG61NKf","label":"Computer Vision","value":"Computer Vision"}],"title":"10 Organizations Leading the Way in Computer Vision"},{"_createdAt":"2019-06-10T20:30:00Z","author":{"_id":"26fb3cc4-608d-40e1-bb4d-955bceda232a","avatar":{"_type":"image","asset":{"_ref":"image-e0fe681e594567792ac79048513fe955cc770f54-518x518-svg","_type":"reference"}},"bio":"From self-driving cars to smart hardware, Sama fuels AI. Founded over a decade ago, we’re experts in image, video and sensor data annotation and validation for machine learning algorithms in industries including automotive, navigation, AR/VR, biotech, agriculture, manufacturing, and e-commerce. Our staff are driven by a mission to expand opportunity for low-income people through the digital economy, and our social business model has helped over 50,000 people lift themselves out of poverty.","name":"Sama Team","slug":{"_type":"slug","current":"sama-team"}},"config":{"description":"The Sama Hackathon in Costa Rica encouraged 56 students to look for ways to use data science to help reduce poverty and income inequality.","openGraphImage":null,"title":"53 Students Use Data Science to Reduce Poverty and Income Inequality"},"estimatedReadingTime":null,"featured_image":{"_type":"image","asset":{"_ref":"image-b8d4bb8d54ed036603c03aa7803647dcd5b0709c-1500x1125-jpg","_type":"reference"}},"plaintextBody":null,"slug":null,"tags":[{"_key":"3Lg7mrMf","label":"Ethical AI","value":"Ethical AI"},{"_key":"WFav2zTI","label":"Events","value":"Events"},{"_key":"A0q55Xjf","label":"Impact","value":"Impact"}],"title":"53 Students Use Data Science to Reduce Poverty and Income Inequality"},{"_createdAt":"2019-06-07T20:00:00Z","author":{"_id":"97dc2368-fffb-4c41-82aa-5a9cbe2ec670","avatar":{"_type":"image","asset":{"_ref":"image-af58425525bb33d8cffdc1f1b10f02bf1e4faf57-1916x2028-jpg","_type":"reference"}},"bio":"Sharon is the Content Marketing Manager at Sama where she's responsible for telling the story behind the company's impact sourcing mission and human-powered training data solutions. Sharon holds a MS in Integrated Marketing Communications and is passionate about helping social enterprises transform abstract concepts into results-driven marketing.","name":"Sharon L. Hadden","slug":{"_type":"slug","current":"sharon-l-hadden"}},"config":{"description":"13 open source datasets for machine learning, including one dataset featured in the Fine-Grained Visual Categorization (FGVC) workshop at CVPR 2019.","openGraphImage":null,"title":"13 Open Source Datasets for Machine Learning"},"estimatedReadingTime":null,"featured_image":{"_type":"image","asset":{"_ref":"image-bbc3a22b57173b2dd2c6020fe7af40171efed6a9-2250x1500-jpg","_type":"reference"}},"plaintextBody":null,"slug":null,"tags":[{"_key":"h28cARez","label":"Machine Learning","value":"Machine Learning"},{"_key":"dDZvCu9M","label":"Best of","value":"Best of"},{"_key":"WAc2iHgu","label":"Events","value":"Events"},{"_key":"hPEDVzwV","label":"Open Datasets","value":"Open Datasets"}],"title":"13 Open Source Datasets for Machine Learning"},{"_createdAt":"2019-06-06T23:01:00Z","author":{"_id":"26fb3cc4-608d-40e1-bb4d-955bceda232a","avatar":{"_type":"image","asset":{"_ref":"image-e0fe681e594567792ac79048513fe955cc770f54-518x518-svg","_type":"reference"}},"bio":"From self-driving cars to smart hardware, Sama fuels AI. Founded over a decade ago, we’re experts in image, video and sensor data annotation and validation for machine learning algorithms in industries including automotive, navigation, AR/VR, biotech, agriculture, manufacturing, and e-commerce. Our staff are driven by a mission to expand opportunity for low-income people through the digital economy, and our social business model has helped over 50,000 people lift themselves out of poverty.","name":"Sama Team","slug":{"_type":"slug","current":"sama-team"}},"config":{"description":"Kirk Boydston, Training Data Specialist at Sama shares five considerations to move your machine learning model toward level 4 autonomous driving.","openGraphImage":null,"title":"Moving Toward Level 4 Autonomous Driving"},"estimatedReadingTime":null,"featured_image":{"_type":"image","asset":{"_ref":"image-ea7c2cbe6b2ae714f214ce5750d2f485e58d429e-2441x1500-jpg","_type":"reference"}},"plaintextBody":null,"slug":null,"tags":[{"_key":"3KIYoFV1","label":"Machine Learning","value":"Machine Learning"},{"_key":"bPng3xAl","label":"Training Data","value":"Training Data"},{"_key":"TRiIb7nw","label":"Data Quality","value":"Data Quality"},{"_key":"KO7eeuZJ","label":"Autonomous Transportation","value":"Autonomous Transportation"}],"title":"Moving Toward Level 4 Autonomous Driving"},{"_createdAt":"2019-06-06T02:48:23Z","author":{"_id":"97dc2368-fffb-4c41-82aa-5a9cbe2ec670","avatar":{"_type":"image","asset":{"_ref":"image-af58425525bb33d8cffdc1f1b10f02bf1e4faf57-1916x2028-jpg","_type":"reference"}},"bio":"Sharon is the Content Marketing Manager at Sama where she's responsible for telling the story behind the company's impact sourcing mission and human-powered training data solutions. Sharon holds a MS in Integrated Marketing Communications and is passionate about helping social enterprises transform abstract concepts into results-driven marketing.","name":"Sharon L. Hadden","slug":{"_type":"slug","current":"sharon-l-hadden"}},"config":{"description":"AI-enabled products come with their share of challenges. Here's how Vulcan partnered with Sama to use artificial intelligence for wildlife conservation.","openGraphImage":null,"title":"How Vulcan is Using AI for Wildlife Conservation"},"estimatedReadingTime":null,"featured_image":{"_type":"image","asset":{"_ref":"image-72a27932f674f6ebfb6d90744a43bead1069a121-2250x1500-jpg","_type":"reference"}},"plaintextBody":null,"slug":null,"tags":[{"_key":"GIh9aQR1","label":"Case Studies","value":"Case Studies"}],"title":"How Vulcan is Using AI for Wildlife Conservation"},{"_createdAt":"2019-06-05T14:21:10Z","author":{"_id":"6dd25391-26af-42ff-a2a2-f0778ce1b002","avatar":{"_type":"image","asset":{"_ref":"image-4e1c47984bb16cb0370855b6272663d6744216d3-450x450-jpg","_type":"reference"}},"bio":"Currently a Senior Product Manager at Sama, Audrey guides cross-functional teams to create thoughtful product solutions. She has guided teams of designers and engineers at HUGE Inc. and NBCUniversal, and monitored user analytics at the Wall Street Journal. With a BA in history from Harvard, an MA in anthropology from Columbia and an MBA from UNC Chapel Hill KFBS, Audrey is passionate a using technology and data analytics facilitate social impact and environmental solutions through technology.","name":"Audrey Boguchwal","slug":{"_type":"slug","current":"audrey-boguchwal"}},"config":{"description":"Samasource exhibited and presented at the venerable 2019 Embedded Vision Summit in Santa Clara, California.","openGraphImage":null,"title":"Highlights from the 2019 Embedded Vision Summit"},"estimatedReadingTime":null,"featured_image":{"_type":"image","asset":{"_ref":"image-1184784eeedb6464bcb4703dda418de157e6b21c-2250x1500-jpg","_type":"reference"}},"plaintextBody":null,"slug":null,"tags":[{"_key":"2Ur4O0La","label":"Best of","value":"Best of"},{"_key":"8FMbOtTY","label":"Events","value":"Events"}],"title":"Highlights from the 2019 Embedded Vision Summit"},{"_createdAt":"2019-05-29T20:30:00Z","author":{"_id":"a0737369-6ea9-40c1-a9cf-eb99927afadf","avatar":{"_type":"image","asset":{"_ref":"image-e7eabfb4112ca13a4f63e989039243ccde7396ff-3834x3447-jpg","_type":"reference"}},"bio":"Twisha is the Senior Impact Manager at Sama and oversees the end-to-end implementation of the global measurement and evaluation (M&E) system. A large part of her cross-functional work involves utilizing data to analyze the social impact of the business model and invest in innovative worker-centric initiatives.","name":"Twisha Mehta","slug":{"_type":"slug","current":"twisha-mehta"}},"config":{"description":"As a social business, we often face the dual challenge of generating social impact while balancing business needs. Learn how we're measuring impact right.","openGraphImage":null,"title":"Measuring Impact for a Social Enterprise"},"estimatedReadingTime":null,"featured_image":{"_type":"image","asset":{"_ref":"image-4135d710bc08353f4e6ef67905ad0f2dbcb73a54-5012x3432-jpg","_type":"reference"}},"plaintextBody":null,"slug":null,"tags":[{"_key":"fAZImpYg","label":"Ethical AI","value":"Ethical AI"},{"_key":"i7FgIhg1","label":"Impact","value":"Impact"}],"title":"Measuring Impact for a Social Enterprise"},{"_createdAt":"2019-05-20T18:30:00Z","author":{"_id":"6dd25391-26af-42ff-a2a2-f0778ce1b002","avatar":{"_type":"image","asset":{"_ref":"image-4e1c47984bb16cb0370855b6272663d6744216d3-450x450-jpg","_type":"reference"}},"bio":"Currently a Senior Product Manager at Sama, Audrey guides cross-functional teams to create thoughtful product solutions. She has guided teams of designers and engineers at HUGE Inc. and NBCUniversal, and monitored user analytics at the Wall Street Journal. With a BA in history from Harvard, an MA in anthropology from Columbia and an MBA from UNC Chapel Hill KFBS, Audrey is passionate a using technology and data analytics facilitate social impact and environmental solutions through technology.","name":"Audrey Boguchwal","slug":{"_type":"slug","current":"audrey-boguchwal"}},"config":{"description":"During Embedded Vision Summit 2019, Audrey Boguchwal will share four training data strategies that help AI teams avoid training data bias.","openGraphImage":null,"title":"4 Training Data Strategies to Avoid Bias"},"estimatedReadingTime":null,"featured_image":{"_type":"image","asset":{"_ref":"image-f9a4a7493982c6bf1be96e8260df8a98e4467b28-2250x1500-jpg","_type":"reference"}},"plaintextBody":null,"slug":null,"tags":[{"_key":"79xbZuT2","label":"Events","value":"Events"},{"_key":"hX284VAD","label":"Training Data","value":"Training Data"},{"_key":"VrBfZ9C5","label":"AI Bias","value":"AI Bias"}],"title":"4 Training Data Strategies to Avoid Bias"},{"_createdAt":"2018-12-14T19:54:00Z","author":{"_id":"71091c91-664a-44a6-9474-acc40eb12457","avatar":{"_type":"image","asset":{"_ref":"image-bc776336801adf71e2599337e8d6f02186b109d0-500x500-jpg","_type":"reference"}},"bio":"Matthew leads the product team at Sama, responsible for the platform that enables Sama's AI/ML data enrichment teams, internal enterprise operations tools to ensure quality and scalability, and all new product initiatives for the evolution of algorithm development and human-powered automation.","name":"Matthew Landry","slug":{"_type":"slug","current":"matthew-landry"}},"config":{"description":"Training your AI in 3D","openGraphImage":null,"title":"Training Your AI in 3D"},"estimatedReadingTime":null,"featured_image":{"_type":"image","asset":{"_ref":"image-9a175242c5b6d9d34ab8d001420280c4279ffe11-1125x1500-jpg","_type":"reference"}},"plaintextBody":null,"slug":null,"tags":[{"_key":"C3ND2OEf","label":"Product","value":"Product"},{"_key":"dJfUvcIY","label":"Training Data","value":"Training Data"},{"_key":"Se91A2Xp","label":"Data Annotation","value":"Data Annotation"}],"title":"Training Your AI in 3D"},{"_createdAt":"2018-09-08T19:40:00Z","author":{"_id":"26fb3cc4-608d-40e1-bb4d-955bceda232a","avatar":{"_type":"image","asset":{"_ref":"image-e0fe681e594567792ac79048513fe955cc770f54-518x518-svg","_type":"reference"}},"bio":"From self-driving cars to smart hardware, Sama fuels AI. Founded over a decade ago, we’re experts in image, video and sensor data annotation and validation for machine learning algorithms in industries including automotive, navigation, AR/VR, biotech, agriculture, manufacturing, and e-commerce. Our staff are driven by a mission to expand opportunity for low-income people through the digital economy, and our social business model has helped over 50,000 people lift themselves out of poverty.","name":"Sama Team","slug":{"_type":"slug","current":"sama-team"}},"config":{"description":"Coming AI events to attend September - October 2018","openGraphImage":null,"title":"AI Events to Attend in Fall of 2018"},"estimatedReadingTime":null,"featured_image":{"_type":"image","asset":{"_ref":"image-ed0c756ff646aae4c0602af5a501a53f5046d398-1500x1000-jpg","_type":"reference"}},"plaintextBody":null,"slug":null,"tags":[{"_key":"t34DnXsa","label":"AI","value":"AI"},{"_key":"m7M7ftb0","label":"Events","value":"Events"}],"title":"AI Events to Attend in Fall of 2018"},{"_createdAt":"2018-07-17T00:00:00Z","author":{"_id":"71091c91-664a-44a6-9474-acc40eb12457","avatar":{"_type":"image","asset":{"_ref":"image-bc776336801adf71e2599337e8d6f02186b109d0-500x500-jpg","_type":"reference"}},"bio":"Matthew leads the product team at Sama, responsible for the platform that enables Sama's AI/ML data enrichment teams, internal enterprise operations tools to ensure quality and scalability, and all new product initiatives for the evolution of algorithm development and human-powered automation.","name":"Matthew Landry","slug":{"_type":"slug","current":"matthew-landry"}},"config":{"description":"Announcing object tracking with video annotation","openGraphImage":null,"title":"Introducing Object Tracking with Video Annotation"},"estimatedReadingTime":null,"featured_image":{"_type":"image","asset":{"_ref":"image-af58edf394d9676203b9bc44284f08ccf52125a6-1000x1500-jpg","_type":"reference"}},"plaintextBody":null,"slug":null,"tags":[{"_key":"lFK49VoI","label":"Machine Learning","value":"Machine Learning"},{"_key":"uWZdY0Qc","label":"Product","value":"Product"},{"_key":"vbSgnXan","label":"Video Annotation","value":"Video Annotation"},{"_key":"NfB0x55k","label":"Data Annotation","value":"Data Annotation"}],"title":"Introducing Object Tracking with Video Annotation"},{"_createdAt":"2018-06-21T18:31:10Z","author":{"_id":"26fb3cc4-608d-40e1-bb4d-955bceda232a","avatar":{"_type":"image","asset":{"_ref":"image-e0fe681e594567792ac79048513fe955cc770f54-518x518-svg","_type":"reference"}},"bio":"From self-driving cars to smart hardware, Sama fuels AI. Founded over a decade ago, we’re experts in image, video and sensor data annotation and validation for machine learning algorithms in industries including automotive, navigation, AR/VR, biotech, agriculture, manufacturing, and e-commerce. Our staff are driven by a mission to expand opportunity for low-income people through the digital economy, and our social business model has helped over 50,000 people lift themselves out of poverty.","name":"Sama Team","slug":{"_type":"slug","current":"sama-team"}},"config":{"description":"Machine Learning 101: in this post, weÃƒÂ¢Ã¢â€šÂ¬Ã¢â€žÂ¢ll present a simple overview of machine learning and how it helps computers solve complex problems.","openGraphImage":null,"title":"Machine Learning 101"},"estimatedReadingTime":null,"featured_image":{"_type":"image","asset":{"_ref":"image-c664f546c6c09a66a670e1248bbb5b2b9055ae81-1500x1072-jpg","_type":"reference"}},"plaintextBody":null,"slug":null,"tags":[{"_key":"sD519oq6","label":"Machine Learning","value":"Machine Learning"},{"_key":"y63rBA8Q","label":"Best of","value":"Best of"},{"_key":"NDx7I7j8","label":"Training Data","value":"Training Data"}],"title":"Machine Learning 101"},{"_createdAt":"2018-05-18T17:00:00Z","author":{"_id":"73009228-1a1b-400d-b745-5fd85486dff0","avatar":{"_type":"image","asset":{"_ref":"image-e0fe681e594567792ac79048513fe955cc770f54-518x518-svg","_type":"reference"}},"bio":null,"name":"David Munene Gakuru","slug":{"_type":"slug","current":"david-munene-gakuru"}},"config":{"description":"Why ISO certification matters: Picking the right training data partner for your algorithm.","openGraphImage":null,"title":"Why ISO Certification Matters: Choosing the Right Training Data Partner"},"estimatedReadingTime":null,"featured_image":{"_type":"image","asset":{"_ref":"image-aae8da0891ca0f4d1128a15f20089c0e731872d0-1500x1000-jpg","_type":"reference"}},"plaintextBody":null,"slug":null,"tags":[{"_key":"olaOVXMP","label":"Security & Trust","value":"Security & Trust"},{"_key":"IDs9S3Ja","label":"Training Data","value":"Training Data"}],"title":"Why ISO Certification Matters: Choosing the Right Training Data Partner"},{"_createdAt":"2018-05-11T16:00:00Z","author":{"_id":"6dd25391-26af-42ff-a2a2-f0778ce1b002","avatar":{"_type":"image","asset":{"_ref":"image-4e1c47984bb16cb0370855b6272663d6744216d3-450x450-jpg","_type":"reference"}},"bio":"Currently a Senior Product Manager at Sama, Audrey guides cross-functional teams to create thoughtful product solutions. She has guided teams of designers and engineers at HUGE Inc. and NBCUniversal, and monitored user analytics at the Wall Street Journal. With a BA in history from Harvard, an MA in anthropology from Columbia and an MBA from UNC Chapel Hill KFBS, Audrey is passionate a using technology and data analytics facilitate social impact and environmental solutions through technology.","name":"Audrey Boguchwal","slug":{"_type":"slug","current":"audrey-boguchwal"}},"config":{"description":"We'll showcase how SamaÃƒÂ¢Ã¢â€šÂ¬Ã¢â€žÂ¢s web research and data cleaning services help create training data for Quid to build their NLP-powered data platform.","openGraphImage":null,"title":"How Quid Creates Reliable Business Intelligence"},"estimatedReadingTime":null,"featured_image":{"_type":"image","asset":{"_ref":"image-df12378ee9ac92007db6ab4b43e58310688aeb2a-1125x1500-jpg","_type":"reference"}},"plaintextBody":null,"slug":null,"tags":[{"_key":"1EAOekEr","label":"Case Studies","value":"Case Studies"}],"title":"How Quid Creates Reliable Business Intelligence"},{"_createdAt":"2018-03-30T22:32:27Z","author":{"_id":"26fb3cc4-608d-40e1-bb4d-955bceda232a","avatar":{"_type":"image","asset":{"_ref":"image-e0fe681e594567792ac79048513fe955cc770f54-518x518-svg","_type":"reference"}},"bio":"From self-driving cars to smart hardware, Sama fuels AI. Founded over a decade ago, we’re experts in image, video and sensor data annotation and validation for machine learning algorithms in industries including automotive, navigation, AR/VR, biotech, agriculture, manufacturing, and e-commerce. Our staff are driven by a mission to expand opportunity for low-income people through the digital economy, and our social business model has helped over 50,000 people lift themselves out of poverty.","name":"Sama Team","slug":{"_type":"slug","current":"sama-team"}},"config":{"description":"Data collection is a systematic strategy for gathering and measuring information from a variety of sources to get an accurate picture about a specific area of interest.","openGraphImage":null,"title":"What is Data Collection and Why Do You Care?"},"estimatedReadingTime":null,"featured_image":{"_type":"image","asset":{"_ref":"image-25260ecbc486f8d6c5ce3cbf310355c6b9c90532-1500x1000-jpg","_type":"reference"}},"plaintextBody":null,"slug":{"_type":"slug","current":"what-is-data-collection-and-why-do-you-care"},"tags":[{"_key":"E5C8tuMS","label":"Training Data","value":"Training Data"},{"_key":"nEjDa8yW","label":"Data Quality","value":"Data Quality"}],"title":"What is Data Collection and Why Do You Care?"},{"_createdAt":"2018-03-20T21:00:00Z","author":{"_id":"54800006-1861-42a5-a4bb-0aa2441aef30","avatar":{"_type":"image","asset":{"_ref":"image-ffd42fb1fe492d2a4a5421d537e379ee2ef7850b-299x299-jpg","_type":"reference"}},"bio":"Steve is a Senior Account Executive for Sama focusing on AI applications for the automotive industry.","name":"Steve Allen","slug":{"_type":"slug","current":"steve-allen"}},"config":{"description":"Steve Allen of Sama share's the key questions he gets asked about LiDAR and Point Cloud Annotation.","openGraphImage":null,"title":"What's the Latest with Lidar and Point Cloud Annotation?"},"estimatedReadingTime":null,"featured_image":{"_type":"image","asset":{"_ref":"image-200df2138bcc00249eacdf9d29fa4c78fc756b0a-844x1500-jpg","_type":"reference"}},"plaintextBody":null,"slug":null,"tags":[{"_key":"DAOlTUFZ","label":"Events","value":"Events"},{"_key":"8LUsgcYe","label":"Data Annotation","value":"Data Annotation"},{"_key":"CvHVKSNz","label":"LiDAR","value":"LiDAR"}],"title":"What's the Latest with Lidar and Point Cloud Annotation?"},{"_createdAt":"2018-03-15T18:31:04Z","author":{"_id":"71091c91-664a-44a6-9474-acc40eb12457","avatar":{"_type":"image","asset":{"_ref":"image-bc776336801adf71e2599337e8d6f02186b109d0-500x500-jpg","_type":"reference"}},"bio":"Matthew leads the product team at Sama, responsible for the platform that enables Sama's AI/ML data enrichment teams, internal enterprise operations tools to ensure quality and scalability, and all new product initiatives for the evolution of algorithm development and human-powered automation.","name":"Matthew Landry","slug":{"_type":"slug","current":"matthew-landry"}},"config":{"description":"Last week, Sama visited the Auto.AI event, which bills itself as the platform bringing together the stakeholders who play an active role in the deep driving, computer vision, and sensor fusion.","openGraphImage":null,"title":"Takeaways from AutoAI Conference 2018"},"estimatedReadingTime":null,"featured_image":{"_type":"image","asset":{"_ref":"image-9296abfc6dc641ff3c4469e7235289ee1aa70b58-1500x1000-jpg","_type":"reference"}},"plaintextBody":null,"slug":null,"tags":[{"_key":"2fZXZfik","label":"AI","value":"AI"},{"_key":"bS0jYOSG","label":"Events","value":"Events"},{"_key":"hKUrqBWv","label":"Autonomous Transportation","value":"Autonomous Transportation"}],"title":"Takeaways from AutoAI Conference 2018"},{"_createdAt":"2018-01-24T20:52:26Z","author":{"_id":"cc6094b6-cdfd-4509-b972-c1539888dcdf","avatar":{"_type":"image","asset":{"_ref":"image-e0fe681e594567792ac79048513fe955cc770f54-518x518-svg","_type":"reference"}},"bio":"Currently a Senior Account Executive at Sama, Marcelo works with enterprise clients in the high-tech space to help develop their AI strategies and get the most out of their training data. He has managed relationships with Fortune 500-level clients at numerous companies in various technology spaces - hardware, SaaS and services. Marcelo is driven by the goal of reducing global poverty through Sama’s social impact mission.","name":"Marcelo Benedetti","slug":{"_type":"slug","current":"marcelo-benedetti"}},"config":{"description":"With increased buzz around synthetic data, it is important to understand the advantages and limitations of this solution, and the overall affect on the application.","openGraphImage":null,"title":"The Advantages and Limitations of Synthetic Data"},"estimatedReadingTime":null,"featured_image":{"_type":"image","asset":{"_ref":"image-e6e7bab73442aa5bcd307816c3419505a7895093-1500x1500-jpg","_type":"reference"}},"plaintextBody":null,"slug":null,"tags":[{"_key":"VJ46fjrk","label":"Training Data","value":"Training Data"}],"title":"The Advantages and Limitations of Synthetic Data"},{"_createdAt":"2018-01-18T18:08:16Z","author":{"_id":"cc6094b6-cdfd-4509-b972-c1539888dcdf","avatar":{"_type":"image","asset":{"_ref":"image-e0fe681e594567792ac79048513fe955cc770f54-518x518-svg","_type":"reference"}},"bio":"Currently a Senior Account Executive at Sama, Marcelo works with enterprise clients in the high-tech space to help develop their AI strategies and get the most out of their training data. He has managed relationships with Fortune 500-level clients at numerous companies in various technology spaces - hardware, SaaS and services. Marcelo is driven by the goal of reducing global poverty through Sama’s social impact mission.","name":"Marcelo Benedetti","slug":{"_type":"slug","current":"marcelo-benedetti"}},"config":{"description":"Synthetic data is system-generated data that mimics real data in terms of essential parameters set by the user.","openGraphImage":null,"title":"What is Synthetic Data?"},"estimatedReadingTime":null,"featured_image":{"_type":"image","asset":{"_ref":"image-52e0da07c653ab82df020267a98b83d1893bf5f3-1500x1500-jpg","_type":"reference"}},"plaintextBody":null,"slug":null,"tags":[{"_key":"ON1ZQ2UR","label":"Training Data","value":"Training Data"}],"title":"What is Synthetic Data?"},{"_createdAt":"2017-12-18T20:37:13Z","author":{"_id":"ba12f1d5-b083-4eb7-929d-7e1639ef64c5","avatar":{"_type":"image","asset":{"_ref":"image-e0fe681e594567792ac79048513fe955cc770f54-518x518-svg","_type":"reference"}},"bio":"Daniele is a Sales Operations and Engineering Senior Manager for Sama working with teams in EMEA and APAC.","name":"Daniele Packard","slug":{"_type":"slug","current":"daniele-packard"}},"config":{"description":"The best way for a computer to gain knowledge is to start by showing it exactly what it is you want it to do. For this, we use training data.","openGraphImage":null,"title":"What is Training Data?"},"estimatedReadingTime":null,"featured_image":{"_type":"image","asset":{"_ref":"image-34e0689c14c9330dffeed72f7c6cbef59e2f9ad5-1500x1504-jpg","_type":"reference"}},"plaintextBody":null,"slug":null,"tags":[{"_key":"4Phssued","label":"Training Data","value":"Training Data"}],"title":"What is Training Data?"},{"_createdAt":"2017-05-24T21:33:56Z","author":{"_id":"6dd25391-26af-42ff-a2a2-f0778ce1b002","avatar":{"_type":"image","asset":{"_ref":"image-4e1c47984bb16cb0370855b6272663d6744216d3-450x450-jpg","_type":"reference"}},"bio":"Currently a Senior Product Manager at Sama, Audrey guides cross-functional teams to create thoughtful product solutions. She has guided teams of designers and engineers at HUGE Inc. and NBCUniversal, and monitored user analytics at the Wall Street Journal. With a BA in history from Harvard, an MA in anthropology from Columbia and an MBA from UNC Chapel Hill KFBS, Audrey is passionate a using technology and data analytics facilitate social impact and environmental solutions through technology.","name":"Audrey Boguchwal","slug":{"_type":"slug","current":"audrey-boguchwal"}},"config":{"description":"Better Algorithms, Better Lives: Reducing Poverty Through Training Data","openGraphImage":null,"title":"Better Algorithms, Better Lives: Reducing Poverty Through Training Data"},"estimatedReadingTime":null,"featured_image":"","plaintextBody":null,"slug":null,"tags":[{"_key":"Bx4Do9xK","label":"Ethical AI","value":"Ethical AI"},{"_key":"Rx6gXgmn","label":"Impact","value":"Impact"},{"_key":"iujrQUVj","label":"Use Cases","value":"Use Cases"},{"_key":"v5mZqxPX","label":"Data Annotation","value":"Data Annotation"}],"title":"Better Algorithms, Better Lives: Reducing Poverty Through Training Data"},{"_createdAt":"2017-05-15T23:51:58Z","author":{"_id":"6dd25391-26af-42ff-a2a2-f0778ce1b002","avatar":{"_type":"image","asset":{"_ref":"image-4e1c47984bb16cb0370855b6272663d6744216d3-450x450-jpg","_type":"reference"}},"bio":"Currently a Senior Product Manager at Sama, Audrey guides cross-functional teams to create thoughtful product solutions. She has guided teams of designers and engineers at HUGE Inc. and NBCUniversal, and monitored user analytics at the Wall Street Journal. With a BA in history from Harvard, an MA in anthropology from Columbia and an MBA from UNC Chapel Hill KFBS, Audrey is passionate a using technology and data analytics facilitate social impact and environmental solutions through technology.","name":"Audrey Boguchwal","slug":{"_type":"slug","current":"audrey-boguchwal"}},"config":{"description":"How exactly does Sama move people out of poverty?","openGraphImage":null,"title":"How Samasource Moves People Out of Poverty with Digital Work"},"estimatedReadingTime":null,"featured_image":{"_type":"image","asset":{"_ref":"image-bde2f64018e50b7615f188245cc00fe516e84936-693x462-jpg","_type":"reference"}},"plaintextBody":null,"slug":null,"tags":[{"_key":"Z2i2Xm9p","label":"Ethical AI","value":"Ethical AI"},{"_key":"NE08Dk4r","label":"Impact","value":"Impact"},{"_key":"mwOWz5qA","label":"Data Annotation","value":"Data Annotation"}],"title":"How Samasource Moves People Out of Poverty with Digital Work"},{"_createdAt":"2017-03-21T20:31:18Z","author":{"_id":"ba12f1d5-b083-4eb7-929d-7e1639ef64c5","avatar":{"_type":"image","asset":{"_ref":"image-e0fe681e594567792ac79048513fe955cc770f54-518x518-svg","_type":"reference"}},"bio":"Daniele is a Sales Operations and Engineering Senior Manager for Sama working with teams in EMEA and APAC.","name":"Daniele Packard","slug":{"_type":"slug","current":"daniele-packard"}},"config":{"description":"3 Computer Vision Applications You Haven't Heard Of... Yet","openGraphImage":null,"title":"3 Computer Vision Applications You Haven't Heard Of...Yet"},"estimatedReadingTime":null,"featured_image":{"_type":"image","asset":{"_ref":"image-e7af72154b4cdac45f8526a3934f9ac612e23d37-513x321-jpg","_type":"reference"}},"plaintextBody":null,"slug":null,"tags":[{"_key":"zGqHljfi","label":"AI","value":"AI"},{"_key":"QcKBgjbl","label":"Events","value":"Events"},{"_key":"mpmDlNYK","label":"Computer Vision","value":"Computer Vision"}],"title":"3 Computer Vision Applications You Haven't Heard Of...Yet"},{"_createdAt":"2016-09-21T18:56:59Z","author":{"_id":"88af0504-c0e4-4479-b961-0d74424c8aff","avatar":{"_type":"image","asset":{"_ref":"image-e0fe681e594567792ac79048513fe955cc770f54-518x518-svg","_type":"reference"}},"bio":null,"name":"Andrew Ho","slug":{"_type":"slug","current":"andrew-ho"}},"config":{"description":"Winning Customers with Algorithms:Ãƒâ€šÃ‚Â How Teams in Nairobi Help Shape Your Shopping Experience","openGraphImage":null,"title":"Winning Customers with Algorithms:Ãƒâ€šÃ‚Â How Teams in Nairobi Help Shape Your Shopping Experience"},"estimatedReadingTime":null,"featured_image":{"_type":"image","asset":{"_ref":"image-c5d3596e3d13a8462000fb2d564532cb99198bff-290x210-jpg","_type":"reference"}},"plaintextBody":null,"slug":null,"tags":[{"_key":"a60hER5C","label":"Training Data","value":"Training Data"},{"_key":"GJU9hmyY","label":"Data Annotation","value":"Data Annotation"},{"_key":"mMxaxwhQ","label":"Retail","value":"Retail"}],"title":"Winning Customers with Algorithms:Ãƒâ€šÃ‚Â How Teams in Nairobi Help Shape Your Shopping Experience"},{"_createdAt":"2016-01-26T21:48:00Z","author":{"_id":"037257b7-27fe-47e4-8b0b-7fc05f55fa6d","avatar":{"_type":"image","asset":{"_ref":"image-d3fb21c2ca35139da39b453c1981b5d04545ab51-800x800-webp","_type":"reference"}},"bio":null,"name":"Leila Janah","slug":{"_type":"slug","current":"leila-janah"}},"config":{"description":"Davos: It's Not Enough to do Less Bad (5 Tech and Impact Trends)","openGraphImage":null,"title":"Davos: It's Not Enough to Do Less Bad (5 Tech and Impact Trends)"},"estimatedReadingTime":null,"featured_image":{"_type":"image","asset":{"_ref":"image-37701649c15c883643f12a6b0a10ebb11dfdd4c3-5472x3648-jpg","_type":"reference"}},"plaintextBody":null,"slug":null,"tags":[{"_key":"XcKmjphM","label":"Ethical AI","value":"Ethical AI"},{"_key":"1tC6Pi0u","label":"Impact","value":"Impact"},{"_key":"X3YfCf7h","label":"Leila Janah","value":"Leila Janah"}],"title":"Davos: It's Not Enough to Do Less Bad (5 Tech and Impact Trends)"}],"pageConfig":{"title":"Sama Blog | Training Data, AI and Impact Sourcing Insights","description":"From machine learning to training data strategy, the Sama blog covers research, news and other AI trends from thought leaders across the globe."}},"__N_SSG":true}